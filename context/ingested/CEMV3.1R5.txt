 
Common Methodology 
for Information Technology 
Security Evaluation 
 
 
 
 
 
 
Evaluation methodology 
 
April 2017 
 
Version 3.1 
Revision 5 
 
 
 
CCMB-2017-04-004 

 
Page 2 of 430 Version 3.1 April 2017 
Foreword 
 
This version of the Common Methodology for Information Technology Security Evaluation 
(CEM v3.1) is the first major revision since being published as CEM v2.3 in 2005.  
 
CEM v3.1 aims to: eliminate redundant evaluation activities; reduce/eliminate activities that 
contribute little to the final assurance of a product; clarify CEM terminology to reduce 
misunderstanding; restructure and refocus the evaluation act ivities to those areas where 
security assurance is gained; and add new CEM requirements if needed. 
 
Trademarks: 
 UNIX is a registered trademark of The Open Group in the United States and other 
countries 
 Windows is a registered trademark of Microsoft Corpora tion in the United States 
and other countries 
 
 
April 2017 Version 3.1 Page 3 of 430 
Legal Notice: 
 
The governmental organisations listed below contributed to the development of this version 
of the Common Methodology for Information Technology Security Evaluation. As the joint 
holders of the copyright in the Common Methodology  for Information Technology Security 
Evaluation, version 3.1  (called “CEM 3.1”), they hereby grant non -exclusive license to 
ISO/IEC to use CEM 3.1 in the continued development/maintenance of the ISO/IEC 18045 
international standard. However, these governmental organisations retain the right to use, 
copy, distribute, translate or modify CEM  3.1 as they see fit. 
 
Australia: The Australian Signals Directorate; 
Canada: Communications Security Establishment; 
France: Agence Nationale de la Sécurité des Systèmes d'Information; 
Germany: Bundesamt für Sicherheit in der Informationstechnik; 
Japan: Information Technology Promotion Agency; 
Netherlands: Netherlands National Communications Security Agency; 
New Zealand: Government Communications Security Bureau; 
Republic of Korea: National Security Research Institute; 
Spain: Ministerio de Administraciones Públicas and  
 Centro Criptológico Nacional; 
Sweden: Swedish Defence Materiel Administration; 
United Kingdom: National Cyber Security Centre; 
United States: The National Security Agency and the 
 National Institute of Standards and Technology. 
Table of contents 
Page 4 of 430 Version 3.1 April 2017 
Table of Contents 
1 INTRODUCTION ............................................................................................. 12 
2 SCOPE ........................................................................................................... 13 
3 NORMATIVE REFERENCES ......................................................................... 14 
4 TERMS AND DEFINITIONS ........................................................................... 15 
5 SYMBOLS AND ABBREVIATED TERMS ..................................................... 17 
6 OVERVIEW ..................................................................................................... 18 
6.1 Organisation of the CEM ...................................................................................................................... 18 
7 DOCUMENT CONVENTIONS ........................................................................ 19 
7.1 Terminology ............................................................................................................................................ 19 
7.2 Verb usage .............................................................................................................................................. 19 
7.3 General evaluation guidance ................................................................................................................. 19 
7.4 Relationship between CC and CEM structures ................................................................................... 19 
8 EVALUATION PROCESS AND RELATED TASKS ....................................... 21 
8.1 Introduction ............................................................................................................................................ 21 
8.2 Evaluation process overview ................................................................................................................. 21 
8.2.1 Objectives ....................................................................................................................................... 21 
8.2.2 Responsibilities of the roles ............................................................................................................ 21 
8.2.3 Relationship of roles ....................................................................................................................... 22 
8.2.4 General evaluation model ............................................................................................................... 22 
8.2.5 Evaluator verdicts ........................................................................................................................... 23 
8.3 Evaluation input task ............................................................................................................................. 25 
8.3.1 Objectives ....................................................................................................................................... 25 
8.3.2 Application notes ............................................................................................................................ 25 
8.3.3 Management of evaluation evidence sub-task ................................................................................ 26 
8.4 Evaluation sub-activities ........................................................................................................................ 27 
8.5 Evaluation output task ........................................................................................................................... 27 
8.5.1 Objectives ....................................................................................................................................... 27 
8.5.2 Management of evaluation outputs ................................................................................................. 27 
8.5.3 Application notes ............................................................................................................................ 28 
8.5.4 Write OR sub-task .......................................................................................................................... 28 
8.5.5 Write ETR sub-task ........................................................................................................................ 28 
9 CLASS APE: PROTECTION PROFILE EVALUATION ................................. 36 
Table of contents 
April 2017 Version 3.1 Page 5 of 430 
9.1 Introduction ............................................................................................................................................ 36 
9.2 Application notes .................................................................................................................................... 36 
9.2.1 Re-using the evaluation results of certified PPs.............................................................................. 36 
9.3 PP introduction (APE_INT) .................................................................................................................. 37 
9.3.1 Evaluation of sub-activity (APE_INT.1) ........................................................................................ 37 
9.4 Conformance claims (APE_CCL) ......................................................................................................... 39 
9.4.1 Evaluation of sub-activity (APE_CCL.1) ....................................................................................... 39 
9.5 Security problem definition (APE_SPD) .............................................................................................. 48 
9.5.1 Evaluation of sub-activity (APE_SPD.1) ....................................................................................... 48 
9.6 Security objectives (APE_OBJ) ............................................................................................................ 50 
9.6.1 Evaluation of sub-activity (APE_OBJ.1) ........................................................................................ 50 
9.6.2 Evaluation of sub-activity (APE_OBJ.2) ........................................................................................ 50 
9.7 Extended components definition (APE_ECD) ..................................................................................... 54 
9.7.1 Evaluation of sub-activity (APE_ECD.1) ....................................................................................... 54 
9.8 Security requirements (APE_REQ) ...................................................................................................... 59 
9.8.1 Evaluation of sub-activity (APE_REQ.1) ....................................................................................... 59 
9.8.2 Evaluation of sub-activity (APE_REQ.2) ....................................................................................... 62 
10 CLASS ACE: PROTECTION PROFILE CONFIGURATION EVALUATION .. 68 
10.1 Introduction ....................................................................................................................................... 68 
10.2 PP-Module introduction (ACE_INT) .............................................................................................. 70 
10.2.1 Evaluation of sub-activity (ACE_INT.1) ........................................................................................ 70 
10.3 PP-Module conformance claims (ACE_CCL) ................................................................................ 71 
10.3.1 Evaluation of sub-activity (ACE_CCL.1) ....................................................................................... 71 
10.4 PP-Module Security problem definition (ACE_SPD) .................................................................... 73 
10.4.1 Evaluation of sub-activity (ACE_SPD.1) ....................................................................................... 73 
10.5 PP-Module Security objectives (ACE_OBJ) ................................................................................... 74 
10.5.1 Evaluation of sub-activity (ACE_OBJ.1) ....................................................................................... 74 
10.6 PP-Module extended components definition (ACE_ECD) ............................................................ 75 
10.6.1 Evaluation of sub-activity (ACE_ECD.1) ...................................................................................... 75 
10.7 PP-Module security requirements (ACE_REQ) ............................................................................. 76 
10.7.1 Evaluation of sub-activity (ACE_REQ.1) ...................................................................................... 76 
10.8 PP-Module consistency (ACE_MCO) .............................................................................................. 77 
10.8.1 Evaluation of sub-activity (ACE_MCO.1) ..................................................................................... 77 
10.9 PP-Configuration consistency (ACE_CCO) .................................................................................... 79 
10.9.1 Evaluation of sub-activity (ACE_CCO.1) ...................................................................................... 79 
11 CLASS ASE: SECURITY TARGET EVALUATION ....................................... 82 
11.1 Introduction ....................................................................................................................................... 82 
11.2 Application notes ............................................................................................................................... 82 
Table of contents 
Page 6 of 430 Version 3.1 April 2017 
11.2.1 Re-using the evaluation results of certified PPs ............................................................................. 82 
11.3 ST introduction (ASE_INT) ............................................................................................................. 83 
11.3.1 Evaluation of sub-activity (ASE_INT.1) ........................................................................................ 83 
11.4 Conformance claims (ASE_CCL) .................................................................................................... 87 
11.4.1 Evaluation of sub-activity (ASE_CCL.1) ....................................................................................... 87 
11.5 Security problem definition (ASE_SPD) ......................................................................................... 98 
11.5.1 Evaluation of sub-activity (ASE_SPD.1) ....................................................................................... 98 
11.6 Security objectives (ASE_OBJ) ...................................................................................................... 100 
11.6.1 Evaluation of sub-activity (ASE_OBJ.1)...................................................................................... 100 
11.6.2 Evaluation of sub-activity (ASE_OBJ.2)...................................................................................... 100 
11.7 Extended components definition (ASE_ECD) .............................................................................. 104 
11.7.1 Evaluation of sub-activity (ASE_ECD.1) ..................................................................................... 104 
11.8 Security requirements (ASE_REQ) ............................................................................................... 109 
11.8.1 Evaluation of sub-activity (ASE_REQ.1) ..................................................................................... 109 
11.8.2 Evaluation of sub-activity (ASE_REQ.2) ..................................................................................... 112 
11.9 TOE summary specification (ASE_TSS) ....................................................................................... 118 
11.9.1 Evaluation of sub-activity (ASE_TSS.1) ...................................................................................... 118 
11.9.2 Evaluation of sub-activity (ASE_TSS.2) ...................................................................................... 119 
12 CLASS ADV: DEVELOPMENT .................................................................... 121 
12.1 Introduction ..................................................................................................................................... 121 
12.2 Application notes ............................................................................................................................. 121 
12.3 Security Architecture (ADV_ARC) ............................................................................................... 123 
12.3.1 Evaluation of sub-activity (ADV_ARC.1) ................................................................................... 123 
12.4 Functional specification (ADV_FSP) ............................................................................................. 129 
12.4.1 Evaluation of sub-activity (ADV_FSP.1) ..................................................................................... 129 
12.4.2 Evaluation of sub-activity (ADV_FSP.2) ..................................................................................... 133 
12.4.3 Evaluation of sub-activity (ADV_FSP.3) ..................................................................................... 139 
12.4.4 Evaluation of sub-activity (ADV_FSP.4) ..................................................................................... 145 
12.4.5 Evaluation of sub-activity (ADV_FSP.5) ..................................................................................... 152 
12.4.6 Evaluation of sub-activity (ADV_FSP.6) ..................................................................................... 159 
12.5 Implementation representation (ADV_IMP) ................................................................................ 160 
12.5.1 Evaluation of sub-activity (ADV_IMP.1) .................................................................................... 160 
12.5.2 Evaluation of sub-activity (ADV_IMP.2) .................................................................................... 162 
12.6 TSF internals (ADV_INT) .............................................................................................................. 163 
12.6.1 Evaluation of sub-activity (ADV_INT.1) ..................................................................................... 163 
12.6.2 Evaluation of sub-activity (ADV_INT.2) ..................................................................................... 166 
12.6.3 Evaluation of sub-activity (ADV_INT.3) ..................................................................................... 168 
12.7 Security policy modelling (ADV_SPM) ......................................................................................... 169 
12.7.1 Evaluation of sub-activity (ADV_SPM.1) .................................................................................... 169 
12.8 TOE design (ADV_TDS) ................................................................................................................. 170 
12.8.1 Evaluation of sub-activity (ADV_TDS.1) .................................................................................... 170 
12.8.2 Evaluation of sub-activity (ADV_TDS.2) .................................................................................... 174 
12.8.3 Evaluation of sub-activity (ADV_TDS.3) .................................................................................... 180 
Table of contents 
April 2017 Version 3.1 Page 7 of 430 
12.8.4 Evaluation of sub-activity (ADV_TDS.4) .................................................................................... 192 
12.8.5 Evaluation of sub-activity (ADV_TDS.5) .................................................................................... 204 
12.8.6 Evaluation of sub-activity (ADV_TDS.6) .................................................................................... 204 
13 CLASS AGD: GUIDANCE DOCUMENTS .................................................... 205 
13.1 Introduction ..................................................................................................................................... 205 
13.2 Application notes ............................................................................................................................. 205 
13.3 Operational user guidance (AGD_OPE) ....................................................................................... 206 
13.3.1 Evaluation of sub-activity (AGD_OPE.1) .................................................................................... 206 
13.4 Preparative procedures (AGD_PRE) ............................................................................................ 210 
13.4.1 Evaluation of sub-activity (AGD_PRE.1) .................................................................................... 210 
14 CLASS ALC: LIFE-CYCLE SUPPORT ........................................................ 213 
14.1 Introduction ..................................................................................................................................... 213 
14.2 CM capabilities (ALC_CMC)......................................................................................................... 214 
14.2.1 Evaluation of sub-activity (ALC_CMC.1) ................................................................................... 214 
14.2.2 Evaluation of sub-activity (ALC_CMC.2) ................................................................................... 215 
14.2.3 Evaluation of sub-activity (ALC_CMC.3) ................................................................................... 217 
14.2.4 Evaluation of sub-activity (ALC_CMC.4) ................................................................................... 221 
14.2.5 Evaluation of sub-activity (ALC_CMC.5) ................................................................................... 228 
14.3 CM scope (ALC_CMS) ................................................................................................................... 237 
14.3.1 Evaluation of sub-activity (ALC_CMS.1) .................................................................................... 237 
14.3.2 Evaluation of sub-activity (ALC_CMS.2) .................................................................................... 237 
14.3.3 Evaluation of sub-activity (ALC_CMS.3) .................................................................................... 238 
14.3.4 Evaluation of sub-activity (ALC_CMS.4) .................................................................................... 239 
14.3.5 Evaluation of sub-activity (ALC_CMS.5) .................................................................................... 241 
14.4 Delivery (ALC_DEL) ...................................................................................................................... 243 
14.4.1 Evaluation of sub-activity (ALC_DEL.1) ..................................................................................... 243 
14.5 Development security (ALC_DVS) ................................................................................................ 245 
14.5.1 Evaluation of sub-activity (ALC_DVS.1) .................................................................................... 245 
14.5.2 Evaluation of sub-activity (ALC_DVS.2) .................................................................................... 248 
14.6 Flaw remediation (ALC_FLR) ....................................................................................................... 253 
14.6.1 Evaluation of sub-activity (ALC_FLR.1) ..................................................................................... 253 
14.6.2 Evaluation of sub-activity (ALC_FLR.2) ..................................................................................... 255 
14.6.3 Evaluation of sub-activity (ALC_FLR.3) ..................................................................................... 259 
14.7 Life-cycle definition (ALC_LCD) ................................................................................................... 266 
14.7.1 Evaluation of sub-activity (ALC_LCD.1) .................................................................................... 266 
14.7.2 Evaluation of sub-activity (ALC_LCD.2) .................................................................................... 267 
14.8 Tools and techniques (ALC_TAT) ................................................................................................. 270 
14.8.1 Evaluation of sub-activity (ALC_TAT.1) ..................................................................................... 270 
14.8.2 Evaluation of sub-activity (ALC_TAT.2) ..................................................................................... 272 
14.8.3 Evaluation of sub-activity (ALC_TAT.3) ..................................................................................... 275 
15 CLASS ATE: TESTS .................................................................................... 279 
Table of contents 
Page 8 of 430 Version 3.1 April 2017 
15.1 Introduction ..................................................................................................................................... 279 
15.2 Application notes ............................................................................................................................. 279 
15.2.1 Understanding the expected behaviour of the TOE ...................................................................... 280 
15.2.2 Testing vs. alternate approaches to verify the expected behaviour of functionality  ..................... 280 
15.2.3 Verifying the adequacy of tests .................................................................................................... 281 
15.3 Coverage (ATE_COV) .................................................................................................................... 282 
15.3.1 Evaluation of sub-activity (ATE_COV.1) .................................................................................... 282 
15.3.2 Evaluation of sub-activity (ATE_COV.2) .................................................................................... 283 
15.3.3 Evaluation of sub-activity (ATE_COV.3) .................................................................................... 284 
15.4 Depth (ATE_DPT) ........................................................................................................................... 285 
15.4.1 Evaluation of sub-activity (ATE_DPT.1) ..................................................................................... 285 
15.4.2 Evaluation of sub-activity (ATE_DPT.2) ..................................................................................... 288 
15.4.3 Evaluation of sub-activity (ATE_DPT.3) ..................................................................................... 291 
15.4.4 Evaluation of sub-activity (ATE_DPT.4) ..................................................................................... 294 
15.5 Functional tests (ATE_FUN) .......................................................................................................... 295 
15.5.1 Evaluation of sub-activity (ATE_FUN.1) .................................................................................... 295 
15.5.2 Evaluation of sub-activity (ATE_FUN.2) .................................................................................... 298 
15.6 Independent testing (ATE_IND) .................................................................................................... 299 
15.6.1 Evaluation of sub-activity (ATE_IND.1) ..................................................................................... 299 
15.6.2 Evaluation of sub-activity (ATE_IND.2) ..................................................................................... 304 
15.6.3 Evaluation of sub-activity (ATE_IND.3) ..................................................................................... 310 
16 CLASS AVA: VULNERABILITY ASSESSMENT ......................................... 311 
16.1 Introduction ..................................................................................................................................... 311 
16.2 Vulnerability analysis (AVA_VAN) ............................................................................................... 312 
16.2.1 Evaluation of sub-activity (AVA_VAN.1) ................................................................................... 312 
16.2.2 Evaluation of sub-activity (AVA_VAN.2) ................................................................................... 318 
16.2.3 Evaluation of sub-activity (AVA_VAN.3) ................................................................................... 326 
16.2.4 Evaluation of sub-activity (AVA_VAN.4) ................................................................................... 337 
16.2.5 Evaluation of sub-activity (AVA_VAN.5) ................................................................................... 346 
17 CLASS ACO: COMPOSITION ..................................................................... 347 
17.1 Introduction ..................................................................................................................................... 347 
17.2 Application notes ............................................................................................................................. 347 
17.3 Composition rationale (ACO_COR) .............................................................................................. 349 
17.3.1 Evaluation of sub-activity (ACO_COR.1) .................................................................................... 349 
17.4 Development evidence (ACO_DEV) .............................................................................................. 357 
17.4.1 Evaluation of sub-activity (ACO_DEV.1) .................................................................................... 357 
17.4.2 Evaluation of sub-activity (ACO_DEV.2) .................................................................................... 358 
17.4.3 Evaluation of sub-activity (ACO_DEV.3) .................................................................................... 360 
17.5 Reliance of dependent component (ACO_REL) ........................................................................... 364 
17.5.1 Evaluation of sub-activity (ACO_REL.1) .................................................................................... 364 
17.5.2 Evaluation of sub-activity (ACO_REL.2) .................................................................................... 366 
17.6 Composed TOE testing (ACO_CTT) ............................................................................................. 370 
17.6.1 Evaluation of sub-activity (ACO_CTT.1) .................................................................................... 370 
Table of contents 
April 2017 Version 3.1 Page 9 of 430 
17.6.2 Evaluation of sub-activity (ACO_CTT.2) .................................................................................... 373 
17.7 Composition vulnerability analysis (ACO_VUL) ......................................................................... 377 
17.7.1 Evaluation of sub-activity (ACO_VUL.1) .................................................................................... 377 
17.7.2 Evaluation of sub-activity (ACO_VUL.2) .................................................................................... 380 
17.7.3 Evaluation of sub-activity (ACO_VUL.3) .................................................................................... 385 
A GENERAL EVALUATION GUIDANCE ........................................................ 390 
A.1 Objectives ......................................................................................................................................... 390 
A.2 Sampling ........................................................................................................................................... 390 
A.3 Dependencies .................................................................................................................................... 392 
A.3.1 Dependencies between activities .................................................................................................. 393 
A.3.2 Dependencies between sub-activities ........................................................................................... 393 
A.3.3 Dependencies between actions ..................................................................................................... 393 
A.4 Site Visits .......................................................................................................................................... 394 
A.4.1 Introduction .................................................................................................................................. 394 
A.4.2 General Approach ......................................................................................................................... 394 
A.4.3 Orientation Guide for the Preparation of the Check List .............................................................. 395 
A.4.4 Example of a checklist .................................................................................................................. 397 
A.5 Scheme Responsibilities .................................................................................................................. 400 
B VULNERABILITY ASSESSMENT (AVA) ..................................................... 402 
B.1 What is Vulnerability Analysis ....................................................................................................... 402 
B.2 Evaluator construction of a Vulnerability Analysis ..................................................................... 403 
B.2.1 Generic vulnerability guidance ..................................................................................................... 403 
B.2.2 Identification of Potential Vulnerabilities ..................................................................................... 413 
B.3 When attack potential is used ......................................................................................................... 417 
B.3.1 Developer...................................................................................................................................... 417 
B.3.2 Evaluator ....................................................................................................................................... 417 
B.4 Calculating attack potential ............................................................................................................ 419 
B.4.1 Application of attack potential ...................................................................................................... 419 
B.4.2 Characterising attack potential ...................................................................................................... 420 
B.5 Example calculation for direct attack ............................................................................................ 429 
 
List of figures 
Page 10 of 430 Version 3.1 April 2017 
List of figures 
 
Figure 1 - Mapping of the CC and CEM structures .............................................................. 20 
Figure 2 - Generic evaluation model .................................................................................... 23 
Figure 3 - Example of the verdict assignment rule ............................................................... 24 
Figure 4 - ETR information content for a PP evaluation ...................................................... 29 
Figure 5 - ETR information content for a TOE evaluation ................................................... 32 
Figure 6 - Evaluation of a PP-Configuration ........................................................................ 69 
 
List of tables 
April 2017 Version 3.1 Page 11 of 430 
List of tables 
 
Table 1  Example of a checklist at EAL 4 (extract) ............................................................ 398 
Table 2 Vulnerability testing and attack potential ............................................................... 418 
Table 3 Calculation of attack potential ................................................................................ 426 
Table 4 Rating of vulnerabilities and TOE resistance ......................................................... 428 
 
Introduction 
Page 12 of 430 Version 3.1 April 2017 
1 Introduction 
1 The target audience for the Common Methodology for Information 
Technology Security Evaluation (CEM) is primarily evaluators applying the 
CC and certifiers confirming evaluator actions; evaluation sponsors, 
developers, PP/ST authors and other parties inter ested in IT security may be 
a secondary audience. 
2 The CEM recognises that not all questions concerning IT security evaluation 
will be answered herein and that further interpretations will be needed. 
Individual schemes will determine how to handle such inte rpretations, 
although these may be subject to mutual recognition agreements. A list of 
methodology-related activities that may be handled by individual schemes 
can be found in Annex A. 
Scope 
April 2017 Version 3.1 Page 13 of 430 
2 Scope 
3 The Common Methodology for Information Technology Security Evaluation 
(CEM) is a companion document to the Common Criteria for Information 
Technology Security Evaluation (CC). The CEM defines the minimum 
actions to be performed by an evaluator in order to conduct a CC evaluation, 
using the criteria and evaluation evidence defined in the CC. 
4 The CEM does not define evaluator actions for certain high assurance CC 
components, where there is as yet no generally agreed guidance. 
Normative references 
Page 14 of 430 Version 3.1 April 2017 
3 Normative references 
5 The following referenced documents are indispen sable for the application of 
this document. For dated references, only the edition cited applies. For 
undated references, the latest edition of the referenced document (including 
any amendments) applies. 
[CC] Common Criteria for Information Technology 
Security Evaluation, Version 3.1, revision 5, April 
2017.  
Terms and definitions 
April 2017 Version 3.1 Page 15 of 430 
4 Terms and definitions 
6 For the purposes of this document, the following terms and definitions apply. 
7 Terms which are presented in bold -faced type are themselves defined in this 
Section. 
8 action  evaluator action element of the CC Part 3  
These actions are either explicitly stated as evaluator actions or implicitly 
derived from developer actions (implied evaluator actions) within the CC 
Part 3 assurance components.  
9 activity  application of an assurance class of the CC Part 3  
10 check  generate a verdict by a simple comparison  
Evaluator expertise is not required. The statement that uses this verb 
describes what is mapped.  
11 evaluation deliverable  any resource required from the sponsor or 
developer by th e evaluator or evaluation authority to perform one or more 
evaluation or evaluation oversight activities  
12 evaluation evidence  tangible evaluation deliverable 
13 evaluation technical report  report that documents the overall verdict  
and its justification, p roduced by the evaluator and submitted to an 
evaluation authority 
14 examine  generate a verdict by analysis using evaluator expertise  
The statement that uses this verb identifies what is analysed and the 
properties for which it is analysed.  
15 interpretation  clarification or amplification of a CC, CEM or scheme 
requirement 
16 methodology  system of principles, procedures and processes applied to 
IT security evaluations  
17 observation report  report written by the evaluator requesting a 
clarification or identifying a problem during the evaluation  
18 overall verdict  pass or fail statement issued by an evaluator with respect 
to the result of an evaluation  
19 oversight verdict  statement issued by an evaluation authority confirming 
or rejecting an overall verdict  based on the results of evaluation oversight 
activities  
Terms and definitions 
Page 16 of 430 Version 3.1 April 2017 
20 record  retain a written description of procedures, events, observations, 
insights and results in sufficient detail to enable the work performed during 
the evaluation to be reconstructed at a later time  
21 report  include evaluation results and supporting material in the 
Evaluation Technical Report or an Observation Report 
22 scheme  set of rules, established by an evaluation authority, defining the 
evaluation environment, including criteria and methodology required to 
conduct IT security evaluations  
23 sub-activity  application of an assurance component of the CC Part 3  
Assurance families are not explicitly addressed in the CEM because 
evaluations are conducted on a single assurance component from an 
assurance family.  
24 tracing  simple directional relation between two sets of entities, which 
shows which entities in the first set correspond to which entities in the 
second  
25 verdict  pass, fail or inconclusive  statement issued by an evaluator with 
respect to a CC evaluator action element, assurance component, or class  
Also see overall verdict.  
26 work unit  most granular level of evaluation work  
Each CEM action comprises one or more work units, which are grouped 
within the CEM action by CC content and presen tation of evidence or 
developer action element. The work units are presented in the CEM in the 
same order as the CC elements from which they are derived. Work units are 
identified in the left margin by a symbol such as ALC_TAT.1-2. I n this 
symbol, the string ALC_TAT.1 indicates the CC component (i.e. the CEM 
sub-activity), and the final digit (2) indicates that this is the second work unit 
in the ALC_TAT.1 sub-activity.  
Symbols and abbreviated terms 
April 2017 Version 3.1 Page 17 of 430 
5 Symbols and abbreviated terms 
CEM Common Methodology for Information Technology 
Security Evaluation  
ETR Evaluation Technical Report  
OR Observation Report  
Overview 
Page 18 of 430 Version 3.1 April 2017 
6 Overview 
6.1 Organisation of the CEM 
27 Chapter 7 defines the conventions used in the CEM. 
28 Chapter 8 describes general evaluation tasks with no verdicts associated with 
them as they do not map to CC evaluator action elements. 
29 Chapter 9 addresses the work necessary for reachi ng an evaluation result on 
a PP. 
30 Chapters 11 to 17 define the evaluation activities, organised by Assurance 
Classes. 
31 Annex A covers the basic evaluation techniques used to provide technical 
evidence of evaluation results. 
32 Annex B provides an explanation of the Vulnerability Analysis criteria and 
examples of their application. 
Document Conventions 
April 2017 Version 3.1 Page 19 of 430 
7 Document Conventions 
7.1 Terminology 
33 Unlike the CC, where each element maintains the last digit of its identifying 
symbol for all components within the family, the CEM may introduce new 
work units when a CC evaluator action element changes from sub -activity to 
sub-activity; as a result, the last digit of the work unit's identifying symbol 
may change although the work unit remains unchanged. 
34 Any methodology -specific evaluation work required that is not derived 
directly from CC requirements is termed task or sub-task. 
7.2 Verb usage 
35 All work unit and sub-task verbs are preceded by the auxiliary verb shall and 
by p resenting both the verb and the shall in bold italic  type face. The 
auxiliary verb shall is used only when the provided text is mandatory and 
therefore only within the work units and sub -tasks. The work units and sub -
tasks contain mandatory activities that the evaluator must perform in order to 
assign verdicts. 
36 Guidance text accompanying work units and sub -tasks gives further 
explanation on how to apply the CC words in an evaluation. The verb usage 
is in accordance with ISO definitions for these verbs. The auxiliary verb 
should is used when the described method is strongly preferred. All other 
auxiliary verbs, including may, are used where the described method(s) is 
allowed but is neither recommended nor strongly preferred; it is merely 
explanation. 
37 The verbs check, examine, report and record are used with a precise meaning 
within this part of the CEM and the Chapter 4 should be referenced for their 
definitions. 
7.3 General evaluation guidance 
38 Material that has applicability to more than one sub -activity is collected in 
one place. Guidance whose applicability is widespread (across activities and 
EALs) has been collected into Annex A. Guidance that pertains to multiple 
sub-activities within a single activity has been provided in the introduction to 
that activity. If guidance pertains to only a single sub -activity, it is presented 
within that sub-activity. 
7.4 Relationship between CC and CEM structures 
39 There are direct relationships between the CC structure (i.e. class, family, 
component and element) and the structure of the CEM. Figure 1 illustrates 
the correspondence between the CC constructs of class, family and evaluator 
action elements and CEM activities, sub -activities and act ions. However, 
Document Conventions 
Page 20 of 430 Version 3.1 April 2017 
several CEM work units may result from the requirements noted in CC 
developer action and content and presentation elements. 
 
Figure 1 - Mapping of the CC and CEM structures 
Evaluation process and related tasks 
April 2017 Version 3.1 Page 21 of 430 
8 Evaluation process and related tasks 
8.1 Introduction 
40 This chapter provides an overview of the evaluation process and defines the 
tasks an evaluator is intended to perform when conducting an evaluation. 
41 Each evaluation, whether of a PP or TOE (including ST), follows the same 
process, and has four eva luator tasks in common: the input task, the output 
task, the evaluation sub -activities, and the demonstration of the technical 
competence to the evaluation authority task. 
42 The input task and the output tasks, which are related to management of 
evaluation e vidence and to report generation, are entirely described in this 
chapter. Each task has associated sub -tasks that apply to, and are normative 
for all CC evaluations (evaluation of a PP or a TOE). 
43 The evaluation sub -activities are only introduced in this ch apter, and fully 
described in the following chapters. 
44 In contrast to the evaluation sub -activities, input and output tasks have no 
verdicts associated with them as they do not map to CC evaluator action 
elements; they are performed in order to ensure confo rmance with the 
universal principles and to comply with the CEM. 
45 The demonstration of the technical competence to the evaluation authority 
task may be fulfilled by the evaluation authority analysis of the output tasks 
results, or may include the demonstrat ion by the evaluators of their 
understanding of the inputs for the evaluation sub -activities. This task has no 
associated evaluator verdict, but has an evaluator authority verdict. The 
detailed criteria to pass this task are left to the discretion of the e valuation 
authority, as noted in Annex A.5. 
8.2 Evaluation process overview 
8.2.1 Objectives 
46 This section presents the general model of the methodology and identifies:  
a) roles and responsibilities of the parties involved in the e valuation 
process;  
b) the general evaluation model.  
8.2.2 Responsibilities of the roles 
47 The general model defines the following roles: sponsor, developer, evaluator 
and evaluation authority. 
Evaluation process and related tasks 
Page 22 of 430 Version 3.1 April 2017 
48 The sponsor is responsible for requesting and supporting an evaluation. This 
means that the sponsor establishes the different agreements for the evaluation 
(e.g. commissioning the evaluation). Moreover, the sponsor is responsible 
for ensuring that the evaluator is provided with the evaluation evidence. 
49 The developer produces t he TOE and is responsible for providing the 
evidence required for the evaluation (e.g. training, design information), on 
behalf of the sponsor. 
50 The evaluator performs the evaluation tasks required in the context of an 
evaluation: the evaluator receives the evaluation evidence from the developer 
on behalf of the sponsor or directly from the sponsor, performs the 
evaluation sub -activities and provides the results of the evaluation 
assessment to the evaluation authority. 
51 The evaluation authority establishes an d maintains the scheme, monitors the 
evaluation conducted by the evaluator, and issues certification/validation 
reports as well as certificates based on the evaluation results provided by the 
evaluator. 
8.2.3 Relationship of roles 
52 To prevent undue influence from  improperly affecting an evaluation, some 
separation of roles is required. This implies that the roles described above are 
fulfilled by different entities, except that the roles of developer and sponsor 
may be satisfied by a single entity. 
53 Moreover, some e valuations (e.g. EAL1 evaluation) may not require the 
developer to be involved in the project. In this case, it is the sponsor who 
provides the TOE to the evaluator and who generates the evaluation evidence. 
8.2.4 General evaluation model 
54 The evaluation process consists of the evaluator performing the evaluation 
input task, the evaluation output task and the evaluation sub-activities. Figure 
2 provides an overview of the relationship between these tasks and sub -
activities. 
Evaluation process and related tasks 
April 2017 Version 3.1 Page 23 of 430 
 
Figure 2 - Generic evaluation model 
55 The evaluation process may be preceded by a preparation phase where initial 
contact is made between the sponsor and the evaluator. The work that is 
performed and the involvement of the different roles during  this phase may 
vary. It is typically during this step that the evaluator performs a feasibility 
analysis to assess the likelihood of a successful evaluation. 
8.2.5 Evaluator verdicts 
56 The evaluator assigns verdicts to the requirements of the CC and not to those 
of the CEM. The most granular CC structure to which a verdict is assigned is 
the evaluator action element (explicit or implied). A verdict is assigned to an 
applicable CC evaluator action element as a result of performing the 
corresponding CEM action and i ts constituent work units. Finally, an 
evaluation result is assigned, as described in CC Part 1, Chapter 10, 
Evaluation results. 
Evaluation process and related tasks 
Page 24 of 430 Version 3.1 April 2017 
 
Figure 3 - Example of the verdict assignment rule 
57 The CEM recognises three mutually exclusive verdict states:  
a) Conditions for a pass verdict are defined as an evaluator completion 
of the CC evaluator action element and determination that the 
requirements for the PP, ST or TOE under evaluation are met. The 
conditions for passing the element are defined as:  
1) the constituent work units of the related CEM action, and;  
2) all evaluation evidence required for performing these work 
units is coherent, that is it can be fully and completely 
understood by the evaluator, and  
3) all evaluati on evidence required for performing these work 
units does not have any obvious internal inconsistencies or 
inconsistencies with other evaluation evidence. Note that 
obvious means here that the evaluator discovers this 
inconsistency while performing the wor k units: the evaluator 
should not undertake a full consistency analysis across the 
entire evaluation evidence every time a work unit is 
performed.  
b) Conditions for a fail verdict are defined as an evaluator completion of 
the CC evaluator action element and determination that the 
requirements for the PP, ST, or TOE under evaluation are not met, or 
Evaluation process and related tasks 
April 2017 Version 3.1 Page 25 of 430 
that the evidence is incoherent, or an obvious inconsistency in the 
evaluation evidence has been found;  
c) All verdicts are initially inconclusive and remain so until either a pass 
or fail verdict is assigned.  
58 The overall verdict is pass if and only if all the constituent verdicts are also 
pass. In the example illustrated in Figure 3, if the verdict for one evaluator 
action element is fail then the verdicts for the corresponding assurance 
component, assurance class, and overall verdict are also fail. 
8.3 Evaluation input task 
8.3.1 Objectives 
59 The objective of this task is to ensure that the evaluator has available the 
correct version of the evaluation evid ence necessary for the evaluation and 
that it is adequately protected. Otherwise, the technical accuracy of the 
evaluation cannot be assured, nor can it be assured that the evaluation is 
being conducted in a way to provide repeatable and reproducible results. 
8.3.2 Application notes 
60 The responsibility to provide all the required evaluation evidence lies with 
the sponsor. However, most of the evaluation evidence is likely to be 
produced and supplied by the developer, on behalf of the sponsor. 
61 Since the assurance r equirements apply to the entire TOE, all evaluation 
evidence pertaining to all parts of the TOE is to be made available to the 
evaluator. The scope and required content of such evaluation evidence is 
independent of the level of control that the developer h as over each of the 
parts of the TOE. For example, if design is required, then the TOE design 
(ADV_TDS) requirements will apply to all subsystems that are part of the 
TSF. In addition, assurance requirements that call for procedures to b e in 
place (for example, CM capabilities (ALC_CMC)  and Delivery 
(ALC_DEL)) will also apply to the entire TOE (including any part produced 
by another developer). 
62 It is recommended that the evaluator, in conjunction with  the sponsor, 
produce an index to required evaluation evidence. This index may be a set of 
references to the documentation. This index should contain enough 
information (e.g. a brief summary of each document, or at least an explicit 
title, indication of the sections of interest) to help the evaluator to find easily 
the required evidence. 
63 It is the information contained in the evaluation evidence that is required, not 
any particular document structure. Evaluation evidence for a sub -activity 
may be provided b y separate documents, or a single document may satisfy 
several of the input requirements of a sub-activity. 
Evaluation process and related tasks 
Page 26 of 430 Version 3.1 April 2017 
64 The evaluator requires stable and formally -issued versions of evaluation 
evidence. However, draft evaluation evidence may be provided during an 
evaluation, for example, to help an evaluator make an early, informal 
assessment, but is not used as the basis for verdicts. It may be helpful for the 
evaluator to see draft versions of particular appropriate evaluation evidence, 
such as:  
a) test documentation, to allow the evaluator to make an early 
assessment of tests and test procedures;  
b) design documents, to provide the evaluator with background for 
understanding the TOE design;  
c) source code or hardware drawings, to allow the evaluator to assess 
the application of the developer's standards.  
65 Draft evaluation evidence is more likely to be encountered where the 
evaluation of a TOE is performed concurrently with its development. 
However, it may also be encountered during the evaluation of an already -
developed TOE where the developer has had to perform additional work to 
address a problem identified by the evaluator (e.g. to correct an error in 
design or implementation) or to provide evaluation evidence of security that 
is not provided in the existing documentation  (e.g. in the case of a TOE not 
originally developed to meet the requirements of the CC). 
8.3.3 Management of evaluation evidence sub-task 
8.3.3.1 Configuration control 
66 The evaluator shall perform configuration control of the evaluation evidence. 
67 The CC implies that the  evaluator is able to identify and locate each item of 
evaluation evidence after it has been received and is able to determine 
whether a specific version of a document is in the evaluator's possession. 
68 The evaluator shall protect  the evaluation evidence fr om alteration or loss 
while it is in the evaluator's possession. 
8.3.3.2 Disposal 
69 Schemes may wish to control the disposal of evaluation evidence at the 
conclusion of an evaluation. The disposal of the evaluation evidence should 
be achieved by one or more of:  
a) returning the evaluation evidence;  
b) archiving the evaluation evidence;  
c) destroying the evaluation evidence.  
Evaluation process and related tasks 
April 2017 Version 3.1 Page 27 of 430 
8.3.3.3 Confidentiality 
70 An evaluator may have access to sponsor and developer commercially -
sensitive information (e.g. TOE design information, specialist tool s), and 
may have access to nationally -sensitive information during the course of an 
evaluation. Schemes may wish to impose requirements for the evaluator to 
maintain the confidentiality of the evaluation evidence. The sponsor and 
evaluator may mutually agree to additional requirements as long as these are 
consistent with the scheme. 
71 Confidentiality requirements affect many aspects of evaluation work, 
including the receipt, handling, storage and disposal of evaluation evidence. 
8.4 Evaluation sub-activities 
72 The evaluation sub -activities vary depending whether it is a PP or a TOE 
evaluation. Moreover, in the case of a TOE evaluation, the sub -activities 
depend upon the selected assurance requirements. 
8.5 Evaluation output task 
8.5.1 Objectives 
73 The objective of this Section is to describe the Observation Report (OR) and 
the Evaluation Technical Report (ETR). Schemes may require additional 
evaluator reports such as reports on individual units of work, or may require 
additional information to be contained in the OR and the ETR.  The CEM 
does not preclude the addition of information into these reports as the CEM 
specifies only the minimum information content. 
74 Consistent reporting of evaluation results facilitates the achievement of the 
universal principle of repeatability and repr oducibility of results. The 
consistency covers the type and the amount of information reported in the 
ETR and OR. ETR and OR consistency among different evaluations is the 
responsibility of the evaluation authority. 
75 The evaluator performs the two following  sub-tasks in order to achieve the 
CEM requirements for the information content of reports:  
a) write OR sub-task (if needed in the context of the evaluation);  
b) write ETR sub-task.  
8.5.2 Management of evaluation outputs 
76 The evaluator delivers the ETR to the evalua tion authority, as well as any 
ORs as they become available. Requirements for controls on handling the 
ETR and ORs are established by the scheme which may include delivery to 
the sponsor or developer. The ETR and ORs may include sensitive or 
proprietary information and may need to be sanitised before they are given to 
the sponsor. 
Evaluation process and related tasks 
Page 28 of 430 Version 3.1 April 2017 
8.5.3 Application notes 
77 In this version of the CEM, the requirements for the provision of evaluator 
evidence to support re -evaluation and re-use have not been explicitly stated. 
Where information for re-evaluation or re-use is required by the sponsor, the 
scheme under which the evaluation is being performed should be consulted. 
8.5.4 Write OR sub-task 
78 ORs provide the evaluator with a mechanism to request a clarification (e.g. 
from the evaluati on authority on the application of a requirement) or to 
identify a problem with an aspect of the evaluation. 
79 In the case of a fail verdict, the evaluator shall provide an OR to reflect the 
evaluation result. Otherwise, the evaluator may use ORs as one way of 
expressing clarification needs. 
80 For each OR, the evaluator shall report the following:  
a) the identifier of the PP or TOE evaluated;  
b) the evaluation task/sub -activity during which the observation was 
generated;  
c) the observation;  
d) the assessment of its sev erity (e.g. implies a fail verdict, holds up 
progress on the evaluation, requires a resolution prior to evaluation 
being completed);  
e) the identification of the organisation responsible for resolving the 
issue;  
f) the recommended timetable for resolution;  
g) the assessment of the impact on the evaluation of failure to resolve 
the observation.  
81 The intended audience of an OR and procedures for handling the report 
depend on the nature of the report's content and on the scheme. Schemes may 
distinguish different types of ORs or define additional types, with associated 
differences in required information and distribution (e.g. evaluation ORs to 
evaluation authorities and sponsors). 
8.5.5 Write ETR sub-task 
8.5.5.1 Objectives 
82 The evaluator shall provide an ETR to present technical j ustification of the 
verdicts. 
Evaluation process and related tasks 
April 2017 Version 3.1 Page 29 of 430 
83 The CEM defines the ETR's minimum content requirement; however, 
schemes may specify additional content and specific presentational and 
structural requirements. For instance, schemes may require that certain 
introductory material (e.g. disclaimers and copyright Chapters) be reported in 
the ETR. 
84 The reader of the ETR is assumed to be familiar with general concepts of 
information security, the CC, the CEM, evaluation approaches and IT. 
85 The ETR supports the evaluation authority to confirm that the evaluation was 
done to the required standard, but it is anticipated that the documented results 
may not provide all of the necessary information, so additional information 
specifically requested by the scheme may be necessary. This aspect is 
outside the scope of the CEM. 
8.5.5.2 ETR for a PP Evaluation 
86 This Section describes the minimum content of the ETR for a PP evaluation. 
The contents of the ETR are portrayed in Figure 4; this figure may be used as 
a guide when constructing the structural outline of the ETR document. 
 
Figure 4 - ETR information content for a PP evaluation 
8.5.5.2.1 Introduction 
Evaluation process and related tasks 
Page 30 of 430 Version 3.1 April 2017 
87 The evaluator shall report evaluation scheme identifiers. 
88 Evaluation scheme identifiers (e.g. logos) are the inform ation required to 
unambiguously identify the scheme responsible for the evaluation oversight. 
89 The evaluator shall report ETR configuration control identifiers. 
90 The ETR configuration control identifiers contain information that identifies 
the ETR (e.g. name, date and version number). 
91 The evaluator shall report PP configuration control identifiers. 
92 PP configuration control identifiers (e.g. name, date and version number) are 
required to identify what is being evaluated in order for the evaluation 
authority to  verify that the verdicts have been assigned correctly by the 
evaluator. 
93 The evaluator shall report the identity of the developer. 
94 The identity of the PP developer is required to identify the party responsible 
for producing the PP. 
95 The evaluator shall report the identity of the sponsor. 
96 The identity of the sponsor is required to identify the party responsible for 
providing evaluation evidence to the evaluator. 
97 The evaluator shall report the identity of the evaluator. 
98 The identity of the evaluator is require d to identify the party performing the 
evaluation and responsible for the evaluation verdicts. 
8.5.5.2.2 Evaluation 
99 The evaluator shall report  the evaluation methods, techniques, tools and 
standards used. 
100 The evaluator references the evaluation criteria, methodology  and 
interpretations used to evaluate the PP. 
101 The evaluator shall report  any constraints on the evaluation, constraints on 
the handling of evaluation results and assumptions made during the 
evaluation that have an impact on the evaluation results. 
102 The eval uator may include information in relation to legal or statutory 
aspects, organisation, confidentiality, etc. 
8.5.5.2.3 Results of the evaluation 
103 The evaluator shall report  a verdict and a supporting rationale for each 
assurance component that constitutes an APE activity, as a result of 
performing the corresponding CEM action and its constituent work units. 
Evaluation process and related tasks 
April 2017 Version 3.1 Page 31 of 430 
104 The rationale justifies the verdict using the CC, the CEM, any interpretations 
and the evaluation evidence examined and shows how the ev aluation 
evidence does or does not meet each aspect of the criteria. It contains a 
description of the work performed, the method used, and any derivation of 
results. The rationale may provide detail to the level of a CEM work unit. 
8.5.5.2.4 Conclusions and recommendations 
105 The evaluator shall report the conclusions of the evaluation, in particular the 
overall verdict as defined in CC Part 1 Chapter 10, Evaluation results , and 
determined by application of the verdict assignment described in 8.2.5. 
106 The evaluator provides recommendations that may be useful for the 
evaluation authority. These recommendations may include shortcomings of 
the PP discovered during the evaluation or mention of features which are 
particularly useful. 
8.5.5.2.5 List of evaluation evidence 
107 The evaluator shall report for each item of evaluation evidence the following 
information:  
 the issuing body (e.g. the developer, the sponsor);  
 the title;  
 the unique reference (e.g. issue date and version number).  
8.5.5.2.6 List of acronyms/Glossary of terms 
108 The evaluator shall report any acronyms or abbreviations used in the ETR. 
109 Glossary definitions already defined by the CC or CEM need not be repeated 
in the ETR. 
8.5.5.2.7 Observation reports 
110 The evaluator shall report  a com plete list that uniquely identifies the ORs 
raised during the evaluation and their status. 
111 For each OR, the list should contain its identifier as well as its title or a brief 
summary of its content. 
8.5.5.3 ETR for a TOE Evaluation 
112 This Section describes the minim um content of the ETR for a TOE 
evaluation. The contents of the ETR are portrayed in Figure 5; this figure 
may be used as a guide when constructing the structural outline of the ETR 
document. 
Evaluation process and related tasks 
Page 32 of 430 Version 3.1 April 2017 
 
Figure 5 - ETR information content for a TOE evaluation 
8.5.5.3.1 Introduction 
113 The evaluator shall report evaluation scheme identifiers. 
114 Evaluation scheme identifiers (e.g. logos) are the information required to 
unambiguously identify the scheme responsible for the evaluation oversight. 
115 The evaluator shall report ETR configuration control identifiers. 
116 The ETR configuration control identifiers contain information that identifies 
the ETR (e.g. name, date and version number). 
117 The evaluator shall report ST and TOE configuration control identifiers. 
118 ST and TOE configuration control identifiers identify what is being 
evaluated in order for the evaluation authority to verify that the verdicts have 
been assigned correctly by the evaluator. 
119 If the ST claims that the TOE conforms to the requ irements of one or more 
PPs, the ETR shall report the reference of the corresponding PPs. 
Evaluation process and related tasks 
April 2017 Version 3.1 Page 33 of 430 
120 The PPs reference contains information that uniquely identifies the PPs (e.g. 
title, date, and version number). 
121 The evaluator shall report the identity of the developer. 
122 The identity of the TOE developer is required to identify the party 
responsible for producing the TOE. 
123 The evaluator shall report the identity of the sponsor. 
124 The identity of the sponsor is required to identify the party responsible for 
providing evaluation evidence to the evaluator. 
125 The evaluator shall report the identity of the evaluator. 
126 The identity of the evaluator is required to identify the party performing the 
evaluation and responsible for the evaluation verdicts. 
8.5.5.3.2 Architectural description of the TOE 
127 The evaluator shall report a high level description of the TOE and its major 
components based on the evaluation evidence described in the CC assurance 
family entitled TOE design (ADV_TDS), where applicable. 
128 The intent of this Sect ion is to characterise the degree of architectural 
separation of the major components. If there is no TOE design (ADV_TDS) 
requirement in the ST, this is not applicable and is considered to be satisfied. 
8.5.5.3.3 Evaluation 
129 The evaluator shall re port the evaluation methods, techniques, tools and 
standards used. 
130 The evaluator may reference the evaluation criteria, methodology and 
interpretations used to evaluate the TOE or the devices used to perform the 
tests. 
131 The evaluator shall report  any constraints on the evaluation, constraints on 
the distribution of evaluation results and assumptions made during the 
evaluation that have an impact on the evaluation results. 
132 The evaluator may include information in relation to legal or statutory 
aspects, organisation, confidentiality, etc. 
8.5.5.3.4 Results of the evaluation 
133 For each activity on which the TOE is evaluated, the evaluator shall report:  
 the title of the activity considered;  
Evaluation process and related tasks 
Page 34 of 430 Version 3.1 April 2017 
 a verdict and a supporting rationale for each assurance component 
that constitutes this activity, as a result of performing the 
corresponding CEM action and its constituent work units.  
134 The rationale justifies the verdict using the CC, the CEM, any interpretations 
and the evaluation evidence examined and shows how the evaluation 
evidence does or does not meet each aspect of the criteria. It contains a 
description of the work performed, the method used, and any derivation of 
results. The rationale may provide detail to the level of a CEM work unit. 
135 The evaluator shall report  all informatio n specifically required by a work 
unit. 
136 For the AVA and ATE activities, work units that identify information to be 
reported in the ETR have been defined. 
8.5.5.3.5 Conclusions and recommendations 
137 The evaluator shall report  the conclusions of the evaluation, which will 
relate to whether the TOE has satisfied its associated ST, in particular the 
overall verdict as defined in CC Part 1 Chapter 10, Evaluation results , and 
determined by application of the verdict assignment described in 8.2.5. 
138 The evaluator provides recommendations that may be useful for the 
evaluation authority. These recommendations may include shortcomings of 
the IT product discovered during the evaluation or mention of features which 
are particularly useful. 
8.5.5.3.6 List of evaluation evidence 
139 The evaluator shall report for each item of evaluation evidence the following 
information:  
 the issuing body (e.g. the developer, the sponsor);  
 the title;  
 the unique reference (e.g. issue date and version number).  
8.5.5.3.7 List of acronyms/Glossary of terms 
140 The evaluator shall report any acronyms or abbreviations used in the ETR. 
141 Glossary definitions already defined by the CC or CEM need not be repeated 
in the ETR. 
8.5.5.3.8 Observation reports 
142 The evaluator shall report  a complete list that uniquely identifies the ORs 
raised during the evaluation and their status. 
Evaluation process and related tasks 
April 2017 Version 3.1 Page 35 of 430 
143 For each OR, the list should contain its identifier as well as its title or a brief 
summary of its content. 
Class APE: Protection Profile evaluation 
Page 36 of 430 Version 3.1 April 2017 
9 Class APE: Protection Profile evaluation 
9.1 Introduction 
144 This Chapter describes the evaluation of a PP. The requirements and 
methodology for PP evaluation are identical for each PP evaluation, 
regardless of the EAL (or other set of assurance requirements) that is claimed 
in the PP. The evaluation methodology in this Chapter is based on the 
requirements on the PP as specified in CC Part 3 class APE. 
145 This Chapter should be used in conjunction with Annexes A, B and C, 
Guidance for Operations in CC Part 1, as these Annexes clarify the concepts 
here and provide many examples. 
9.2 Application notes 
9.2.1 Re-using the evaluation results of certified PPs 
146 While evaluating a PP that is based on one or more certified PPs, it may be 
possible to re-use the fact that these PPs were certified. The potential for re -
use of the result of a certified PP is greater if the PP under evalua tion does 
not add threats, OSPs, security objectives and/or security requirements to 
those of the PP that conformance is being claimed to. If the PP under 
evaluation contains much more than the certified PP, re -use may not be 
useful at all. 
147 The evaluator is allowed to re -use the PP evaluation results by doing certain 
analyses only partially or not at all if these analyses or parts thereof were 
already done as part of the PP evaluation. While doing this, the evaluator 
should assume that the analyses in the PP were performed correctly. 
148 An example would be where the PP that conformance is being claimed to 
contains a set of security requirements, and these were determined to be 
internally consistent during its evaluation. If the PP under evaluation uses the 
exact same requirements, the consistency analysis does not have to be 
repeated during the PP evaluation. If the PP under evaluation adds one or 
more requirements, or performs operations on these requirements, the 
analysis will have to be repeated. However, it may be possible to save work 
in this consistency analysis by using the fact that the original requirements 
are internally consistent. If the original requirements are internally consistent, 
the evaluator only has to determine that:  
a) the set of all new and/or changed requirements is internally consistent, 
and  
b) the set of all new and/or changed requirements is consistent with the 
original requirements.  
149 The evaluator notes in the ETR each case where analyses are not done or 
only partially done for this reason. 
Class APE: Protection Profile evaluation 
April 2017 Version 3.1 Page 37 of 430 
9.3 PP introduction (APE_INT) 
9.3.1 Evaluation of sub-activity (APE_INT.1) 
9.3.1.1 Objectives 
150 The objective of this sub -activity is to determine whether the PP is correctly 
identified, and whether the PP reference and TOE overview are consistent 
with each other. 
9.3.1.2 Input 
151 The evaluation evidence for this sub-activity is:  
a) the PP.  
9.3.1.3 Action APE_INT.1.1E 
APE_INT.1.1C The PP introduction shall contain a PP reference and a TOE overview.  
APE_INT.1-1 The evaluator shall check  that the PP introduction contains a PP reference 
and a TOE overview. 
APE_INT.1.2C The PP reference shall uniquely identify the PP.  
APE_INT.1-2 The evaluator shall examine the PP reference to determine that it uniquely 
identifies the PP. 
152 The evaluator determines that the PP reference identifies the PP itself, so that 
it may be easily dis tinguished from other PPs, and that it also uniquely 
identifies each version of the PP, e.g. by including a version number and/or a 
date of publication. 
153 The PP should have some referencing system that is capable of supporting 
unique references (e.g. use of numbers, letters or dates). 
APE_INT.1.3C The TOE overview shall summarise the usage and major security features 
of the TOE.  
APE_INT.1-3 The evaluator shall examine the TOE overview to determine that it describes 
the usage and major security features of the TOE. 
154 The TOE overview should briefly (i.e. several paragraphs) describe the usage 
and major security features expected of the TOE. The TOE overview should 
enable consumers and potential TOE developers to quickly determine 
whether the PP is of interest to them. 
155 The evaluator determines that the overview is clear enough for TOE 
developers and consumers, and sufficient to give them a general 
understanding of the intended usage and major security features of the TOE. 
APE_INT.1.4C The TOE overview shall identify the TOE type.  
Class APE: Protection Profile evaluation 
Page 38 of 430 Version 3.1 April 2017 
APE_INT.1-4 The evaluator shall check that the TOE overview identifies the TOE type. 
APE_INT.1.5C The TOE overview shall identify any non -TOE 
hardware/software/firmware available to the TOE.  
APE_INT.1-5 The evaluator shall examine the TOE overview to determine that it identifies 
any non-TOE hardware/software/firmware available to the TOE. 
156 While some TOEs may run stand -alone, other TOEs (notably software 
TOEs) need additional hardware, software or firmware to operate. In this 
section of the PP, the PP author lists all hardware, software, and/or firmware 
that will be available for the TOE to run on. 
157 This identification should be detailed enough for potential consumers and 
TOE developers to determine whether their TOE may  operate with the listed 
hardware, software and firmware. 
Class APE: Protection Profile evaluation 
April 2017 Version 3.1 Page 39 of 430 
9.4 Conformance claims (APE_CCL) 
9.4.1 Evaluation of sub-activity (APE_CCL.1) 
9.4.1.1 Objectives 
158 The objective of this sub -activity is to determine the validity of various 
conformance claims. These describe how the PP conforms to the CC, other 
PPs and packages. 
9.4.1.2 Input 
159 The evaluation evidence for this sub-activity is:  
a) the PP;  
b) the PP(s) that the PP claims conformance to;  
c) the package(s) that the PP claims conformance to.  
9.4.1.3 Action APE_CCL.1.1E 
APE_CCL.1.1C The conformance claim shall contain a CC conformance claim that 
identifies the version of the CC to which the PP claims conformance.  
APE_CCL.1-1 The evaluator shall check  that the conformance claim contains a CC 
conformance claim that identifies the version of the CC to which the PP 
claims conformance. 
160 The evaluator determines that the CC conformance claim identifies the 
version of t he CC that was used to develop this PP. This should include the 
version number of the CC and, unless the International English version of the 
CC was used, the language of the version of the CC that was used. 
APE_CCL.1.2C The CC conformance claim shall describe the conformance of the PP to 
CC Part 2 as either CC Part 2 conformant or CC Part 2 extended.  
APE_CCL.1-2 The evaluator shall check that the CC conformance cla im states a claim of 
either CC Part 2 conformant or CC Part 2 extended for the PP. 
APE_CCL.1.3C The CC conformance claim shall describe the conformance of the PP to 
CC Part 3 as either CC Part 3 conformant or CC Part 3 extended.  
APE_CCL.1-3 The evaluator shall check that the CC conformance claim states a claim of 
either CC Part 3 conformant or CC Part 3 extended for the PP. 
APE_CCL.1.4C The CC conformance claim shall be consistent with the extended 
components definition.  
APE_CCL.1-4 The evaluator shall examine  the CC conformance claim for CC Part 2 to 
determine that it is consistent with the extended components definition. 
Class APE: Protection Profile evaluation 
Page 40 of 430 Version 3.1 April 2017 
161 If the CC conformance claim contains CC Part 2 conformant, the evaluator 
determines that the extended components definition does not define 
functional components. 
162 If the CC conformance claim contains CC Part  2 extended, the evaluator 
determines that the extended components definition defines at least one 
extended functional component. 
APE_CCL.1-5 The evaluator shall examine  the CC conformance claim for CC Part 3 to 
determine that it is consistent with the extended components definition. 
163 If the CC conformance claim contains CC Part 3 conformant, the evaluator 
determines that the extended components definition does not define 
assurance components. 
164 If the CC conformance  claim contains CC Part 3 extended, the evaluator 
determines that the extended components definition defines at least one 
extended assurance component. 
APE_CCL.1.5C The conformance claim shall identify all PP s and security requirement 
packages to which the PP claims conformance.  
APE_CCL.1-6 The evaluator shall check  that the conformance claim contains a PP claim 
that identifies all PPs for which the PP claims conformance. 
165 If the PP does not claim conformance to another PP, this work unit is not 
applicable and therefore considered to be satisfied. 
166 The evaluator determines that any referenced PPs are unambiguously 
identified (e.g. by title and version number, or by the  identification included 
in the introduction of that PP). 
167 The evaluator is reminded that claims of partial conformance to a PP are not 
permitted. 
APE_CCL.1-7 The evaluator shall check  that the conformance claim c ontains a package 
claim that identifies all packages to which the PP claims conformance. 
168 If the PP does not claim conformance to a package, this work unit is not 
applicable and therefore considered to be satisfied. 
169 The evaluator determines that any referen ced packages are unambiguously 
identified (e.g. by title and version number, or by the identification included 
in the introduction of that package). 
170 The evaluator is reminded that claims of partial conformance to a package 
are not permitted. 
APE_CCL.1.6C The conformance claim shall describe any conformance of the PP to a 
package as either package-conformant or package-augmented.  
Class APE: Protection Profile evaluation 
April 2017 Version 3.1 Page 41 of 430 
APE_CCL.1-8 The evaluator shall check that, for each identified package, the conformance 
claim states a claim of either package -name conformant or package -name 
augmented. 
171 If the PP does not claim conformance to a package, this work unit is not 
applicable and therefore considered to be satisfied. 
172 If the package conformance claim contains package -name conformant, the 
evaluator determines that:  
a) If the package is an assurance package, then the PP contains all SARs 
included in the package, but no additional SARs.  
b) If the package is a functional pa ckage, then the PP contains all SFRs 
included in the package, but no additional SFRs.  
173 If the package conformance claim contains package -name augmented, the 
evaluator determines that:  
a) If the package is an assurance package, then the PP contains all SARs 
included in the package, and at least one additional SAR or at least 
one SAR that is hierarchical to a SAR in the package.  
b) If the package is a functional package, then the PP contains all SFRs 
included in the package, and at least one additional SFR or at least 
one SFR that is hierarchical to a SFR in the package.  
APE_CCL.1.7C The conformance claim rationale shall demonstrate that the TOE type is 
consistent with the TOE type in the PPs for which conformance i s being 
claimed.  
APE_CCL.1-9 The evaluator shall examine  the conformance claim rationale to determine 
that the TOE type of the TOE is consistent with all TOE types of the PPs. 
174 If the PP does not claim conformanc e to another PP, this work unit is not 
applicable and therefore considered to be satisfied. 
175 The relation between the types may be simple: a firewall PP claiming 
conformance to another firewall PP, or more complex: a smart card PP 
claiming conformance to a number of other PPs at the same time: a PP for 
the integrated circuit, a PP for the smart card OS, and two PPs for two 
applications on the smart card. 
APE_CCL.1.8C The conformance claim rationale shall demons trate that the statement of 
the security problem definition is consistent with the statement of the 
security problem definition in the PPs for which conformance is being 
claimed.  
APE_CCL.1-10 The evaluator shall examine  the conformance claim rationale to determine 
that it demonstrates that the statement of security problem definition is 
consistent, as defined by the conformance statement of the PP, with the 
Class APE: Protection Profile evaluation 
Page 42 of 430 Version 3.1 April 2017 
statements of security problem definition stated in t he PPs to which 
conformance is being claimed. 
176 If the PP under evaluation does not claim conformance with another PP, this 
work unit is not applicable and therefore considered to be satisfied. 
177 If the PP to which conformance is being claimed does not have a statement 
of security problem definition, this work unit is not applicable and therefore 
considered to be satisfied. 
178 If strict conformance is required by the PP to which conformance is being 
claimed, no conformance claim rationale is required. Instead, the  evaluator 
determines whether  
a) the threats in the PP under evaluation are a superset of or identical to 
the threats in the PP to which conformance is being claimed;  
b) the OSPs in the PP under evaluation are a superset of or identical to 
the OSPs in the PP to which conformance is being claimed;  
c) the assumptions in the PP claiming conformance are identical to the 
assumptions in the PP to which conformance is being claimed, with 
two possible exceptions described in the following two bullet points;  
 an assumptio n (or part of an assumption) from the PP to 
which conformance is claimed, can be omitted, if all security 
objectives for the operational environment addressing this 
assumption (or part of an assumption) are replaced by security 
objectives for the TOE; 
 an assumption can be added to the assumptions defined in the 
PP to which conformance is claimed, if a justification is given, 
why the new assumption neither mitigates a threat (or a part 
of a threat) meant to be addressed by security objectives for 
the TOE in the PP to which conformance is claimed, nor 
fulfills an OSP (or part of an OSP) meant to be addressed by 
security objectives for the TOE in the PP to which 
conformance is claimed. 
When examining a PP, which omits assumptions from another PP to which 
conformance is claimed, or adds new assumptions, the evaluator shall 
carefully determine, if the conditions given above are fulfilled. The 
following discussion gives some motivation and examples for these cases:  
 Example for omitting an assumption: A PP to which  
conformance is claimed, may contain an assumption stating 
that the operational environment prevents unauthorized 
modification or interception of data sent to an external 
interface of the TOE. This may be the case if the TOE accepts 
data in clear text and without integrity protection at this 
interface and is assumed to be located in a secure operational 
Class APE: Protection Profile evaluation 
April 2017 Version 3.1 Page 43 of 430 
environment, which will prevent attackers from accessing 
these data. The assumption will then be mapped in the PP, to 
which conformance is claimed, to some objective for the 
operational environment stating that the data interchanged at 
this interface are protected by adequate measures in the 
operational environment. If a PP claiming this PP, defines a 
more secure TOE, which has an additional security objectiv e 
stating that the TOE itself protects these data, for example by 
providing a secure channel for encryption and integrity 
protection of all data transferred via this interface, the 
corresponding objective and assumption for the operational 
environment can be omitted from the PP claiming 
conformance. This is also called re -assigning of the objective, 
since the objective is re -assigned from the operational 
environment to the TOE. Note, that this TOE is still secure in 
an operational environment fulfilling the  omitted assumption 
and therefore still fulfills the PP to which conformance is 
claimed. 
 Example for adding an assumption: In this example the PP to 
which conformance is claimed, is designed to specify 
requirements for a TOE of type "Firewall" and the auth or of 
another PP wishes to claim conformance to this PP for a TOE, 
which implements a firewall, but additionally provides the 
functionality of a virtual private network (VPN) component. 
For the VPN functionality the TOE needs cryptographic keys 
and these k eys may also have to be handled securely by the 
operational environment (e. g. if symmetric keys are used to 
secure the network connection and therefore need to be 
provided in some secure way to other components in the 
network). In this case it is acceptab le to add an assumption 
that the cryptographic keys used by the VPN are handled 
securely by the operational environment. This assumption 
does not address threats or OSPs of the PP to which 
conformance is claimed, and therefore fulfills the conditions 
stated above. 
 Counterexample for adding an assumption: In a variant of the 
first example a PP to which conformance is claimed, may 
already contain an objective for the TOE to provide a secure 
channel for one of its interfaces, and this objective is mapped 
to a threat of unauthorized modification or reading of the data 
on this interface. In this case it is clearly not allowed for 
another PP claiming this PP, to add an assumption for the 
operational environment, which assumes that the operational 
environment prote cts data on this interface against 
modification or unauthorized reading of the data. This 
assumption would reduce a threat, which is meant to be 
addressed by the TOE. Therefore a TOE fulfilling a PP with 
this added assumption would not automatically fulfil l the PP 
Class APE: Protection Profile evaluation 
Page 44 of 430 Version 3.1 April 2017 
to which conformance is claimed, anymore and this addition 
is therefore not allowed. 
 Second counterexample for adding an assumption: In the 
example above of a TOE implementing a firewall it would not 
be admissible to add a general assumption that the TOE is 
only connected to trusted devices, because this would 
obviously remove essential threats relevant for a firewall 
(namely that there is untrusted IP traffic, which needs to be 
filtered). Therefore this addition would not be allowed.  
179 If demonstrable conformance is required by the PP to which conformance is 
being claimed, the evaluator examines the conformance claim rationale to 
determine that it demonstrates that the statement of security problem 
definition of the PP under evaluation is equivalent  or more restrictive than 
the statement of security problem definition in the PP to which conformance 
is being claimed. 
180 For this, the conformance claim rationale needs to demonstrate that the 
security problem definition in the PP claiming conformance is eq uivalent (or 
more restrictive) than the security problem definition in the PP to which 
conformance is claimed. This means that:  
 all TOEs that would meet the security problem definition in the PP 
claiming conformance also meet the security problem definiti on in 
the PP to which conformance is claimed. This can also be shown 
indirectly by demonstrating that every event, which realizes a threat 
defined in the PP to which conformance is claimed, or violates an 
OSP defined in the PP to which conformance is claim ed, would also 
realize a threat stated in the PP claiming conformance or violate an 
OSP defined in the PP claiming conformance. Note that fulfilling an 
OSP stated in the PP claiming conformance may avert a threat stated 
in the PP to which conformance is cl aimed, or that averting a threat 
stated in the PP claiming conformance may fulfill an OSP stated in 
the PP to which conformance is claimed, so threats and OSPs can 
substitute each other; 
 all operational environments that would meet the security problem 
definition in the PP to which conformance is claimed, would also 
meet the security problem definition in the PP claiming conformance 
(with one exception in the next bullet); 
 besides a set of assumptions in the PP claiming conformance needed 
to demonstrate con formance to the SPD of the PP to which 
conformance is claimed, an PP claiming conformance may specify 
further assumptions, but only if these additional assumptions are 
independent of and do not affect the security problem definition as 
defined in the PP to  which conformance is claimed. More detailed, 
there are no assumptions in the PP claiming conformance that 
exclude threats to the TOE that need to be countered by the TOE 
according to the PP to which conformance is claimed. Similarly, 
Class APE: Protection Profile evaluation 
April 2017 Version 3.1 Page 45 of 430 
there are no assumptions in the PP claiming conformance that realize 
aspects of an OSP stated in the PP to which conformance is claimed, 
which are meant to be fulfilled by the TOE according to the PP to 
which conformance is claimed. 
APE_CCL.1.9C The conformance claim rationale shall demonstrate that the statement of 
security objectives is consistent with the statement of security objectives in 
the PPs for which conformance is being claimed.  
APE_CCL.1-11 The evaluator shall examine  the conformance claim rationale to determine 
that the statement of security objectives is consistent, as defined by the 
conformance statement of the PPs, with the statement of security objectives 
in the PPs. 
181 If the PP does not claim conformance to another PP, this work unit is not 
applicable and therefore considered to be satisfied. 
182 If strict conformance is required by the PP to which conformance is being 
claimed, no conformance claim rationale is required. I nstead, the evaluator 
determines whether:  
 The PP under evaluation contains all security objectives for the TOE 
of the PP to which conformance is being claimed. Note that it is 
allowed for the PP under evaluation to have additional security 
objectives for the TOE; 
 The security objectives for the operational environment in the PP 
claiming conformance are identical to the security objectives for the 
operational environment in the PP to which conformance is being 
claimed, with two possible exceptions described  in the following two 
bullet points;  
 a security objective for the operational environment (or part of such 
security objective) from the PP to which conformance is claimed, can 
be replaced by the same (part of the) security objective stated for the 
TOE;  
 a security objective for the operational environment can be added to 
the objectives defined in the PP to which conformance is claimed, if a 
justification is given, why the new objective neither mitigates a threat 
(or a part of a threat) meant to be addresse d by security objectives for 
the TOE in the PP to which conformance is claimed, nor fulfills an 
OSP (or part of an OSP) meant to be addressed by security objectives 
for the TOE in the PP to which conformance is claimed.  
When examining a PP claiming anothe r PP which omits security objectives 
for the operational environment from the PP to which conformance is 
claimed, or adds new security objectives for the operational environment, the 
evaluator shall carefully determine, if the conditions given above are fulfilled. 
The examples given for the case of assumptions in the preceding work unit 
are also valid here. 
Class APE: Protection Profile evaluation 
Page 46 of 430 Version 3.1 April 2017 
183 If demonstrable conformance is required by the PP to which conformance is 
being claimed, the evaluator examines the conformance claim rationale to 
determine that it demonstrates that the statement of security objectives of the 
PP under evaluation is equivalent or more restrictive than the statement of 
security objectives in the PP to which conformance is being claimed. 
184 For this the conformance claim ratio nale needs to demonstrate that the 
security objectives in the PP claiming conformance are equivalent (or more 
restrictive) than the security objectives in the PP to which conformance is 
claimed. This means that:  
 all TOEs that would meet the security objec tives for the TOE in the 
PP claiming conformance also meet the security objectives for the 
TOE in the PP to which conformance is claimed; 
 all operational environments that would meet the security objectives 
for the operational environment in the PP to whic h conformance is 
claimed, would also meet the security objectives for the operational 
environment in the PP claiming conformance (with one exception in 
the next bullet); 
 besides a set of security objectives for the operational environment in 
the PP claimin g conformance, which are used to demonstrate 
conformance to the set of security objectives defined in the PP to 
which conformance is claimed, an PP claiming conformance may 
specify further security objectives for the operational environment, 
but only if th ese security objectives neither affect the original set of 
security objectives for the TOE nor the security objectives for the 
operational environment as defined in the PP to which conformance 
is claimed. 
APE_CCL.1.10C The conformance claim rationale shall demonstrate that the statement of 
security requirements is consistent with the statement of security 
requirements in the PPs for which conformance is being claimed.  
APE_CCL.1-12 The evaluator shall examine  the PP to determine that it is consistent, as 
defined by the conformance statement of the PP, with all security 
requirements in the PPs for which conformance is being claimed. 
185 If the PP does not claim confo rmance to another PP, this work unit is not 
applicable and therefore considered to be satisfied. 
186 If strict conformance is required by the PP to which conformance is being 
claimed, no conformance claim rationale is required. Instead, the evaluator 
determines whether the statement of security requirements in the PP under 
evaluation is a superset of or identical to the statement of security 
requirements in the PP to which conformance is being claimed (for strict 
conformance). 
187 If demonstrable conformance is req uired by the PP to which conformance is 
being claimed, the evaluator examines the conformance claim rationale to 
Class APE: Protection Profile evaluation 
April 2017 Version 3.1 Page 47 of 430 
determine that it demonstrates that the statement of security requirements of 
the PP under evaluation is equivalent or more restrictive than th e statement 
of security requirements in the PP to which conformance is being claimed. 
188 For:  
 SFRs: The conformance rationale in the PP claiming conformance 
shall demonstrate that the overall set of requirements defined by the 
SFRs in the PP claiming conform ance is equivalent (or more 
restrictive) than the overall set of requirements defined by the SFRs 
in the PP to which conformance is claimed. This means that all TOEs 
that would meet the requirements defined by the set of all SFRs in the 
PP claiming conform ance would also meet the requirements defined 
by the set of all SFRs in the PP to which conformance is claimed; 
 SARs: The PP claiming conformance shall contain all SARs in the 
PP to which conformance is claimed, but may claim additional SARs 
or replace SARs by hierarchically stronger SARs. The completion of 
operations in the PP claiming conformance must be consistent with 
that in the PP to which conformance is claimed; either the same 
completion will be used in the PP claiming conformance as that in the 
PP to which conformance is claimed or a completion that makes the 
SAR more restrictive (the rules of refinement apply). 
APE_CCL.1.11C The conformance statement shall describe the conformance required of 
any PPs/STs to the PP as strict-PP or demonstrable-PP conformance.  
APE_CCL.1-13 The evaluator shall check that the PP conformance statement states a claim 
of strict-PP or demonstrable-PP conformance. 
Class APE: Protection Profile evaluation 
Page 48 of 430 Version 3.1 April 2017 
9.5 Security problem definition (APE_SPD) 
9.5.1 Evaluation of sub-activity (APE_SPD.1) 
9.5.1.1 Objectives 
189 The objective of this sub -activity is to determine that the security problem 
intended to be addressed by the TOE and its operational environment is 
clearly defined. 
9.5.1.2 Input 
190 The evaluation evidence for this sub-activity is:  
a) the PP.  
9.5.1.3 Action APE_SPD.1.1E 
APE_SPD.1.1C The security problem definition shall describe the threats.  
APE_SPD.1-1 The evaluator shall check that the security problem definition describes the 
threats. 
191 If all security objectives are derived from assumptions and/or OSPs only, the 
statement of threats need not be present in the PP. I n this case, this work unit 
is not applicable and therefore considered to be satisfied. 
192 The evaluator determines that the security problem definition describes the 
threats that must be countered by the TOE and/or its operational environment. 
APE_SPD.1.2C All threats shall be described in terms of a threat agent, an asset, and an 
adverse action.  
APE_SPD.1-2 The evaluator shall examine  the security problem definition to determine 
that all threats are described in terms of a threat agent, an asset, and an 
adverse action. 
193 If all security objectives are derived from assumptions and OSPs only, the 
statement of threats need not be present in the PP. In this case, this work unit 
is not applicable and therefore considered to be satisfied. 
194 Threat agents may be further described by aspects such as expertise, resource, 
opportunity, and motivation. 
APE_SPD.1.3C The security problem definition shall describe the OSPs.  
APE_SPD.1-3 The evaluator shall examine  that the security problem definition describes 
the OSPs. 
195 If all security objectives are derived from assumptions and/or threats only, 
OSPs need not be present in the PP. In this case, this work unit is not 
applicable and therefore considered to be satisfied. 
Class APE: Protection Profile evaluation 
April 2017 Version 3.1 Page 49 of 430 
196 The evaluator determines that OSP statements are made in terms of rules or 
guidelines that must be followed by the TOE and/or its ope rational 
environment. 
197 The evaluator determines that each OSP is explained and/or interpreted in 
sufficient detail to make it clearly understandable; a clear presentation of 
policy statements is necessary to permit tracing security objectives to them. 
APE_SPD.1.4C The security problem definition shall describe the assumptions about the 
operational environment of the TOE.  
APE_SPD.1-4 The evaluator shall examine  the se curity problem definition to determine 
that it describes the assumptions about the operational environment of the 
TOE. 
198 If there are no assumptions, this work unit is not applicable and is therefore 
considered to be satisfied. 
199 The evaluator determines that each assumption about the operational 
environment of the TOE is explained in sufficient detail to enable consumers 
to determine that their operational environment matches the assumption. If 
the assumptions are not clearly understood, the end result may be that the 
TOE is used in an operational environment in which it will not function in a 
secure manner. 
Class APE: Protection Profile evaluation 
Page 50 of 430 Version 3.1 April 2017 
9.6 Security objectives (APE_OBJ) 
9.6.1 Evaluation of sub-activity (APE_OBJ.1) 
9.6.1.1 Objectives 
200 The objective of this sub -activity is to determine whether the security 
objectives for the operational environment are clearly defined. 
9.6.1.2 Input 
201 The evaluation evidence for this sub-activity is:  
a) the PP.  
9.6.1.3 Action APE_OBJ.1.1E 
APE_OBJ.1.1C The statement of security objectives shall describe the security objectives 
for the operational environment.  
APE_OBJ.1-1 The evaluator shall check  that the statement of security objectives defines 
the security objectives for the operational environment. 
202 The evaluator checks that the security objectives for the operational 
environment are identified. 
9.6.2 Evaluation of sub-activity (APE_OBJ.2) 
9.6.2.1 Objectives 
203 The objective of this sub -activity is to determine whether the sec urity 
objectives adequately and completely address the security problem definition 
and that the division of this problem between the TOE and its operational 
environment is clearly defined. 
9.6.2.2 Input 
204 The evaluation evidence for this sub-activity is:  
a) the PP.  
9.6.2.3 Action APE_OBJ.2.1E 
APE_OBJ.2.1C The statement of security objectives shall describe the security objectives 
for the TOE and the security objectives for the operational environment.  
APE_OBJ.2-1 The evaluator shall check  that the statement of security objectives defines 
the security objectives for the TOE and the security objectives for the 
operational environment. 
205 The evaluator checks that both categories of security objectives are clearly 
identified and separated from the other category. 
Class APE: Protection Profile evaluation 
April 2017 Version 3.1 Page 51 of 430 
APE_OBJ.2.2C The security objectives rationale shall trace each security objective for t he 
TOE back to threats countered by that security objective and OSPs 
enforced by that security objective.  
APE_OBJ.2-2 The evaluator shall check  that the security objectives rationale traces all 
security objectives for the TOE back to threats countered by the objectives 
and/or OSPs enforced by the objectives. 
206 Each security objective for the TOE may trace back to threats or OSPs, or a 
combination of threats and OSPs, but it must trace back to at least one threat 
or OSP. 
207 Failure to trace implies that either the security objectives rationale is 
incomplete, the security problem definition is incomplete, or the security 
objective for the TOE has no useful purpose. 
APE_OBJ.2.3C The security objectives rationale shall trace each security objective for the 
operational environment back to threats countered by that security 
objective, OSPs enforced by that security objective, and assumptions 
upheld by that security objective.  
APE_OBJ.2-3 The evaluator shall check  that the security objectives rationale traces the 
security objectives for the operational environment back to threats countered 
by that security objective, to OSPs enforced by that security objective, and to 
assumptions upheld by that security objective. 
208 Each security objective for the operational environment may trace back to 
threats, OSPs, assumptions, or a combination of threats, OSPs and/or 
assumptions, but it must trace back to at least one threat, OSP or assumption. 
209 Failure to trace implies that either the security objectives rationale is 
incomplete, the security problem definition is incomplete, or the security 
objective for the operational environment has no useful purpose. 
APE_OBJ.2.4C The security objectives rationale shall demonstrate that the security 
objectives counter all threats.  
APE_OBJ.2-4 The evaluator shall examine  the security objectives rationale to determine 
that it justifies for each threat that the security objectives are suitable to 
counter that threat. 
210 If no security objectives trace back to the threat, the evaluator action related 
to this work unit is assigned a fail verdict. 
211 The evaluator determines that the justification for a threat shows whether the 
threat is removed, diminished or mitigated. 
212 The evaluator determines that the justification for a threat demonstrates that 
the security objectives are sufficient: if all security objectives that trace back 
to the threat are achieved, the threat is removed, sufficiently diminished, or 
the effects of the threat are sufficiently mitigated. 
Class APE: Protection Profile evaluation 
Page 52 of 430 Version 3.1 April 2017 
213 Note that the tracings from security objectives to threats provided in the 
security objectives rationale may be part of a justification, but do not 
constitute a justification by themselves. Even in the case that a security 
objective is merely a statement reflecting the intent to prevent a particular 
threat from being realised, a justi fication is required, but this justification 
may be as minimal as “Security Objective X directly counters Threat Y”. 
214 The evaluator also determines that each security objective that traces back to 
a threat is necessary: when the security objective is achiev ed it actually 
contributes to the removal, diminishing or mitigation of that threat. 
APE_OBJ.2.5C The security objectives rationale shall demonstrate that the security 
objectives enforce all OSPs.  
APE_OBJ.2-5 The evaluator shall examine  the security objectives rationale to determine 
that for each OSP it justifies that the security objectives are suitable to 
enforce that OSP. 
215 If no security objectives trace back to the OSP, the evaluator action related to 
this work unit is assigned a fail verdict. 
216 The evaluator determines that the justification for an OSP demonstrates that 
the security objectives are sufficient: if all security objectives that trace back 
to that OSP are achieved, the OSP is enforced. 
217 The evaluator also determines that each security objective that traces back to 
an OSP is necessary: when the security objective is achieved it actually 
contributes to the enforcement of the OSP. 
218 Note that the tracings from  security objectives to OSPs provided in the 
security objectives rationale may be part of a justification, but do not 
constitute a justification by themselves. In the case that a security objective is 
merely a statement reflecting the intent to enforce a p articular OSP, a 
justification is required, but this justification may be as minimal as “Security 
Objective X directly enforces OSP Y”. 
APE_OBJ.2.6C The security objectives rationale shall demonstrate that th e security 
objectives for the operational environment uphold all assumptions.  
APE_OBJ.2-6 The evaluator shall examine  the security objectives rationale to determine 
that for each assumption for the operational e nvironment it contains an 
appropriate justification that the security objectives for the operational 
environment are suitable to uphold that assumption. 
219 If no security objectives for the operational environment trace back to the 
assumption, the evaluator a ction related to this work unit is assigned a fail 
verdict. 
220 The evaluator determines that the justification for an assumption about the 
operational environment of the TOE demonstrates that the security objectives 
are sufficient: if all security objectives for the operational environment that 
Class APE: Protection Profile evaluation 
April 2017 Version 3.1 Page 53 of 430 
trace back to that assumption are achieved, the operational environment 
upholds the assumption. 
221 The evaluator also determines that each security objective for the operational 
environment that traces back to an assumptio n about the operational 
environment of the TOE is necessary: when the security objective is 
achieved it actually contributes to the operational environment upholding the 
assumption. 
222 Note that the tracings from security objectives for the operational 
environment to assumptions provided in the security objectives rationale may 
be a part of a justification, but do not constitute a justification by themselves. 
Even in the case that a security objective of the operational environment is 
merely a restatement of a n assumption, a justification is required, but this 
justification may be as minimal as “Security Objective X directly upholds 
Assumption Y”. 
Class APE: Protection Profile evaluation 
Page 54 of 430 Version 3.1 April 2017 
9.7 Extended components definition (APE_ECD) 
9.7.1 Evaluation of sub-activity (APE_ECD.1) 
9.7.1.1 Objectives 
223 The objective of this s ub-activity is to determine whether extended 
components have been clearly and unambiguously defined, and whether they 
are necessary, i.e. they may not be clearly expressed using existing CC Part 2 
or CC Part 3 components. 
9.7.1.2 Input 
224 The evaluation evidence for this sub-activity is:  
a) the PP.  
9.7.1.3 Action APE_ECD.1.1E 
APE_ECD.1.1C The statement of security requirements shall identify all extended security 
requirements.  
APE_ECD.1-1 The evaluator shall check that all security requirements in the statement of 
security requirements that are not identified as extended requirements are 
present in CC Part 2 or in CC Part 3. 
APE_ECD.1.2C The extended components definition shall define an extended component 
for each extended security requirement.  
APE_ECD.1-2 The evaluator shall check  that the extended components definition defines 
an extended component for each extended security requirement. 
225 If the PP does not contain extended security requirements, this work unit is 
not applicable and therefore considered to be satisfied. 
226 A single extended component may be used to define multiple iterations of an 
extended security requirement, it is not necessary to repeat this definition for 
each iteration. 
APE_ECD.1.3C The extended components definition shall describe ho w each extended 
component is related to the existing CC components, families, and classes.  
APE_ECD.1-3 The evaluator shall examine  the extended components definition to 
determine that it describes how each exten ded component fits into the 
existing CC components, families, and classes. 
227 If the PP does not contain extended security requirements, this work unit is 
not applicable and therefore considered to be satisfied. 
228 The evaluator determines that each extended component is either:  
a) a member of an existing CC Part 2 or CC Part 3 family, or  
Class APE: Protection Profile evaluation 
April 2017 Version 3.1 Page 55 of 430 
b) a member of a new family defined in the PP.  
229 If the extended component is a member of an existing CC Part 2 or CC Part 3 
family, the evaluator determines that the extended compon ents definition 
adequately describes why the extended component should be a member of 
that family and how it relates to other components of that family. 
230 If the extended component is a member of a new family defined in the PP, 
the evaluator confirms that th e extended component is not appropriate for an 
existing family. 
231 If the PP defines new families, the evaluator determines that each new family 
is either:  
a) a member of an existing CC Part 2 or CC Part 3 class, or  
b) a member of a new class defined in the PP.  
232 If the family is a member of an existing CC Part 2 or CC Part 3 class, the 
evaluator determines that the extended components definition adequately 
describes why the family should be a member of that class and how it relates 
to other families in that class. 
233 If the family is a member of a new class defined in the PP, the evaluator 
confirms that the family is not appropriate for an existing class. 
APE_ECD.1-4 The evaluator shall examine  the extended components defini tion to 
determine that each definition of an extended component identifies all 
applicable dependencies of that component. 
234 If the PP does not contain extended security requirements, this work unit is 
not applicable and therefore considered to be satisfied. 
235 The evaluator confirms that no applicable dependencies have been 
overlooked by the PP author. 
APE_ECD.1.4C The extended components definition shall use the existing CC components, 
families, classes, and methodology as a model for presentation.  
APE_ECD.1-5 The evaluator shall examine  the extended components definition to 
determine that each extended functional component uses the existing CC Part 
2 components as a model for presentation. 
236 If the PP does not contain extended SFRs, this work unit is not applicable 
and therefore considered to be satisfied. 
237 The evaluator determines that the extended functional component is 
consistent with CC Part 2 Section 7.1.3, Component structure. 
238 If the extended functional component uses operations, the evaluator 
determines that the extended functional component is consistent with CC 
Part 1 Section 8.1, Operations. 
Class APE: Protection Profile evaluation 
Page 56 of 430 Version 3.1 April 2017 
239 If the extended functional component is hierarchical to an existing functional 
component, the evaluator determines that the extended functional component 
is consistent with CC Part 2 Section 7.2.1, Component changes highlighting. 
APE_ECD.1-6 The evaluator shall examine  the extended components definition to 
determine that each definition of a new functional family uses the existing 
CC functional families as a model for presentation. 
240 If the PP does not define new functional families, this work unit is not 
applicable and therefore considered to be satisfied. 
241 The evaluator determines that all new functional families are defined 
consistent with CC Part 2 Section 7.1.2, Family structure. 
APE_ECD.1-7 The evaluator shall examine  the extended components definition to 
determine that each definition of a new functional class uses the existing CC 
functional classes as a model for presentation. 
242 If the PP does not define new functional classes, this work unit is not 
applicable and therefore considered to be satisfied. 
243 The evaluator determines that all new functional classes are defined 
consistent with CC Part 2 Section 7.1.1, Class structure 
APE_ECD.1-8 The evaluator shall examine  the extended components definition to 
determine that each definition of an extended assurance compo nent uses the 
existing CC Part 3 components as a model for presentation. 
244 If the PP does not contain extended SARs, this work unit is not applicable 
and therefore considered to be satisfied. 
245 The evaluator determines that the extended assurance component def inition 
is consistent with CC Part 3 Section 7.1.3, Assurance component structure. 
246 If the extended assurance component uses operations, the evaluator 
determines that the extended assurance component is consistent with CC Part 
1 Section 8.1, Operations. 
247 If the extended assurance component is hierarchical to an existing assurance 
component, the evaluator determines that the extended assurance component 
is consistent with CC Part 3 Section 7.1.3, Assurance component structure. 
APE_ECD.1-9 The evaluator shall examine  the extended components definition to 
determine that, for each defined extended assurance component, applicable 
methodology has been provided. 
248 If the PP does not contain extended SARs, this work unit is not applicable 
and therefore considered to be satisfied. 
249 The evaluator determines that, for each evaluator action element of each 
extended SAR,  one or more work units are provided and that successfully 
Class APE: Protection Profile evaluation 
April 2017 Version 3.1 Page 57 of 430 
performing all work units for a given evaluator action element will 
demonstrate that the element has been achieved. 
APE_ECD.1-10 The evaluator shall e xamine the extended components definition to 
determine that each definition of a new assurance family uses the existing 
CC assurance families as a model for presentation. 
250 If the PP does not define new assurance families, this work unit is not 
applicable and therefore considered to be satisfied. 
251 The evaluator determines that all new assurance families are defined 
consistent with CC Part 3 Section 7.1.2, Assurance family structure. 
APE_ECD.1-11 The evaluator shall examine  the extended components definition to 
determine that each definition of a new assurance class uses the existing CC 
assurance classes as a model for presentation. 
252 If the PP does not define new assurance classe s, this work unit is not 
applicable and therefore considered to be satisfied. 
253 The evaluator determines that all new assurance classes are defined 
consistent with CC Part 3 Section 7.1.1, Assurance class structure. 
APE_ECD.1.5C The extended components shall consist of measurable and objective 
elements such that conformance or nonconformance to these elements can 
be demonstrated.  
APE_ECD.1-12 The evaluator shall examine  the extended components definition to 
determine that each element in each extended component is measurable and 
states objective evaluation requirements, such that conformance or 
nonconformance can be demonstrated. 
254 If the PP does not contain extended security requirements, this work unit is 
not applicable and therefore considered to be satisfied. 
255 The evaluator determines that elements of extended functional components 
are stated in such a way that they are testable,  and traceable through the 
appropriate TSF representations. 
256 The evaluator also determines that elements of extended assurance 
components avoid the need for subjective evaluator judgement. 
257 The evaluator is reminded that whilst being measurable and objective  is 
appropriate for all evaluation criteria, it is acknowledged that no formal 
method exists to prove such properties. Therefore the existing CC functional 
and assurance components are to be used as a model for determining what 
constitutes conformance to this requirement. 
Class APE: Protection Profile evaluation 
Page 58 of 430 Version 3.1 April 2017 
9.7.1.4 Action APE_ECD.1.2E 
APE_ECD.1-13 The evaluator shall examine  the extended components definition to 
determine that each extended component may not be clearly expressed using 
existing components. 
258 If the PP does not contain extended security requirements, this work unit is 
not applicable and therefore considered to be satisfied. 
259 The evaluator should take components from CC Part 2 and CC Part 3, other 
extended components that have been defined in the PP, combinations of 
these components, and possible operations on these components into account 
when making this determination. 
260 The evaluator is reminded that the role of this work unit is to preclude 
unnecessary duplication of components, that is, components that may be 
clearly expressed by using other components. The evaluator should not 
undertake an exhaustive search of all possible combinations of components 
including operations in an attempt to find a way  to express the extended 
component by using existing components. 
Class APE: Protection Profile evaluation 
April 2017 Version 3.1 Page 59 of 430 
9.8 Security requirements (APE_REQ) 
9.8.1 Evaluation of sub-activity (APE_REQ.1) 
9.8.1.1 Objectives 
261 The objective of this sub -activity is to determine whether the SFRs and 
SARs are clear, unambiguous and well -defined and whether they are 
internally consistent. 
9.8.1.2 Input 
262 The evaluation evidence for this sub-activity is:  
a) the PP.  
9.8.1.3 Action APE_REQ.1.1E 
APE_REQ.1.1C The statem ent of security requirements shall describe the SFRs and the 
SARs.  
APE_REQ.1-1 The evaluator shall check  that the statement of security requirements 
describes the SFRs. 
263 The evaluator determines that each SFR is identified by one of the following 
means:  
a) by reference to an individual component in CC Part 2;  
b) by reference to an extended component in the extended components 
definition of the PP;  
c) by reference to a PP that the PP claims to be conformant with;  
d) by reference to a security requirements package that the PP claims to 
be conformant with;  
e) by reproduction in the PP. 
264 It is not required to use the same means of identification for all SFRs. 
APE_REQ.1-2 The evaluator shall check  that the statement of security requirements 
describes the SARs. 
265 The evaluator determines that each SAR is identified by one of the following 
means:  
a) by reference to an individual component in CC Part 3;  
b) by reference to an extended component in the extended components 
definition of the PP;  
c) by reference to a PP that the PP claims to be conformant with;  
Class APE: Protection Profile evaluation 
Page 60 of 430 Version 3.1 April 2017 
d) by reference to a security requirements package that the PP claims to 
be conformant with;  
e) by reproduction in the PP. 
266 It is not required to use the same means of identification for all SARs. 
APE_REQ.1.2C All subjects, objects, operations, security attributes, external entities and 
other terms that are used in the SFRs and the SARs shall be defined.  
APE_REQ.1-3 The evaluator shall examine  the PP to determine that all subjects, objects, 
operations, security attributes, external entities and other terms that are used 
in the SFRs and the SARs are defined. 
267 The evaluator determines that the PP defines all:  
 (types of) subjects and objects that are used in the SFRs; 
 (types of) security attributes of subjects, users, objects, information, 
sessions and/or resources, possible values that these attributes may 
take and a ny relations between these values (e.g. top_secret is 
“higher” than secret); 
 (types of) operations that are used in the SFRs, including the effects 
of these operations; 
 (types of) external entities in the SFRs; 
 other terms that are introduced in the SFRs a nd/or SARs by 
completing operations, if these terms are not immediately clear, or 
are used outside their dictionary definition. 
268 The goal of this work unit is to ensure that the SFRs and SARs are well -
defined and that no misunderstanding may occur due to th e introduction of 
vague terms. This work unit should not be taken into extremes, by forcing 
the PP writer to define every single word. The general audience of a set of 
security requirements should be assumed to have a reasonable knowledge of 
IT, security and Common Criteria. 
269 All of the above may be presented in groups, classes, roles, types or other 
groupings or characterisations that allow easy understanding. 
270 The evaluator is reminded that these lists and definitions do not have to be 
part of the statement  of security requirements, but may be placed (in part or 
in whole) in different sections. This may be especially applicable if the same 
terms are used in the rest of the PP. 
APE_REQ.1.3C The statement of secu rity requirements shall identify all operations on the 
security requirements.  
APE_REQ.1-4 The evaluator shall check  that the statement of security requirements 
identifies all operations on the security requirements. 
Class APE: Protection Profile evaluation 
April 2017 Version 3.1 Page 61 of 430 
271 The evaluator determines that all operations are identified in each SFR or 
SAR where such an operation is used. This includes both completed 
operations and uncompleted operations. Identification may be achieved by 
typographical distinctions, or by exp licit identification in the surrounding 
text, or by any other distinctive means. 
APE_REQ.1.4C All operations shall be performed correctly.  
APE_REQ.1-5 The evaluato r shall examine  the statement of security requirements to 
determine that all assignment operations are performed correctly. 
272 Guidance on the correct performance of operations may be found in CC Part 
1 Annex C, Guidance for Operations. 
APE_REQ.1-6 The evaluator shall examine  the statement of security requirements to 
determine that all iteration operations are performed correctly. 
273 Guidance on the correct performance of operation s may be found in CC Part 
1 Annex C, Guidance for Operations. 
APE_REQ.1-7 The evaluator shall examine  the statement of security requirements to 
determine that all selection operations are performed correctly. 
274 Guidance on the correct performance of operations may be found in CC Part 
1 Annex C, Guidance for Operations. 
APE_REQ.1-8 The evaluator shall examine  the statement of security requirements to 
determine that all refinement operations are performed correctly. 
275 Guidance on the correct performance of operations may be found in CC Part 
1 Annex C, Guidance for Operations. 
APE_REQ.1.5C Each dependency of the security requirements shall either be satisfied, or 
the security requirements rationale shall justify the dependency not being 
satisfied.  
APE_REQ.1-9 The evaluator shall examine  the statement of security requirements to 
determine that each dependency of the security requirements is either 
satisfied, or that the security requirements rationale justifies the dependency  
not being satisfied. 
276 A dependency is satisfied by the inclusion of the relevant component (or one 
that is hierarchical to it) within the statement of security requirements. The 
component used to satisfy the dependency should, if necessary, be modified 
by operations to ensure that it actually satisfies that dependency. 
277 A justification that a dependency is not met should address either:  
a) why the dependency is not necessary or useful, in which case no 
further information is required; or  
Class APE: Protection Profile evaluation 
Page 62 of 430 Version 3.1 April 2017 
b) that the dependency h as been addressed by the operational 
environment of the TOE, in which case the justification should 
describe how the security objectives for the operational environment 
address this dependency.  
APE_REQ.1.6C The statement of security requirements shall be internally consistent.  
APE_REQ.1-10 The evaluator shall examine  the statement of security requirements to 
determine that it is internally consistent. 
278 The evalua tor determines that the combined set of all SFRs and SARs is 
internally consistent. 
279 The evaluator determines that on all occasions where different security 
requirements apply to the same types of developer evidence, events, 
operations, data, tests to be pe rformed etc. or to “all objects”, “all subjects” 
etc., that these requirements do not conflict. 
280 Some possible conflicts are:  
a) an extended SAR specifying that the design of a certain 
cryptographic algorithm is to be kept secret, and another extended 
SAR specifying an open source review;  
b) FAU_GEN.1 Audit data generation specifying that subject identity is 
to be logged, FDP_ACC.1 Subset access control  specifying who has 
access to these logs, and FPR_UNO.1 Unobservability  specifying 
that some actions of subjects should be unobservable to other subjects. 
If the subject that should not be able to see an activity may access 
logs of this activity, these SFRs conflict;  
c) FDP_RIP.1 Subset residual information protection  specifying 
deletion of information no longer needed, and FDP_ROL.1 Basic 
rollback specifying that a TOE may return to a previous state. If the 
information that is needed for the rollback to the previo us state has 
been deleted, these requirements conflict;  
d) Multiple iterations of FDP_ACC.1 Subset access control  especially 
where some iterations cover the same subjects, objects, or operations. 
If one access control SFR allows a subject to perform an operation on 
an object, while another access control SFR does not allow this, these 
requirements conflict.  
9.8.2 Evaluation of sub-activity (APE_REQ.2) 
9.8.2.1 Objectives 
281 The objective of this sub -activity is to determine whether the SFRs and 
SARs are c lear, unambiguous and well -defined, whether they are internally 
consistent, and whether the SFRs meet the security objectives of the TOE. 
Class APE: Protection Profile evaluation 
April 2017 Version 3.1 Page 63 of 430 
9.8.2.2 Input 
282 The evaluation evidence for this sub-activity is:  
a) the PP.  
9.8.2.3 Action APE_REQ.2.1E 
APE_REQ.2.1C The statement of security requirements shall describe the SFRs and the 
SARs.  
APE_REQ.2-1 The evaluator shall check  that the statement of  security requirements 
describes the SFRs. 
283 The evaluator determines that each SFR is identified by one of the following 
means:  
a) by reference to an individual component in CC Part 2;  
b) by reference to an extended component in the extended components 
definition of the PP;  
c) by reference to an individual component in a PP that the PP claims to 
be conformant with;  
d) by reference to an individual component in a security requirements 
package that the PP claims to be conformant with;  
e) by reproduction in the PP. 
284 It is not required to use the same means of identification for all SFRs. 
APE_REQ.2-2 The evaluator shall check  that the statement of security requirements 
describes the SARs. 
285 The evaluator determines that each SAR is identified by one of the following 
means:  
a) by reference to an individual component in CC Part 3;  
b) by reference to an extended component in the extended components 
definition of the PP;  
c) by reference to an individual component in a PP that the PP claims to 
be conformant with;  
d) by reference to an individual component in a security requirements 
package that the PP claims to be conformant with;  
e) by reproduction in the PP. 
286 It is not required to use the same means of identification for all SARs. 
Class APE: Protection Profile evaluation 
Page 64 of 430 Version 3.1 April 2017 
APE_REQ.2.2C All subjects, objects, operations, security attributes, external entities and 
other terms that are used in the SFRs and the SARs shall be defined.  
APE_REQ.2-3 The evaluator shall examine  the PP to determine that all subjects, objects, 
operations, security attributes, external entities and other terms that are used 
in the SFRs and the SARs are defined. 
287 The evaluator determines that the PP defines all:  
 (types of) subjects and objects that are used in the SFRs; 
 (types of) security attributes of subjects, users, objects, information, 
sessions and/or resources, possible values that these attributes may 
take and any relations between these values (e.g. top_secret is 
“higher” than secret); 
 (types of) operations that are used in the SFRs, including the effects 
of these operations; 
 (types of) external entities in the SFRs; 
 other terms that are introduced in the SFRs and/or SARs by 
completing operations, if these terms are not imm ediately clear, or 
are used outside their dictionary definition. 
288 The goal of this work unit is to ensure that the SFRs and SARs are well -
defined and that no misunderstanding may occur due to the introduction of 
vague terms. This work unit should not be tak en into extremes, by forcing 
the PP writer to define every single word. The general audience of a set of 
security requirements should be assumed to have a reasonable knowledge of 
IT, security and Common Criteria. 
289 All of the above may be presented in groups , classes, roles, types or other 
groupings or characterisations that allow easy understanding. 
290 The evaluator is reminded that these lists and definitions do not have to be 
part of the statement of security requirements, but may be placed (in part or 
in whole) in different sections. This may be especially applicable if the same 
terms are used in the rest of the PP. 
APE_REQ.2.3C The statement of security requirements shall identify all operations on the 
security requirements.  
APE_REQ.2-4 The evaluator shall check  that the statement of security requirements 
identifies all operations on the security requirements. 
291 The evaluator determines that all operations are identifie d in each SFR or 
SAR where such an operation is used. This includes both completed 
operations and uncompleted operations. Identification may be achieved by 
typographical distinctions, or by explicit identification in the surrounding 
text, or by any other distinctive means. 
Class APE: Protection Profile evaluation 
April 2017 Version 3.1 Page 65 of 430 
APE_REQ.2.4C All operations shall be performed correctly.  
APE_REQ.2-5 The evaluator shall examine  the statement of security requirements to 
determine that all assignment operations are performed correctly. 
292 Guidance on the correct performance of operations may be found in CC Part 
1 Annex C, Guidance for Operations. 
APE_REQ.2-6 The evaluator shall examine  the statement of security requirements to 
determine that all iteration operations are performed correctly. 
293 Guidance on the correct performance of operations may be found in CC Part 
1 Annex C, Guidance for Operations. 
APE_REQ.2-7 The evaluator shall examine  the statement of security requirements to 
determine that all selection operations are performed correctly. 
294 Guidance on the correct per formance of operations may be found in CC Part 
1 Annex C, Guidance for Operations. 
APE_REQ.2-8 The evaluator shall examine  the statement of security requirements to 
determine that all refinement operations are performed correctly. 
295 Guidance on the correct performance of operations may be found in CC Part 
1 Annex C, Guidance for Operations. 
APE_REQ.2.5C Each dependency of the security requirements shall either be satisfied, or 
the security requirements rationale shall justify the dependency not being 
satisfied.  
APE_REQ.2-9 The evaluator shall examin e the statement of security requirements to 
determine that each dependency of the security requirements is either 
satisfied, or that the security requirements rationale justifies the dependency 
not being satisfied. 
296 A dependency is satisfied by the inclusio n of the relevant component (or one 
that is hierarchical to it) within the statement of security requirements. The 
component used to satisfy the dependency should, if necessary, be modified 
by operations to ensure that it actually satisfies that dependency. 
297 A justification that a dependency is not met should address either:  
a) why the dependency is not necessary or useful, in which case no 
further information is required; or  
b) that the dependency has been addressed by the operational 
environment of the TOE, in  which case the justification should 
describe how the security objectives for the operational environment 
address this dependency.  
APE_REQ.2.6C The security requirements rationale shall trace each SFR back t o the 
security objectives for the TOE.  
Class APE: Protection Profile evaluation 
Page 66 of 430 Version 3.1 April 2017 
APE_REQ.2-10 The evaluator shall check that the security requirements rationale traces each 
SFR back to the security objectives for the TOE. 
298 The evaluator determines that each SFR is traced back to at least one security 
objective for the TOE. 
299 Failure to trace implies that either the security requirements rationale is 
incomplete, the security objectives for the TOE are incomplete, or the SFR 
has no useful purpose. 
APE_REQ.2.7C The security requirements rationale shall demonstrate that the SFRs meet 
all security objectives for the TOE.  
APE_REQ.2-11 The evaluator shall examine the security requirements rationale to determine 
that for each security objective for the TOE it justifies that the SFRs are 
suitable to meet that security objective for the TOE. 
300 If no SFRs trace back to the security objective for the TOE, the evaluator 
action related to this work unit is assigned a fail verdict. 
301 The evaluator determines that the justification for a security objective for the 
TOE demonstrates that the SFRs are sufficient: if all SFRs that trace back to 
the objective are satisfied, the security objective for the TOE is achieved. 
302 If the SFRs that trace back to a security objective for the TOE have any 
uncompleted assignments, or uncompleted or restricted selections, the 
evaluator determines that for every conceivable completion or combination 
of completions of these operations, the security objective is still met. 
303 The evaluator also determines that each SFR that traces back to a security 
objective for the TOE is necessary: when the SFR is satisfied, it actually 
contributes to achieving the security objective. 
304 Note that the tracings from SFRs to security objectives for the TOE provided 
in the security requirements rationale may be a part of the justification, but 
do not constitute a justification by themselves. 
APE_REQ.2.8C The security requirements rationale shall explain why the SARs were 
chosen.  
APE_REQ.2-12 The evaluator shall check  that the security requirements rationale explains 
why the SARs were chosen. 
305 The evaluator is reminded that any explanation is correct, as long as it is 
coherent and neither the SARs nor the explanation have obvious 
inconsistencies with the remainder of the PP. 
306 An example of an obvious inconsistency between the SARs and the 
remainder of the PP would be to have threat agents that are very capable, but 
an AVA_VAN SAR that does not protect against these threat agents. 
APE_REQ.2.9C The statement of security requirements shall be internally consistent.  
Class APE: Protection Profile evaluation 
April 2017 Version 3.1 Page 67 of 430 
APE_REQ.2-13 The evaluator shall examine  the statement of security requirements to 
determine that it is internally consistent. 
307 The evaluator determines that th e combined set of all SFRs and SARs is 
internally consistent. 
308 The evaluator determines that on all occasions where different security 
requirements apply to the same types of developer evidence, events, 
operations, data, tests to be performed etc. or to “al l objects”, “all subjects” 
etc., that these requirements do not conflict. 
309 Some possible conflicts are:  
a) an extended SAR specifying that the design of a certain 
cryptographic algorithm is to be kept secret, and another extended 
SAR specifying an open source review;  
b) FAU_GEN.1 Audit data generation specifying that subject identity is 
to be logged, FDP_ACC.1 Subset access control  specifying who has 
access to these logs, and FPR_UNO.1 Unobservability  specifying 
that some actions of subjects should be unobservable to other subjects. 
If the subject that should not be able to see an activity may access 
logs of this activity, these SFRs conflict;  
c) FDP_RIP.1 Subset residual information protection  specifying 
deletion of information no longer needed, and FDP_ROL.1 Basic 
rollback specifying that a TOE may return to a previous state. If the 
information that is needed for the rollback to the previous state has 
been deleted, these requirements conflict;  
d) Multiple iterations of FDP_ACC.1 Subset access control  especially 
where some iterations cover the same subjects, objects, or operations. 
If one access control SFR allows a subject to perform an operat ion on 
an object, while another access control SFR does not allow this, these 
requirements conflict.  
Class ACE: Protection Profile Configuration evaluation 
Page 68 of 430 Version 3.1 April 2017 
10 Class ACE: Protection Profile 
Configuration evaluation 
10.1 Introduction 
310 All Base -PP(s) referenced in the PP -Module must be evaluated before the 
evaluation of a PP-Configuration. 
311 One possibility for evaluating a PP -Configuration is to flatten all the 
components of the PP(s) and PP -Modules composing the PP -Configuration 
and evaluating the resulting PP as a standard PP. 
312 Another possibility for evaluation of a PP -Configuration composed of 
several PP-Modules proceeds PP -Module by PP -Module. Considering a PP -
Configuration composed of the Protection Profiles P i and the PP-Modules Mj, 
evaluation of the PP -Configuration proceeds with the following steps, 
illustrated in Figure 6:  
a) first evaluating independently all Protection Profiles Pi; 
b) evaluating the PP -Configuration C1 composed of the PP -Module M1 
with the Protection Profiles Pi; 
c) evaluating the PP -Configuration C i+1 composed of the PP -Module 
Mi+1 with the PP -Configuration C i considered as a standard PP (cf. 
Section B.13 in CC Part 1); 
d) iterating the step 3 for all the PP-Modules. 
313 Steps 2 and 3 are themselves performed in two steps:  
a) Evaluation of the PP -Module with its Base -PP(s) (Evaluation of sub-
activity (ACE_MCO.1)) 
b) Extension of the evaluation (consistency assessment) to the other 
elements of the PP -Configuration ( Evaluation of sub -activity 
(ACE_CCO.1)) 
Class ACE: Protection Profile Configuration evaluation 
April 2017 Version 3.1 Page 69 of 430 
 
Figure 6 - Evaluation of a PP-Configuration 
314 The ACE evaluation methodology is based on APE's. The common parts are 
not duplicated in this document but referred to. 
Class ACE: Protection Profile Configuration evaluation 
Page 70 of 430 Version 3.1 April 2017 
10.2 PP-Module introduction (ACE_INT) 
10.2.1 Evaluation of sub-activity (ACE_INT.1) 
10.2.1.1 Objectives 
315 The objective of this sub -activity is to determine whether the PP -Module is 
correctly identified, and whether the Base -PP(s) and TOE overview are 
consistent with each other. 
10.2.1.2 Input 
316 The evaluation evidence for this sub-activity is:  
a) the PP-Module; 
b) its Base-PP(s) 
10.2.1.3 Application notes 
317 All actions of APE_INT.1.1E hold. 
10.2.1.4 Action ACE_INT.1.1E 
ACE_INT.1.1C The PP -Module introduction shall uniquely identify all the Base -PPs on 
which the PP -Module relies, including their logical structuring and 
relationship to the PP-Module according to CC Part 1, section B.14.3.2. 
ACE_INT.1-1 The evaluator shall check  that the PP -Module introduction identifies the  
Base-PP(s) on which the PP-Module relies. 
ACE_INT.1.2C The TOE overview shall identify the differences introduced by the PP -
Module with respect to the TOE overview of its Base-PP(s). 
ACE_INT.1-2 The evaluator shall check that the TOE overview identifies the differences 
introduced by the PP -Module with respect to the TOE overview of its Base -
PP(s). 
Class ACE: Protection Profile Configuration evaluation 
April 2017 Version 3.1 Page 71 of 430 
10.3 PP-Module conformance claims (ACE_CCL) 
10.3.1 Evaluation of sub-activity (ACE_CCL.1) 
10.3.1.1 Objectives 
318 The objective of this sub -activity is to determine the validity of various 
conformance claims. These describe how the PP-Module conforms to the CC 
Part 2 and SFR packages. 
10.3.1.2 Input 
319 The evaluation evidence for this sub-activity is:  
a) the PP-Module; 
b) the SFR package(s) that the PP claims conformance to. 
10.3.1.3 Action ACE_CCL.1.1E 
ACE_CCL.1.1C The conformance claim shall contain a CC conformance claim that 
identifies the version of the CC to which the PP -Module claims 
conformance.  
ACE_CCL.1-1 The evaluator shall check  that the conformance claim contains a CC 
conformance claim that identifies the version of the CC to  which the PP -
Module claims conformance. 
320 The evaluator determines that the CC conformance claim identifies the 
version of the CC that was used to develop this PP -Module. This should 
include the version number of the CC and, unless the International English  
version of the CC was used, the language of the version of the CC that was 
used. 
ACE_CCL.1.2C The CC conformance claim shall describe the conformance of the PP -
Module to CC Part 2 as either CC Part 2 conform ant or CC Part 2 
extended.  
ACE_CCL.1-2 The evaluator shall check that the CC conformance claim states a claim of 
either CC Part 2 conformant or CC Part 2 extended for the PP-Module. 
ACE_CCL.1.3C The conformance claim shall identify all security functional requirement 
packages to which the PP-Module claims conformance 
ACE_CCL.1-3 The evaluator shall check  that the conforman ce claim contains a package 
claim that identifies all security functional requirement packages to which 
the PP-Module claims conformance. 
321 If the PP -Module does not claim conformance to a security functional 
requirement package, this work unit is not applic able and therefore 
considered to be satisfied. 
Class ACE: Protection Profile Configuration evaluation 
Page 72 of 430 Version 3.1 April 2017 
322 The evaluator determines that any referenced security functional requirement 
packages are unambiguously identified (e.g. by title and version number, or 
by the identification included in the introduction of th at security functional 
requirement package). 
323 The evaluator is reminded that claims of partial conformance to a security 
functional requirement package are not permitted. 
ACE_CCL.1.4C The CC conformance claim shall be consistent with the extended 
components definition. 
ACE_CCL.1-4 The evaluator shall examine  the CC conformance claim for CC Part 2 to 
determine that it is consistent with the extended components definition. 
324 If the CC conformance claim contains CC Part 2 conformant, the evaluator 
determines that the extended components definition does not define 
functional components. 
325 If the CC conformance claim contains CC Part 2 extended, the evaluator 
determines that th e extended components definition defines at least one 
extended functional component. 
Class ACE: Protection Profile Configuration evaluation 
April 2017 Version 3.1 Page 73 of 430 
10.4 PP-Module Security problem definition (ACE_SPD) 
10.4.1 Evaluation of sub-activity (ACE_SPD.1) 
10.4.1.1 Application notes 
326 All actions of APE_SPD.1.1E hold. 
Class ACE: Protection Profile Configuration evaluation 
Page 74 of 430 Version 3.1 April 2017 
10.5 PP-Module Security objectives (ACE_OBJ) 
10.5.1 Evaluation of sub-activity (ACE_OBJ.1) 
10.5.1.1 Application notes 
327 All actions of APE_OBJ.2.1E hold. 
Class ACE: Protection Profile Configuration evaluation 
April 2017 Version 3.1 Page 75 of 430 
10.6 PP-Module extended components definition (ACE_ECD) 
10.6.1 Evaluation of sub-activity (ACE_ECD.1) 
10.6.1.1 Application notes 
328 All actions of APE_ECD.1.1E hold. 
Class ACE: Protection Profile Configuration evaluation 
Page 76 of 430 Version 3.1 April 2017 
10.7 PP-Module security requirements (ACE_REQ) 
10.7.1 Evaluation of sub-activity (ACE_REQ.1) 
10.7.1.1 Application notes 
329 All actions of APE_REQ.2.1E hold without considering the SAR part which 
is empty in PP-Modules. 
Class ACE: Protection Profile Configuration evaluation 
April 2017 Version 3.1 Page 77 of 430 
10.8 PP-Module consistency (ACE_MCO) 
10.8.1 Evaluation of sub-activity (ACE_MCO.1) 
10.8.1.1 Objectives 
330 The objective of this sub -activity is to determine the consistency of the PP -
Module regarding its Base-PP(s). 
10.8.1.2 Input 
331 The evaluation evidence for this sub-activity is:  
a) the PP-Module; 
b) its Base-PP(s). 
10.8.1.3 Action ACE_MCO.1.1E 
ACE_MCO.1.1C The consistency rationale shall demonstrate that the TOE type of the PP -
Module is consistent with the TOE type(s) in the Base -PPs identified in the 
PP-Module introduction. 
ACE_MCO.1-1 The evaluator shall examine the consistency rationale to determine that the 
TOE type of the PP-Module is consistent with all the TOE types of the Base -
PP(s). 
332 The relation between the types may be simple: a PP-Module may consider a 
TOE that provides additional security functionality regarding, or more 
complex: a TOE that provides a given security functionality in a specific way. 
ACE_MCO.1.2C The consistency ra tionale shall demonstrate that the statement of the 
security problem definition is consistent with the statement of the security 
problem definition in the Base -PPs identified in the PP -Module 
introduction. 
ACE_MCO.1-2 The evaluator shall examine  the PP -Module consistency rationale to 
determine that it demonstrates that the statement of security problem 
definition of the PP -Module is consistent with the statements of security 
problem definition stated in its Base-PPs. 
333 In particular, the evaluator examines the consistency rationale to determine 
that:  
a) the statements of threats, assumptions and OSPs in the PP -Module do 
not contradict those from the Base-PP(s). 
b) the statement of assumptions in the PP -Module addresses aspects out 
of scope of the Base -PP, in which case, the addition of elements is 
allowed. 
Class ACE: Protection Profile Configuration evaluation 
Page 78 of 430 Version 3.1 April 2017 
ACE_MCO.1.3C The consistency rationale shall demonstrate that the statement of security 
objectives is consistent with the  statement of security objectives in the 
Base-PPs identified in the PP-Module introduction. 
ACE_MCO.1-3 The evaluator shall examine the consistency rationale to determine that the 
statement of security objectives  of the PP -Module is consistent with the 
statement of security objectives of its Base-PP(s). 
334 In particular, the evaluator examines the consistency rationale to determine 
that:  
a) the statements of the security objectives for the TOE and the security 
objectives for the operational environment in the PP -Module do not 
contradict those from the Base-PPs. 
b) the statement of the security objectives for the operational 
environment in the PP -Module addresses aspects out of scope of the 
Base-PP, in which case, the addition of elements is allowed. 
ACE_MCO.1.4C The consistency rationale shall demonstrate that the statement of security 
requirements is consistent with the statement of security requirements in 
the Base-PPs identified in the PP-Module introduction. 
ACE_MCO.1-4 The evaluator shall examine the consistency rationale to determine that the 
statement of security requirements of the PP -Module is consistent with the 
statement of security requirements of its Base -PPs, that is, the SFRs of the 
PP-Module either complete or refine the SFRs of the Base -PP(s) and that no 
contradiction arises from the whole set of SFRs of the PP -Module and the 
Base-PP(s). 
Class ACE: Protection Profile Configuration evaluation 
April 2017 Version 3.1 Page 79 of 430 
10.9 PP-Configuration consistency (ACE_CCO) 
10.9.1 Evaluation of sub-activity (ACE_CCO.1) 
10.9.1.1 Objectives 
335 The objective of this sub -activity is to determine whether the PP -
Configuration and its components are correctly identified. 
336 The objective of this sub -activity is also to determine the consistency of the 
PP-Configuration regarding the whole set of Protection Profiles and PP -
Modules. 
337 For the consistency analysis required by this activity, the application notes of 
the CEM, Section 9.2.1 (9.2.1, Re-using the evalu ation results of certified 
PPs), is applicable to determine which parts of the Base -PPs are to be re -
evaluated during the evaluation of PP-Configuration 
10.9.1.2 Input 
338 The evaluation evidence for this sub-activity is:  
a) the PP-Configuration reference; 
b) the PP-Configuration components statement; 
c) the PP(s) and PP-Modules identified in the components statement. 
10.9.1.3 Action ACE_CCO.1.1E 
ACE_CCO.1.1C The PP -Configuration reference shall uniquely identify the PP -
Configuration. 
ACE_CCO.1-1 The evaluator shall examine  the PP -Configuration reference to determine 
that it uniquely identifies the PP-Configuration. 
339 The evaluator determines that the PP -Configuration reference identifies the 
PP-Configuration itself, so that it may be easily distinguished from other PPs, 
PP-Configurations and PP-Modules, and that it also uniquely identifies each 
version of the PP-Configuration, e.g. by including a version number and/or a 
date of publication. 
340 The PP-Configuration should have some referencing system that is capable 
of supporting unique references (e.g. use of numbers, letters or dates). 
ACE_CCO.1.2C The components statements shall uniquely identify the Protection Profiles 
and the PP-Modules that compose the PP-Configuration. 
ACE_CCO.1-2 The evaluator shall examine the PP-Configuration components statement to 
determine that it uniquely identifies the Protection Profiles and PP -Modules 
contained in the PP-Configuration. 
Class ACE: Protection Profile Configuration evaluation 
Page 80 of 430 Version 3.1 April 2017 
341 The Protection Profiles should have been certified and available for use in 
security targets. 
ACE_CCO.1.3C The conformance statement shall specify the kind of conformity of the PP -
Configuration, either strict or demonstrable. The conformance claim shall 
contain a CC conformance claim that identifies the ve rsion of the CC to 
which the PP -Configuration and its underlying Base -PP(s) and PP -
Module claim conformance. 
ACE_CCO.1-3 The evaluator shall examine the PP-Configuration conformance statement to 
determine that it  specifies the kind of conformity required: strict or 
demonstrable. 
342 The evaluator shall check  that the conformance claim contains a CC 
conformance claim that identifies the version of the CC to which the PP -
Configuration and its underlying Base -PP(s) and P P-Module claim 
conformance. 
343 The evaluator shall examine  the PP -Configuration conformance claim to 
determine the compatibility between all CC versions that are related to the 
PP-Configuration and its underlying Base-PP(s) and PP-Module. 
344 If at least one of t he Protection Profiles identified in the PP -Configuration 
components statement claims strict conformance, then the PP -Configuration 
conformance claim has to state strict conformance also. CC versions used in 
a PP-Configuration and its underlying Base-PP(s) and PP-Module have to be 
compatible. If compatibility is not obvious, guidance from the certification 
scheme should be asked. 
ACE_CCO.1.4C The SAR statement shall specify the set of SAR or predefined EAL tha t 
applies to this PP-Configuration. 
ACE_CCO.1-4 The evaluator shall examine  the PP -Configuration SAR statement to 
determine that it specifies a well-formed package of SAR. The SAR package 
can be build in with com ponents from CC Part 3 or can refer to a specific 
SAR package stated in one of the Protection Profiles composing the PP -
Configuration. 
345 If the set of SAR comes from CC Part 3 then the evaluator shall check that it 
is well-formed: it is closed by dependencies or the SAR statements provide a 
sound discarding rationale. 
346 The evaluator shall check  that the set of SAR of the PP -Configuration is 
consistent with respect to the SARs of each of the Protection Profiles 
contained in the PP -Configuration: for any SAR com ponent in each of the 
Protection Profile, the PP-Configuration provides either the same component 
or a higher component in the family hierarchy. If the SAR component in the 
Protection Profile is a refinement of a standard component, then the 
correspondent SAR component in the PP -Configuration has to include these 
refinements. If two Protection Profiles refine the same SAR component, the 
Class ACE: Protection Profile Configuration evaluation 
April 2017 Version 3.1 Page 81 of 430 
evaluator shall check that the refinements are not contradictory and that the 
corresponding SAR component in the PP-Configuration meets both. 
ACE_CCO.1.5C The Base -PP(s) on which the PP -Modules relies shall belong the 
Protection Profiles identified in the components statement of the PP -
Configuration. 
ACE_CCO.1-5 The evaluator shall check that the Base-PP(s) of the PP-Module are included 
in the set of PP(s) selected for the PP-Configuration. 
10.9.1.4 Action ACE_CCO.1.2E 
ACE_CCO.1-6 The evaluator shall check  that the PP -Configuration made up of all the 
Protection Profiles and PP -Modules identified in the components statement 
of the PP -Configuration is consistent. That is, the evaluator shall check that 
no cont radiction arises from the whole set of Protection Profiles and PP -
Modules included in the PP-Configuration. 
347 The evaluator can organise this work in many ways; the actual organisation 
may depend on the will to derive evaluation results for more than one PP -
Configuration at a time. 
348 For instance, the evaluator can process in two steps as follows:  
a) Assess the consistency of the set of Protection Profiles composing the 
PP-Configuration, 
b) Then proceed with the assessment of the PP -Configuration 
consistency incrementally, by adding one PP-Module at a time. 
349 An alternative is to proceed incrementally but mixing PPs and PP -Modules 
or to flatten the definition of the PP -Configuration (cf. Annex B in CC Part 
1) and to assess the consistency of the whole set of elements. 
350 Any incremental consistency analysis step where C is a subset of the PP -
Configuration and X is a PP or a PP -Module that has to be added to C 
consists in:  
 assessing that the SPD, the objectives and the SFRs o f X do not 
contradict the statements in C; 
 the assumptions and objectives for the environment in X either are 
the same as in C or address security aspects that are out of the scope 
of C. 
351 Note that if X is a PP -Module, C contains all its Base -PP(s) and Evaluation 
of sub -activity (ACE_MCO.1)  has succeed for X, then the consistency 
analysis step has to be performed with respect to the components of C 
different from these Base-PP(s) only. 
Class ASE: Security Target evaluation 
Page 82 of 430 Version 3.1 April 2017 
11 Class ASE: Security Target evaluation 
11.1 Introduction 
352 This Chapter describes the evaluation of an ST. The ST evaluation should be 
started prior to any TOE evaluation sub -activities since the ST provides the 
basis and context to perform these sub -activities. The evaluation 
methodology in this section is based on the requirements on the ST as 
specified in CC Part 3 class ASE. 
353 This Chapter should be used in conjunction with Annexes A, B and C, 
Guidance for Operations in CC Part 1, as these Annexes clarify the concepts 
here and provide many examples. 
11.2 Application notes 
11.2.1 Re-using the evaluation results of certified PPs 
354 While evaluating an ST that is based on one  or more certified PPs, it may be 
possible to re-use the fact that these PPs were certified. The potential for re -
use of the result of a certified PP is greater if the ST does not add threats, 
OSPs, assumptions, security objectives and/or security requirem ents to those 
of the PP. If the ST contains much more than the certified PP, re-use may not 
be useful at all. 
355 The evaluator is allowed to re -use the PP evaluation results by doing certain 
analyses only partially or not at all if these analyses or parts the reof were 
already done as part of the PP evaluation. While doing this, the evaluator 
should assume that the analyses in the PP were performed correctly. 
356 An example would be where the PP contains a set of security requirements, 
and these were determined to be internally consistent during the PP 
evaluation. If the ST uses the exact same requirements, the consistency 
analysis does not have to be repeated during the ST evaluation. If the ST 
adds one or more requirements, or performs operations on these requirements, 
the analysis will have to be repeated. However, it may be possible to save 
work in this consistency analysis by using the fact that the original 
requirements are internally consistent. If the original requirements are 
internally consistent, the evaluator only has to determine that:  
a) the set of all new and/or changed requirements is internally consistent, 
and  
b) the set of all new and/or changed requirements is consistent with the 
original requirements. 
357 The evaluator notes in the ETR each case where anal yses are not done or 
only partially done for this reason. 
Class ASE: Security Target evaluation 
April 2017 Version 3.1 Page 83 of 430 
11.3 ST introduction (ASE_INT) 
11.3.1 Evaluation of sub-activity (ASE_INT.1) 
11.3.1.1 Objectives 
358 The objective of this sub -activity is to determine whether the ST and the 
TOE are correctly identified, whether the TOE i s correctly described in a 
narrative way at three levels of abstraction (TOE reference, TOE overview 
and TOE description), and whether these three descriptions are consistent 
with each other. 
11.3.1.2 Input 
359 The evaluation evidence for this sub-activity is:  
a) the ST.  
11.3.1.3 Action ASE_INT.1.1E 
ASE_INT.1.1C The ST introduction shall contain an ST reference, a TOE reference, a 
TOE overview and a TOE description.  
ASE_INT.1-1 The evaluator shall check that the ST introduction contains an ST reference, 
a TOE reference, a TOE overview and a TOE description. 
ASE_INT.1.2C The ST reference shall uniquely identify the ST.  
ASE_INT.1-2 The evaluator shall examine the ST reference to determine that it uniquely 
identifies the ST. 
360 The evaluator determines that the ST reference identifies the ST itself, so that 
it may be easily distinguished from other STs, and that it also uniquely 
identifies each version of the ST, e.g. by including a version number and/or a 
date of publication. 
361 In evaluations where a CM system is provided, the evaluator may validate 
the uniquene ss of the reference by checking the configuration list. In the 
other cases, the ST should have some referencing system that is capable of 
supporting unique references (e.g. use of numbers, letters or dates). 
ASE_INT.1.3C The TOE reference shall uniquely identify the TOE.  
ASE_INT.1-3 The evaluator shall examine the TOE reference to determine that it uniquely 
identifies the TOE. 
362 The evaluator determines that the TOE reference uniquely identifies the TOE, 
so that it is clear to which TOE the ST refers, and that it also identifies the 
version of the TOE, e.g. by including a version/release/build number, or a 
date of release. 
Class ASE: Security Target evaluation 
Page 84 of 430 Version 3.1 April 2017 
363 In the end of the evaluation, the evaluator shall check  the TOE reference, 
and any unique identifiers associated with the TOE physical components are 
consistent with the identifier(s) assigned to the TOE evaluated in work units 
related to ALC_CMC.x.1C and the configuration list evaluated in work units  
related to ALC_CMS.x.2C. 
ASE_INT.1-4 The evaluator shall examine  the TOE reference to determine that it is not 
misleading. 
364 If the TOE is related to one or more well -known products, it is allowed to 
reflect this in the TOE reference. However, this should not be used to 
mislead consumers and it must be made clear which part of the product has 
been evaluated. 
365 When a TOE needs some required non -TOE hardware/software/firmware to 
run properly, the TOE reference may inc lude the name of the non -TOE 
hardware/software/firmware used by the TOE, however it must be made 
clear that the non-TOE hardware/software/firmware has not been evaluated. 
ASE_INT.1.4C The TOE overview shall s ummarise the usage and major security features 
of the TOE.  
ASE_INT.1-5 The evaluator shall examine the TOE overview to determine that it describes 
the usage and major security features of the TOE. 
366 The TOE overview should briefly (i.e. several paragraphs) describe the usage 
and major security features of the TOE. The TOE overview should enable 
potential consumers to quickly determine whether the TOE may be suitable 
for their security needs. 
367 The TOE overview may de scribe security features that provided by the 
product, and users may expect in that product type, but it must be clear those 
features that are evaluated and those are not evaluated. 
368 The TOE overview shall be consistent with information provided in other 
sections of the Security Target such as the TOE description, the security 
objectives, the security functional requirements, and the TOE summary 
specification. In addition to ensuring the evaluated security features are 
consistently described throughout the ST, this means that any security feature 
that is not evaluated is only discussed within the ST introduction. 
369 The TOE overview in an ST for a composed TOE should describe the usage 
and major security feature of the composed TOE, rather than those of the 
individual component TOEs. 
370 The evaluator determines that the overview is clear enough for consumers, 
and sufficient to give them a general understanding of the intended usage and 
major security features of the TOE. 
ASE_INT.1.5C The TOE overview shall identify the TOE type.  
ASE_INT.1-6 The evaluator shall check that the TOE overview identifies the TOE type. 
Class ASE: Security Target evaluation 
April 2017 Version 3.1 Page 85 of 430 
ASE_INT.1-7 The evaluator shall examine  the TOE overview to determine that the TOE 
type is not misleading. 
371 There are situations where the general consumer would expect certain 
functionality of the TOE because of its TOE type. If this functionality is 
absent in the TOE, the ev aluator determines that the TOE overview 
adequately discusses this absence. 
372 There are also TOEs where the general consumer would expect that the TOE 
should be able to operate in a certain operational environment because of its 
TOE type. If the TOE is unabl e to operate in such an operational 
environment, the evaluator determines that the TOE overview adequately 
discusses this. 
ASE_INT.1.6C The TOE overview shall identify any non -TOE 
hardware/software/firmware required by the TOE.  
ASE_INT.1-8 The evaluator shall examine the TOE overview to determine that it identifies 
any non-TOE hardware/software/firmware required by the TOE. 
373 While some TOEs are able to run stand -alone, other TOEs (notably software 
TOEs) need additional hardware, software or firmware to operate. If the TOE 
does not require any hardware, software or firmware, this work unit is not 
applicable and therefore considered to be satisfied. 
374 The evaluator determ ines that the TOE overview identifies any additional 
hardware, software and firmware needed by the TOE to operate. This 
identification does not have to be exhaustive, but detailed enough for 
potential consumers of the TOE to determine whether their current hardware, 
software and firmware support use of the TOE, and, if this is not the case, 
which additional hardware, software and/or firmware is needed. 
ASE_INT.1.7C The TOE description shall describe the physical scope of the TOE.  
ASE_INT.1-9 The evaluator shall examine  the TOE description to determine that it 
describes the physical scope of the TOE. 
375 The evaluator determines that the TOE description lists the hardware , 
firmware, software and guidance parts that constitute the TOE and describes 
them at a level of detail that is sufficient to give the reader a general 
understanding of those parts. 
376 As a minimum the TOE description will cover the following elements:  
a) Each separately delivered part of the TOE, which will be identified 
by its unique identifier and the current format (binary, wafer, inlay, 
*.pdf, *.doc, *.chm etc.).  
b) The delivery method used by the developer to make available each 
part to the TOE consumer (Web site download, courier delivery, etc.)  
Class ASE: Security Target evaluation 
Page 86 of 430 Version 3.1 April 2017 
377 The physical description will also include some clear statements about the 
evaluated TOE configuration. In the case where a product could have 
multiple physical components, and therefore multiple configurations, the  
evaluated configurations must be briefly described and identified. 
378 The evaluator also determines that there is no possible misunderstanding as 
to whether any hardware, firmware, software or guidance part is part of the 
TOE or not. 
ASE_INT.1.8C The TOE description shall describe the logical scope of the TOE.  
ASE_INT.1-10 The evaluator shall examine  the TOE description to determine that it 
describes the logical scope of the TOE. 
379 The evaluator determines that the TOE description discusses the logical 
security features offered by the TOE at a level of detail that is sufficient to 
give the reader a general understanding of those features. 
380 The evaluator also determines  that there is no possible misunderstanding as 
to whether any logical security feature is offered by the TOE or not. 
381 An ST for a composed TOE may refer out to the description of the logical 
scope of the component TOEs, provided in the component TOE STs to 
provide the majority of this description for the composed TOE. However, the 
evaluator determines that the composed TOE ST clearly discusses which 
features of the individual components are not within the composed TOE, and 
therefore not a feature of the composed TOE. 
11.3.1.4 Action ASE_INT.1.2E 
ASE_INT.1-11 The evaluator shall examine  the TOE reference, TOE overview and TOE 
description to determine that they are consistent with each other. 
Class ASE: Security Target evaluation 
April 2017 Version 3.1 Page 87 of 430 
11.4 Conformance claims (ASE_CCL) 
11.4.1 Evaluation of sub-activity (ASE_CCL.1) 
11.4.1.1 Objectives 
382 The objective of this sub -activity is to determine the validity of various 
conformance claims. These describe how the ST and the TOE conform to the 
CC and how the ST conforms to PPs and packages. 
11.4.1.2 Input 
383 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the PP(s) that the ST claims conformance to;  
c) the package(s) that the ST claims conformance to.  
11.4.1.3 Action ASE_CCL.1.1E 
ASE_CCL.1.1C The conformance claim shall contain a CC conformance claim that 
identifies the version of the CC to which the ST and the TOE claim 
conformance.  
ASE_CCL.1-1 The evaluator shall check  that the conformance claim contains a CC 
conformance claim that identifies the version of the CC to which the ST and 
the TOE claim conformance. 
384 The evaluator determines that the CC conformance claim identifies the 
version of the CC that was used to develop this ST. This should include the 
version number of the CC and, unless the International English version of the 
CC was used, the language of the version of the CC that was used. 
385 For a composed TOE, the evaluator will  consider any differences between 
the version of the CC claimed for a component and the version of the CC 
claimed for the composed TOE. If the versions differ the evaluator will 
assess whether the differences between the versions will lead to conflicting 
claims. 
386 For instances where the CC conformance claims for the base TOE and 
dependent TOE are for different major releases of the CC (e.g. one 
component TOE conformance claim is CC v2.x and the other component 
TOE conformance claim is CC v3.x), the conforman ce claim for the 
composed TOE will be the earlier release of the CC, as the CC is developed 
with an aim to provide backwards compatibility (although this may not be 
achieved in the strictest sense, it is understood to be achieved in principle). 
ASE_CCL.1.2C The CC conformance claim shall describe the conformance of the ST to 
CC Part 2 as either CC Part 2 conformant or CC Part 2 extended.  
Class ASE: Security Target evaluation 
Page 88 of 430 Version 3.1 April 2017 
ASE_CCL.1-2 The evaluator shall check that the CC conformance claim states a claim of 
either CC Part 2 conformant or CC Part 2 extended for the ST. 
387 For a composed TOE, the evaluator will consider whether this claim is 
consistent not only with the CC Part 2, but also with the claims o f 
conformance to CC Part 2 by each of the component TOEs. I.e. if one or 
more component TOEs claims to be CC Part 2 extended, then the composed 
TOE should also claim to be CC Part 2 extended. 
388 The CC conformance claim for the composed TOE may be CC Part 2 
extended, even though the component TOEs are Part 2 conformant, in the 
event that additional SFRs are claimed for the base TOE (see composed TOE 
guidance for ASE_CCL.1.6C) 
ASE_CCL.1.3C The CC conformance claim shall describe the conformance of the ST to 
CC Part 3 as either CC Part 3 conformant or CC Part 3 extended.  
ASE_CCL.1-3 The evaluator shall check that the CC conformance claim states a c laim of 
either CC Part 3 conformant or CC Part 3 extended for the ST. 
ASE_CCL.1.4C The CC conformance claim shall be consistent with the extended 
components definition.  
ASE_CCL.1-4 The evaluator shall examine  the CC conformance claim for CC Part 2 to 
determine that it is consistent with the extended components definition. 
389 If the CC conformance claim contains CC Part 2 conformant, the evaluator 
determines that the ex tended components definition does not define 
functional components. 
390 If the CC conformance claim contains CC Part 2 extended, the evaluator 
determines that the extended components definition defines at least one 
extended functional component. 
ASE_CCL.1-5 The evaluator shall examine  the CC conformance claim for CC Part 3 to 
determine that it is consistent with the extended components definition. 
391 If the CC conformance claim contains CC Part 3 conformant, the evaluato r 
determines that the extended components definition does not define 
assurance components. 
392 If the CC conformance claim contains CC Part 3 extended, the evaluator 
determines that the extended components definition defines at least one 
extended assurance component. 
ASE_CCL.1.5C The conformance claim shall identify all PPs and security requirement 
packages to which the ST claims conformance.  
ASE_CCL.1-6 The evaluator shall check  that the conformance claim contains a PP claim 
that identifies all PPs for which the ST claims conformance. 
Class ASE: Security Target evaluation 
April 2017 Version 3.1 Page 89 of 430 
393 If the ST does not claim conformance to a PP, this work unit is not 
applicable and therefore considered to be satisfied. 
394 The evaluator de termines that any referenced PPs are unambiguously 
identified (e.g. by title and version number, or by the identification included 
in the introduction of that PP). Only those PPs to which the ST claims strict 
or demonstrable conformance are allowed to be i dentified in the 
conformance claim section that means claiming partial conformance to a PP 
or PP-configuration is not permitted. 
395 Therefore, conformance to a PP requiring a composite solution may be 
claimed in an ST for a composed TOE. Conformance to such a  PP would not 
have been possible during the evaluation of the component TOEs, as these 
components would not have satisfied the composed solution. This is only 
possible in the instances where the 'composite' PP permits use of the 
composition evaluation approach (use of ACO components). 
396 The ST for a composed TOE will identify the STs of the component TOEs 
from which the composed ST is comprised. The composed TOE is 
essentially claiming conformance to the STs of the component TOEs. 
ASE_CCL.1-7 The evaluator shall check  that the conformance claim contains a package 
claim that identifies all packages to which the ST claims conformance. 
397 If the ST does not claim conformance to a package, this work unit is not 
applicable and therefore considered to be satisfied. 
398 The evaluator determines that any referenced packages are unambiguously 
identified (e.g. by title and version number, or by the identification included 
in the introduction of that package). 
399 The evaluator determines that the component TOE STs from which the 
composed TOE is derived are also unambiguously identified. 
400 The evaluator is reminded that claims of partial conformance to a package 
are not permitted. 
ASE_CCL.1.6C The conformance claim shall describe any conformance of the ST to a 
package as either package-conformant or package-augmented.  
ASE_CCL.1-8 The evaluator shall check that, for each identified package, the conforma nce 
claim states a claim of either package -name conformant or package -name 
augmented. 
401 If the ST does not claim conformance to a package, this work unit is not 
applicable and therefore considered to be satisfied. 
402 If the package conformance claim contains pa ckage-name conformant, the 
evaluator determines that:  
a) If the package is an assurance package, then the ST contains all SARs 
included in the package, but no additional SARs.  
Class ASE: Security Target evaluation 
Page 90 of 430 Version 3.1 April 2017 
b) If the package is a functional package, then the ST contains all SFRs 
included in the package, but no additional SFRs.  
403 If the package conformance claim contains package -name augmented, the 
evaluator determines that:  
a) If the package is an assurance package then the ST contains all SARs 
included in the package, and at least one addition al SAR or at least 
one SAR that is hierarchical to a SAR in the package.  
b) If the package is a functional package, then the ST contains all SFRs 
included in the package, and at least one additional SFR or at least 
one SFR that is hierarchical to a SFR in the package.  
ASE_CCL.1.7C The conformance claim rationale shall demonstrate that the TOE type is 
consistent with the TOE type in the PPs for which conformance is being 
claimed.  
ASE_CCL.1-9 The evaluator shall examine  the conformance claim rationale to determine 
that the TOE type of the TOE is consistent with all TOE types of the PPs. 
404 If the ST does not claim conformance to a PP, this work unit is not 
applicable and therefore considered to be satisfied. 
405 The relation between the types may be simple: a firewall ST claiming 
conformance to a firewall PP, or more complex: a smart card ST claiming 
conformance to a number of PPs at the same time (a PP for the integrated 
circuit, a PP for the smart card OS, and two PPs for two applications on the 
smart card). 
406 For a composed TOE, the evaluator will determine whether the conformance 
claim rationale demonstrates that the TOE types of the component TOEs are 
consistent with the comp osed TOE type. This does not mean that both the 
component and the composed TOE types have to be the same, but rather that 
the component TOEs are suitable for integration to provide the composed 
TOE. It should be made clear in the composed TOE ST which SFRs  are only 
included as a result of composition, and were not examined as SFRs in the 
base and dependent TOE (e.g. EALx) evaluation. 
ASE_CCL.1.8C The conformance claim rationale shall demonstrate that the state ment of 
the security problem definition is consistent with the statement of the 
security problem definition in the PPs for which conformance is being 
claimed.  
ASE_CCL.1-10 The evaluator shall examine  the conformance claim rationale to determine 
that it demonstrates that the statement of security problem definition is 
consistent, as defined by the conformance statement of the PP, with the 
statements of security problem definition stated in the PPs to which 
conformance is being claimed. 
Class ASE: Security Target evaluation 
April 2017 Version 3.1 Page 91 of 430 
407 If the ST does not claim conformance with a PP, this work unit is not 
applicable and therefore considered to be satisfied. 
408 If the PP does not have a statement of security problem definition, this work 
unit is not applicable and therefore considered to be satisfied. 
409 If strict conformance is required by the PP to which conformance is being 
claimed no conformance claim rationale is required. Instead, the evaluator 
determines whether:  
a) the threats in the ST are a superset of or identic al to the threats in the 
PP to which conformance is being claimed;  
b) the OSPs in the ST are a superset of or identical to the OSPs in the PP 
to which conformance is being claimed;  
c) the assumptions in the ST are identical to the assumptions in the PP 
to which conformance is being claimed, with two possible exceptions 
described in the following two bullet points;  
 an assumption (or part of an assumption) from the PP can be 
omitted, if all security objectives for the operational 
environment addressing this assu mption (or part of an 
assumption) are replaced by security objectives for the TOE; 
 an assumption can be added to the assumptions defined in the 
PP, if a rationale is given, why the new assumption neither 
mitigates a threat (or a part of a threat) meant to be addressed 
by security objectives for the TOE in the PP, nor fulfils an 
OSP (or part of an OSP) meant to be addressed by security 
objectives for the TOE in the PP. 
When examining an ST claiming a PP, which omits assumptions from the PP 
or adds new assump tions, the evaluator shall carefully determine, if the 
conditions given above are fulfilled. The following discussion gives some 
motivation and examples for these cases:  
 Example for omitting an assumption: A PP may contain an 
assumption stating that the o perational environment prevents 
unauthorised modification or interception of data sent to an 
external interface of the TOE. This may be the case if the 
TOE accepts data in clear text and without integrity protection 
at this interface and is assumed to be l ocated in a secure 
operational environment, which will prevent attackers from 
accessing these data. The assumption will then be mapped in 
the PP to some objective for the operational environment 
stating that the data interchanged at this interface are 
protected by adequate measures in the operational 
environment. If an ST claiming this PP defines a more secure 
TOE, which has an additional security objective stating that 
the TOE itself protects these data, for example by providing a 
Class ASE: Security Target evaluation 
Page 92 of 430 Version 3.1 April 2017 
secure channel for encryp tion and integrity protection of all 
data transferred via this interface, the corresponding objective 
and assumption for the operational environment can be 
omitted from the ST. This is also called re -assigning of the 
objective, since the objective is re -assigned from the 
operational environment to the TOE. Note, that this TOE is 
still secure in an operational environment fulfilling the 
omitted assumption and therefore still fulfils the PP. 
 Example for adding an assumption: In this example the PP is 
designed to specify requirements for a TOE of type "Firewall" 
and an ST author wishes to claim this PP for a TOE, which 
implements a firewall, but additionally provides the 
functionality of a virtual private network (VPN) component. 
For the VPN functionality the T OE needs cryptographic keys 
and these keys may also have to be handled securely by the 
operational environment (e. g. if symmetric keys are used to 
secure the network connection and therefore need to be 
provided in some secure way to other components in th e 
network). In this case it is acceptable to add an assumption 
that the cryptographic keys used by the VPN are handled 
securely by the operational environment. This assumption 
does not address threats or OSPs of the PP and therefore 
fulfils the conditions stated above. 
 Counterexample for adding an assumption: In a variant of the 
first example a PP may already contain an objective for the 
TOE to provide a secure channel for one of its interfaces, and 
this objective is mapped to a threat of unauthorised 
modification or reading of the data on this interface. In this 
case it is clearly not allowed for an ST claiming this PP to add 
an assumption for the operational environment, which 
assumes that the operational environment protects data on this 
interface against modification or unauthorised reading of the 
data. This assumption would reduce a threat, which is meant 
to be addressed by the TOE. Therefore a TOE fulfilling an ST 
with this added assumption would not automatically fulfil the 
PP any more and this addition is therefore not allowed. 
 Second counterexample for adding an assumption: In the 
example above of a TOE implementing a firewall it would not 
be admissible to add a general assumption that the TOE is 
only connected to trusted devices, because this would 
obviously remove essential threats relevant for a firewall 
(namely that there is untrusted IP traffic, which needs to be 
filtered). Therefore this addition would not be allowed.  
410 If demonstrable conformance is required by the PP, the evaluator examines 
the conformance claim rationale to determine that it demonstrates that the 
statement of security problem definition of the ST is equivalent or more 
Class ASE: Security Target evaluation 
April 2017 Version 3.1 Page 93 of 430 
restrictive than the statement of security problem definition in the PP to 
which conformance is being claimed. 
411 For this, the conformance claim rationale needs to demonstrate that the 
security problem definition in the ST is equivalent (or more restrictive) than 
the security problem definition in the PP. This means that:  
 all TOEs that would meet the security problem  definition in the ST 
also meet the security problem definition in the PP. This can also be 
shown indirectly by demonstrating that every event, which realises a 
threat defined in the PP or violates an OSP defined in the PP, would 
also realise a threat stat ed in the ST or violate an OSP defined in the 
ST. Note that fulfilling an OSP stated in the ST may avert a threat 
stated in the PP or that averting a threat stated in the ST may fulfil an 
OSP stated in the PP, so threats and OSPs can substitute each other; 
 all operational environments that would meet the security problem 
definition in the PP would also meet the security problem definition 
in the ST (with one exception in the next bullet); 
 besides a set of assumptions in the ST needed to demonstrate 
conformance to the SPD of the PP, an ST may specify further 
assumptions, but only if these additional assumptions are independent 
of and do not affect the security problem definition as defined in the 
PP. More detailed, there are no assumptions in the ST that excl ude 
threats to the TOE that need to be countered by the TOE according to 
the PP. Similarly, there are no assumptions in the ST that realise 
aspects of an OSP stated in the PP, which are meant to be fulfilled by 
the TOE according to the PP." 
412 For a composed TOE, the evaluator will consider whether the security 
problem definition of the composed TOE is consistent with that specified in 
the STs for the component TOEs. This is determined in terms of 
demonstrable conformance. In particular, the evaluator examines  the 
conformance claim rationale to determine that:  
a) Threat statements and OSPs in the composed TOE ST do not 
contradict those from the component STs. 
b) Any assumptions made in the component STs are upheld in the 
composed TOE ST. That is, either the assumpti on should also be 
present in the composed ST, or the assumption should be positively 
addressed in the composed ST. The assumption may be positively 
addressed through specification of requirements in the composed 
TOE to provide functionality fulfilling the concern captured in the 
assumption. 
ASE_CCL.1.9C The conformance claim rationale shall demonstrate that the statement of 
security objectives is consistent with the statement of security objectives in 
the PPs for which conformance is being claimed.  
Class ASE: Security Target evaluation 
Page 94 of 430 Version 3.1 April 2017 
ASE_CCL.1-11 The evaluator shall examine  the conformance claim rationale to determine 
that the statement of security objectives is consistent, as defined by the 
conformance statement of the PP, with the statement of security objectives in 
the PPs to which conformance is being claimed. 
413 If the ST does not claim conformance to a PP, this work unit is not 
applicable and therefore considered to be satisfied. 
414 If strict conform ance is required by the PP to which conformance is being 
claimed, no conformance claim rationale is required. Instead, the evaluator 
determines whether:  
 The ST contains all security objectives for the TOE of the PP to 
which conformance is being claimed. N ote that it is allowed for the 
ST under evaluation to have additional security objectives for the 
TOE; 
 The security objectives for the operational environment in the ST are 
identical to the security objectives for the operational environment in 
the PP to w hich conformance is being claimed, with two possible 
exceptions described in the following two bullet points;  
 a security objective for the operational environment (or part of such 
security objective) from the PP can be replaced by the same (part of 
the) security objective stated for the TOE;  
 a security objective for the operational environment can be added to 
the objectives defined in the PP, if a justification is given, why the 
new objective neither mitigates a threat (or a part of a threat) meant to 
be addressed by security objectives for the TOE in the PP, nor fulfils 
an OSP (or part of an OSP) meant to be addressed by security 
objectives for the TOE in the PP.  
When examining an ST claiming a PP, which omits security objectives for 
the operational environment from the PP or adds new security objectives for 
the operational environment, the evaluator shall carefully determine, if the 
conditions given above are fulfilled. The examples given for the case of 
assumptions in the preceding work unit are also valid here. 
415 If demonstrable conformance is required by the PP to which conformance is 
being claimed, the evaluator examines the conformance claim rationale to 
determine that it demonstrates that the statement of security objectives of the 
ST is equivalent or  more restrictive than the statement of security objectives 
in the PP to which conformance is being claimed. 
416 For this the conformance claim rationale needs to demonstrate that the 
security objectives in the ST are equivalent (or more restrictive) than the 
security objectives in the PP. This means that:  
 all TOEs that would meet the security objectives for the TOE in the 
ST also meet the security objectives for the TOE in the PP; 
Class ASE: Security Target evaluation 
April 2017 Version 3.1 Page 95 of 430 
 all operational environments that would meet the security objectives 
for the op erational environment in the PP would also meet the 
security objectives for the operational environment in the ST (with 
one exception in the next bullet); 
 besides a set of security objectives for the operational environment in 
the ST, which are used to dem onstrate conformance to the set of 
security objectives defined in the PP, an ST may specify further 
security objectives for the operational environment, but only if these 
security objectives neither affect the original set of security objectives 
for the TO E nor the security objectives for the operational 
environment as defined in the PP to which conformance is claimed." 
417 For a composed TOE, the evaluator will consider whether the security 
objectives of the composed TOE are consistent with that specified in t he STs 
for the component TOEs. This is determined in terms of demonstrable 
conformance. In particular, the evaluator examines the conformance claim 
rationale to determine that:  
a) The statement of security objectives in the dependent TOE ST 
relevant to any I T in the operational environment are consistent with 
the statement of security objectives for the TOE in the base TOE ST. 
It is not expected that the statement of security objectives for the 
environment within in the dependent TOE ST will cover all aspects  
of the statement of security objectives for the TOE in the base TOE 
ST. 
b) The statement of security objectives in the composed ST is consistent 
with the statements of security objectives in the STs for the 
component TOEs. 
418 If demonstrable conformance is requ ired by the PP, the evaluator examines 
the conformance claim rationale to determine that it demonstrates that the 
statement of security objectives of the ST is at least equivalent to the 
statement of security objectives in the PP, or component TOE ST in th e case 
of a composed TOE ST. 
ASE_CCL.1.10C The conformance claim rationale shall demonstrate that the statement of 
security requirements is consistent with the statement of security 
requirements in the PPs for which conformance is being claimed.  
ASE_CCL.1-12 The evaluator shall examine  the ST to determine that it is consistent, as 
defined by the conformance statement of the PP, with all security 
requirements in the PPs for which conformance is being claimed. 
419 If the ST does not claim conformance to a PP, this work unit is not 
applicable and therefore considered to be satisfied. 
420 If strict conformance is required by the PP to which conformance is being 
claimed, no conformance claim rationale is required. Instead, the evaluator 
determines whether the statement of security requirements in the ST is a 
Class ASE: Security Target evaluation 
Page 96 of 430 Version 3.1 April 2017 
superset of or identical to the statement of security requirements in the PP to 
which conformance is being claimed (for strict conformance). 
421 If demonstrable conformance is required by the PP to which conformance is 
being claimed, the evaluator examines the conformance claim rationale to 
determine that it demonstrates that the statement of security requirements of 
the ST i s equivalent or more restrictive than the statement of security 
requirements in the PP to which conformance is being claimed. 
422 For:  
 SFRs: The conformance rationale in the ST shall demonstrate that the 
overall set of requirements defined by the SFRs in the ST is 
equivalent (or more restrictive) than the overall set of requirements 
defined by the SFRs in the PP. This means that all TOEs that would 
meet the requirements defined by the set of all SFRs in the ST would 
also meet the requirements defined by the set of all SFRs in the PP; 
 SARs: The ST shall contain all SARs in the PP, but may claim 
additional SARs or replace SARs by hierarchically stronger SARs. 
The completion of operations in the ST must be consistent with that 
in the PP; either the same completion will be used in the ST as that in 
the PP or a completion that makes the SAR more restrictive (the rules 
of refinement apply). 
423 For a composed TOE, the evaluator will consider whether the security 
requirements of the composed TOE are consistent with that sp ecified in the 
STs for the component TOEs. This is determined in terms of demonstrable 
conformance. In particular, the evaluator examines the conformance 
rationale to determine that:  
a) The statement of security requirements in the dependent TOE ST 
relevant to any IT in the operational environment is consistent with 
the statement of security requirements for the TOE in the base TOE 
ST. It is not expected that the statement of security requirements for 
the environment within in the dependent TOE ST will cover all 
aspects of the statement of security requirements for the TOE in the 
base TOE ST, as some SFRs may need to be added to the statement 
of security requirements in the composed TOE ST. However, the 
statement of security requirements in the base should sup port the 
operation of the dependent component. 
b) The statement of security objectives in the dependent TOE ST 
relevant to any IT in the operational environment is consistent with 
the statement of security requirements for the TOE in the base TOE 
ST. It is not expected that the statement of security objectives for the 
environment within in the dependent TOE ST will cover all aspects 
of the statement of security requirements for the TOE in the base 
TOE ST. 
Class ASE: Security Target evaluation 
April 2017 Version 3.1 Page 97 of 430 
c) The statement of security requirements in the composed is consistent 
with the statements of security requirements in the STs for the 
component TOEs. 
424 If demonstrable conformance is required by the PP to which conformance is 
being claimed, the evaluator examines the conformance claim rationale to 
determine that it demonstrates that the statement of security requirements of 
the ST is at least equivalent to the statement of security requirements in the 
PP, or component TOE ST in the case of a composed TOE ST. 
Class ASE: Security Target evaluation 
Page 98 of 430 Version 3.1 April 2017 
11.5 Security problem definition (ASE_SPD) 
11.5.1 Evaluation of sub-activity (ASE_SPD.1) 
11.5.1.1 Objectives 
425 The objective of this sub -activity is to determine that the security problem 
intended to be addressed by the TOE and its operational environment is 
clearly defined. 
11.5.1.2 Input 
426 The evaluation evidence for this sub-activity is:  
a) the ST.  
11.5.1.3 Action ASE_SPD.1.1E 
ASE_SPD.1.1C The security problem definition shall describe the threats.  
ASE_SPD.1-1 The evaluator shall check that the security problem definition describes the 
threats. 
427 If all security objectives are derived from assumptions and/or OSPs only, the 
statement of threats need not be present in the ST. In this case, this work unit 
is not applicable and therefore considered to be satisfied. 
428 The evaluator determines that the security problem definition describes the 
threats that must be countered by the TOE and/or operational environment. 
ASE_SPD.1.2C All threats shall be described in terms of a threat agent, an asset, and an 
adverse action.  
ASE_SPD.1-2 The evaluator shall examine  the security problem definition to determine 
that all threats are described in terms of a threat agent, an asset, and an 
adverse action. 
429 If all security objectives are derived from assumptions and/or OSPs only, the 
statement of threats need not be present in the ST. In this case, this work unit 
is not applicable and therefore considered to be satisfied. 
430 Threat agents may be further described by aspects such as expertise, resource, 
opportunity, and motivation. 
ASE_SPD.1.3C The security problem definition shall describe the OSPs.  
ASE_SPD.1-3 The evaluator shall examine  that the security problem definition describes 
the OSPs. 
431 If all security objectives are derived from assumptions and threats only, 
OSPs need not be present in the ST. In this case,  this work unit is not 
applicable and therefore considered to be satisfied. 
Class ASE: Security Target evaluation 
April 2017 Version 3.1 Page 99 of 430 
432 The evaluator determines that OSP statements are made in terms of rules or 
guidelines that must be followed by the TOE and/or its operational 
environment. 
433 The evaluator determines that each OSP is explained and/or interpreted in 
sufficient detail to make it clearly understandable; a clear presentation of 
policy statements is necessary to permit tracing security objectives to them. 
ASE_SPD.1.4C The security problem definition shall describe the assumptions about the 
operational environment of the TOE.  
ASE_SPD.1-4 The evaluator shall examine  the security problem definition to determine 
that it describes the assumptions about the operational environment of the 
TOE. 
434 If there are no assumptions, this work unit is not applicable and is therefore 
considered to be satisfied. 
435 The evaluator determines that each assumption about the operational 
environment of the TOE is explained in sufficient detail to enable consumers 
to determine that their operational environment matches the assumption. If 
the assumptions are not clearly understood, the end result may be that the 
TOE is used in an operational environm ent in which it will not function in a 
secure manner. 
Class ASE: Security Target evaluation 
Page 100 of 430 Version 3.1 April 2017 
11.6 Security objectives (ASE_OBJ) 
11.6.1 Evaluation of sub-activity (ASE_OBJ.1) 
11.6.1.1 Objectives 
436 The objective of this sub -activity is to determine whether the security 
objectives for the operational environment are clearly defined. 
11.6.1.2 Input 
437 The evaluation evidence for this sub-activity is:  
a) the ST.  
11.6.1.3 Action ASE_OBJ.1.1E 
ASE_OBJ.1.1C The statement of security objectives shall descr ibe the security objectives 
for the operational environment.  
ASE_OBJ.1-1 The evaluator shall check  that the statement of security objectives defines 
the security objectives for the operational environment. 
438 The e valuator checks that the security objectives for the operational 
environment are identified. 
11.6.2 Evaluation of sub-activity (ASE_OBJ.2) 
11.6.2.1 Objectives 
439 The objective of this sub -activity is to determine whether the security 
objectives adequately and completely address the security problem definition 
and that the division of this problem between the TOE and its operational 
environment is clearly defined. 
11.6.2.2 Input 
440 The evaluation evidence for this sub-activity is:  
a) the ST.  
11.6.2.3 Action ASE_OBJ.2.1E 
ASE_OBJ.2.1C The statement of security objectives shall describe the security objectives 
for the TOE and the security objectives for the operational environment.  
ASE_OBJ.2-1 The evaluator shall check  that the statement of security objectives defines 
the security objectives for the TOE and the security objectives for the 
operational environment. 
441 The evaluator checks that both categories of security objectives are clearly 
identified and separated from the other category. 
Class ASE: Security Target evaluation 
April 2017 Version 3.1 Page 101 of 430 
ASE_OBJ.2.2C The security objectives rationale shall trace each security objective for the 
TOE back to threats countered by that securi ty objective and OSPs 
enforced by that security objective.  
ASE_OBJ.2-2 The evaluator shall check  that the security objectives rationale traces all 
security objectives for the TOE back to threats countered by the  objectives 
and/or OSPs enforced by the objectives. 
442 Each security objective for the TOE may trace back to threats or OSPs, or a 
combination of threats and OSPs, but it must trace back to at least one threat 
or OSP. 
443 Failure to trace implies that either the security objectives rationale is 
incomplete, the security problem definition is incomplete, or the security 
objective for the TOE has no useful purpose. 
ASE_OBJ.2.3C The security objectives rationale shall tr ace each security objective for the 
operational environment back to threats countered by that security 
objective, OSPs enforced by that security objective, and assumptions 
upheld by that security objective.  
ASE_OBJ.2-3 The evaluator shall check  that the security objectives rationale traces the 
security objectives for the operational environment back to threats countered 
by that security objective, to OSPs enforced by that security objective, and to 
assumptions upheld by that security objective. 
444 Each security objective for the operational environment may trace back to 
threats, OSPs, assumptions, or a combination of threats, OSPs and/or 
assumptions, but it must trace back to at least one threat, OSP or assumption. 
445 Failure to trace implies that either the security objectives rationale is 
incomplete, the security problem definition is incomplete, or the security 
objective for the operational environment has no useful purpose. 
ASE_OBJ.2.4C The security objectives rationale shall demonstrate that the security 
objectives counter all threats.  
ASE_OBJ.2-4 The evaluator shall examine  the security objectives rationale to determine 
that it justifies for each threat that the security objectives are suitable to 
counter that threat. 
446 If no security objectives trace back to the threat, the evaluator action related 
to this work unit is assigned a fail verdict. 
447 The evaluator determines that the justification for a threat shows whether the 
threat is removed, diminished or mitigated. 
448 The evaluator determines that the justification for a threat demonstrates that 
the security objectives are sufficient: if all security objectives that trace back 
to the threat are achieved, the threat is removed, sufficiently diminished, or 
the effects of the threat are sufficiently mitigated. 
Class ASE: Security Target evaluation 
Page 102 of 430 Version 3.1 April 2017 
449 Note that the tracings from security objectives to threats provided in the 
security objectives rationale may be part of a justi fication, but do not 
constitute a justification by themselves. Even in the case that a security 
objective is merely a statement reflecting the intent to prevent a particular 
threat from being realised, a justification is required, but this justification 
may be as minimal as “Security Objective X directly counters Threat Y”. 
450 The evaluator also determines that each security objective that traces back to 
a threat is necessary: when the security objective is achieved it actually 
contributes to the removal, diminishing or mitigation of that threat. 
ASE_OBJ.2.5C The security objectives rationale shall demonstrate that the security 
objectives enforce all OSPs.  
ASE_OBJ.2-5 The evaluator shall examine  the security objectives rationale to determine 
that for each OSP it justifies that the security objectives are suitable to 
enforce that OSP. 
451 If no security objectives trace back to the OSP, the evaluator action related to 
this work unit is assigned a fail verdict. 
452 The evaluator determines that the justification for an OSP demonstrates that 
the security objectives are sufficient: if all security objectives that trace back 
to that OSP are achieved, the OSP is enforced. 
453 The evaluator also determines that each security objective that traces back to 
an OSP is necessary: when the security objective is achieved it actually 
contributes to the enforcement of the OSP. 
454 Note that the tracings from security objectives to OSPs provided in the 
security objectives rationale may be part of a justification, but do not 
constitute a justification by themselves. In the case that a security objective is 
merely a statement reflecting the intent to enforce a particular OSP, a 
justification is required, but this justification may be as minimal as “Security 
Objective X directly enforces OSP Y”. 
ASE_OBJ.2.6C The security objectives rationale shall demonstrate that the security 
objectives for the operational environment uphold all assumptions.  
ASE_OBJ.2-6 The evaluator shall examine  the security objectives rationale to determine 
that for each assumption for the operational environment it contains an 
appropriate justifica tion that the security objectives for the operational 
environment are suitable to uphold that assumption. 
455 If no security objectives for the operational environment trace back to the 
assumption, the evaluator action related to this work unit is assigned a f ail 
verdict. 
456 The evaluator determines that the justification for an assumption about the 
operational environment of the TOE demonstrates that the security objectives 
are sufficient: if all security objectives for the operational environment that 
Class ASE: Security Target evaluation 
April 2017 Version 3.1 Page 103 of 430 
trace back  to that assumption are achieved, the operational environment 
upholds the assumption. 
457 The evaluator also determines that each security objective for the operational 
environment that traces back to an assumption about the operational 
environment of the TOE is necessary: when the security objective is 
achieved it actually contributes to the operational environment upholding the 
assumption. 
458 Note that the tracings from security objectives for the operational 
environment to assumptions provided in the security objectives rationale may 
be a part of a justification, but do not constitute a justification by themselves. 
Even in the case that a security objective of the operational environment is 
merely a restatement of an assumption, a justification is required, but this 
justification may be as minimal as “Security Objective X directly upholds 
Assumption Y”. 
Class ASE: Security Target evaluation 
Page 104 of 430 Version 3.1 April 2017 
11.7 Extended components definition (ASE_ECD) 
11.7.1 Evaluation of sub-activity (ASE_ECD.1) 
11.7.1.1 Objectives 
459 The objective of this sub -activity is to determine whether extended 
components have been clearly and unambiguously defined, and whether they 
are necessary, i.e. they may not be clearly expressed using existing CC Part 2 
or CC Part 3 components. 
11.7.1.2 Input 
460 The evaluation evidence for this sub-activity is:  
a) the ST.  
11.7.1.3 Action ASE_ECD.1.1E 
ASE_ECD.1.1C The statement of security requirements shall identify all extended security 
requirements.  
ASE_ECD.1-1 The evaluator shall check that all security requirements in the statement of 
security requirements that are not identified as extended requirements are 
present in CC Part 2 or in CC Part 3. 
ASE_ECD.1.2C The extended components definition shall define an extended component 
for each extended security requirement.  
ASE_ECD.1-2 The evaluator shall check  that the extended components definition defines 
an extended component for each extended security requirement. 
461 If the ST does not contain extended security requirements, this work unit is 
not applicable and therefore considered to be satisfied. 
462 A single extended component may be used to define multiple iterations of an 
extended security requirement, it is not necessary to repeat this definition for 
each iteration. 
ASE_ECD.1.3C The extended components definition shall describe how each extended 
component is related to the existing CC components, families, and classes.  
ASE_ECD.1-3 The evaluator shall examine  the extended components definition to 
determine that it describes how each extended component fits into the 
existing CC components, families, and classes. 
463 If the ST does not contain extended security requirements, this work unit is 
not applicable and therefore considered to be satisfied. 
464 The evaluator determines that each extended component is either:  
a) a member of an existing CC Part 2 or CC Part 3 family, or 
Class ASE: Security Target evaluation 
April 2017 Version 3.1 Page 105 of 430 
b) a member of a new family defined in the ST. 
465 If the extended component is a member of an existing CC Part 2 or CC Part 3 
family, the evaluator determines that the extended components definition 
adequately describes why the exte nded component should be a member of 
that family and how it relates to other components of that family. 
466 If the extended component is a member of a new family defined in the ST, 
the evaluator confirms that the extended component is not appropriate for an 
existing family. 
467 If the ST defines new families, the evaluator determines that each new family 
is either:  
a) a member of an existing CC Part 2 or CC Part 3 class, or 
b) a member of a new class defined in the ST. 
468 If the family is a member of an existing CC Part 2 or CC Part 3 class, the 
evaluator determines that the extended components definition adequately 
describes why the family should be a member of that class and how it relates 
to other families in that class. 
469 If the family is a member of a new class defined i n the ST, the evaluator 
confirms that the family is not appropriate for an existing class. 
ASE_ECD.1-4 The evaluator shall examine  the extended components definition to 
determine that each definition of an extend ed component identifies all 
applicable dependencies of that component. 
470 If the ST does not contain extended security requirements, this work unit is 
not applicable and therefore considered to be satisfied. 
471 The evaluator confirms that no applicable dependenc ies have been 
overlooked by the ST author. 
ASE_ECD.1.4C The extended components definition shall use the existing CC components, 
families, classes, and methodology as a model for presentation.  
ASE_ECD.1-5 The evaluator shall examine  the extended components definition to 
determine that each extended functional component uses the existing CC Part 
2 components as a model for presentation. 
472 If the ST does not contain ext ended SFRs, this work unit is not applicable 
and therefore considered to be satisfied. 
473 The evaluator determines that the extended functional component is 
consistent with CC Part 2 Section 7.1.3, Component structure. 
474 If the ex tended functional component uses operations, the evaluator 
determines that the extended functional component is consistent with CC 
Part 1 Section 8.1, Operations. 
Class ASE: Security Target evaluation 
Page 106 of 430 Version 3.1 April 2017 
475 If the extended functional component is hierarchical to an e xisting functional 
component, the evaluator determines that the extended functional component 
is consistent with CC Part 2 Section 7.2.1, Component changes highlighting. 
ASE_ECD.1-6 The evaluator shall examine  the extended components definition to 
determine that each definition of a new functional family uses the existing 
CC functional families as a model for presentation. 
476 If the ST does not define new functional families,  this work unit is not 
applicable and therefore considered to be satisfied. 
477 The evaluator determines that all new functional families are defined 
consistent with CC Part 2 Section 7.1.2, Family structure. 
ASE_ECD.1-7 The evaluator shall examine  the extended components definition to 
determine that each definition of a new functional class uses the existing CC 
functional classes as a model for presentation. 
478 If the ST does not define new f unctional classes, this work unit is not 
applicable and therefore considered to be satisfied. 
479 The evaluator determines that all new functional classes are defined 
consistent with CC Part 2 Section 7.1.1, Class structure. 
ASE_ECD.1-8 The evaluator shall examine  the extended components definition to 
determine that each definition of an extended assurance component uses the 
existing CC Part 3 components as a model for presentation. 
480 If the ST does not contain extended SARs, this work unit is not applicable 
and therefore considered to be satisfied. 
481 The evaluator determines that the extended assurance component definition 
is consistent with CC Part 3 Section 7.1.3, Assurance component structure. 
482 If the extended assurance component uses operations, the evaluator 
determines that the extended assurance component is consistent with CC Part 
1 Section 8.1, Operations. 
483 If the extended assurance component is hierarchical to an existing assurance 
component, the evaluator determines that the extended assurance component 
is consistent with CC Part 3 Section 7.1.3, Assurance component structure. 
ASE_ECD.1-9 The evaluator shall examine  the extended components definition to 
determine that, for each defined extended assurance component, applicable 
methodology has been provided. 
484 If the ST does not contain extended SARs, this work unit is not applicable 
and therefore considered to be satisfied. 
485 The evaluator determines that, for each evaluator action element of each 
extended SAR, one or more work units are provided and that succ essfully 
Class ASE: Security Target evaluation 
April 2017 Version 3.1 Page 107 of 430 
performing all work units for a given evaluator action element will 
demonstrate that the element has been achieved. 
ASE_ECD.1-10 The evaluator shall examine  the extended components definition to 
determine that each definition of a new assurance family uses the existing 
CC assurance families as a model for presentation. 
486 If the ST does not define new assurance families, this work unit is not 
applicable and therefore considered to be satisfied. 
487 The evalua tor determines that all new assurance families are defined 
consistent with CC Part 3 Section 7.1.2, Assurance family structure. 
ASE_ECD.1-11 The evaluator shall examine  the extended components definition to 
determine that each definition of a new assurance class uses the existing CC 
assurance classes as a model for presentation. 
488 If the ST does not define new assurance classes, this work unit is not 
applicable and therefore considered to be satisfied. 
489 The evaluator determines that all new assurance classes are defined 
consistent with CC Part 3 Section 7.1.1, Assurance class structure. 
ASE_ECD.1.5C The extended components shall consist of measurable and objective 
elements such that conformance or nonconformance to these elements can 
be demonstrated.  
ASE_ECD.1-12 The evaluator shall examine  the ext ended components definition to 
determine that each element in each extended component is measurable and 
states objective evaluation requirements, such that conformance or 
nonconformance can be demonstrated. 
490 If the ST does not contain extended security requ irements, this work unit is 
not applicable and therefore considered to be satisfied. 
491 The evaluator determines that elements of extended functional components 
are stated in such a way that they are testable, and traceable through the 
appropriate TSF representations. 
492 The evaluator also determines that elements of extended assurance 
components avoid the need for subjective evaluator judgement. 
493 The evaluator is reminded that whilst being measurable and objective is 
appropriate for all evaluation criteria, it is  acknowledged that no formal 
method exists to prove such properties. Therefore the existing CC functional 
and assurance components are to be used as a model for determining what 
constitutes conformance with this requirement. 
Class ASE: Security Target evaluation 
Page 108 of 430 Version 3.1 April 2017 
11.7.1.4 Action ASE_ECD.1.2E 
ASE_ECD.1-13 The evaluator shall examine  the extended components definition to 
determine that each extended component can not be clearly expressed using 
existing components. 
494 If the ST does not contain extended security requirements, this work unit is 
not applicable and therefore considered to be satisfied. 
495 The evaluator should take components from CC Part 2 and CC Part 3, other 
extended components that have been defined in the  ST, combinations of 
these components, and possible operations on these components into account 
when making this determination. 
496 The evaluator is reminded that the role of this work unit is to preclude 
unnecessary duplication of components, that is, compone nts that may be 
clearly expressed by using other components. The evaluator should not 
undertake an exhaustive search of all possible combinations of components 
including operations in an attempt to find a way to express the extended 
component by using existing components. 
Class ASE: Security Target evaluation 
April 2017 Version 3.1 Page 109 of 430 
11.8 Security requirements (ASE_REQ) 
11.8.1 Evaluation of sub-activity (ASE_REQ.1) 
11.8.1.1 Objectives 
497 The objective of this sub -activity is to determine whether the SFRs and 
SARs are clear, unambiguous and well -defined and whether they are 
internally consistent. 
11.8.1.2 Input 
498 The evaluation evidence for this sub-activity is:  
a) the ST.  
11.8.1.3 Action ASE_REQ.1.1E 
ASE_REQ.1.1C The statement of security requirements shall describe the SFRs and the 
SARs.  
ASE_REQ.1-1 The evaluator shall check  that the statement of security requirements 
describes the SFRs. 
499 The evaluator determines that each SFR is identified by one of the following 
means:  
a) by reference to an individual component in CC Part 2;  
b) by reference to an extended component in the extended components 
definition of the ST;  
c) by reference to a PP that the ST claims to be conformant with;  
d) by reference to a security requirements package that t he ST claims to 
be conformant with;  
e) by reproduction in the ST. 
500 It is not required to use the same means of identification for all SFRs. 
ASE_REQ.1-2 The evaluator shall check  that the statement of security requir ements 
describes the SARs. 
501 The evaluator determines that each SAR is identified by one of the following 
means:  
a) by reference to an individual component in CC Part 3;  
b) by reference to an extended component in the extended components 
definition of the ST;  
c) by reference to a PP that the ST claims to be conformant with;  
Class ASE: Security Target evaluation 
Page 110 of 430 Version 3.1 April 2017 
d) by reference to a security requirements package that the ST claims to 
be conformant with;  
e) by reproduction in the ST. 
502 It is not required to use the same means of identification for all SARs. 
ASE_REQ.1.2C All subjects, objects, operations, security attributes, external entities and 
other terms that are used in the SFRs and the SARs shall be defined.  
ASE_REQ.1-3 The evaluator shall examine  the ST to determine that all subjects, objects, 
operations, security attributes, external entities and other terms that are used 
in the SFRs and the SARs are defined. 
503 The evaluator determines that the ST defines all:  
 (types of) subjects and objects that are used in the SFRs; 
 (types of) security attributes of subjects, users, objects, information, 
sessions and/or resources, possible values that these attributes may 
take and any relations between these values (e.g. top_secr et is 
“higher” than secret); 
 (types of) operations that are used in the SFRs, including the effects 
of these operations; 
 (types of) external entities in the SFRs; 
 other terms that are introduced in the SFRs and/or SARs by 
completing operations, if these te rms are not immediately clear, or 
are used outside their dictionary definition. 
504 The goal of this work unit is to ensure that the SFRs and SARs are well -
defined and that no misunderstanding may occur due to the introduction of 
vague terms. This work unit sh ould not be taken into extremes, by forcing 
the ST writer to define every single word. The general audience of a set of 
security requirements should be assumed to have a reasonable knowledge of 
IT, security and Common Criteria. 
505 All of the above may be pres ented in groups, classes, roles, types or other 
groupings or characterisations that allow easy understanding. 
506 The evaluator is reminded that these lists and definitions do not have to be 
part of the statement of security requirements, but may be placed (in  part or 
in whole) in different sections. This may be especially applicable if the same 
terms are used in the rest of the ST. 
ASE_REQ.1.3C The statement of security requirements shall identify all operations on the 
security requirements.  
ASE_REQ.1-4 The evaluator shall check  that the statement of security requirements 
identifies all operations on the security requirements. 
Class ASE: Security Target evaluation 
April 2017 Version 3.1 Page 111 of 430 
507 The evaluator determines that all operation s are identified in each SFR or 
SAR where such an operation is used. Identification may be achieved by 
typographical distinctions, or by explicit identification in the surrounding 
text, or by any other distinctive means. 
ASE_REQ.1.4C All operations shall be performed correctly.  
ASE_REQ.1-5 The evaluator shall examine  the statement of security requirements to 
determine that all assignment operations are performed correctly. 
508 Guidance on the correct performance of operations may be found in CC Part 
1 Annex C, Guidance for Operations. 
ASE_REQ.1-6 The evaluator shall examine  the statement o f security requirements to 
determine that all iteration operations are performed correctly. 
509 Guidance on the correct performance of operations may be found in CC Part 
1 Annex C, Guidance for Operations. 
ASE_REQ.1-7 The evaluator shall examine  the statement of security requirements to 
determine that all selection operations are performed correctly. 
510 Guidance on the correct performance of operations may be found in CC Part 
1 Annex C, Guidance for Operations. 
ASE_REQ.1-8 The evaluator shall examine  the statement of security requirements to 
determine that all refinement operations are performed correctly. 
511 Guidance on the correct performance of operations may be found in CC Part 
1 Annex C, Guidance for Operations. 
ASE_REQ.1.5C Each dependency of the security requireme nts shall either be satisfied, or 
the security requirements rationale shall justify the dependency not being 
satisfied.  
ASE_REQ.1-9 The evaluator shall examine  the statement of security requirements to 
determine that each dependency of the security requirements is either 
satisfied, or that a security requirements rationale is provided which justifies 
the dependency not being satisfied. 
512 A dependency is satisfied by the inclusion of the relevant component (or one 
that is hierarchical to it) within the statement of security requirements. The 
component used to satisfy the dependency should, if necessary, be modified 
by operations to ensure that it actually satisfies that dependency. 
513 A justification that a dependency is not met should address either:  
a) why the dependency is not necessary or useful, in which case no 
further information is required; or  
b) that the dependency has been addressed by the operational 
environment of the TOE, in which case the justification should 
Class ASE: Security Target evaluation 
Page 112 of 430 Version 3.1 April 2017 
describe how the security objectives for the operational environment 
address this dependency.  
ASE_REQ.1.6C The statement of security requirements shall be internally consistent.  
ASE_REQ.1-10 The evaluator shall examine  the statement of security requirements to 
determine that it is internally consistent. 
514 The evaluator determines that the combined set of all SFRs and SARs is 
internally consistent. 
515 The evaluator de termines that on all occasions where different security 
requirements apply to the same types of developer evidence, events, 
operations, data, tests to be performed etc. or to “all objects”, “all subjects” 
etc., that these requirements do not conflict. 
516 Some possible conflicts are:  
a) an extended SAR specifying that the design of a certain 
cryptographic algorithm is to be kept secret, and another extended 
SAR specifying an open source review;  
b) FAU_GEN.1 Audit data generation specifying that subject identity is 
to be logged, FDP_ACC.1 Subset access control  specifying who has 
access to these logs, and FPR_UNO.1 Unobservability  specifying 
that some actions of subjects should be unobservable to other subjects. 
If the subject that should not be able to see an activity may access 
logs of this activity, these SFRs conflict;  
c) FDP_RIP.1 Subset residual information protection  specifying 
deletion of information no longer needed, and FDP_ROL.1 Basic 
rollback specifying that a TOE may return to a previous state. If the 
information that is needed for the rollback to the previous state has 
been deleted, these requirements conflict;  
d) Multiple iterations of FDP_ACC.1 Subset access control  especially 
where some iterations cover the same subjects, objects, or operations. 
If one access control SFR allows a subject to perform an operation on 
an object, while another access control SFR does not allow this, these 
requirements conflict.  
11.8.2 Evaluation of sub-activity (ASE_REQ.2) 
11.8.2.1 Objectives 
517 The objective of this sub -activity is to determine whether the SFRs and 
SARs are clear, unambiguous and well -defined, whether they are internally 
consistent, and whether the SFRs meet the security objectives of the TOE. 
11.8.2.2 Input 
518 The evaluation evidence for this sub-activity is:  
Class ASE: Security Target evaluation 
April 2017 Version 3.1 Page 113 of 430 
a) the ST.  
11.8.2.3 Action ASE_REQ.2.1E 
ASE_REQ.2.1C The statement of security  requirements shall describe the SFRs and the 
SARs.  
ASE_REQ.2-1 The evaluator shall check  that the statement of security requirements 
describes the SFRs. 
519 The evaluator determines that each SFRs is identified by one of the 
following means:  
a) by reference to an individual component in CC Part 2;  
b) by reference to an extended component in the extended components 
definition of the ST;  
c) by reference to an individual component in a PP that the ST claims to 
be conformant with;  
d) by reference to an individual component in a security requirements 
package that the ST claims to be conformant with;  
e) by reproduction in the ST. 
520 It is not required to use the same means of identification for all SFRs. 
ASE_REQ.2-2 The evaluator shall check  that the statement of security requirements 
describes the SARs. 
521 The evaluator determines that all SARs are identified by one of the following 
means:  
a) by reference to an individual component in CC Part 3;  
b) by reference to an extended component in the extended components 
definition of the ST;  
c) by reference to an individual component in a PP that the ST claims to 
be conformant with;  
d) by reference to an individual component in a security requirements 
package that the ST claims to be conformant with;  
e) by reproduction in the ST. 
522 It is not required to use the same means of identification for all SARs. 
ASE_REQ.2.2C All subjects, objects, operations, security attributes , external entities and 
other terms that are used in the SFRs and the SARs shall be defined.  
Class ASE: Security Target evaluation 
Page 114 of 430 Version 3.1 April 2017 
ASE_REQ.2-3 The evaluator shall examine  the ST to determine that all subjects, objects, 
operations, security attributes, external entities and other terms that are used 
in the SFRs and the SARs are defined. 
523 The evaluator determines that the ST defines all:  
 (types of) subjects and objects that are used in the SFRs; 
 (types of) security attributes of subjects, users, object s, information, 
sessions and/or resources, possible values that these attributes may 
take and any relations between these values (e.g. top_secret is 
“higher” than secret); 
 (types of) operations that are used in the SFRs, including the effects 
of these operations; 
 (types of) external entities in the SFRs; 
 other terms that are introduced in the SFRs and/or SARs by 
completing operations, if these terms are not immediately clear, or 
are used outside their dictionary definition. 
524 The goal of this work unit is to ensure that the SFRs and SARs are well -
defined and that no misunderstanding may occur due to the introduction of 
vague terms. This work unit should not be taken into extremes, by forcing 
the ST writer to define every single word. The general audience of a set of 
security requirements should be assumed to have a reasonable knowledge of 
IT, security and Common Criteria. 
525 All of the above may be presented in groups, classes, roles, types or other 
groupings or characterisations that allow easy understanding. 
526 The evaluator is reminded that these lists and definitions do not have to be 
part of the statement of security requirements, but may be placed (in part or 
in whole) in different sections. This may be especially applicable if the same 
terms are used in the rest of the ST. 
ASE_REQ.2.3C The statement of security requirements shall identify all operations on the 
security requirements.  
ASE_REQ.2-4 The evaluator shall check  that the statement of security requirements 
identifies all operations on the security requirements. 
527 The evaluator determines that all operations are identified in each SFR or 
SAR where such an operation is used. Identification may be achieved by 
typographical distinctions, or by explicit identification in the surrounding 
text, or by any other distinctive means. 
ASE_REQ.2.4C All operations shall be performed correctly.  
ASE_REQ.2-5 The evaluator shall examine  the statement of security requirements to 
determine that all assignment operations are performed correctly. 
Class ASE: Security Target evaluation 
April 2017 Version 3.1 Page 115 of 430 
528 Guidance on the correct performance of operations may be found in CC Part 
1 Annex C, Guidance for Operations. 
ASE_REQ.2-6 The evaluator shall examine  the statement of security requirements to 
determine that all iteration operations are performed correctly. 
529 Guidance on the correct performance of operations may be found in CC Part 
1 Annex C, Guidance for Operations. 
ASE_REQ.2-7 The evaluator shall examine  the statement of security requirements to 
determine that all selection operations are performed correctly. 
530 Guidance on the correct performance of operations may be found in CC Part 
1 Annex C, Guidance for Operations. 
ASE_REQ.2-8 The evaluator shall examine  the statement of security requirements to 
determine that all refinement operations are performed correctly. 
531 Guidance on the correct performance of operations may be found in CC Part 
1 Annex C, Guidance for Operations. 
ASE_REQ.2.5C Each dependency of the security requirements shall either be satisfied, or 
the security requirements rationale shall justify the dependency not being 
satisfied.  
ASE_REQ.2-9 The evaluator shall examine  the statement of security requirements to 
determine that each dependency of the security requirements is either 
satisfied, or that the security requirements rationa le justifies the dependency 
not being satisfied. 
532 A dependency is satisfied by the inclusion of the relevant component (or one 
that is hierarchical to it) within the statement of security requirements. The 
component used to satisfy the dependency should, if  necessary, be modified 
by operations to ensure that it actually satisfies that dependency. 
533 A justification that a dependency is not met should address either:  
a) why the dependency is not necessary or useful, in which case no 
further information is required; or  
b) that the dependency has been addressed by the operational 
environment of the TOE, in which case the justification should 
describe how the security objectives for the operational environment 
address this dependency.  
ASE_REQ.2.6C The security requirements rationale shall trace each SFR back to the 
security objectives for the TOE.  
ASE_REQ.2-10 The evaluator shall check that the security requirements rationale traces each 
SFR back to the security objectives for the TOE. 
Class ASE: Security Target evaluation 
Page 116 of 430 Version 3.1 April 2017 
534 The evaluator determines that each SFR is traced back to at least one security 
objective for the TOE. 
535 Failure to trace implies that either the security requirements rationale is 
incomplete, the security objectives for the TOE are incomplete, or the SFR 
has no useful purpose. 
ASE_REQ.2.7C The security requirements rationale shall demonstrate that the SFRs meet 
all security objectives for the TOE.  
ASE_REQ.2-11 The evaluator shall examine the security requirements rationale to determine 
that for each security objective for the TOE it demonstrates that the SFRs are 
suitable to meet that security objective for the TOE. 
536 If no SFRs trace back to the security objective for the TOE, the evaluator 
action related to this work unit is assigned a fail verdict. 
537 The evaluator determines that the justification for a security objective for the 
TOE demonstrates that the S FRs are sufficient: if all SFRs that trace back to 
the objective are satisfied, the security objective for the TOE is achieved. 
538 The evaluator also determines that each SFR that traces back to a security 
objective for the TOE is necessary: when the SFR is s atisfied, it actually 
contributes to achieving the security objective. 
539 Note that the tracings from SFRs to security objectives for the TOE provided 
in the security requirements rationale may be a part of the justification, but 
do not constitute a justification by themselves. 
ASE_REQ.2.8C The security requirements rationale shall explain why the SARs were 
chosen.  
ASE_REQ.2-12 The evaluator shall check  that the sec urity requirements rationale explains 
why the SARs were chosen. 
540 The evaluator is reminded that any explanation is correct, as long as it is 
coherent and neither the SARs nor the explanation have obvious 
inconsistencies with the remainder of the ST. 
541 An exam ple of an obvious inconsistency between the SARs and the 
remainder of the ST would be to have threat agents that are very capable, but 
an AVA_VAN SAR that does not protect against these threat agents. 
ASE_REQ.2.9C The statement of security requirements shall be internally consistent.  
ASE_REQ.2-13 The evaluator shall examine  the statement of security requirements to 
determine that it is internally consistent. 
542 The evaluator determines that the combined set of all SFRs and SARs is 
internally consistent. 
Class ASE: Security Target evaluation 
April 2017 Version 3.1 Page 117 of 430 
543 The evaluator determines that on all occasions where different security 
requirements apply to the same types of developer evidence, eve nts, 
operations, data, tests to be performed etc. or to “all objects”, “all subjects” 
etc., that these requirements do not conflict. 
544 Some possible conflicts are:  
a) an extended SAR specifying that the design of a certain 
cryptographic algorithm is to be kept  secret, and another extended 
assurance requirement specifying an open source review;  
b) FAU_GEN.1 Audit data generation specifying that subject identity is 
to be logged, FDP_ACC.1 Subset access control  specifying who has 
access to these logs, and FPR_UNO.1 Unobservability  specifying 
that some actions of subjects should be unobservable to other subjects. 
If the subject that should not be able to see an activity may access 
logs of this activity, these SFRs conflict;  
c) FDP_RIP.1 Subset residual information protection  specifying 
deletion of information no longer needed, and FDP_ROL.1 Basic 
rollback specifying that a TOE may return to a previous state. If the 
information that is needed for the rollback to the previous state has 
been deleted, these requirements conflict;  
d) Multiple iterations of FDP_ACC.1 Subset access control  especially 
where some iterations cover the same subjects, objects, o r operations. 
If one access control SFR allows a subject to perform an operation on 
an object, while another access control SFR does not allow this, these 
requirements conflict.  
Class ASE: Security Target evaluation 
Page 118 of 430 Version 3.1 April 2017 
11.9 TOE summary specification (ASE_TSS) 
11.9.1 Evaluation of sub-activity (ASE_TSS.1) 
11.9.1.1 Objectives 
545 The objective of this sub -activity is to determine whether the TOE summary 
specification addresses all SFRs, and whether the TOE summary 
specification is consistent with other narrative descriptions of the TOE. 
11.9.1.2 Input 
546 The evaluation evidence for this sub-activity is:  
a) the ST.  
11.9.1.3 Action ASE_TSS.1.1E 
ASE_TSS.1.1C The TOE summary specification shall describe how the TOE meets each 
SFR.  
ASE_TSS.1-1 The evaluator shall examine  the TOE summary specification to determine 
that it describes how the TOE meets each SFR. 
547 The evaluator determines that the TOE summary specification provides, for 
each SFR from the statement of se curity requirements, a description on how 
that SFR is met. 
548 The evaluator is reminded that the objective of each description is to provide 
potential consumers of the TOE with a high -level view of how the developer 
intends to satisfy each SFR and that the de scriptions therefore should not be 
overly detailed. Often several SFRs will be implemented in one context; for 
instance a password authentication mechanism may implement FIA_UAU.1, 
FIA_SOS.1 and FIA_UID.1. Therefore usually the TSS will not consist of a 
long list with texts for each single SFR, but complete groups of SFRs may be 
covered by one text passage. 
549 For a composed TOE, the evaluator also determines tha t it is clear which 
component provides each SFR or how the components combine to meet each 
SFR. 
11.9.1.4 Action ASE_TSS.1.2E 
ASE_TSS.1-2 The evaluator shall examine  the TOE su mmary specification to determine 
that it is consistent with the TOE overview and the TOE description. 
550 The TOE overview, TOE description, and TOE summary specification 
describe the TOE in a narrative form at increasing levels of detail. These 
descriptions therefore need to be consistent. 
Class ASE: Security Target evaluation 
April 2017 Version 3.1 Page 119 of 430 
11.9.2 Evaluation of sub-activity (ASE_TSS.2) 
11.9.2.1 Objectives 
551 The objective of this sub -activity is to determine whether the TOE summary 
specification addresses all SFRs, whether the TOE summary specification 
addresses interference, log ical tampering and bypass, and whether the TOE 
summary specification is consistent with other narrative descriptions of the 
TOE. 
11.9.2.2 Input 
552 The evaluation evidence for this sub-activity is:  
a) the ST.  
11.9.2.3 Action ASE_TSS.2.1E 
ASE_TSS.2.1C The TOE summary specification shall describe how the TOE meets each 
SFR.  
ASE_TSS.2-1 The evaluator shall examine  the TOE summary specification to  determine 
that it describes how the TOE meets each SFR. 
553 The evaluator determines that the TOE summary specification provides, for 
each SFR from the statement of security requirements, a description on how 
that SFR is met. 
554 The evaluator is reminded that th e objective of each description is to provide 
potential consumers of the TOE with a high -level view of how the developer 
intends to satisfy each SFR and that the descriptions therefore should not be 
overly detailed. Often several SFRs will be implemented i n one context; for 
instance a password authentication mechanism may implement FIA_UAU.1, 
FIA_SOS.1 and FIA_UID.1. Therefore usually the TSS will not consist of a 
long list with texts for each single SFR, but complete groups of SFRs may be 
covered by one text passage. 
555 For a composed TOE, the evaluator also determines that it is clear which 
component provides each SFR or how the components combine to meet each 
SFR. 
ASE_TSS.2.2C The TOE summary specification shall describe how the TOE protects itself 
against interference and logical tampering.  
ASE_TSS.2-2 The evaluator shall examine  the TOE summary specification to determine 
that it describes how the TOE protects itself against interference and logical 
tampering. 
556 The evaluator is reminded that the objective of each description is to provide 
potential consumers of the TOE wi th a high-level view of how the developer 
intends to provide protection against interference and logical tampering and 
that the descriptions therefore should not be overly detailed. 
Class ASE: Security Target evaluation 
Page 120 of 430 Version 3.1 April 2017 
557 For a composed TOE, the evaluator also determines that it is clear which 
component provides the protection or how the components combine to 
provide protection. 
ASE_TSS.2.3C The TOE summary specification shall describe how the TOE protects itself 
against bypass.  
ASE_TSS.2-3 The evaluator shall examine  the TOE summary specification to determine 
that it describes how the TOE protects itself against bypass. 
558 The evaluator is reminded that the objective of each description is to provide 
potential consumers of the TOE with a high -level view of how the developer 
intends to provide protection against bypass and that the descriptions 
therefore should not be overly detailed. 
559 For a composed TOE, the evaluator also determines that it is clear which 
component provides the protection or how the components combine to 
provide protection. 
11.9.2.4 Action ASE_TSS.2.2E 
ASE_TSS.2-4 The evaluator shall examine  the TOE summary specif ication to determine 
that it is consistent with the TOE overview and the TOE description. 
560 The TOE overview, TOE description, and TOE summary specification 
describe the TOE in a narrative form at increasing levels of detail. These 
descriptions therefore need to be consistent. 
Class ADV: Development 
April 2017 Version 3.1 Page 121 of 430 
12 Class ADV: Development 
12.1 Introduction 
561 The purpose of the development activity is to assess the design 
documentation in terms of its adequacy to understand how the TSF meets the 
SFRs and how the implementation of these SFRs cannot be tamp ered with or 
bypassed. This understanding is achieved through examination of 
increasingly refined descriptions of the TSF design documentation. Design 
documentation consists of a functional specification (which describes the 
interfaces of the TSF), a TOE d esign description (which describes the 
architecture of the TSF in terms of how it works in order to perform the 
functions related to the SFRs being claimed), and an implementation 
description (a source code level description). In addition, there is a secur ity 
architecture description (which describes the architectural properties of the 
TSF to explain how its security enforcement cannot be compromised or 
bypassed), an internals description (which describes how the TSF was 
constructed in a manner that encoura ges understandability), and a security 
policy model (which formally describes the security policies enforced by the 
TSF). 
12.2 Application notes 
562 The CC requirements for design documentation are levelled by the amount, 
and detail of information provided, and the  degree of formality of the 
presentation of the information. At lower levels, the most security -critical 
portions of the TSF are described with the most detail, while less security -
critical portions of the TSF are merely summarised; added assurance is 
gained by increasing the amount of information about the most security -
critical portions of the TSF, and increasing the details about the less security-
critical portions. The most assurance is achieved when thorough details and 
information of all portions are provided. 
563 The CC considers a document's degree of formality (that is, whether it is 
informal or semiformal) to be hierarchical. An informal document is one that 
is expressed in a natural language. The methodology does not dictate the 
specific language that  must be used; that issue is left for the scheme. The 
following paragraphs differentiate the contents of the different informal 
documents. 
564 A functional specification provides a description of the purpose and method -
of-use of interfaces to the TSF. For exam ple, if an operating system presents 
the user with a means of self -identification, of creating files, of modifying or 
deleting files, of setting permissions defining what other users may access 
files, and of communicating with remote machines, its function al 
specification would contain descriptions of each of these and how they are 
realised through interactions with the externally-visible interfaces to the TSF. 
If there is also audit functionality that detects and record the occurrences of 
such events, descriptions of this audit functionality would also be expected to 
Class ADV: Development 
Page 122 of 430 Version 3.1 April 2017 
be part of the functional specification; while this functionality is technically 
not directly invoked by the user at the external interface, it certainly is 
affected by what occurs at the user's external interface. 
565 A design description is expressed in terms of logical divisions (subsystems 
or modules) that each provide a comprehensible service or function. For 
example, a firewall might be composed of subsystems that deal with packet 
filtering, w ith remote administration, with auditing, and with connection -
level filtering. The design description of the firewall would describe the 
actions that are taken, in terms of what actions each subsystem takes when an 
incoming packet arrives at the firewall. 
Class ADV: Development 
April 2017 Version 3.1 Page 123 of 430 
12.3 Security Architecture (ADV_ARC) 
12.3.1 Evaluation of sub-activity (ADV_ARC.1) 
12.3.1.1 Objectives 
566 The objective of this sub -activity is to determine whether the TSF is 
structured such that it cannot be tampered with or bypassed, and whether 
TSFs that provide security domains isolate those domains from each other. 
12.3.1.2 Input 
567 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the functional specification;  
c) the TOE design;  
d) the security architecture description;  
e) the implementation representation (if available);  
f) the operational user guidance;  
12.3.1.3 Application notes 
568 The notions of self -protection, domain separation, and non -bypassability are 
distinct from security functionality expressed in Part 2 SFRs because self -
protection and non -bypassability largely have no directly obs ervable 
interface at the TSF. Rather, they are properties of the TSF that are achieved 
through the design of the TOE, and enforced by the correct implementation 
of that design. Also, the evaluation of these properties is less straight-forward 
than the eval uation of mechanisms; it is more difficult to check for the 
absence of functionality than for its presence. However, the determination 
that these properties are being satisfied is just as critical as the determination 
that the mechanisms are properly implemented. 
569 The overall approach used is that the developer provides a TSF that meets 
the above -mentioned properties, and provides evidence (in the form of 
documentation) that can be analysed to show that the properties are indeed 
met. The evaluator has the re sponsibility for looking at the evidence and, 
coupled with other evidence delivered for the TOE, determining that the 
properties are achieved. The work units can be characterised as those 
detailing with what information has to be provided, and those dealin g with 
the actual analysis the evaluator performs. 
570 The security architecture description describes how domains are defined and 
how the TSF keeps them separate. It describes what prevents untrusted 
processes from getting to the TSF and modifying it. It describes what ensures 
that all resources under the TSF's control are adequately protected and that 
Class ADV: Development 
Page 124 of 430 Version 3.1 April 2017 
all actions related to the SFRs are mediated by the TSF. It explains any role 
the environment plays in any of these (e.g. presuming it gets correctly 
invoked by  its underlying environment, how is its security functionality 
invoked?). In short, it explains how the TOE is considered to be providing 
any kind of security service. 
571 The analyses the evaluator performs must be done in the context of all of the 
development evidence provided for the TOE, at the level of detail the 
evidence is provided. At lower assurance levels there should not be the 
expectation that, for example, TSF self -protection is completely analysed, 
because only high -level design representations wi ll be available. The 
evaluator also needs to be sure to use information gleaned from other 
portions of their analysis (e.g., analysis of the TOE design) in making their 
assessments for the properties being examined in the following work units. 
12.3.1.4 Action ADV_ARC.1.1E 
ADV_ARC.1.1C The security architecture description shall be at a level of detail 
commensurate with the description of the SFR -enforcing abstractions 
described in the TOE design document.  
ADV_ARC.1-1 The evaluator shall examine  the security architecture description to 
determine that the information provided in the evidence is presented at a 
level of detail commens urate with the descriptions of the SFR -enforcing 
abstractions contained in the functional specification and TOE design 
document. 
572 With respect to the functional specification, the evaluator should ensure that 
the self-protection functionality described cover those effects that are evident 
at the TSFI. Such a description might include protection placed upon the 
executable images of the TSF, and protection placed on objects (e.g., files 
used by the TSF). The evaluator ensures that the functionality that might be 
invoked through the TSFI is described. 
573 If Evaluation of sub -activity (ADV_TDS.1)  or Evaluation of sub -activity 
(ADV_TDS.2) is included, the evaluator ensures the security architecture 
description contains inform ation on how any subsystems that contribute to 
TSF domain separation work. 
574 If Evaluation of sub -activity (ADV_TDS.3)  or higher is available, the 
evaluator ensures that the security architecture description also contains 
implementation-dependent information. For example, such a description 
might contain information pertaining to coding conventions for parameter 
checking that would prevent TSF compromises (e.g. buffer overflows), and 
information on stack management for call and return ope rations. The 
evaluator checks the descriptions of the mechanisms to ensure that the level 
of detail is such that there is little ambiguity between the description in the 
security architecture description and the implementation representation. 
575 The evaluator action related to this work unit is assigned a fail verdict if the 
security architecture description mentions any module, subsystem, or 
Class ADV: Development 
April 2017 Version 3.1 Page 125 of 430 
interface that is not described in the functional specification or TOE design 
document. 
ADV_ARC.1.2C The security architecture description shall describe the security domains 
maintained by the TSF consistently with the SFRs.  
ADV_ARC.1-2 The evaluator shall examine  the security arch itecture description to 
determine that it describes the security domains maintained by the TSF. 
576 Security domains refer to environments supplied by the TSF for use by 
potentially-harmful entities; for example, a typical secure operating system 
supplies a se t of resources (address space, per -process environment 
variables) for use by processes with limited access rights and security 
properties. The evaluator determines that the developer's description of the 
security domains takes into account all of the SFRs claimed by the TOE. 
577 For some TOEs such domains do not exist because all of the interactions 
available to users are severely constrained by the TSF. A packet -filter 
firewall is an example of such a TOE. Users on the LAN or WAN do not 
interact with the TOE, so there need be no security domains; there are only 
data structures maintained by the TSF to keep the users' packets separated. 
The evaluator ensures that any claim that there are no domains is supported 
by the evidence and that no such domains are, in fact, available. 
ADV_ARC.1.3C The security architecture description shall describe how the TSF 
initialisation process is secure.  
ADV_ARC.1-3 The evaluator shall exam ine the security architecture description to 
determine that the initialisation process preserves security. 
578 The information provided in the security architecture description relating to 
TSF initialisation is directed at the TOE components that are involved in 
bringing the TSF into an initial secure state (i.e. when all parts of the TSF are 
operational) when power -on or a reset is applied. This discussion in the 
security architecture description should list the system initialisation 
components and the process ing that occurs in transitioning from the “down” 
state to the initial secure state. 
579 It is often the case that the components that perform this initialisation 
function are not accessible after the secure state is achieved; if this is the case 
then the secur ity architecture description identifies the components and 
explains how they are not reachable by untrusted entities after the TSF has 
been established. In this respect, the property that needs to be preserved is 
that these components either 1) cannot be a ccessed by untrusted entities after 
the secure state is achieved, or 2) if they provide interfaces to untrusted 
entities, these TSFI cannot be used to tamper with the TSF. 
580 The TOE components related to TSF initialisation, then, are treated 
themselves as part of the TSF, and analysed from that perspective. It should 
be noted that even though these are treated as part of the TSF, it is likely that 
Class ADV: Development 
Page 126 of 430 Version 3.1 April 2017 
a justification (as allowed by TSF internals (ADV_INT) ) can be made that 
they do not have to meet the internal structuring requirements of ADV_INT. 
ADV_ARC.1.4C The security architecture description shall demonstrate that the TSF 
protects itself from tampering.  
ADV_ARC.1-4 The evaluator shall examine  the security architecture description to 
determine that it contains information sufficient to support a determination 
that the TSF is able to protect itself from tampering by untru sted active 
entities. 
581 ”Self-protection” refers to the ability of the TSF to protect itself from 
manipulation from external entities that may result in changes to the TSF. 
For TOEs that have dependencies on other IT entities, it is often the case that 
the TOE uses services supplied by the other IT entities in order to perform its 
functions. In such cases, the TSF alone does not protect itself because it 
depends on the other IT entities to provide some of the protection. For the 
purposes of the security architecture description, the notion of self-protection 
applies only to the services provided by the TSF through its TSFI, and not to 
services provided by underlying IT entities that it uses. 
582 Self-protection is typically achieved by a variety of means, ranging from 
physical and logical restrictions on access to the TOE; to hardware -based 
means (e.g. “execution rings” and memory management functionality); to 
software-based means (e.g. boundary checking of inputs on a trusted server). 
The evaluator determines that all such mechanisms are described. 
583 The evaluator determines that the design description covers how user input is 
handled by the TSF in such a way that the TSF does not subject itself to 
being corrupted by that user input. For example, the TSF might implem ent 
the notion of privilege and protect itself by using privileged-mode routines to 
handle user input. The TSF might make use of processor -based separation 
mechanisms such as privilege levels or rings. The TSF might implement 
software protection constructs  or coding conventions that contribute to 
implementing separation of software domains, perhaps by delineating user 
address space from system address space. And the TSF might have reliance 
its environment to provide some support to the protection of the TSF. 
584 All of the mechanisms contributing to the domain separation functions are 
described. The evaluator should use knowledge gained from other evidence 
(functional specification, TOE design, TSF internals description, other parts 
of the security architecture description, or implementation representation, as 
included in the assurance package for the TOE) in determining if any 
functionality contributing to self -protection was described that is not present 
in the security architecture description. 
585 Accuracy of the description of the self-protection mechanisms is the property 
that the description faithfully describes what is implemented. The evaluator 
should use other evidence (functional specification, TOE design, TSF 
Internals documentation, other parts of the sec urity architecture description, 
implementation representation, as included in the ST for the TOE) in 
Class ADV: Development 
April 2017 Version 3.1 Page 127 of 430 
determining whether there are discrepancies in any descriptions of the self -
protection mechanisms. If Implementation representation (ADV_IMP)  is 
included in the assurance package for the TOE, the evaluator will choose a 
sample of the implementation representation; the evaluator should also 
ensure that the descriptions are accurate for the sample chosen. If an 
evaluator cannot understand ho w a certain self -protection mechanism works 
or could work in the system architecture, it may be the case that the 
description is not accurate. 
ADV_ARC.1.5C The security architecture description shall demonstr ate that the TSF 
prevents bypass of the SFR-enforcing functionality.  
ADV_ARC.1-5 The evaluator shall examine  the security architecture description to 
determine that it presents an analysis that adequately descri bes how the SFR-
enforcing mechanisms cannot be bypassed. 
586 Non-bypassability is a property that the security functionality of the TSF (as 
specified by the SFRs) is always invoked. For example, if access control to 
files is specified as a capability of the TS F via an SFR, there must be no 
interfaces through which files can be accessed without invoking the TSF's 
access control mechanism (such as an interface through which a raw disk 
access takes place). 
587 Describing how the TSF mechanisms cannot be bypassed gener ally requires 
a systematic argument based on the TSF and the TSFIs. The description of 
how the TSF works (contained in the design decomposition evidence, such 
as the functional specification, TOE design documentation) - along with the 
information in the TSS - provides the background necessary for the evaluator 
to understand what resources are being protected and what security functions 
are being provided. The functional specification provides descriptions of the 
TSFIs through which the resources/functions are accessed. 
588 The evaluator assesses the description provided (and other information 
provided by the developer, such as the functional specification) to ensure that 
no available interface can be used to bypass the TSF. This means that every 
available interface must be either unrelated to the SFRs that are claimed in 
the ST (and does not interact with anything that is used to satisfy SFRs) or 
else uses the security functionality that is described in other development 
evidence in the manner described. For exam ple, a game would likely be 
unrelated to the SFRs, so there must be an explanation of how it cannot 
affect security. Access to user data, however, is likely to be related to access 
control SFRs, so the explanation would describe how the security 
functionality works when invoked through the data -access interfaces. Such a 
description is needed for every available interface. 
589 An example of a description follows. Suppose the TSF provides file 
protection. Further suppose that although the “traditional” system cal l TSFIs 
for open, read, and write invoke the file protection mechanism described in 
the TOE design, there exists a TSFI that allows access to a batch job facility 
(creating batch jobs, deleting jobs, modifying unprocessed jobs). The 
evaluator should be abl e to determine from the vendor -provided description 
Class ADV: Development 
Page 128 of 430 Version 3.1 April 2017 
that this TSFI invokes the same protection mechanisms as do the 
“traditional” interfaces. This could be done, for example, by referencing the 
appropriate sections of the TOE design that discuss how the batch job facility 
TSFI achieves its security objectives. 
590 Using this same example, suppose there is a TSFI whose sole purpose is to 
display the time of day. The evaluator should determine that the description 
adequately argues that this TSFI is not capable of manipulating any protected 
resources and should not invoke any security functionality. 
591 Another example of bypass is when the TSF is supposed to maintain 
confidentiality of a cryptographic key (one is allowed to use it for 
cryptographic operations, but is  not allowed to read/write it). If an attacker 
has direct physical access to the device, he might be able to examine side -
channels such as the power usage of the device, the exact timing of the 
device, or even any electromagnetic emanations of the device a nd, from this, 
infer the key. 
592 If such side -channels may be present, the demonstration should address the 
mechanisms that prevent these side-channels from occurring, such as random 
internal clocks, dual -line technology etc. Verification of these mechanisms 
would be verified by a combination of purely design -based arguments and 
testing. 
593 For a final example using security functionality rather than a protected 
resource, consider an ST that contains FCO_NRO.2 Enforced proof of origin, 
which requires that the TSF provides evidence of origination for information 
types specified in the ST. Suppose that the “information types” included all 
information that is sent by the TOE via e -mail. In this case the evaluator 
should examine the description to ensure that all TSFI that can be invoked to 
send e -mail perform the “evidence of origination generation” function are 
detailed. The description might point to user guidance to show all places 
where e -mail can originate (e.g., e -mail program, notification from 
scripts/batch jobs) and then how each of these places invokes the evidence 
generation function. 
594 The evaluator should also ensure that the description is comprehensive, in 
that each interface is analysed with respect to the entire set of claimed SFRs. 
This may require the evaluator to examine supporting information 
(functional specification, TOE design, other parts of the security architecture 
description, operational user guidance, and perhaps even the implementation 
representation, as provided for the TOE) to determine that the description has 
correctly capture all aspects of an interface. The evaluator should consider 
what SFRs each TSFI might affect (from the description of the TSFI and its 
implementation in the supporting documentation), and then ex amine the 
description to determine whether it covers those aspects. 
Class ADV: Development 
April 2017 Version 3.1 Page 129 of 430 
12.4 Functional specification (ADV_FSP) 
12.4.1 Evaluation of sub-activity (ADV_FSP.1) 
12.4.1.1 Objectives 
595 The objective of this sub -activity is to determine whether the developer has 
provided a high -level des cription of at least the SFR -enforcing and SFR -
supporting TSFIs, in terms of descriptions of their parameters. There is no 
other required evidence that can be expected to be available to measure the 
accuracy of these descriptions; the evaluator merely ensu res the descriptions 
seem plausible. 
12.4.1.2 Input 
596 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the functional specification;  
c) the operational user guidance;  
12.4.1.3 Action ADV_FSP.1.1E 
ADV_FSP.1.1C The functional specification shall describe the purpose and method of use 
for each SFR-enforcing and SFR-supporting TSFI.  
ADV_FSP.1-1 The evaluator shall examine the functional specification to determine that it 
states the purpose of each SFR-supporting and SFR-enforcing TSFI. 
597 The purpose of a TSFI is a general statement summarising the functionality 
provided by the interface. It is not intended to be a complete statement of t he 
actions and results related to the interface, but rather a statement to help the 
reader understand in general what the interface is intended to be used for. 
The evaluator should not only determine that the purpose exists, but also that 
it accurately reflects the TSFI by taking into account other information about 
the interface, such as the description of the parameters; this can be done in 
association with other work units for this component. 
598 If an action available through an interface plays a role in en forcing any 
security policy on the TOE (that is, if one of the actions of the interface can 
be traced to one of the SFRs levied on the TSF), then that interface is SFR-
enforcing. Such policies are not limited to the access control policies, but 
also refer to any functionality specified by one of the SFRs contained in the 
ST. Note that it is possible that an interface may have various actions and 
results, some of which may be SFR-enforcing and some of which may not. 
599 Interfaces to (or actions available throug h an interface relating to) actions 
that SFR -enforcing functionality depends on, but need only to function 
correctly in order for the security policies of the TOE to be preserved, are 
Class ADV: Development 
Page 130 of 430 Version 3.1 April 2017 
termed SFR supporting . Interfaces to actions on which SFR -enforcing 
functionality has no dependence are termed SFR non-interfering. 
600 It should be noted that in order for an interface to be SFR supporting or SFR 
non-interfering it must have no SFR-enforcing actions or results. In contrast, 
an SFR-enforcing interface may have SFR -supporting actions (for example, 
the ability to set the system clock may be an SFR -enforcing action of an 
interface, but if that same interface is used to display the system date that 
action may only be SFR supporting). An example of a purely SFR -
supporting interface is a system call interface that is used both by untrusted 
users and by a portion of the TSF that is running in user mode. 
601 At this level, it is unlikely that a developer will have expended effort to label 
interfaces as SFR -enforcing and SFR -supporting. In the case that this has 
been done, the evaluator should verify to the extent that supporting 
documentation (e.g., operational user guidance) allows that this identification 
is correct. Note that this identification activity is necessary for seve ral work 
units for this component. 
602 In the more likely case that the developer has not labelled the interfaces, the 
evaluator must perform their own identification of the interfaces first, and 
then determine whether the required information (for this work u nit, the 
purpose) is present. Again, because of the lack of supporting evidence this 
identification will be difficult and have low assurance that all appropriate 
interfaces have been correctly identified, but nonetheless the evaluator 
examines other eviden ce available for the TOE to ensure as complete 
coverage as is possible. 
ADV_FSP.1-2 The evaluator shall examine  the functional specification to determine that 
the method of use for each SFR-supporting and SFR-enforcing TSFI is given. 
603 See work unit ADV_FSP.1-1 for a discussion on the identification of SFR -
supporting and SFR-enforcing TSFI. 
604 The method of use for a TSFI summarises how the interface is manipulated 
in order to invoke the actions and obtain the results associated with the TSFI. 
The evaluator should be able to determine, from reading this material in the 
functional specification, how to use each interface. This does not necessarily 
mean that there needs to be a separate method of use for each TSFI, as it may 
be possible to describe in general how kernel calls are invoked, for instance, 
and then identify each interface using that general style. Different types of 
interfaces will require different method of use specifications. APIs, ne twork 
protocol interfaces, system configuration parameters, and hardware bus 
interfaces all have very different methods of use, and this should be taken 
into account by the developer when developing the functional specification, 
as well as by the evaluator evaluating the functional specification. 
605 For administrative interfaces whose functionality is documented as being 
inaccessible to untrusted users, the evaluator ensures that the method of 
making the functions inaccessible is described in the functional specification. 
Class ADV: Development 
April 2017 Version 3.1 Page 131 of 430 
It should be noted that this inaccessibility needs to be tested by the developer 
in their test suite. 
ADV_FSP.1.2C The functional specification shall identify all parameters associated with 
each SFR-enforcing and SFR-supporting TSFI.  
ADV_FSP.1-3 The evaluator shall examine the presentation of the TSFI to determine that it 
identifies all parameters associated with each SFR -enforcing and SFR -
supporting TSFI. 
606 See work unit ADV_FSP.1-1 for a discussion on the identification of SFR -
supporting and SFR-enforcing TSFI. 
607 The evaluator examines the functional specification to ensure that all of the 
parameters are described for identified TSFI . Parameters are explicit inputs 
or outputs to an interface that control the behaviour of that interface. For 
examples, parameters are the arguments supplied to an API; the various 
fields in packet for a given network protocol; the individual key values in  the 
Windows Registry; the signals across a set of pins on a chip; etc. 
608 While difficult to obtain much assurance that all parameters for the 
applicable TSFI have been identified, the evaluator should also check other 
evidence provided for the evaluation (e .g., operational user guidance) to see 
if behaviour or additional parameters are described there but not in the 
functional specification. 
ADV_FSP.1.3C The functional specification shall provide rationale for the implicit 
categorisation of interfaces as SFR-non-interfering.  
ADV_FSP.1-4 The evaluator shall examine the rationale provided by the developer for the 
implicit categorisation of interfaces as SFR -non-interfering to determine that 
it is accurate. 
609 In the case where the developer has provided adequate documentation to 
perform the analysis called for by the rest of the work units for this 
component without explicitly identifying SFR-enforcing and SFR-supporting 
interfaces, this work unit should be considered satisfied. 
610 This work unit is intended to apply to cases where the developer has not 
described a portion of the TSFI, claiming that it is SFR -non-interfering and 
therefore not subject to other requirements of this component. In such a case, 
the developer provides a rationale for this characterisation in sufficient detail 
such that the evaluator understands the rationale, the characteristics of the 
interfaces affected (e.g., their high -level function with respect to the TOE, 
such as “colour palette manipulation”), and that the claim that these are SFR -
non-interfering is supported. Given the level of assurance the evaluator 
should not expect more detail than is provided for the SFR -enforcing or 
SFR-supporting interf aces, and in fact the detail should be much less. In 
most cases, individual interfaces should not need to be addressed in the 
developer-provided rationale section. 
Class ADV: Development 
Page 132 of 430 Version 3.1 April 2017 
ADV_FSP.1.4C The tracing shall demonstrate t hat the SFRs trace to TSFIs in the 
functional specification.  
ADV_FSP.1-5 The evaluator shall check  that the tracing links the SFRs to the 
corresponding TSFIs. 
611 The tracing is provided by the developer to serve as  a guide to which SFRs 
are related to which TSFIs. This tracing can be as simple as a table; it is used 
as input to the evaluator for use in the following work units, in which the 
evaluator verifies its completeness and accuracy. 
12.4.1.4 Action ADV_FSP.1.2E 
ADV_FSP.1-6 The evaluator shall examine the functional specification to determine that it 
is a complete instantiation of the SFRs. 
612 To ensure that all SFRs are covered by th e functional specification, as well 
as the test coverage analysis, the evaluator may build upon the developer's 
tracing (see ADV_FSP.1-5 a map between the TOE security functional 
requirements and the TSFI). Note that this  map may have to be at a level of 
detail below the component or even element level of the requirements, 
because of operations (assignments, refinements, selections) performed on 
the functional requirement by the ST author. 
613 For example, the FDP_ACC.1 component contains an element with 
assignments. If the ST contained, for instance, ten rules in the FDP_ACC.1 
assignment, and these ten rules were covered by three different TSFI, it 
would be inadequate for the evaluator to map FDP_ACC.1 to TSFI A, B, and 
C and claim they had completed the work unit. Instead, the evaluator would 
map FDP_ACC.1 (rule 1) to TSFI A; FDP_ACC.1 (rule 2) to TSFI B; etc. It 
might also be the case that the interface is a wrapper interface (e.g., IOCTL), 
in which case the mapping would need to be specific to certain set of 
parameters for a given interface. 
614 The evaluator must rec ognise that for requirements that have little or no 
manifestation at the TSF boundary (e.g., FDP_RIP) it is not expected that 
they completely map those requirements to the TSFI. The analysis for those 
requirements will be per formed in the analysis for the TOE design 
(ADV_TDS) when included in the ST. It is also important to note that since 
the parameters associated with TSFIs must be fully specified, the evaluator 
should be able to determine if a ll aspects of an SFR appear to be 
implemented at the interface level. 
ADV_FSP.1-7 The evaluator shall examine the functional specification to determine that it 
is an accurate instantiation of the SFRs. 
615 For each functional requirement in the ST that results in effects visible at the 
TSF boundary, the information in the associated TSFI for that requirement 
specifies the required functionality described by the requirement. For 
example, if the ST contains a requiremen t for access control lists, and the 
only TSFI that map to that requirement specify functionality for Unix -style 
Class ADV: Development 
April 2017 Version 3.1 Page 133 of 430 
protection bits, then the functional specification is not accurate with respect 
to the requirements. 
616 The evaluator must recognise that for requi rements that have little or no 
manifestation at the TSF boundary (e.g., FDP_RIP) it is not expected that the 
evaluator completely map those requirements to the TSFI. The analysis for 
those requirements will be performed in th e analysis for the TOE design 
(ADV_TDS) when included in the ST. 
12.4.2 Evaluation of sub-activity (ADV_FSP.2) 
12.4.2.1 Objectives 
617 The objective of this sub -activity is to determine whether the developer has 
provided a description of the TSF Is in terms of their purpose, method of use, 
and parameters. In addition, the SFR -enforcing actions, results and error 
messages of each TSFI that is SFR-enforcing are also described. 
12.4.2.2 Input 
618 The evaluation evidence for this sub -activity that is required by t he work -
units is:  
a) the ST;  
b) the functional specification;  
c) the TOE design.  
619 The evaluation evidence for this sub -activity that is used if included in the 
ST for the TOE is:  
a) the security architecture description;  
b) the operational user guidance;  
12.4.2.3 Action ADV_FSP.2.1E 
ADV_FSP.2.1C The functional specification shall completely represent the TSF.  
ADV_FSP.2-1 The evaluator shall examine  the functional specification to determine that 
the TSF is fully represented. 
620 The identification of the TSFI is a necessary prerequisite to all other 
activities in this sub-activity. The TSF must be identified (done as part of the 
TOE design (ADV_TDS)  work units) in order to identify the TSFI. This 
activity can be done at a high level to ensure that no large groups of 
interfaces have been missed (network protocols, hardware interfaces, 
configuration files), or at a low level as the evaluation of the functional 
specification proceeds. 
Class ADV: Development 
Page 134 of 430 Version 3.1 April 2017 
621 In making an assessment for this work unit, the evaluator determines that all 
portions of the TSF are addressed in terms of the interfaces listed in the 
functional specification. All portions of the TSF should have a corresponding 
interface description, or if there are no corresponding interfaces for a portion 
of the TSF, the evaluator determines that that is acceptable. 
ADV_FSP.2.2C The functional speci fication shall describe the purpose and method of use 
for all TSFI.  
ADV_FSP.2-2 The evaluator shall examine the functional specification to determine that it 
states the purpose of each TSFI. 
622 The purpose of a TSF I is a general statement summarising the functionality 
provided by the interface. It is not intended to be a complete statement of the 
actions and results related to the interface, but rather a statement to help the 
reader understand in general what the in terface is intended to be used for. 
The evaluator should not only determine that the purpose exists, but also that 
it accurately reflects the TSFI by taking into account other information about 
the interface, such as the description of actions and error messages. 
ADV_FSP.2-3 The evaluator shall examine  the functional specification to determine that 
the method of use for each TSFI is given. 
623 The method of use for a TSFI summarises how the interface is manipulated 
in order to invoke the actions and obtain the results associated with the TSFI. 
The evaluator should be able to determine, from reading this material in the 
functional specification, how to use each interface. This does not necessarily 
mean that there needs to be a separate method of use for each TSFI, as it may 
be possible to describe in general how kernel calls are invoked, for instance, 
and then identify each interface using that general style. Different types of 
interfaces will require different method of  use specifications. APIs, network 
protocol interfaces, system configuration parameters, and hardware bus 
interfaces all have very different methods of use, and this should be taken 
into account by the developer when developing the functional specification , 
as well as by the evaluator evaluating the functional specification. 
624 For administrative interfaces whose functionality is documented as being 
inaccessible to untrusted users, the evaluator ensures that the method of 
making the functions inaccessible is described in the functional specification. 
It should be noted that this inaccessibility needs to be tested by the developer 
in their test suite. 
625 The evaluator should not only determine that the set of method of use 
descriptions exist, but also that they accurately cover each TSFI. 
ADV_FSP.2.3C The functional specification shall identify and describe all parameters 
associated with each TSFI.  
ADV_FSP.2-4 The evaluator shall examine the presentation of the TSFI to determine that it 
completely identifies all parameters associated with every TSFI. 
Class ADV: Development 
April 2017 Version 3.1 Page 135 of 430 
626 The evaluator examines the functional specification to ensure that all of the 
parameters are described for each TSFI. Parameter s are explicit inputs or 
outputs to an interface that control the behaviour of that interface. For 
examples, parameters are the arguments supplied to an API; the various 
fields in packet for a given network protocol; the individual key values in the 
Windows Registry; the signals across a set of pins on a chip; etc. 
627 In order to determine that all of the parameters are present in the TSFI, the 
evaluator should examine the rest of the interface description (actions, error 
messages, etc.) to determine if the ef fects of the parameter are accounted for 
in the description. The evaluator should also check other evidence provided 
for the evaluation (e.g., TOE design, security architecture description, 
operational user guidance, implementation representation) to see if behaviour 
or additional parameters are described there but not in the functional 
specification. 
ADV_FSP.2-5 The evaluator shall examine the presentation of the TSFI to determine that it 
completely and accuratel y describes all parameters associated with every 
TSFI. 
628 Once all of the parameters have been identified, the evaluator needs to ensure 
that they are accurately described, and that the description of the parameters 
is complete. A parameter description tells what the parameter is in some 
meaningful way. For instance, the interface foo(i) could be described as 
having “parameter i which is an integer"; this is not an acceptable parameter 
description. A description such as “parameter i is an integer that indicates the 
number of users currently logged in to the system” is much more acceptable. 
629 In order to determine that the description of the parameters is complete, the 
evaluator should examine the rest of the interface description (purpose, 
method of use, actions,  error messages, etc.) to determine if the descriptions 
of the parameter(s) are accounted for in the description. The evaluator should 
also check other evidence provided (e.g., TOE design, architectural design, 
operational user guidance, implementation representation) to see if behaviour 
or additional parameters are described there but not in the functional 
specification. 
ADV_FSP.2.4C For each SFR -enforcing TSFI, the functional specification shall describe 
the SFR-enforcing actions associated with the TSFI.  
ADV_FSP.2-6 The evaluator shall examine the presentation of the TSFI to determine that it 
completely and accurately describes the SFR -enforcing actions associated  
with the SFR-enforcing TSFIs. 
630 If an action available through an interface can be traced to one of the SFRs 
levied on the TSF, then that interface is SFR-enforcing. Such policies are not 
limited to the access control policies, but also refer to any functio nality 
specified by one of the SFRs contained in the ST. Note that it is possible that 
an interface may have various actions and results, some of which may be 
SFR-enforcing and some of which may not. 
Class ADV: Development 
Page 136 of 430 Version 3.1 April 2017 
631 The developer is not required to “label” interfaces as S FR-enforcing, and 
likewise is not required to identify actions available through an interface as 
SFR-enforcing. It is the evaluator's responsibility to examine the evidence 
provided by the developer and determine that the required information is 
present. I n the case where the developer has identified the SFR -enforcing 
TSFI and SFR-enforcing actions available through those TSFI, the evaluator 
must judge completeness and accuracy based on other information supplied 
for the evaluation (e.g., TOE design, securi ty architecture description, 
operational user guidance), and on the other information presented for the 
interfaces (parameters and parameter descriptions, error messages, etc.). 
632 In this case (where the developer has provided only the SFR -enforcing 
information for SFR -enforcing TSFI) the evaluator also ensures that no 
interfaces have been mis -categorised. This is done by examining other 
information supplied for the evaluation (e.g., TOE design, security 
architecture description, operational user guidance), a nd the other 
information presented for the interfaces (parameters and parameter 
descriptions, for example) not labelled as SFR-enforcing. 
633 In the case where the developer has provided the same level of information 
on all interfaces, the evaluator performs t he same type of analysis mentioned 
in the previous paragraphs. The evaluator should determine which interfaces 
are SFR-enforcing and which are not, and subsequently ensure that the SFR -
enforcing aspects of the SFR-enforcing actions are appropriately described. 
634 The SFR-enforcing actions are those that are visible at any external interface 
and that provide for the enforcement of the SFRs being claimed. For example, 
if audit requirements are included in the ST, then audit -related actions would 
be SFR-enforcing and therefore must be described, even if the result of that 
action is generally not visible through the invoked interface (as is often the 
case with audit, where a user action at one interface would produce an audit 
record visible at another interface). 
635 The level of description that is required is that sufficient for the reader to 
understand what role the TSFI actions play with respect to the SFR. The 
evaluator should keep in mind that the description should be detailed enough 
to support the generation (and assessment) of test cases against that interface. 
If the description is unclear or lacking detail such that meaningful testing 
cannot be conducted against the TSFI, it is likely that the description is 
inadequate. 
ADV_FSP.2.5C For each SFR -enforcing TSFI, the functional specification shall describe 
direct error messages resulting from processing associated with the SFR -
enforcing actions.  
ADV_FSP.2-7 The evaluator shall examine the presentation of the TSFI to determine that it 
completely and accurately describes error messages that may result from 
SFR-enforcing actions associated with each SFR-enforcing TSFI. 
636 This work unit should be performed in conjunction with, o r after, work unit 
ADV_FSP.2-6 in order to ensure the set of SFR -enforcing TSFI and SFR -
Class ADV: Development 
April 2017 Version 3.1 Page 137 of 430 
enforcing actions is correctly identified. The developer may provide more 
information than is required (for example, all error messages associate d with 
each interface), in which the case the evaluator should restrict their 
assessment of completeness and accuracy to only those that they determine 
to be associated with SFR-enforcing actions of SFR-enforcing TSFI. 
637 Errors can take many forms, depending  on the interface being described. For 
an API, the interface itself may return an error code, set a global error 
condition, or set a certain parameter with an error code. For a configuration 
file, an incorrectly configured parameter may cause an error mess age to be 
written to a log file. For a hardware PCI card, an error condition may raise a 
signal on the bus, or trigger an exception condition to the CPU. 
638 Errors (and the associated error messages) come about through the 
invocation of an interface. The proc essing that occurs in response to the 
interface invocation may encounter error conditions, which trigger (through 
an implementation-specific mechanism) an error message to be generated. In 
some instances this may be a return value from the interface itself ; in other 
instances a global value may be set and checked after the invocation of an 
interface. It is likely that a TOE will have a number of low -level error 
messages that may result from fundamental resource conditions, such as 
“disk full” or “resource l ocked”. While these error messages may map to a 
large number of TSFI, they could be used to detect instances where detail 
from an interface description has been omitted. For instance, a TSFI that 
produces a “disk full” message, but has no obvious descripti on of why that 
TSFI should cause an access to the disk in its description of actions, might 
cause the evaluator to examine other evidence ( Security Architecture 
(ADV_ARC), TOE design (ADV_TDS) ) related that TSFI to det ermine if 
the description is accurate. 
639 In order to determine that the description of the error messages of a TSFI is 
accurate and complete, the evaluator measures the interface description 
against the other evidence provided for the evaluation (e.g., TOE d esign, 
security architecture description, operational user guidance), as well as other 
evidence available for that TSFI (parameters, analysis from work unit 
ADV_FSP.2-6). 
ADV_FSP.2.6C The tracing shall demonstrate that the SFRs trace to TSFIs in the 
functional specification.  
ADV_FSP.2-8 The evaluator shall check  that the tracing links the SFRs to the 
corresponding TSFIs. 
640 The tracing is provided by the developer to serve as a guide to which SFRs 
are related to which TSFIs. This tracing can be as simple as a table; it is used 
as input to the evaluator for use in the following work units, in which the 
evaluator verifies its completeness and accuracy. 
Class ADV: Development 
Page 138 of 430 Version 3.1 April 2017 
12.4.2.4 Action ADV_FSP.2.2E 
ADV_FSP.2-9 The evaluator shall examine the functional specification to determine that it 
is a complete instantiation of the SFRs. 
641 To ensure that all SFRs are covered by the functional specification, as well 
as the test coverage analysis, the evaluator may build upon the developer's 
tracing (see ADV_FSP.2-8 a map between the TOE security functional 
requirements and the TSFI. Note that this map may have to be at a level of 
detail below the component or even element level of the requirements, 
because of operations (assignments, refinements, selections) performed on 
the functional requirement by the ST author. 
642 For example, the FDP_ACC.1 component contains an element with 
assignments. If the ST contained, for instance, ten rules in the FDP_ACC.1 
assignment, and these ten rules were covered by three different TSFI, it 
would be inadequate for the evaluator to map FDP_ACC.1 to TSFI A, B, and 
C and claim they had completed the work unit. Instead, the evaluator would 
map FDP_ACC.1 (rule 1) to TSFI A; FDP_ACC.1 (rule 2) to TSFI B; etc. It 
might also be the case that the interface is a wrapper interface (e.g., IOCTL), 
in which case the mapping would need to be specific to certain set of 
parameters for a given interface. 
643 The evaluator must recognise that for requirements that have little or no 
manifestation at the TSF boundary (e.g., FDP_RIP) it is not expected that 
they completely map those requirements to the TSFI. The an alysis for those 
requirements will be performed in the analysis for the TOE design 
(ADV_TDS) when included in the ST. It is also important to note that since 
the parameters, actions, and error messages associated with TSFIs m ust be 
fully specified, the evaluator should be able to determine if all aspects of an 
SFR appear to be implemented at the interface level. 
ADV_FSP.2-10 The evaluator shall examine the functional specification to determine that it 
is an accurate instantiation of the SFRs. 
644 For each functional requirement in the ST that results in effects visible at the 
TSF boundary, the information in the associated TSFI for that requirement 
specifies the required functionality described by the requirement. For 
example, if the ST contains a requirement for access control lists, and the 
only TSFI that map to that requirement specify functionality for Unix -style 
protection bits, then the functional specification is not accurate wit h respect 
to the requirements. 
645 The evaluator must recognise that for requirements that have little or no 
manifestation at the TSF boundary (e.g., FDP_RIP) it is not expected that the 
evaluator completely map those requirement s to the TSFI. The analysis for 
those requirements will be performed in the analysis for the TOE design 
(ADV_TDS) when included in the ST. 
Class ADV: Development 
April 2017 Version 3.1 Page 139 of 430 
12.4.3 Evaluation of sub-activity (ADV_FSP.3) 
12.4.3.1 Objectives 
646 The objective of this sub -activity is to determine whether the developer has 
provided a description of the TSFIs in terms of their purpose, method of use, 
and parameters. In addition, the actions, results and error messages of each 
TSFI are also described sufficiently that it can be determin ed whether they 
are SFR -enforcing, with the SFR -enforcing TSFI being described in more 
detail than other TSFIs. 
12.4.3.2 Input 
647 The evaluation evidence for this sub -activity that is required by the work -
units is:  
a) the ST;  
b) the functional specification;  
c) the TOE design.  
648 The evaluation evidence for this sub -activity that is used if included in the 
ST for the TOE is:  
a) the security architecture description;  
b) the implementation representation;  
c) the TSF internals description;  
d) the operational user guidance;  
12.4.3.3 Action ADV_FSP.3.1E 
ADV_FSP.3.1C The functional specification shall completely represent the TSF.  
ADV_FSP.3-1 The evaluator shall examine the functional specification to determine that 
the TSF is fully represented. 
649 The identification of the TSFI is a necessary prerequisite to all other 
activities in this sub-activity. The TSF must be identified (done as part of the 
TOE design (ADV_TDS)  work units) in order to identify the TSFI. This 
activity can be done at a high level to ensure that no large groups of 
interfaces have been missed (network protocols, hardware interfaces, 
configuration files), or at a low level as the  evaluation of the functional 
specification proceeds. 
650 In making an assessment for this work unit, the evaluator determines that all 
portions of the TSF are addressed in terms of the interfaces listed in the 
functional specification. All portions of the TSF should have a corresponding 
Class ADV: Development 
Page 140 of 430 Version 3.1 April 2017 
interface description, or if there are no corresponding interfaces for a portion 
of the TSF, the evaluator determines that that is acceptable. 
ADV_FSP.3.2C The functional specification shall describe the purpose and method of use 
for all TSFI.  
ADV_FSP.3-2 The evaluator shall examine the functional specification to determine that it 
states the purpose of each TSFI. 
651 The purpose of a TSFI i s a general statement summarising the functionality 
provided by the interface. It is not intended to be a complete statement of the 
actions and results related to the interface, but rather a statement to help the 
reader understand in general what the inter face is intended to be used for. 
The evaluator should not only determine that the purpose exists, but also that 
it accurately reflects the TSFI by taking into account other information about 
the interface, such as the description of actions and error messages. 
ADV_FSP.3-3 The evaluator shall examine  the functional specification to determine that 
the method of use for each TSFI is given. 
652 The method of use for a TSFI summarises how the interface is manipulated 
in order to invoke the actions and obtain the results associated with the TSFI. 
The evaluator should be able to determine, from reading this material in the 
functional specification, how to use each interface. This does not necessarily 
mean that there needs to be a separate method of use for each TSFI, as it may 
be possible to describe in general how kernel calls are invoked, for instance, 
and then identify each interface using that general style. Different types of 
interfaces will require different method of us e specifications. APIs, network 
protocol interfaces, system configuration parameters, and hardware bus 
interfaces all have very different methods of use, and this should be taken 
into account by the developer when developing the functional specification, 
as well as by the evaluator evaluating the functional specification. 
653 For administrative interfaces whose functionality is documented as being 
inaccessible to untrusted users, the evaluator ensures that the method of 
making the functions inaccessible is described in the functional specification. 
It should be noted that this inaccessibility needs to be tested by the developer 
in their test suite. 
654 The evaluator should not only determine that the set of method of use 
descriptions exist, but also that they accurately cover each TSFI. 
ADV_FSP.3.3C The functional specification shall identify and describe all parameters 
associated with each TSFI.  
ADV_FSP.3-4 The evaluator shall examine the presentation of the TSFI to determine that it 
completely identifies all parameters associated with every TSFI. 
655 The evaluator examines the functional specification to ensure that all of the 
parameters are described for each TSFI. Parameters a re explicit inputs or 
outputs to an interface that control the behaviour of that interface. For 
Class ADV: Development 
April 2017 Version 3.1 Page 141 of 430 
examples, parameters are the arguments supplied to an API; the various 
fields in packet for a given network protocol; the individual key values in the 
Windows Registry; the signals across a set of pins on a chip; etc. 
656 In order to determine that all of the parameters are present in the TSFI, the 
evaluator should examine the rest of the interface description (actions, error 
messages, etc.) to determine if the effec ts of the parameter are accounted for 
in the description. The evaluator should also check other evidence provided 
for the evaluation (e.g., TOE design, security architecture description, 
operational user guidance, implementation representation) to see if behaviour 
or additional parameters are described there but not in the functional 
specification. 
ADV_FSP.3-5 The evaluator shall examine the presentation of the TSFI to determine that it 
completely and accurately d escribes all parameters associated with every 
TSFI. 
657 Once all of the parameters have been identified, the evaluator needs to ensure 
that they are accurately described, and that the description of the parameters 
is complete. A parameter description tells wha t the parameter is in some 
meaningful way. For instance, the interface foo(i) could be described as 
having “parameter i which is an integer”; this is not an acceptable parameter 
description. A description such as “parameter i is an integer that indicates the 
number of users currently logged in to the system” is much more acceptable. 
658 In order to determine that the description of the parameters is complete, the 
evaluator should examine the rest of the interface description (purpose, 
method of use, actions, er ror messages, etc.) to determine if the descriptions 
of the parameter(s) are accounted for in the description. The evaluator should 
also check other evidence provided (e.g., TOE design, architectural design, 
operational user guidance, implementation representation) to see if behaviour 
or additional parameters are described there but not in the functional 
specification. 
ADV_FSP.3.4C For each SFR -enforcing TSFI, the functional specification shall describe 
the SFR-enforcing actions associated with the TSFI.  
ADV_FSP.3-6 The evaluator shall examine the presentation of the TSFI to determine that it 
completely and accurately describes the SFR -enforcing actions associated 
with the SFR-enforcing TSFIs. 
659 If an action available through an interface plays a role in enforcing any 
security policy on the TOE (that is, if one of the actions of the interface can 
be traced to one of the SFRs levied on the TSF), then that interface is SFR-
enforcing. Such policies are not limited to the access control policies, but 
also refer to any functionality specified by one of the SFRs contained in the 
ST. Note that it is possible that an interface may have various actions and 
results, some of which may be SFR-enforcing and some of which may not. 
660 The developer is not required to “label” interfaces as SFR -enforcing, and 
likewise is not required to identify actions available through an interface as 
Class ADV: Development 
Page 142 of 430 Version 3.1 April 2017 
SFR-enforcing. It is the evaluator's responsibility to examine the evidence 
provided by the developer and determine that the required information is 
present. In the case where the developer has identified the SFR -enforcing 
TSFI and SFR-enforcing actions available through those TSFI, the evaluator 
must judge co mpleteness and accuracy based on other information supplied 
for the evaluation (e.g., TOE design, security architecture description, 
operational user guidance), and on the other information presented for the 
interfaces (parameters and parameter descriptions, error messages, etc.). 
661 In this case (developer has provided only the SFR -enforcing information for 
SFR-enforcing TSFI) the evaluator also ensures that no interfaces have been 
mis-categorised. This is done by examining other information supplied for 
the evaluation (e.g., TOE design, security architecture description, 
operational user guidance), and the other information presented for the 
interfaces (parameters and parameter descriptions, for example) not labelled 
as SFR -enforcing. The analysis done for wo rk units ADV_FSP.3-7 and 
ADV_FSP.3-8 are also used in making this determination. 
662 In the case where the developer has provided the same level of information 
on all interfaces, the evaluator performs the same type of analysis mentioned 
in the previous paragraphs. The evaluator should determine which interfaces 
are SFR-enforcing and which are not, and subsequently ensure that the SFR -
enforcing aspects of the SFR -enforcing actions are appropr iately described. 
Note that in this case, the evaluator should be able to perform the bulk of the 
work associated with work unit ADV_FSP.3-8 in the course of performing 
this SFR-enforcing analysis. 
663 The SFR-enforcing actions are those that are visible at any external interface 
and that provide for the enforcement of the SFRs being claimed. For example, 
if audit requirements are included in the ST, then audit -related actions would 
be SFR-enforcing and therefore must be described, even i f the result of that 
action is generally not visible through the invoked interface (as is often the 
case with audit, where a user action at one interface would produce an audit 
record visible at another interface). 
664 The level of description that is required  is that sufficient for the reader to 
understand what role the TSFI actions play with respect to the SFR. The 
evaluator should keep in mind that the description should be detailed enough 
to support the generation (and assessment) of test cases against that interface. 
If the description is unclear or lacking detail such that meaningful testing 
cannot be conducted against the TSFI, it is likely that the description is 
inadequate. 
ADV_FSP.3.5C For each SFR -enforcing TSFI, the functional specification shall describe 
direct error messages resulting from SFR-enforcing actions and exceptions 
associated with invocation of the TSFI.  
ADV_FSP.3-7 The evaluator shall examine the presentation of the TSFI to determine that it 
completely and accurately describes error messages that may result from an 
invocation of each SFR-enforcing TSFI. 
Class ADV: Development 
April 2017 Version 3.1 Page 143 of 430 
665 This work unit should be performed in conjunction with, or after, work unit 
ADV_FSP.3-6 in order to ensure the set of SFR -enforcing TSFI is correctly 
identified. The evaluator should note that the requirement and associated 
work unit is that all direct error messages associated with an SFR -enforcing 
TSFI must be described, that are associated with SFR-enforcing actions. This 
is because at this level of assurance, the “extra” information provided by the 
error message descriptions should be used in determining whether all of the 
SFR-enforcing aspects of an interface have been appropriately described. For 
instance, if an error message associated with a TSFI (e.g., “access denied”) 
indicated that an SFR-enforcing decision or action had taken place, but in the 
description of the SFR -enforcing actions there was no mention of that 
particular SFR -enforcing mechanism, then the description may not be 
complete. 
666 Errors can take many forms, depending on the interface being described. For 
an API, the interface itself may return an error code, set a global error 
condition, or set a certain para meter with an error code. For a configuration 
file, an incorrectly configured parameter may cause an error message to be 
written to a log file. For a hardware PCI card, an error condition may raise a 
signal on the bus, or trigger an exception condition to the CPU. 
667 Errors (and the associated error messages) come about through the 
invocation of an interface. The processing that occurs in response to the 
interface invocation may encounter error conditions, which trigger (through 
an implementation-specific mechanism) an error message to be generated. In 
some instances this may be a return value from the interface itself; in other 
instances a global value may be set and checked after the invocation of an 
interface. It is likely that a TOE will have a number of lo w-level error 
messages that may result from fundamental resource conditions, such as 
“disk full” or “resource locked”. While these error messages may map to a 
large number of TSFI, they could be used to detect instances where detail 
from an interface descr iption has been omitted. For instance, a TSFI that 
produces a “disk full” message, but has no obvious description of why that 
TSFI should cause an access to the disk in its description of actions, might 
cause the evaluator to examine other evidence ( Security Architecture 
(ADV_ARC), TOE design (ADV_TDS) ) related that TSFI to determine if 
the description is accurate. 
668 In order to determine that the description of the error messages of a TSFI is 
accurate and complete, the e valuator measures the interface description 
against the other evidence provided for the evaluation (e.g., TOE design, 
security architecture description, operational user guidance), as well as for 
other evidence supplied for that TSFI (description of SFR -enforcing actions, 
summary of SFR-supporting and SFR-non-interfering actions and results). 
ADV_FSP.3.6C The functional specification shall summarise the SFR -supporting and 
SFR-non-interfering actions associated with each TSFI.  
ADV_FSP.3-8 The evaluator shall examine the presentation of the TSFI to determine that it 
summarises the SFR -supporting and SFR -non-interfering actions associated 
with each TSFI. 
Class ADV: Development 
Page 144 of 430 Version 3.1 April 2017 
669 The purpose of this work unit is to supplement the details about the SFR -
enforcing actions (provided in work unit ADV_FSP.3-6) with a summary of 
the remaining actions (i.e., those that are not SFR -enforcing). This covers all 
SFR-supporting and SFR-non-interfering actions, whether invokable through 
SFR-enforcing TSFI or through SFR -supporting or SFR -non-interfering 
TSFI. Such a summary about all SFR -supporting and SFR -non-interfering 
actions helps to provide a more complete picture of the functions p rovided 
by the TSF, and is to be used by the evaluator in determining whether an 
action or TSFI may have been mis-categorised. 
670 The information to be provided is more abstract than that required for SFR -
enforcing actions. While it should still be detailed e nough so that the reader 
can understand what the action does, the description does not have to be 
detailed enough to support writing tests against it, for instance. For the 
evaluator, the key is that the information must be sufficient to make a 
positive de termination that the action is SFR -supporting or SFR -non-
interfering. If that level of information is missing, the summary is 
insufficient and more information must be obtained. 
ADV_FSP.3.7C The tracing shall  demonstrate that the SFRs trace to TSFIs in the 
functional specification.  
ADV_FSP.3-9 The evaluator shall check  that the tracing links the SFRs to the 
corresponding TSFIs. 
671 The tracing is provided by the develop er to serve as a guide to which SFRs 
are related to which TSFIs. This tracing can be as simple as a table; it is used 
as input to the evaluator for use in the following work units, in which the 
evaluator verifies its completeness and accuracy. 
12.4.3.4 Action ADV_FSP.3.2E 
ADV_FSP.3-10 The evaluator shall examine the functional specification to determine that it 
is a complete instantiation of the SFRs. 
672 To ensure that all SFRs  are covered by the functional specification, as well 
as the test coverage analysis, the evaluator may build upon the developer's 
tracing (see ADV_FSP.3-9 a map between the TOE security functional 
requirements and the TSF I. Note that this map may have to be at a level of 
detail below the component or even element level of the requirements, 
because of operations (assignments, refinements, selections) performed on 
the functional requirement by the ST author. 
673 For example, the  FDP_ACC.1 component contains an element with 
assignments. If the ST contained, for instance, ten rules in the FDP_ACC.1 
assignment, and these ten rules were covered by three different TSFI,  it 
would be inadequate for the evaluator to map FDP_ACC.1 to TSFI A, B, and 
C and claim they had completed the work unit. Instead, the evaluator would 
map FDP_ACC.1 (rule 1) to TSFI A; FDP_ACC.1 (rule 2) to TSFI B; etc. It 
might also be the case that the interface is a wrapper interface (e.g., IOCTL), 
Class ADV: Development 
April 2017 Version 3.1 Page 145 of 430 
in which case the mapping would need to be specific to certain set of 
parameters for a given interface. 
674 The e valuator must recognise that for requirements that have little or no 
manifestation at the TSF boundary (e.g., FDP_RIP) it is not expected that 
they completely map those requirements to the TSFI. The analysis for those 
requirements will be performed in the analysis for the TOE design 
(ADV_TDS) when included in the ST. It is also important to note that since 
the parameters, actions, and error messages associated with TSFIs must be 
fully specified, the evaluator should be able to determine if all aspects of an 
SFR appear to be implemented at the interface level. 
ADV_FSP.3-11 The evaluator shall examine the functional specification to determine that it 
is an accurate instantiation of the SFRs. 
675 For each functional requirement in the ST that results in effects visible at the 
TSF boundary, the information in the associated TSFI for that requirement 
specifies the required functionality described by the require ment. For 
example, if the ST contains a requirement for access control lists, and the 
only TSFI that map to that requirement specify functionality for Unix -style 
protection bits, then the functional specification is not accurate with respect 
to the requirements. 
676 The evaluator must recognise that for requirements that have little or no 
manifestation at the TSF boundary (e.g., FDP_RIP) it is not expected that the 
evaluator completely map those requirements to the TSFI. The analy sis for 
those requirements will be performed in the analysis for the TOE design 
(ADV_TDS) when included in the ST. 
12.4.4 Evaluation of sub-activity (ADV_FSP.4) 
12.4.4.1 Objectives 
677 The objective of this sub -activity is to determine whether t he developer has 
completely described all of the TSFI in a manner such that the evaluator is 
able to determine whether the TSFI are completely and accurately described, 
and appears to implement the security functional requirements of the ST. 
12.4.4.2 Input 
678 The eval uation evidence for this sub -activity that is required by the work -
units is:  
a) the ST;  
b) the functional specification;  
c) the TOE design.  
679 The evaluation evidence for this sub -activity that is used if included in the 
ST for the TOE is:  
Class ADV: Development 
Page 146 of 430 Version 3.1 April 2017 
a) the security architecture description;  
b) the implementation representation;  
c) the TSF internals description;  
d) the operational user guidance;  
12.4.4.3 Application notes 
680 The functional specification describes the interfaces to the TSF (the TSFI) in 
a structured manner. Because of the depend ency on Evaluation of sub -
activity (ADV_TDS.1), the evaluator is expected to have identified the TSF 
prior to beginning work on this sub -activity. Without firm knowledge of 
what comprises the TSF, it is not possible to assess the compl eteness of the 
TSFI. 
681 In performing the various work units included in this family, the evaluator is 
asked to make assessments of accuracy and completeness of several factors 
(the TSFI itself, as well as the individual components (parameters, actions, 
error messages, etc.) of the TSFI). In doing this analysis, the evaluator is 
expected to use the documentation provided for the evaluation. This includes 
the ST, the TOE design, and may include other documentation such as the 
operational user guidance, security  architecture description, and 
implementation representation. The documentation should be examined in an 
iterative fashion. The evaluator may read, for example, in the TOE design 
how a certain function is implemented, but see no way to invoke that 
function from the interface. This might cause the evaluator to question the 
completeness of a particular TSFI description, or whether an interface has 
been left out of the functional specification altogether. Describing analysis 
activities of this sort in the ETR is a key method in providing rationale that 
the work units have been performed appropriately. 
682 It should be recognised that there exist functional requirements whose 
functionality is manifested wholly or in part architecturally, rather than 
through a specif ic mechanism. An example of this is the implementation of 
mechanisms implementing the Residual information protection (FDP_RIP)  
requirements. Such mechanisms typically are implemented to ensure a 
behaviour isn't present, which is difficu lt to test and typically is verified 
through analysis. In the cases where such functional requirements are 
included in the ST, it is expected that the evaluator recognise that there may 
be SFRs of this type that have no interfaces, and that this should not  be 
considered a deficiency in the functional specification. 
12.4.4.4 Action ADV_FSP.4.1E 
ADV_FSP.4.1C The functional specification shall completely represent the TSF.  
ADV_FSP.4-1 The evaluator shall examine  the functional specification to determine that 
the TSF is fully represented. 
Class ADV: Development 
April 2017 Version 3.1 Page 147 of 430 
683 The identification of the TSFI is a necessary prerequisite to all other 
activities in this sub-activity. The TSF must be identified (done as part of the 
TOE design (ADV_TDS)  work units) in order to identify the TSFI. This 
activity can be done at a high level to ensure that no large groups of 
interfaces have been missed (network prot ocols, hardware interfaces, 
configuration files), or at a low level as the evaluation of the functional 
specification proceeds. 
684 In making an assessment for this work unit, the evaluator determines that all 
portions of the TSF are addressed in terms of the interfaces listed in the 
functional specification. All portions of the TSF should have a corresponding 
interface description, or if there are no corresponding interfaces for a portion 
of the TSF, the evaluator determines that that is acceptable. 
ADV_FSP.4.2C The functional specification shall describe the purpose and method of use 
for all TSFI.  
ADV_FSP.4-2 The evaluator shall examine the functional specification to determine that it 
states the purpose of each TSFI. 
685 The purpose of a TSFI is a general statement summarising the functionality 
provided by the interface. It is not intended to be a complete statement of the 
actions and results related to the interface, but rather a statement to help the 
reader understand in general what the interface is intended to be used for. 
The evaluator should not only determine that the purpose exists, but also that 
it accurately reflects the TSFI by taking into account other informati on about 
the interface, such as the description of actions and error messages. 
ADV_FSP.4-3 The evaluator shall examine  the functional specification to determine that 
the method of use for each TSFI is given. 
686 The method of use for a TSFI summarises how the interface is manipulated 
in order to invoke the actions and obtain the results associated with the TSFI. 
The evaluator should be able to determine, from reading this material in the 
functional specification, how to use each interface. This does not necessarily 
mean that there needs to be a separate method of use for each TSFI, as it may 
be possible to describe in general how kernel calls are invoked, for instance, 
and then identify each interface using that genera l style. Different types of 
interfaces will require different method of use specifications. APIs, network 
protocol interfaces, system configuration parameters, and hardware bus 
interfaces all have very different methods of use, and this should be taken 
into account by the developer when developing the functional specification, 
as well as by the evaluator evaluating the functional specification. 
687 For administrative interfaces whose functionality is documented as being 
inaccessible to untrusted users, the eval uator ensures that the method of 
making the functions inaccessible is described in the functional specification. 
It should be noted that this inaccessibility needs to be tested by the developer 
in their test suite. 
Class ADV: Development 
Page 148 of 430 Version 3.1 April 2017 
688 The evaluator should not only determine t hat the set of method of use 
descriptions exist, but also that they accurately cover each TSFI. 
ADV_FSP.4-4 The evaluator shall examine  the functional specification to determine the 
completeness of the TSFI 
689 The e valuator shall use the design documentation to identify the possible 
types of interfaces. The evaluator shall search the design documentation and 
the guidance documentation for potential TSFI not contained in the 
developer's documentation, thus indicating that the set of TSFI defined by 
the developer is incomplete. The evaluator shall examine  the arguments 
presented by the developer that the TSFI is complete and check down to the 
lowest level of design or with the implementation representation that no 
additional TSFI exist. 
ADV_FSP.4.3C The functional specification shall identify and describe all parameters 
associated with each TSFI.  
ADV_FSP.4-5 The evaluator shall examine the presentation of the TSFI to determine that it 
completely identifies all parameters associated with every TSFI. 
690 The evaluator examines the functional specification to ensure that all of the 
parameters are described for each TSFI. Parameters are e xplicit inputs or 
outputs to an interface that control the behaviour of that interface. For 
examples, parameters are the arguments supplied to an API; the various 
fields in packet for a given network protocol; the individual key values in the 
Windows Registry; the signals across a set of pins on a chip; etc. 
691 In order to determine that all of the parameters are present in the TSFI, the 
evaluator should examine the rest of the interface description (actions, error 
messages, etc.) to determine if the effects o f the parameter are accounted for 
in the description. The evaluator should also check other evidence provided 
for the evaluation (e.g., TOE design, security architecture description, 
operational user guidance, implementation representation) to see if behaviour 
or additional parameters are described there but not in the functional 
specification. 
ADV_FSP.4-6 The evaluator shall examine the presentation of the TSFI to determine that it 
completely and accurately descr ibes all parameters associated with every 
TSFI. 
692 Once all of the parameters have been identified, the evaluator needs to ensure 
that they are accurately described, and that the description of the parameters 
is complete. A parameter description tells what th e parameter is in some 
meaningful way. For instance, the interface foo(i) could be described as 
having “parameter i which is an integer”; this is not an acceptable parameter 
description. A description such as “parameter i is an integer that indicates the 
number of users currently logged in to the system” is much more acceptable. 
693 In order to determine that the description of the parameters is complete, the 
evaluator should examine the rest of the interface description (purpose, 
Class ADV: Development 
April 2017 Version 3.1 Page 149 of 430 
method of use, actions, error messages, etc.) to determine if the descriptions 
of the parameter(s) are accounted for in the description. The evaluator should 
also check other evidence provided (e.g., TOE design, architectural design, 
operational user guidance, implementation representation) to see if behaviour 
or additional parameters are described there but not in the functional 
specification. 
ADV_FSP.4.4C The functional specification shall describe all actions associated with each 
TSFI.  
ADV_FSP.4-7 The evaluator shall examine the presentation of the TSFI to determine that it 
completely and accurately describes all actions associated with every TSFI. 
694 The evaluator checks to ensure that all of th e actions are described. actions 
available through an interface describe what the interface does (as opposed to 
the TOE design, which describes how the actions are provided by the TSF). 
695 Actions of an interface describe functionality that can be invoked through the 
interface, and can be categorised as regular actions, and SFR-related actions. 
Regular actions are descriptions of what the interface does. The amount of 
information provided for this description is dependant on the complexity of 
the interface. Th e SFR -related actions are those that are visible at any 
external interface (for instance, audit activity caused by the invocation of an 
interface (assuming audit requirements are included in the ST) should be 
described, even though the result of that actio n is generally not visible 
through the invoked interface). Depending on the parameters of an interface, 
there may be many different actions able to be invoked through the interface 
(for instance, an API might have the first parameter be a “subcommand”, and 
the following parameters be specific to that subcommand. The IOCTL API 
in some Unix systems is an example of such an interface). 
696 In order to determine that the description of the actions of a TSFI is complete, 
the evaluator should review the rest of the i nterface description (parameter 
descriptions, error messages, etc.) to determine if the actions described are 
accounted for. The evaluator should also analyse other evidence provided for 
the evaluation (e.g., TOE design, security architecture description, 
operational user guidance, implementation representation) to see if there is 
evidence of actions that are described there but not in the functional 
specification. 
ADV_FSP.4.5C The functional specification sha ll describe all direct error messages that 
may result from an invocation of each TSFI.  
ADV_FSP.4-8 The evaluator shall examine the presentation of the TSFI to determine that it 
completely and accurately describe s all errors messages resulting from an 
invocation of each TSFI. 
697 Errors can take many forms, depending on the interface being described. For 
an API, the interface itself may return an error code; set a global error 
condition, or set a certain parameter wit h an error code. For a configuration 
file, an incorrectly configured parameter may cause an error message to be 
Class ADV: Development 
Page 150 of 430 Version 3.1 April 2017 
written to a log file. For a hardware PCI card, an error condition may raise a 
signal on the bus, or trigger an exception condition to the CPU. 
698 Errors (and the associated error messages) come about through the 
invocation of an interface. The processing that occurs in response to the 
interface invocation may encounter error conditions, which trigger (through 
an implementation-specific mechanism) an error message to be generated. In 
some instances this may be a return value from the interface itself; in other 
instances a global value may be set and checked after the invocation of an 
interface. It is likely that a TOE will have a number of low -level e rror 
messages that may result from fundamental resource conditions, such as 
“disk full” or “resource locked”. While these error messages may map to a 
large number of TSFI, they could be used to detect instances where detail 
from an interface description ha s been omitted. For instance, a TSFI that 
produces a “disk full” message, but has no obvious description of why that 
TSFI should cause an access to the disk in its description of actions, might 
cause the evaluator to examine other evidence ( Security Architecture 
(ADV_ARC), TOE design (ADV_TDS) ) related that TSFI to determine if 
the description is complete and accurate. 
699 The evaluator determines that, for each TSFI, the exact set of error messages 
that can be returned on invoking that interface can be determined. The 
evaluator reviews the evidence provided for the interface to determine if the 
set of errors seems complete. They cross -check this information with other 
evidence provided for the evaluation (e.g., TOE design, security architecture 
description, operational user guidance, implementation representation) to 
ensure that there are no errors steaming from processing mentioned that are 
not included in the functional specification. 
ADV_FSP.4-9 The evaluator shall examine the presentation of the TSFI to determine that it 
completely and accurately describes the meaning of all error messages 
resulting from an invocation of each TSFI. 
700 In order to determine accuracy, the evaluator m ust be able to understand 
meaning of the error. For example, if an interface returns a numeric code of 0, 
1, or 2, the evaluator would not be able to understand the error if the 
functional specification only listed: “possible errors resulting from 
invocation of the foo() interface are 0, 1, or 2”. Instead the evaluator checks 
to ensure that the errors are described such as: “possible errors resulting from 
invocation of the foo() interface are 0 (processing successful), 1 (file not 
found), or 2 (incorrect filename specification)”. 
701 In order to determine that the description of the errors due to invoking a 
TSFI is complete, the evaluator examines the rest of the interface description 
(parameter descriptions, actions, etc.) to determine if potential error 
conditions that might be caused by using such an interface are accounted for. 
The evaluator also checks other evidence provided for the evaluation (e.g. 
TOE design, security architecture description, operational user guidance, 
implementation representation) to s ee if error processing related to the TSFI 
is described there but is not described in the functional specification. 
Class ADV: Development 
April 2017 Version 3.1 Page 151 of 430 
ADV_FSP.4.6C The tracing shall demonstrate that the SFRs trace to TSFIs in the 
functional specification.  
ADV_FSP.4-10 The evaluator shall check  that the tracing links the SFRs to the 
corresponding TSFIs. 
702 The tracing is provided by the developer to serve as a guide to which SFRs 
are related to which TSFIs. This tracing can be as simple as a table; it is used 
as input to the evaluator for use in the following work units, in which the 
evaluator verifies its completeness and accuracy. 
12.4.4.5 Action ADV_FSP.4.2E 
ADV_FSP.4-11 The evaluator shall examine the functional specification to determine that it 
is a complete instantiation of the SFRs. 
703 To ensure that all SFRs are covered by the functional specification, as well 
as the test coverage analysis, the evaluator may build upon the developer's 
tracing (see ADV_FSP.4-10 a map between the TOE security functional 
requirements and the TSFI. Note that this map may have to be at a level of 
detail below the component or even element level of the requirements, 
because of operations (assignments, refinements, selections) performed on 
the functional requirement by the ST author. 
704 For example, the FDP_ACC.1 component contains an el ement with 
assignments. If the ST contained, for instance, ten rules in the FDP_ACC.1 
assignment, and these ten rules were covered by three different TSFI, it 
would be inadequate for the evaluator to map FDP_ACC.1 to TSFI A, B, and 
C and claim they had completed the work unit. Instead, the evaluator would 
map FDP_ACC.1 (rule 1) to TSFI A; FDP_ACC.1 (rule 2) to TSFI B; etc. It 
might also be the case that the interface is a wrapper interface (e.g., IOCTL), 
in which case the mapping would need to be specific to certain set of 
parameters for a given interface. 
705 The evaluator must recognise that for requirements that have little or no  
manifestation at the TSF boundary (e.g., FDP_RIP) it is not expected that 
they completely map those requirements to the TSFI. The analysis for those 
requirements will be performed in the analysis for the TOE design 
(ADV_TDS) when included in the ST. It is also important to note that since 
the parameters, actions, and error messages associated with TSFIs must be 
fully specified, the evaluator should be able to determine if all aspects of an 
SFR appear to be implemented at the interface level. 
ADV_FSP.4-12 The evaluator shall examine the functional specification to determine that it 
is an accurate instantiation of the SFRs. 
706 For each functional requirement in the ST that results in effects visible at the 
TSF boundary, the information in the associated TSFI for that requirement 
specifies the required functionality described by the requirement. For 
example, if the ST contains a requirement for access contr ol lists, and the 
only TSFI that map to that requirement specify functionality for Unix -style 
Class ADV: Development 
Page 152 of 430 Version 3.1 April 2017 
protection bits, then the functional specification is not accurate with respect 
to the requirements. 
707 The evaluator must recognise that for requirements that have little or no 
manifestation at the TSF boundary (e.g., FDP_RIP) it is not expected that the 
evaluator completely map those requirements to the TSFI. The analysis for 
those requirements will be performed in the analysis for the  TOE design 
(ADV_TDS) when included in the ST. 
12.4.5 Evaluation of sub-activity (ADV_FSP.5) 
12.4.5.1 Objectives 
708 The objective of this sub -activity is to determine whether the developer has 
completely described all of the TSFI in a manner su ch that the evaluator is 
able to determine whether the TSFI are completely and accurately described, 
and appears to implement the security functional requirements of the ST. The 
completeness of the interfaces is judged based upon the implementation 
representation. 
12.4.5.2 Input 
709 The evaluation evidence for this sub -activity that is required by the work -
units is:  
a) the ST;  
b) the functional specification;  
c) the TOE design;  
d) the implementation representation.  
710 The evaluation evidence for this sub -activity that is used if included in the 
ST for the TOE is:  
a) the security architecture description;  
b) the TSF internals description;  
c) the formal security policy model;  
d) the operational user guidance;  
12.4.5.3 Action ADV_FSP.5.1E 
ADV_FSP.5.1C The functional specification shall completely represent the TSF.  
ADV_FSP.5-1 The evaluator shall examine  the functional specification to determine that 
the TSF is fully represented. 
711 The identification of the TSFI is a necessary prerequisite to all other 
activities in this sub-activity. The TSF must be identified (done as part of the 
Class ADV: Development 
April 2017 Version 3.1 Page 153 of 430 
TOE design (ADV_TDS)  work units) in order to identify the TSFI. Thi s 
activity can be done at a high level to ensure that no large groups of 
interfaces have been missed (network protocols, hardware interfaces, 
configuration files), or at a low level as the evaluation of the functional 
specification proceeds. 
712 In making an assessment for this work unit, the evaluator determines that all 
portions of the TSF are addressed in terms of the interfaces listed in the 
functional specification. All portions of the TSF should have a corresponding 
interface description, or if there are no corresponding interfaces for a portion 
of the TSF, the evaluator determines that that is acceptable. 
ADV_FSP.5.2C The functional specification shall describe the TSFI using a semi -formal 
style.  
ADV_FSP.5-2 The evaluator shall examine the functional specification to determine that it 
is presented using a semiformal style. 
713 A semi-formal presentation is characterised by a standardised format with a 
well-defined synt ax that reduces ambiguity that may occur in informal 
presentations. Since the intent of the semi -formal format is to enhance the 
reader's ability to understand the presentation, use of certain structured 
presentation methods (pseudo -code, flow charts, bloc k diagrams) are 
appropriate, though not required. 
714 For the purposes of this activity, the evaluator should ensure that the 
interface descriptions are formatted in a structured, consistent manner and 
use common terminology. A semiformal presentation of the i nterfaces also 
implies that the level of detail of the presentation for the interfaces is largely 
consistent across all TSFI. For the functional specification, it is acceptable to 
refer to external specifications for portions of the interface as long as th ose 
external specifications are themselves semiformal. 
ADV_FSP.5.3C The functional specification shall describe the purpose and method of use 
for all TSFI.  
ADV_FSP.5-3 The evaluator shall examine the functional specification to determine that it 
states the purpose of each TSFI. 
715 The purpose of a TSFI is a general statement summarising the functionality 
provided by the interface. It is not intended to be a complete st atement of the 
actions and results related to the interface, but rather a statement to help the 
reader understand in general what the interface is intended to be used for. 
The evaluator should not only determine that the purpose exists, but also that 
it accurately reflects the TSFI by taking into account other information about 
the interface, such as the description of actions and error messages. 
ADV_FSP.5-4 The evaluator shall examine  the functional specification  to determine that 
the method of use for each TSFI is given. 
Class ADV: Development 
Page 154 of 430 Version 3.1 April 2017 
716 The method of use for a TSFI summarises how the interface is manipulated 
in order to invoke the actions and obtain the results associated with the TSFI. 
The evaluator should be able to determine,  from reading this material in the 
functional specification, how to use each interface. This does not necessarily 
mean that there needs to be a separate method of use for each TSFI, as it may 
be possible to describe in general how kernel calls are invoked,  for instance, 
and then identify each interface using that general style. Different types of 
interfaces will require different method of use specifications. APIs, network 
protocol interfaces, system configuration parameters, and hardware bus 
interfaces all  have very different methods of use, and this should be taken 
into account by the developer when developing the functional specification, 
as well as by the evaluator evaluating the functional specification. 
717 For administrative interfaces whose functionality  is documented as being 
inaccessible to untrusted users, the evaluator ensures that the method of 
making the functions inaccessible is described in the functional specification. 
It should be noted that this inaccessibility needs to be tested by the develop er 
in their test suite. 
718 The evaluator should not only determine that the set of method of use 
descriptions exist, but also that they accurately cover each TSFI. 
ADV_FSP.5-5 The evaluator shall examine  the functio nal specification to determine the 
completeness of the TSFI 
719 The evaluator shall use the design documentation to identify the possible 
types of interfaces. The evaluator shall search the design documentation and 
the guidance documentation for potential TSFI  not contained in the 
developer's documentation, thus indicating that the set of TSFI defined by 
the developer is incomplete. The evaluator shall examine  the arguments 
presented by the developer that the TSFI is complete and check down to the 
lowest level of design or with the implementation representation that no 
additional TSFI exist. 
ADV_FSP.5.4C The functional specification shall identify and describe all parameters 
associated with each TSFI.  
ADV_FSP.5-6 The evaluator shall examine the presentation of the TSFI to determine that it 
completely identifies all parameters associated with every TSFI. 
720 The evaluator examines the functional specification to ensure that al l of the 
parameters are described for each TSFI. Parameters are explicit inputs or 
outputs to an interface that control the behaviour of that interface. For 
examples, parameters are the arguments supplied to an API; the various 
fields in packet for a given network protocol; the individual key values in the 
Windows Registry; the signals across a set of pins on a chip; etc. 
721 In order to determine that all of the parameters are present in the TSFI, the 
evaluator should examine the rest of the interface descript ion (actions, error 
messages, etc.) to determine if the effects of the parameter are accounted for 
in the description. The evaluator should also check other evidence provided 
Class ADV: Development 
April 2017 Version 3.1 Page 155 of 430 
for the evaluation (e.g., TOE design, security architecture description, 
operational user guidance, implementation representation) to see if behaviour 
or additional parameters are described there but not in the functional 
specification. 
ADV_FSP.5-7 The evaluator shall examine the presentation of the TSFI to determine that it 
completely and accurately describes all parameters associated with every 
TSFI. 
722 Once all of the parameters have been identified, the evaluator needs to ensure 
that they are accurately described, and that the description of the parameters 
is complete. A parameter description tells what the parameter is in some 
meaningful way. For instance, the interface foo(i) could be described as 
having “parameter i which is an integer”; this is not an acceptable parameter 
description. A description such as “parameter i is an integer that indicates the 
number of users currently logged in to the system”. is much more acceptable. 
723 In order to determine that the description of the parameters is complete, the 
evaluator should examine the rest of the interface description (purpose, 
method of use, actions, error messages, etc.) to determine if the descriptions 
of the parameter(s) are accounted for in the description. The evaluator should 
also check other evidence provided (e.g., TOE design, architec tural design, 
operational user guidance, implementation representation) to see if behaviour 
or additional parameters are described there but not in the functional 
specification. 
ADV_FSP.5.5C The functional specification shall describe all actions associated with each 
TSFI.  
ADV_FSP.5-8 The evaluator shall examine the presentation of the TSFI to determine that it 
completely and accurately describes all actions associated with every TSFI. 
724 The evaluator checks to ensure that all of the actions are described. actions 
available through an interface describe what the interface does (as opposed to 
the TOE design, which describes how the actions are provided by the TSF). 
725 actions of an interface describe functionality that can be invoked through the 
interface, and can be categorised as regular actions, and SFR-related actions. 
Regular actions are descriptions of what the interface does. The amount of 
information provided for th is description is dependant on the complexity of 
the interface. The SFR -related actions are those that are visible at any 
external interface (for instance, audit activity caused by the invocation of an 
interface (assuming audit requirements are included in  the ST) should be 
described, even though the result of that action is generally not visible 
through the invoked interface). Depending on the parameters of an interface, 
there may be many different actions able to be invoked through the interface 
(for instance, an API might have the first parameter be a “subcommand”, and 
the following parameters be specific to that subcommand. The IOCTL API 
in some Unix systems is an example of such an interface). 
Class ADV: Development 
Page 156 of 430 Version 3.1 April 2017 
726 In order to determine that the description of the actions of a TSFI is complete, 
the evaluator should review the rest of the interface description (parameter 
descriptions, error messages, etc.) to determine if the actions described are 
accounted for. The evaluator should also analyse other evidence provided for 
the evaluation (e.g., TOE design, security architecture description, 
operational user guidance, implementation representation) to see if there is 
evidence of actions that are described there but not in the functional 
specification. 
ADV_FSP.5.6C The functional specification shall describe all direct error messages that 
may result from an invocation of each TSFI.  
ADV_FSP.5-9 The evaluator shall examine the presentation of the TSFI to determine that it 
completely and accurately describes all errors messages resulting from an 
invocation of each TSFI. 
727 Errors can take many forms, depending on the interface being described. For 
an API, the interface itself may return an error code; set a global error 
condition, or set a certain parameter with an error code. For a configuration 
file, an incorrectly configured parameter may cause an error message to be 
written to a log file. For a hardware PCI card, an error condition may raise a  
signal on the bus, or trigger an exception condition to the CPU. 
728 Errors (and the associated error messages) come about through the 
invocation of an interface. The processing that occurs in response to the 
interface invocation may encounter error condition s, which trigger (through 
an implementation-specific mechanism) an error message to be generated. In 
some instances this may be a return value from the interface itself; in other 
instances a global value may be set and checked after the invocation of an 
interface. It is likely that a TOE will have a number of low -level error 
messages that may result from fundamental resource conditions, such as 
“disk full” or “resource locked”. While these error messages may map to a 
large number of TSFI, they could be used  to detect instances where detail 
from an interface description has been omitted. For instance, a TSFI that 
produces a “disk full” message, but has no obvious description of why that 
TSFI should cause an access to the disk in its description of actions, mi ght 
cause the evaluator to examine other evidence ( ADV_ARC, ADV_TDS) 
related that TSFI to determine if the description is complete and accurate. 
729 The evaluator determines that, for each TSFI, the  exact set of error messages 
that can be returned on invoking that interface can be determined. The 
evaluator reviews the evidence provided for the interface to determine if the 
set of errors seems complete. They cross -check this information with other 
evidence provided for the evaluation (e.g., TOE design, security architecture 
description, operational user guidance, implementation representation) to 
ensure that there are no errors steaming from processing mentioned that are 
not included in the functional specification. 
ADV_FSP.5-10 The evaluator shall examine the presentation of the TSFI to determine that it 
completely and accurately describes the meaning of all error messages 
resulting from an invocation of each TSFI. 
Class ADV: Development 
April 2017 Version 3.1 Page 157 of 430 
730 In order to determine accuracy, the evaluator must be able to understand 
meaning of the error. For example, if an interface returns a numeric code of 0, 
1, or 2, the evaluator would not be able to understand the error if the 
functional specificat ion only listed: “possible errors resulting from 
invocation of the foo() interface are 0, 1, or 2”. Instead the evaluator checks 
to ensure that the errors are described such as: “possible errors resulting from 
invocation of the foo() interface are 0 (proce ssing successful), 1 (file not 
found), or 2 (incorrect filename specification)”. 
731 In order to determine that the description of the errors due to invoking a 
TSFI is complete, the evaluator examines the rest of the interface description 
(parameter descriptio ns, actions, etc.) to determine if potential error 
conditions that might be caused by using such an interface are accounted for. 
The evaluator also checks other evidence provided for the evaluation (e.g., 
TOE design, security architecture description, oper ational user guidance, 
implementation representation) to see if error processing related to the TSFI 
is described there but is not described in the functional specification. 
ADV_FSP.5.7C The functional specif ication shall describe all error messages that do not 
result from an invocation of a TSFI.  
ADV_FSP.5-11 The evaluator shall examine the functional specification to determine that it 
completely and accurately describes all errors messages that do not result 
from an invocation of any TSFI. 
732 This work unit complements work unit ADV_FSP.5-9, which describes 
those error messages that result from an invocation of the TSFI. Taken 
together, these work units cover all error messages that might be generated 
by the TSF. 
733 The evaluator assesses the completeness and accuracy of the functional 
specification by comparing its contents to instances of error message 
generation within the implementation repre sentation. Most of these error 
messages will have already been covered by work unit ADV_FSP.5-9. 
734 The error messages related to this work unit are typically those that are not 
expected to be generated, but are constructed as a matter of good 
programming practises. For example, a case statement that defines actions 
resulting from each of a list of cases may end with a final else statement to 
apply to anything that might not be expected; this practise ensures the TSF 
does not get into an undefined state. However, it is not expected that the path 
of execution would ever get to this else statement; therefore, any error 
message generation within this else statement would never be generated. 
Although it would not get generated, it must still be included in the 
functional specification. 
ADV_FSP.5.8C The functional specification shall provide a rationale for each error 
message contained in the TSF implementation yet does not result from an 
invocation of a TSFI.  
Class ADV: Development 
Page 158 of 430 Version 3.1 April 2017 
ADV_FSP.5-12 The evaluator shall examine the functional specification to determine that it 
provides a rationale for each error message contained in the TSF 
implementation yet does not result from an invocation of a TSFI. 
735 The evaluator ensures that every error message found under work unit 
ADV_FSP.5-11 contains a rationale describing why it cannot be invoked 
from the TSFI. 
736 As was described in the previous work unit, this ra tionale might be as 
straightforward as the fact that the error message in question is provided for 
completeness of execution logic and that it is never expected to be generated. 
The evaluator ensures that the rationale for each such error message is 
logical. 
ADV_FSP.5.9C The tracing shall demonstrate that the SFRs trace to TSFIs in the 
functional specification.  
ADV_FSP.5-13 The evaluator shall check  that the trac ing links the SFRs to the 
corresponding TSFIs. 
737 The tracing is provided by the developer to serve as a guide to which SFRs 
are related to which TSFIs. This tracing can be as simple as a table; it is used 
as input to the evaluator for use in the following wo rk units, in which the 
evaluator verifies its completeness and accuracy. 
12.4.5.4 Action ADV_FSP.5.2E 
ADV_FSP.5-14 The evaluator shall examine the functional specification to determine that it 
is a complete instantiation of the SFRs. 
738 To ensure that all SFRs are covered by the functional specification, as well 
as the test coverage analysis, the evaluator may build upon the developer's 
tracing (see ADV_FSP.5-13 a map between the TOE security functional 
requirements and the TSFI. Note that this map may have to be at a level of 
detail below the component or even element level of the requirements, 
because of operations (assignments, refinements, selections)  performed on 
the functional requirement by the ST author. 
739 For example, the FDP_ACC.1 component contains an element with 
assignments. If the ST contained, for instance, ten rules in the FDP_ACC.1 
assignment, and these ten rules were covered by three different TSFI, it 
would be inadequate for the evaluator to map FDP_ACC.1 to TSFI A, B, and 
C and claim they had completed the work unit. Instead, the evaluator wo uld 
map FDP_ACC.1 (rule 1) to TSFI A; FDP_ACC.1 (rule 2) to TSFI B; etc. It 
might also be the case that the interface is a wrapper interface (e.g., IOCTL), 
in which case the mapping would ne ed to be specific to certain set of 
parameters for a given interface. 
740 The evaluator must recognise that for requirements that have little or no 
manifestation at the TSF boundary (e.g., FDP_RIP) it is not expected that 
they completely map those requirements to the TSFI. The analysis for those 
Class ADV: Development 
April 2017 Version 3.1 Page 159 of 430 
requirements will be performed in the analysis for the TOE design 
(ADV_TDS) when included in the ST. It is also important to note that since 
the parameters, actions, and error messages associated with TSFIs must be 
fully specified, the evaluator should be able to determine if all aspects of an 
SFR appear to be implemented at the interface level. 
ADV_FSP.5-15 The evaluator shall examine the functional specification to determine that it 
is an accurate instantiation of the SFRs. 
741 For each functional requirement in the ST that results in effects visible at the 
TSF boundary, the information in the associated TSFI for tha t requirement 
specifies the required functionality described by the requirement. For 
example, if the ST contains a requirement for access control lists, and the 
only TSFI that map to that requirement specify functionality for Unix -style 
protection bits, th en the functional specification is not accurate with respect 
to the requirements. 
742 The evaluator must recognise that for requirements that have little or no 
manifestation at the TSF boundary (e.g., FDP_RIP) it is not expected that the 
evaluator completely map those requirements to the TSFI. The analysis for 
those requirements will be performed in the analysis for the TOE design 
(ADV_TDS) when included in the ST. 
12.4.6 Evaluation of sub-activity (ADV_FSP.6) 
743 There is no general guidance; the scheme should be consulted for guidance 
on this sub-activity. 
Class ADV: Development 
Page 160 of 430 Version 3.1 April 2017 
12.5 Implementation representation (ADV_IMP) 
12.5.1 Evaluation of sub-activity (ADV_IMP.1) 
12.5.1.1 Objectives 
744 The objective of this sub -activity is to determine that the imple mentation 
representation made available by the developer is suitable for use in other 
analysis activities; suitability is judged by its conformance to the 
requirements for this component. 
12.5.1.2 Input 
745 The evaluation evidence for this sub-activity is:  
a) the implementation representation;  
b) the documentation of the development tools, as resulting from 
ALC_TAT ;  
c) TOE design description.  
12.5.1.3 Application notes 
746 The entire implementation representation is made available to ensure that 
analysis activities are not curtailed due to lack of information. This does not, 
however, imply that all of the representation is examined when the analysis 
activities are being performed. This is likely impractical in almost all cases, 
in addition to the fact that it most likely will not result in a higher -assurance 
TOE vs. targeted sampling of the implementation representation. For this 
sub-activity, this is even truer. It would not be productive for the evaluator to 
spend large amounts of time verifying the requirements for one portion of the 
implementation representation, and then use a different portion of the 
implementation representation in performing analysis for other work units. 
Therefore, the evaluator is encouraged to select the sample of the 
implementation representation from the areas of the TOE that will be of most 
interest during the analysis performed during work units from other families 
(e.g. ATE_IND, AVA_VAN and ADV_INT). 
12.5.1.4 Action ADV_IMP.1.1E 
ADV_IMP.1.1C The implementation representation shall define the TSF to a level of detail 
such that the TSF can be generated without further design decisions.  
ADV_IMP.1-1 The evaluator shall check that the implementation representation defines the 
TSF to a level of detail such that the TSF can be generated without further 
design decisions. 
747 Source code or hardware diagrams and/or IC hardware design language code 
or layout data that are used to build the actual hardware are examples of parts 
of an implementation representation. The evaluator samples the 
implementation representation to gain  confidence that it is at the appropriate 
Class ADV: Development 
April 2017 Version 3.1 Page 161 of 430 
level and not, for instance, a pseudo -code level which requires additional 
design decisions to be made. The evaluator is encouraged to perform a quick 
check when first looking at the implementation representation t o assure 
themselves that the developer is on the right track. However, the evaluator is 
also encourage to perform the bulk of this check while working on other 
work units that call for examining the implementation; this will ensure the 
sample examined for this work unit is relevant. 
ADV_IMP.1.2C The implementation representation shall be in the form used by the 
development personnel.  
ADV_IMP.1-2 The evaluator shall check that the implementation representation is in the 
form used by development personnel. 
748 The implementation representation is manipulated by the developer in form 
that it suitable for transformation to the actual implementation. For instance, 
the develop er may work with files containing source code, which is 
eventually compiled to become part of the TSF. The developer makes 
available the implementation representation in the form they use, so that the 
evaluator may use automated techniques in the analysis.  This also increases 
the confidence that the implementation representation examined is actually 
the one used in the production of the TSF (as opposed to the case where it is 
supplied in an alternate presentation format, such as a word processor 
document). It should be noted that other forms of the implementation 
representation may also be used by the developer; these forms are supplied 
as well. The overall goal is to supply the evaluator with the information that 
will maximise the evaluator's analysis efforts. 
749 The evaluator samples the implementation representation to gain confidence 
that it is the version that is usable by the developer. The sample is such that 
the evaluator has assurance that all areas of the implementation 
representation are in conformanc e with the requirement; however, a 
complete examination of the entire implementation representation is 
unnecessary. 
750 Conventions in some forms of the implementation representation may make 
it difficult or impossible to determine from just the implementation  
representation itself what the actual result of the compilation or run -time 
interpretation will be. For example, compiler directives for C language 
compilers will cause the compiler to exclude or include entire portions of the 
code. 
751 Some forms of the impl ementation representation may require additional 
information because they introduce significant barriers to understanding and 
analysis. Examples include shrouded source code or source code that has 
been obfuscated in other ways such that it prevents unders tanding and/or 
analysis. These forms of implementation representation typically result from 
by taking a version of the implementation representation that is used by the 
TOE developer and running a shrouding or obfuscation program on it. While 
the shrouded representation is what is compiled and may be closer to the 
implementation (in terms of structure) than the original, un -shrouded 
Class ADV: Development 
Page 162 of 430 Version 3.1 April 2017 
representation, supplying such obfuscated code may cause significantly more 
time to be spent in analysis tasks involving the r epresentation. When such 
forms of representation are created, the components require details on the 
shrouding tools/algorithms used so that the un -shrouded representation can 
be supplied, and the additional information can be used to gain confidence 
that the shrouding process does not compromise any security mechanisms. 
752 The evaluator samples the implementation representation to gain confidence 
that all of the information needed to interpret the implementation 
representation has been supplied. Note that the tools are among those 
referenced by Tools and techniques (ALC_TAT) components. The evaluator 
is encouraged to perform a quick check when first looking at the 
implementation representation to assure themselves that the developer is on 
the right track. However, the evaluator is also encouraged to perform the 
bulk of this check while working on other work units that call for examining 
the implementation; this will ensure the sample examined for this work unit 
is relevant. 
ADV_IMP.1.3C The mapping between the TOE design description and the sample of the 
implementation representation shall demonstrate their correspondence.  
ADV_IMP.1-3 The evaluator shall examine  the mapping between the TOE design 
description and the sample of the implementation representation to determine 
that it is accurate. 
753 The evaluator augments the determination of existence (specified in work 
unit ADV_IMP.1-1) by verifying the accuracy of a portion of the 
implementation representation and the TOE design description. For parts of 
the TOE design description that are interesting, the evaluator would verify 
the implementation representation accurately reflects the description 
provided in the TOE design description. 
754 For example, the TOE design description might identify a login module that 
is used to identify and authenticate users. If user authentication is sufficiently 
significant, the evaluator would verify that t he corresponding code in fact 
implements that service as described in the TOE design description. It might 
also be worthwhile to verify that the code accepts the parameters as 
described in the functional specification. 
755 It is worth pointing out the develope r must choose whether to perform the 
mapping for the entire implementation representation, thereby guaranteeing 
that the chosen sample will be covered, or waiting for the sample to be 
chosen before performing the mapping. The first option is likely more wo rk, 
but may be completed before the evaluation begins. The second option is less 
work, but will produce a suspension of evaluation activity while the 
necessary evidence is being produced. 
12.5.2 Evaluation of sub-activity (ADV_IMP.2) 
756 There is no general guidance;  the scheme should be consulted for guidance 
on this sub-activity. 
Class ADV: Development 
April 2017 Version 3.1 Page 163 of 430 
12.6 TSF internals (ADV_INT) 
12.6.1 Evaluation of sub-activity (ADV_INT.1) 
12.6.1.1 Objectives 
757 The objective of this sub -activity is to determine whether the defined subset 
of the TSF is designed and structure d such that the likelihood of flaws is 
reduced and that maintenance can be more readily performed without the 
introduction of flaws. 
12.6.1.2 Input 
758 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the TOE design description;  
c) the implementation represent ation (if ADV_IMP is part of the 
claimed assurance);  
d) the TSF internals description and justification;  
e) the documentation of the coding standards, as resulting from 
ALC_TAT.  
12.6.1.3 Application notes 
759 The role of the internals description is to provide evidence of the structure of 
the design and implementation of the TSF. 
760 The structure of the design has two aspects: the constituent parts of the TSF 
and the procedures used to design the TSF. In cases wher e the TSF is 
designed in a manner consistent with the design represented by the TOE 
design (see ADV_TDS), the assessment of the TSF design is obvious. In 
cases where the design procedures (see ALC_TAT) are being followed, the 
assessment of the TSF design procedures is similarly obvious. 
761 In cases where the TSF is implemented using procedure -based software, this 
structure is assessed on the basis of its modularity; the modules identified in 
the internals description are the same as the modules identified in the TOE 
design (TOE design (ADV_TDS)). A module consists of one or more source 
code files that cannot be decomposed into smaller compilable units. 
762 The use of the assignment in this component levies stricter constraints on the 
subset of the TSF that is explicitly identified in the assignment 
ADV_INT.1.1D than on the remainder of the TSF. While the entire TSF is to 
be designed using good engineering principles and result in a well -structured 
TSF, only the specified subset is specifically analysed for this characteristic. 
The evaluator determines that the developer's application of coding standards 
result in a TSF that is understandable. 
Class ADV: Development 
Page 164 of 430 Version 3.1 April 2017 
763 The prima ry goal of this component is to ensure the TSF subset's 
implementation representation is understandable to facilitate maintenance 
and analysis (of both the developer and evaluator). 
12.6.1.4 Action ADV_INT.1.1E 
ADV_INT.1.1C The justification shall explain the characteristics used to judge the 
meaning of “well-structured”.  
ADV_INT.1-1 The evaluator shall examine  the justification to determine that it identifies 
the basis for determining whether the TSF is well-structured. 
764 The evaluator verifies that the criteria for determining the characteristic of 
being well -structured are clearly defined in the justification. Acceptable 
criteria typically originate from industry standards for the technology 
discipline. For example, procedural software that executes linearly is 
traditionally viewed as well -structured if it adheres to software engineering 
programming practises, such as those define d in the IEEE Standard ( IEEE 
Std 610.12 -1990). For example, it would identify the criteria for the 
procedural software portions of the TSF subset:  
a) the process used for modular decomposition 
b) coding standards used in the development of the implementation 
c) a description of the maximum acceptable level of intermodule 
coupling exhibited by the TSF subset 
d) a description of the minimum acceptable level of cohesion exhibited 
the modules of the TSF subset 
765 For other types of technologies used in the TOE - such as non -procedural 
software (e.g. object -oriented programming), widespread commodity 
hardware (e.g. PC microprocessors), and special -purpose hardware (e.g. 
smart-card processors) - the evaluator should seek guidance from the 
evaluation authority for determining the adequacy of criteria for being “well -
structured”. 
ADV_INT.1.2C The TSF internals description shall demonstrate that the assigned subset 
of the TSF is well-structured.  
ADV_INT.1-2 The evaluator shall check the TSF internals description to determine that it 
identifies the Assigned subset of the TSF. 
766 This subset may be identified in terms of the internals of the TSF at any layer 
of abstraction. For example, it may be  in terms of the structural elements of 
the TSF as identified in the TOE design (e.g. the audit subsystem), or in 
terms of the implementation (e.g. encrypt.c and decrypt.c files, or the 6227 
IC chip). 
Class ADV: Development 
April 2017 Version 3.1 Page 165 of 430 
767 It is insufficient to identify this subset in terms of the claimed SFRs (e.g. the 
portion of the TSF that provide anonymity as defined in FPR_ANO.2) 
because this does not indicate where to focus the analysis. 
ADV_INT.1-3 The evaluator shall examine the TSF internals description to determine that 
it demonstrates that the assigned TSF subset is well-structured. 
768 The evaluator examines the internals description to ensure that it provides a 
sound explanation of how the TSF subset meets the criteria from 
ADV_INT.1-1 
769 For example, it would explain how the procedural software portions of the 
TSF subset meets the following:  
a) that there is a one -to-one correspondence between the modules 
identified in the TSF subs et and the modules described in the TOE 
design (ADV_TDS) 
b) how the TSF design is a reflection of the modular decomposition 
process 
c) a justification for all instances where the coding standards were not 
used or met 
d) a justificatio n for any coupling or cohesion outside the acceptable 
bounds 
12.6.1.5 Action ADV_INT.1.2E 
ADV_INT.1-4 The evaluator shall determine  that the TOE design for the assigned TSF 
subset is well-structured. 
770 The evaluator examines a sample of the TOE design to verify the accuracy of 
the justification. For example, a sample of the TOE design is analysed to 
determine its adherence to the design standards, etc. As with all areas where 
the evaluator performs activities on a subset the evaluator provides a 
justification of the sample size and scope 
771 The description of the TOE's decomposition into subsystems and modules 
will make the argument that the TSF subset is well -structured self-evident. 
Verification that the procedures for structuring the TSF (as examined in 
ALC_TAT) are being followed will make it self -evident that the TSF subset 
is well-structured. 
ADV_INT.1-5 The evaluator shall determine that the assigned TSF subset is well-structured. 
772 If ADV_IMP is not part of the claimed assurance, then this work unit is not 
applicable and is therefore considered to be satisfied. 
773 The evaluator examines a sample of the TSF subset to verify the accuracy of 
the internals description. For example, a sample of the procedural software 
portions of the TSF subset is analysed to determine its cohesion and coupling, 
Class ADV: Development 
Page 166 of 430 Version 3.1 April 2017 
its adherence to the coding standards, etc. As with all areas where the 
evaluator performs activities on a subset the evaluator provides a justification 
of the sample size and scope. 
12.6.2 Evaluation of sub-activity (ADV_INT.2) 
12.6.2.1 Objectives 
774 The objective of this sub -activity is to determine whether the  TSF is 
designed and structured such that the likelihood of flaws is reduced and that 
maintenance can be more readily performed without the introduction of 
flaws. 
12.6.2.2 Input 
775 The evaluation evidence for this sub-activity is:  
a) the modular design description;  
b) the implementation representation (if ADV_IMP is part of the 
claimed assurance));  
c) the TSF internals description;  
d) the documentation of the coding standards, as resulting from 
ALC_TAT.  
12.6.2.3 Application notes 
776 The role of the internals description is to provide evidence of the structure of 
the design and implementation of the TSF. 
777 The structure of the design has two aspects: the constituent parts of the TSF 
and the procedures used to design the TSF. In ca ses where the TSF is 
designed in a manner consistent with the design represented by the TOE 
design (see ADV_TDS), the assessment of the TSF design is obvious. In 
cases where the design procedures (see ALC_TAT) are being followed, the 
assessment of the TSF design procedures is similarly obvious. 
778 In cases where the TSF is implemented using procedure -based software, this 
structure is assessed on the basis of its modularity; the modules identified in  
the internals description are the same as the modules identified in the TOE 
design (TOE design (ADV_TDS)). A module consists of one or more source 
code files that cannot be decomposed into smaller compilable units. 
779 The primary goal of t his component is to ensure the TSF's implementation 
representation is understandable to facilitate maintenance and analysis (of 
both the developer and evaluator). 
Class ADV: Development 
April 2017 Version 3.1 Page 167 of 430 
12.6.2.4 Action ADV_INT.2.1E 
ADV_INT.2.1C The justification shall describe the characteristics used to judge the 
meaning of “well-structured”.  
ADV_INT.2-1 The evaluator shall examine  the justification to determine that it identifies 
the basis for determining whether the TSF is well-structured. 
780 The evaluator verifies that the criteria for determining the characteristic of 
being well -structured are clearly defined in the justification. Acceptable 
criteria typically origina te from industry standards for the technology 
discipline. For example, procedural software that executes linearly is 
traditionally viewed as well -structured if it adheres to software engineering 
programming practises, such as those defined in the IEEE Stan dard ( IEEE 
Std 610.12 -1990). For example, it would identify the criteria for the 
procedural software portions of the TSF:  
a) the process used for modular decomposition 
b) coding standards used in the development of the implementation 
c) a description of the maximu m acceptable level of intermodule 
coupling exhibited by the TSF 
d) a description of the minimum acceptable level of cohesion exhibited 
the modules of the TSF 
781 For other types of technologies used in the TOE - such as non -procedural 
software (e.g. object -oriented programming), widespread commodity 
hardware (e.g. PC microprocessors), and special -purpose hardware (e.g. 
smart-card processors) - the evaluation authority should be consulted for 
determining the adequacy of criteria for being “well-structured”. 
ADV_INT.2.2C The TSF internals description shall demonstrate that the entire TSF is 
well-structured.  
ADV_INT.2-2 The evaluator shall examine the TSF internals description  to determine that 
it demonstrates that the TSF is well-structured. 
782 The evaluator examines the internals description to ensure that it provides a 
sound explanation of how the TSF meets the criteria from ADV_INT.2-1 
783 For example, it would explain how the procedural software portions of the 
TSF meet the following:  
a) that there is a one -to-one correspondence between the modules 
identified in the TSF and the modules described in the TOE design 
(ADV_TDS) 
b) how the TSF design is a reflection of the modular decomposition 
process 
Class ADV: Development 
Page 168 of 430 Version 3.1 April 2017 
c) a justification for all instances where the coding standards were not 
used or met 
d) a justification for any coupling or cohesion outside the acceptable 
bounds 
12.6.2.5 Action ADV_INT.2.2E 
ADV_INT.2-3 The evaluator shall determine that the TOE design is well-structured. 
784 The evaluator examines the TOE design of a sample of the TSF to verify the 
accuracy o f the justification. For example, a sample of the TOE design is 
analysed to determine its adherence to the design standards, etc. As with all 
areas where the evaluator performs activities on a subset the evaluator 
provides a justification of the sample size and scope 
785 The description of the TOE's decomposition into subsystems and modules 
will make the argument that the TSF subset is well -structured self-evident. 
Verification that the procedures for structuring the TSF (as examined in 
ALC_TAT) are being followed will make it self -evident that the TSF subset 
is well-structured. 
ADV_INT.2-4 The evaluator shall determine that the TSF is well-structured. 
786 If ADV_IMP is not part of the claimed assurance, then this work unit is not 
applicable and is therefore considered to be satisfied. 
787 The evaluator examines a sample of the TSF to verify the accuracy of the 
internals description. For example, a sample of the proc edural software 
portions of the TSF is analysed to determine its cohesion and coupling, its 
adherence to the coding standards, etc. As with all areas where the evaluator 
performs activities on a subset the evaluator provides a justification of the 
sample size and scope. 
12.6.3 Evaluation of sub-activity (ADV_INT.3) 
788 There is no general guidance; the scheme should be consulted for guidance 
on this sub-activity. 
Class ADV: Development 
April 2017 Version 3.1 Page 169 of 430 
12.7 Security policy modelling (ADV_SPM) 
12.7.1 Evaluation of sub-activity (ADV_SPM.1) 
789 There is no general guidance; the scheme should be consulted for guidance 
on this sub-activity. 
Class ADV: Development 
Page 170 of 430 Version 3.1 April 2017 
12.8 TOE design (ADV_TDS) 
12.8.1 Evaluation of sub-activity (ADV_TDS.1) 
12.8.1.1 Input 
790 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the functional specification;  
c) security architecture description;  
d) the TOE design.  
12.8.1.2 Action ADV_TDS.1.1E 
ADV_TDS.1.1C The design shall describe the structure of the TOE in terms of subsystems.  
ADV_TDS.1-1 The evaluator shall examine the TOE design to determine that the structure 
of the entire TOE is described in terms of subsystems. 
791 The evaluator ensures that all of the subsystems of the TOE are identified. 
This description of the TOE will be used as input to work unit ADV_TDS.1-
2, where the parts of the TOE that make up the TSF are identified. That is, 
this requirement is on the entire TOE rather than on only the TSF. 
792 The TOE (and TSF) may be described in multi ple layers of abstraction (i.e. 
subsystems and modules) Depending upon the complexity of the TOE, its 
design may be described in terms of subsystems and modules, as described 
in CC Part 3 Annex A.4, ADV_TDS: Subsystems and Modules. At this level 
of assurance, the decomposition only need be at the “subsystem” level. 
793 In performing this activity, the evaluator examines other evidence presented 
for the TOE (e.g., ST, operator user guidance) to determine that the 
description of the TOE in su ch evidence is consistent with the description 
contained in the TOE design. 
ADV_TDS.1.2C The design shall identify all subsystems of the TSF.  
ADV_TDS.1-2 The evalu ator shall examine  the TOE design to determine that all 
subsystems of the TSF are identified. 
794 In work unit ADV_TDS.1-1 all of the subsystems of the TOE were identified, 
and a determination made that the non -TSF subsystems were correc tly 
characterised. Building on that work, the subsystems that were not 
characterised as non -TSF subsystems should be precisely identified. The 
evaluator determines that, of the hardware and software installed and 
configured according to the Preparative procedures (AGD_PRE)  guidance, 
each subsystem has been accounted for as either one that is part of the TSF, 
or one that is not. 
Class ADV: Development 
April 2017 Version 3.1 Page 171 of 430 
ADV_TDS.1.3C The design shall provide the behaviour summary of e ach SFR-supporting 
or SFR-non-interfering TSF subsystem.  
ADV_TDS.1-3 The evaluator shall examine  the TOE design to determine that each SFR -
supporting or SFR -non-interfering subsystem of the TSF is described such  
that the evaluator can determine that the subsystem is SFR -supporting or 
SFR-non-interfering. 
795 SFR-supporting and SFR -non-interfering subsystems do not need to be 
described in detail as to how they function in the system. However, the 
evaluator makes a det ermination, based on the evidence provided by the 
developer, that the subsystems that do not have high -level descriptions are 
SFR-supporting or SFR-non-interfering. Note that if the developer provides a 
uniform level of detailed documentation then this wor k unit will be largely 
satisfied, since the point of categorising the subsystems is to allow the 
developer to provide less information for SFR -supporting and SFR -non-
interfering subsystems than for SFR-enforcing subsystems. 
796 An SFR -supporting subsystem is o ne that is depended on by an SFR -
enforcing subsystem in order to implement an SFR, but does not play as 
direct a role as an SFR -enforcing subsystem. An SFR -non-interfering 
subsystem is one that is not depended upon, in either a supporting or 
enforcing role, to implement an SFR. 
ADV_TDS.1.4C The design shall summarise the SFR -enforcing behaviour of the SFR -
enforcing subsystems.  
ADV_TDS.1-4 The evaluator shall examine the TOE design to determine that it provides a 
complete, accurate, and high-level summary of the SFR -enforcing behaviour 
of the SFR-enforcing subsystems. 
797 The developer may designate subsystems as SFR-enforcing, SFR-supporting, 
and SFR non -interfering, but  these “tags” are used only to describe the 
amount and type of information the developer must provide, and can be used 
to limit the amount of information the developer has to develop if their 
engineering process does not produce the documentation required.  Whether 
the subsystems have been categorised by the developer or not, it is the 
evaluator's responsibility to determine that the subsystems have the 
appropriate information for their role (SFR -enforcing, etc.) in the TOE, and 
to obtain the appropriate inf ormation from the developer should the 
developer fail to provide the required information for a particular subsystem. 
798 SFR-enforcing behaviour refers to how a subsystem provides the 
functionality that implements an SFR. The goal of evaluator's assessment is  
to give the evaluator with an understanding of the way each SFR -enforcing 
subsystem works. The information provided for the behaviour summary does 
not have to be as detailed as that provided by the behaviour description. For 
example, data structures or da ta items will likely not need to be described in 
detail. It is the evaluator's determination, however, with respect to what 
“high-level” means for a particular TOE, and the evaluator obtains enough 
information from the developer (even if it turns out to be  equivalent to 
Class ADV: Development 
Page 172 of 430 Version 3.1 April 2017 
information provided for subsystem behaviour) to make a sound verdict for 
this work unit. 
799 The evaluator is cautioned, however, that “perfect” assurance is not a goal 
nor required by this work unit, so judgement will have to be exercised in 
determine the amount and composition of the evidence required to make a 
verdict on this work unit. 
800 To determine completeness and accuracy, the evaluator examines other 
information available (e.g., functional specification, security architecture 
description). Summaries of functionality in these documents should be 
consistent with what is provided for evidence for this work unit. 
ADV_TDS.1.5C The design shall provide a description of the interactions among SFR -
enforcing subsystems of the TSF, and between the SFR -enforcing 
subsystems of the TSF and other subsystems of the TSF.  
ADV_TDS.1-5 The evaluator shall examine  the TOE design to determine that interactions 
between the subsystems of the TSF are described. 
801 The goal of describing the interactions between the SFR -enforcing 
subsystems and other subsystems is to help provide the reader a better 
understanding of how the TSF performs it functions. These interactions do 
not n eed to be characterised at the implementation level (e.g., parameters 
passed from one routine in a subsystem to a routine in a different subsystem; 
global variables; hardware signals (e.g., interrupts) from a hardware 
subsystem to an interrupt -handling sub system), but the data elements 
identified for a particular subsystem that are going to be used by another 
subsystem need to be covered in this discussion. Any control relationships 
between subsystems (e.g., a subsystem responsible for configuring a rule 
base for a firewall system and the subsystem that actually implements these 
rules) should also be described. 
802 The evaluators need to use their own judgement in assessing the 
completeness of the description. If the reason for an interaction is unclear, or 
if there are SFR -related interactions (discovered, for instance, in examining 
the descriptions of subsystem behaviour) that do not appear to be described, 
the evaluator ensures that this information is provided by the developer. 
However, if the evaluator can d etermine that interactions among a particular 
set of subsystems, while incompletely described by the developer, will not 
aid in understanding the overall functionality nor security functionality 
provided by the TSF, then the evaluator may choose to conside r the 
description sufficient, and not pursue completeness for its own sake. 
ADV_TDS.1.6C The mapping shall demonstrate that all TSFIs trace to the behaviour 
described in the TOE design that they invoke.  
ADV_TDS.1-6 The evaluator shall examine the TOE design to determine that it contains a 
complete and accurate mapping from the TSFI described in the functional 
specification to the subsystems of the TSF described in the TOE design. 
Class ADV: Development 
April 2017 Version 3.1 Page 173 of 430 
803 The subsystems described in the TOE design provide a description of how 
the TSF works at a detailed level for SFR -enforcing portions of the TSF, and 
at a higher level for other portions of the TSF. The TSFI provide a 
description of how the i mplementation is exercised. The evidence from the 
developer identifies the subsystem that is initially involved when an 
operation is requested at the TSFI, and identify the various subsystems that 
are primarily responsible for implementing the functionalit y. Note that a 
complete “call tree” for each TSFI is not required for this work unit. 
804 The evaluator assesses the completeness of the mapping by ensuring that all 
of the TSFI map to at least one subsystem. The verification of accuracy is 
more complex. 
805 The first aspect of accuracy is that each TSFI is mapped to a subsystem at the 
TSF boundary. This determination can be made by reviewing the subsystem 
description and interactions, and from this information determining its place 
in the architecture. The next as pect of accuracy is that the mapping makes 
sense. For instance, mapping a TSFI dealing with access control to a 
subsystem that checks passwords is not accurate. The evaluator should again 
use judgement in making this determination. The goal is that this information 
aids the evaluator in understanding the system and implementation of the 
SFRs, and ways in which entities at the TSF boundary can interact with the 
TSF. The bulk of the assessment of whether the SFRs are described 
accurately by the subsystems is performed in other work units. 
12.8.1.3 Action ADV_TDS.1.2E 
ADV_TDS.1-7 The evaluator shall examine  the TOE security functional requirements and 
the TOE design, to determine that all ST security functional requirements are 
covered by the TOE design. 
806 The evaluator may construct a map between the TOE security functional 
requirements and the TOE design. This map will likely be from a functional 
requirement to a set of subsystems. Note that this map may have to be at a 
level of detail below the component or even element level of the 
requirements, because of operations (assignments, refinements, selections) 
performed on the functional requirement by the ST author. 
807 For example, the FDP_ACC.1 Subset access control  component contains an 
element with assignments. If the ST contained, for instance, ten rules in the 
FDP_ACC.1 Subset access control  assignment, and these ten rules were 
implemented in specific places within fifteen modules, it would be 
inadequate for the evaluator to map FDP_ACC.1 Subset access control  to 
one subsystem and claim the work unit had been completed. Instead, the 
evaluator would map FDP_ACC.1 Subset access control  (rule 1) to 
subsystem A, behaviours x, y, and z; FDP_ACC.1 Subset access control  
(rule 2) to subsystem A, behaviours x, p, and q; etc. 
ADV_TDS.1-8 The evaluato r shall examine  the TOE design to determine that it is an 
accurate instantiation of all security functional requirements. 
Class ADV: Development 
Page 174 of 430 Version 3.1 April 2017 
808 The evaluator ensures that each security requirement listed in the TOE 
security functional requirements section of the ST has a corres ponding 
design description in the TOE design that accurately details how the TSF 
meets that requirement. This requires that the evaluator identify a collection 
of subsystems that are responsible for implementing a given functional 
requirement, and then exa mine those subsystems to understand how the 
requirement is implemented. Finally, the evaluator would assess whether the 
requirement was accurately implemented. 
809 As an example, if the ST requirements specified a role -based access control 
mechanism, the evaluator would first identify the subsystems that contribute 
to this mechanism's implementation. This could be done by in -depth 
knowledge or understanding of the TOE design or by work done in the 
previous work unit. Note that this trace is only to identify the  subsystems, 
and is not the complete analysis. 
810 The next step would be to understand what mechanism the subsystems 
implemented. For instance, if the design described an implementation of 
access control based on UNIX -style protection bits, the design would n ot be 
an accurate instantiation of those access control requirements present in the 
ST example used above. If the evaluator could not determine that the 
mechanism was accurately implemented because of a lack of detail, the 
evaluator would have to assess wh ether all of the SFR -enforcing subsystems 
have been identified, or if adequate detail had been provided for those 
subsystems. 
12.8.2 Evaluation of sub-activity (ADV_TDS.2) 
12.8.2.1 Input 
811 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the functional specification;  
c) security architecture description;  
d) the TOE design.  
12.8.2.2 Action ADV_TDS.2.1E 
ADV_TDS.2.1C The design shall describe the structure of the TOE in terms of subsystems.  
ADV_TDS.2-1 The evaluator shall examine the TOE design to determine that the structure 
of the entire TOE is described in terms of subsystems. 
812 The evaluator ensures that all of the subsystems of the TOE are identified. 
This description of the TOE will be used as input to work unit ADV_TDS.2-
2, where the parts of the TOE that make up the TSF are identified. That is, 
this requirement is on the entire TOE rather than on only the TSF. 
Class ADV: Development 
April 2017 Version 3.1 Page 175 of 430 
813 The TOE (and TSF) may be described in multiple layers of abstraction (i.e. 
subsystems and modules) Depending upon the complexity of the TOE, its 
design may be described in terms of subsystems and modules, as described 
in CC Part 3 Annex A.4, ADV_TDS: Subsystems and Modules. At this level 
of assurance, the decomposition only need be at the “subsystem” level. 
814 In performing this activity, the evaluator examines other evidence presented 
for the TOE (e.g., ST, operator user guidance) to determine  that the 
description of the TOE in such evidence is consistent with the description 
contained in the TOE design. 
ADV_TDS.2.2C The design shall identify all subsystems of the TSF.  
ADV_TDS.2-2 The evaluator shall examine  the TOE design to determine that all 
subsystems of the TSF are identified. 
815 In work unit ADV_TDS.2-1 all of the subsystems of the TOE were identified, 
and a determination made t hat the non -TSF subsystems were correctly 
characterised. Building on that work, the subsystems that were not 
characterised as non -TSF subsystems should be precisely identified. The 
evaluator determines that, of the hardware and software installed and 
configured according to the Preparative procedures (AGD_PRE)  guidance, 
each subsystem has been accounted for as either one that is part of the TSF, 
or one that is not. 
ADV_TDS.2.3C The design sh all provide the behaviour summary of each SFR non -
interfering subsystem of the TSF.  
ADV_TDS.2-3 The evaluator shall examine  the TOE design to determine that each SFR -
non-interfering subsystem of the TSF is described such that the evaluator can 
determine that the subsystem is SFR-non-interfering. 
816 SFR-non-interfering subsystems do not need to be described in detail as to 
how they function in the system. However, the evaluator makes a 
determination, based on the evi dence provided by the developer, that the 
subsystems that do not have detailed descriptions are SFR -non-interfering. 
Note that if the developer provides a uniform level of detailed documentation 
then this work unit will be largely satisfied, since the poin t of categorising 
the subsystems is to allow the developer to provide less information for SFR-
non-interfering subsystems than for SFR -enforcing and SFR -supporting 
subsystems. 
817 An SFR-non-interfering subsystem is one on which the SFR -enforcing and 
SFR-supporting subsystems have no dependence; that is, they play no role in 
implementing SFR functionality. 
ADV_TDS.2.4C The design shall describe the SFR -enforcing behaviour of the SFR -
enforcing subsystems.  
Class ADV: Development 
Page 176 of 430 Version 3.1 April 2017 
ADV_TDS.2-4 The evaluator shall examine the TOE design to determine that it provides a 
complete, accurate, and detailed description of the SFR -enforcing behaviour 
of the SFR-enforcing subsystems. 
818 The developer may designate subsystems as SFR-enforcing, SFR-supporting, 
and SFR non -interfering, but these “tags” are used only to describe the 
amount and type of information the developer must provide, and can be used 
to limit the amount of information the developer has to deve lop if their 
engineering process does not produce the documentation required. Whether 
the subsystems have been categorised by the developer or not, it is the 
evaluator's responsibility to determine that the subsystems have the 
appropriate information for t heir role (SFR -enforcing, etc.) in the TOE, and 
to obtain the appropriate information from the developer should the 
developer fail to provide the required information for a particular subsystem. 
819 SFR-enforcing behaviour refers to how a subsystem provides th e 
functionality that implements an SFR. While not at the level of an 
algorithmic description, a detailed description of behaviour typically 
discusses how the functionality is provided in terms of what key data and 
data structures are, what control relation ships exist within a subsystem, and 
how these elements work together to provide the SFR -enforcing behaviour. 
Such a description also references SFR -supporting behaviour, which the 
evaluator should consider in performing subsequent work units. 
820 To determine completeness and accuracy, the evaluator examines other 
information available (e.g., functional specification, security architecture 
description). Descriptions of functionality in these documents should be 
consistent with what is provided for evidence for this work unit. 
ADV_TDS.2.5C The design shall summarise the SFR -supporting and SFR-non-interfering 
behaviour of the SFR-enforcing subsystems.  
ADV_TDS.2-5 The evaluator shall examine the TOE design to determine that it provides a 
complete and accurate high -level summary of the SFR -supporting and SFR -
non-interfering behaviour of the SFR-enforcing subsystems. 
821 The developer may designate subsystems as SFR-enforcing, SFR-supporting, 
and SFR non -interfering, but these “tags” are used only to describe the 
amount and type of information the developer must provide, and can be used 
to limit the amount of information the developer has to develop if their 
engineering process doe s not produce the documentation required. Whether 
the subsystems have been categorised by the developer or not, it is the 
evaluator's responsibility to determine that the subsystems have the 
appropriate information for their role (SFR -enforcing, etc.) in t he TOE, and 
to obtain the appropriate information from the developer should the 
developer fail to provide the required information for a particular subsystem. 
822 In contrast to the previous work unit, this work unit calls for the evaluator to 
assess the infor mation provided for SFR -enforcing subsystems that is SFR -
supporting or SFR -non-interfering. The goal of this assessment is two -fold. 
First, it should provide the evaluator greater understanding of the way each 
Class ADV: Development 
April 2017 Version 3.1 Page 177 of 430 
subsystem works. Second, this assessment will help the evaluator to 
determine that all SFR -enforcing behaviour exhibited by a SFR -enforcing 
subsystem has been described. Unlike the previous work unit, the 
information provided for the SFR -supporting or SFR -non-interfering 
behaviour does not have to be as detailed as that provided by the SFR -
enforcing behaviour. For example, data structures or data items that do not 
pertain to SFR-enforcing functionality will likely not need to be described in 
detail, if at all. It is the evaluator's determination, howev er, with respect to 
what “high -level” means for a particular TOE, and the evaluator obtains 
enough information from the developer (even if it turns out to be equivalent 
to information provided for the parts of the subsystem that are SFR -
enforcing) to make a sound verdict for this work unit. 
823 The evaluator is cautioned, however, that “perfect” assurance is not a goal 
nor required by this work unit, so judgement will have to be exercised in 
determine the amount and composition of the evidence required to make a 
verdict on this work unit. 
824 To determine completeness and accuracy, the evaluator examines other 
information available (e.g., functional specification, security architecture 
description). Summaries of functionality in these documents should be 
consistent with what is provided for evidence for this work unit. In particular, 
the functional specification should be used to determine that the behaviour 
required to implement the TSF Interfaces described by the functional 
specification are completely described by the subsystem, since the behaviour 
will either be SFR-enforcing, SFR-supporting or SFR-non-interfering. 
ADV_TDS.2.6C The design shall summarise the behaviour of the SFR -supporting 
subsystems.  
ADV_TDS.2-6 The evaluator shall examine the TOE design to determine that it provides a 
complete and accurate high -level summary of the behaviour of the SFR -
supporting subsystems. 
825 The developer may designate subsystems as SFR-enforcing, SFR-supporting, 
and SFR non -interfering, but these “tags” are used only to describe the 
amount and type of information the developer must provide, and can be used 
to limit the amount of information the developer has to develop if their 
engineering process does not produce the documentation required. Whether 
the subsystems have been categorised by the developer or not, it is the 
evaluator's responsibility to determine that the subsystems have the 
appropriate information for their role (SFR -enforcing, etc.) in the TOE, and 
to obtain the appropriate information from the developer should the 
developer fail to provide the required information for a particular subsystem. 
826 In contrast to the previous two work units, this work unit calls for the 
developer t o provide (and the evaluator to assess) information about SFR 
supporting subsystems. Such subsystems should be referenced by the 
descriptions of the SFR -enforcing subsystems, as well as by the descriptions 
of interactions in work unit ADV_TDS.2-7. The goal of evaluator's 
assessment, like that for the previous work unit, is two -fold. First, it should 
Class ADV: Development 
Page 178 of 430 Version 3.1 April 2017 
provide the evaluator with an understanding of the way each SFR -supporting 
subsystem works. Second, the evaluator determines that the beh aviour is 
summarized in enough detail so that the way in which the subsystem 
supports the SFR -enforcing behaviour is clear, and that the behaviour is not 
itself SFR -enforcing. The information provided for SFR -supporting 
subsystem's behaviour does not have to be as detailed as that provided by the 
SFR-enforcing behaviour. For example, data structures or data items that do 
not pertain to SFR -enforcing functionality will likely not need to be 
described in detail, if at all. It is the evaluator's determination,  however, with 
respect to what “high -level” means for a particular TOE, and the evaluator 
obtains enough information from the developer (even if it turns out to be 
equivalent to information provided for the parts of the subsystem that are 
SFR-enforcing) to make a sound verdict for this work unit. 
827 The evaluator is cautioned, however, that “perfect” assurance is not a goal 
nor required by this work unit, so judgement will have to be exercised in 
determine the amount and composition of the evidence required to  make a 
verdict on this work unit. 
828 To determine completeness and accuracy, the evaluator examines other 
information available (e.g., functional specification, security architecture 
description). Summaries of functionality in these documents should be 
consistent with what is provided for evidence for this work unit. 
ADV_TDS.2.7C The design shall provide a description of the interactions among all 
subsystems of the TSF.  
ADV_TDS.2-7 The evaluator shall examine  the TOE design to determine that interactions 
between the subsystems of the TSF are described. 
829 The goal of describing the interactions between the subsystems is to help 
provide the reader a better understanding of  how the TSF performs it 
functions. These interactions do not need to be characterised at the 
implementation level (e.g., parameters passed from one routine in a 
subsystem to a routine in a different subsystem; global variables; hardware 
signals (e.g., interrupts) from a hardware subsystem to an interrupt -handling 
subsystem), but the data elements identified for a particular subsystem that 
are going to be used by another subsystem need to be covered in this 
discussion. Any control relationships between subs ystems (e.g., a subsystem 
responsible for configuring a rule base for a firewall system and the 
subsystem that actually implements these rules) should also be described. 
830 It should be noted while the developer should characterise all interactions 
between su bsystems, the evaluators need to use their own judgement in 
assessing the completeness of the description. If the reason for an interaction 
is unclear, or if there are SFR -related interactions (discovered, for instance, 
in examining the descriptions of sub system behaviour) that do not appear to 
be described, the evaluator ensures that this information is provided by the 
developer. However, if the evaluator can determine that interactions among a 
particular set of subsystems, while incompletely described by the developer, 
will not aid in understanding the overall functionality nor security 
Class ADV: Development 
April 2017 Version 3.1 Page 179 of 430 
functionality provided by the TSF, then the evaluator may choose to consider 
the description sufficient, and not pursue completeness for its own sake. 
ADV_TDS.2.8C The mapping shall demonstrate that all TSFIs trace to the behaviour 
described in the TOE design that they invoke.  
ADV_TDS.2-8 The evaluator shall examine the TOE design to  determine that it contains a 
complete and accurate mapping from the TSFI described in the functional 
specification to the subsystems of the TSF described in the TOE design. 
831 The subsystems described in the TOE design provide a description of how 
the TSF works at a detailed level for SFR-enforcing portions of the TSF, and 
at a higher level for other portions of the TSF. The TSFI provide a 
description of how the implementation is exercised. The evidence from the 
developer identifies the subsystem that is init ially involved when an 
operation is requested at the TSFI, and identify the various subsystems that 
are primarily responsible for implementing the functionality. Note that a 
complete “call tree” for each TSFI is not required for this work unit. 
832 The evaluator assesses the completeness of the mapping by ensuring that all 
of the TSFI map to at least one subsystem. The verification of accuracy is 
more complex. 
833 The first aspect of accuracy is that each TSFI is mapped to a subsystem at the 
TSF boundary. This dete rmination can be made by reviewing the subsystem 
description and interactions, and from this information determining its place 
in the architecture. The next aspect of accuracy is that the mapping makes 
sense. For instance, mapping a TSFI dealing with acces s control to a 
subsystem that checks passwords is not accurate. The evaluator should again 
use judgement in making this determination. The goal is that this information 
aids the evaluator in understanding the system and implementation of the 
SFRs, and ways  in which entities at the TSF boundary can interact with the 
TSF. The bulk of the assessment of whether the SFRs are described 
accurately by the subsystems is performed in other work units. 
12.8.2.3 Action ADV_TDS.2.2E 
ADV_TDS.2-9 The evaluator shall examine  the TOE security functional requirements and 
the TOE design, to determine that all ST security functional requirements are 
covered by the TOE design. 
834 The evaluator may cons truct a map between the TOE security functional 
requirements and the TOE design. This map will likely be from a functional 
requirement to a set of subsystems. Note that this map may have to be at a 
level of detail below the component or even element level of the 
requirements, because of operations (assignments, refinements, selections) 
performed on the functional requirement by the ST author. 
835 For example, the FDP_ACC.1 Subset access control  component contains an 
element with assignments . If the ST contained, for instance, ten rules in the 
FDP_ACC.1 Subset access control  assignment, and these ten rules were 
Class ADV: Development 
Page 180 of 430 Version 3.1 April 2017 
implemented in specific places within fifteen modules, it would be 
inadequate for the evaluator to map FDP_ACC.1 Subset access control  to 
one subsystem and claim the work unit had been completed. Instead, the 
evaluator would map FDP_ACC.1 Subset access control  (rule 1) to 
subsystem A, behaviours x, y, and z; FDP_ACC.1 Subset access control  
(rule 2) to subsystem A, behaviours x, p, and q; etc. 
ADV_TDS.2-10 The evaluator shall examine  the TOE design to determine that it is an 
accurate instantiation of all security functional requirements. 
836 The evaluator ensures that each security requirement listed in the TOE 
security functional requirements section of the ST has a corresponding 
design description in the TOE design that accurately details how the TSF 
meets that r equirement. This requires that the evaluator identify a collection 
of subsystems that are responsible for implementing a given functional 
requirement, and then examine those subsystems to understand how the 
requirement is implemented. Finally, the evaluato r would assess whether the 
requirement was accurately implemented. 
837 As an example, if the ST requirements specified a role -based access control 
mechanism, the evaluator would first identify the subsystems that contribute 
to this mechanism's implementation. This could be done by in -depth 
knowledge or understanding of the TOE design or by work done in the 
previous work unit. Note that this trace is only to identify the subsystems, 
and is not the complete analysis. 
838 The next step would be to understand what mech anism the subsystems 
implemented. For instance, if the design described an implementation of 
access control based on UNIX -style protection bits, the design would not be 
an accurate instantiation of those access control requirements present in the 
ST exampl e used above. If the evaluator could not determine that the 
mechanism was accurately implemented because of a lack of detail, the 
evaluator would have to assess whether all of the SFR -enforcing subsystems 
have been identified, or if adequate detail had bee n provided for those 
subsystems. 
12.8.3 Evaluation of sub-activity (ADV_TDS.3) 
12.8.3.1 Objectives 
839 The objective of this sub -activity is to determine whether the TOE design 
provides a description of the TOE in terms of subsystems sufficient to 
determine the TSF boundary, and provides a description of the TSF internals 
in terms of modules (and optionally higher -level abstractions). It provides a 
detailed description of the SFR -enforcing modules and enough information 
about the SFR-supporting and SFR-non-interfering modules for the evaluator 
to determine that the SFRs are completely and accurately implemented; as 
such, the TOE design provides an explanation of the implementation 
representation. 
Class ADV: Development 
April 2017 Version 3.1 Page 181 of 430 
12.8.3.2 Input 
840 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the functional specification;  
c) security architecture description;  
d) the TOE design.  
12.8.3.3 Application notes 
841 There are three types of activity that the evaluator must undertake with 
respect to the TOE design. First, the evaluator determines that the TSF 
boundary has been adequat ely described. Second, the evaluator determines 
that the developer has provided documentation that conforms to the content 
and presentation requirements for this subsystem, and that is consistent with 
other documentation provided for the TOE. Finally, the evaluator must 
analyse the design information provided for the SFR -enforcing modules (at a 
detailed level) and the SFR -supporting and SFR-non-interfering modules (at 
a less detailed level) to understand how the system is implemented, and with 
that knowledg e ensure that the TSFI in the functional specification are 
adequately described, and that the test information adequately tests the TSF 
(done in the Class ATE: Tests work units). 
842 It is important to note that while the developer is obligated to provide a 
complete description of the TSF (although SFR -enforcing modules will have 
more detail than the SFR -supporting or SFR -non-interfering modules), the 
evaluator is expected to use their judgement in performing their analysis. 
While the evaluator i s expected to look at every module, the detail to which 
they examine each module may vary. The evaluator analyses each module in 
order to gain enough understanding to determine the effect of the 
functionality of the module on the security of the system, an d the depth to 
which they need to analyse the module may vary depending on the module's 
role in the system. An important aspect of this analysis is that the evaluator 
should use the other documentation provided (TSS, functional specification, 
security architecture description, and the TSF internal document) in order to 
determine that the functionality that is described is correct, and that the 
implicit designation of SFR -supporting or SFR-non-interfering modules (see 
below) is supported by their role in the system architecture. 
843 The developer may designate modules as SFR -enforcing, SFR -supporting, 
and SFR non -interfering, but these “tags” are used only to describe the 
amount and type of information the developer must provide, and can be used 
to limit the amou nt of information the developer has to develop if their 
engineering process does not produce the documentation required. Whether 
the modules have been categorised by the developer or not, it is the 
evaluator's responsibility to determine that the modules h ave the appropriate 
information for their role (SFR-enforcing, etc.) in the TOE, and to obtain the 
Class ADV: Development 
Page 182 of 430 Version 3.1 April 2017 
appropriate information from the developer should the developer fail to 
provide the required information for a particular module. 
12.8.3.4 Action ADV_TDS.3.1E 
ADV_TDS.3.1C The design shall describe the structure of the TOE in terms of subsystems.  
ADV_TDS.3-1 The evaluator shall examine the TOE design to determine that the structure 
of the entire TOE is described in terms of subsystems. 
844 The evaluator ensures that all of the subsystems of the TOE are identified. 
This description of the TOE will be used as input to work unit ADV_TDS.3-
2, where the parts of the TOE that make up the TSF are identified. That is, 
this requirement is on the entire TOE rather than on only the TSF. 
845 The TOE (and TSF) may be described in multiple layers of abstraction (i.e. 
subsystems and m odules). Depending upon the complexity of the TOE, its 
design may be described in terms of subsystems and modules, as described 
in CC Part 3 Annex A.4, ADV_TD S: Subsystems and Modules . For a very 
simple TOE that can be described solely  at the “module” level (see 
ADV_TDS.3-2), this work unit is not applicable and therefore considered to 
be satisfied. 
846 In performing this activity, the evaluator examines other evidence presented 
for the TOE (e.g., ST, operator user gu idance) to determine that the 
description of the TOE in such evidence is consistent with the description 
contained in the TOE design. 
ADV_TDS.3.2C The design shall describe the TSF in terms of modules.  
ADV_TDS.3-2 The evaluator shall examine  the TOE design to determine that the entire 
TSF is described in terms of modules. 
847 The evaluator will examine the modules for specific properties in other work 
units; in this work unit the evaluator determines that the modular description 
covers the entire TSF, and not just a portion of the TSF. The evaluator uses 
other evidence provided for the evaluation (e.g., functional specification, 
security architecture description) in maki ng this determination. For example, 
if the functional specification contains interfaces to functionality that does 
not appear to be described in the TOE design description, it may be the case 
that a portion of the TSF has not been included appropriately. M aking this 
determination will likely be an iterative process, where as more analysis is 
done on the other evidence, more confidence can be gained with respect to 
the completeness of the documentation. 
848 Unlike subsystems, modules describe the implementation in a level of detail 
that can serve as a guide to reviewing the implementation representation. A 
description of a module should be such that one could create an 
implementation of the module from the description, and the resulting 
implementation would be 1)  identical to the actual TSF implementation in 
terms of the interfaces presented, 2) identical in the use of interfaces that are 
Class ADV: Development 
April 2017 Version 3.1 Page 183 of 430 
mentioned in the design, and 3) functionally equivalent to the description of 
the purpose of the TSF module. For instance, RFC 793 provides a high-level 
description of the TCP protocol. It is necessarily implementation 
independent. While it provides a wealth of detail, it is not a suitable design 
description because it is not specific to an implementation. An actual 
implementation can add to the protocol specified in the RFC, and 
implementation choices (for instance, the use of global data vs. local data in 
various parts of the implementation) may have an impact on the analysis that 
is performed. The design description of the TCP m odule would list the 
interfaces presented by the implementation (rather than just those defined in 
RFC 793), as well as an algorithm description of the processing associated 
with the modules implementing TCP (assuming it was part of the TSF). 
ADV_TDS.3.3C The design shall identify all subsystems of the TSF.  
ADV_TDS.3-3 The evaluator shall examine  the TOE design to determine that all 
subsystems of the TSF are identified. 
849 If the design is presented solely in terms of modules, then subsystems in 
these requirements are equivalent to modules and the activity should be 
performed at the module level. 
850 In work unit ADV_TDS.3-1 all of the subsystems of the TOE were identified, 
and a determination made that the non -TSF subsystems were correctly 
characterised. Building on that work, the subsystems that were not 
characterised as non -TSF subsystems should be precisely identified. The 
evaluator determines that , of the hardware and software installed and 
configured according to the Preparative procedures (AGD_PRE)  guidance, 
each subsystem has been accounted for as either one that is part of the TSF, 
or one that is not. 
ADV_TDS.3.4C The design shall provide a description of each subsystem of the TSF.  
ADV_TDS.3-4 The evaluator shall examine  the TOE design to determine that each 
subsystem of the TSF describes its role in the enforcement of SFRs described 
in the ST. 
851 If the design is presented solely in terms of modules, then this work unit will 
be considered satisfied by the assessment done in subsequent work units; no 
explicit action on the part of the evaluator is necessary in this case. 
852 On systems that are complex enough to warrant a subsystem -level 
description of the TSF in addition to the modular description, the goal of the 
subsystem-level description is to give the evaluator context for the modular 
description that follows. Therefore, the evaluator ensures that the subsystem -
level description contains a description of how the security functional 
requirements are achieved in the design, but at a level of abstraction above 
the modular description. This de scription should discuss the mechanisms 
used at a level that is aligned with the module description; this will provide 
the evaluators the road map needed to intelligently assess the information 
contained in the module description. A well -written set of sub system 
Class ADV: Development 
Page 184 of 430 Version 3.1 April 2017 
descriptions will help guide the evaluator in determining the modules that are 
most important to examine, thus focusing the evaluation activity on the 
portions of the TSF that have the most relevance with respect to the 
enforcement of the SFRs. 
853 The evaluator ensures that all subsystems of the TSF have a description. 
While the description should focus on the role that the subsystem plays in 
enforcing or supporting the implementation of the SFRs, enough information 
must be present so that a context for  understanding the SFR -related 
functionality is provided. 
ADV_TDS.3-5 The evaluator shall examine  the TOE design to determine that each SFR -
non-interfering subsystem of the TSF is described such that the evaluator can 
determine that the subsystem is SFR-non-interfering. 
854 If the design is presented solely in terms of modules, then this work unit will 
be considered satisfied by the assessment done in subsequent work units; no 
explicit action on the part of the evaluator is necessary in this case. 
855 An SFR-non-interfering subsystem is one on which the SFR -enforcing and 
SFR-supporting subsystems have no dependence; that is, they play no role in 
implementing SFR functionality. 
856 The evaluator ensures that all subsystems of t he TSF have a description. 
While the description should focus on the role that the subsystem do not 
plays in enforcing or supporting the implementation of the SFRs, enough 
information must be present so that a context for understanding the SFR -
non-interfering functionality is provided. 
ADV_TDS.3.5C The design shall provide a description of the interactions among all 
subsystems of the TSF.  
ADV_TDS.3-6 The evaluator shall examine  the TOE design to determine that interactions 
between the subsystems of the TSF are described. 
857 If the design is presented solely in terms of modules, then this work unit will 
be considered satisfied by the assessment done in subsequent work un its; no 
explicit action on the part of the evaluator is necessary in this case. 
858 On systems that are complex enough to warrant a subsystem -level 
description of the TSF in addition to the modular description, the goal of 
describing the interactions between t he subsystems is to help provide the 
reader a better understanding of how the TSF performs its functions. These 
interactions do not need to be characterised at the implementation level (e.g., 
parameters passed from one routine in a subsystem to a routine i n a different 
subsystem; global variables; hardware signals (e.g., interrupts) from a 
hardware subsystem to an interrupt -handling subsystem), but the data 
elements identified for a particular subsystem that are going to be used by 
another subsystem should be covered in this discussion. Any control 
relationships between subsystems (e.g., a subsystem responsible for 
Class ADV: Development 
April 2017 Version 3.1 Page 185 of 430 
configuring a rule base for a firewall system and the subsystem that actually 
implements these rules) should also be described. 
859 It should be note d while the developer should characterise all interactions 
between subsystems, the evaluators need to use their own judgement in 
assessing the completeness of the description. If the reason for an interaction 
is unclear, or if there are SFR -related interactions (discovered, for instance, 
in examining the module -level documentation) that do not appear to be 
described, the evaluator ensures that this information is provided by the 
developer. However, if the evaluator can determine that interactions among a 
particular set of subsystems, while incompletely described by the developer, 
and a complete description will not aid in understanding the overall 
functionality nor security functionality provided by the TSF, then the 
evaluator may choose to consider the desc ription sufficient, and not pursue 
completeness for its own sake. 
ADV_TDS.3.6C The design shall provide a mapping from the subsystems of the TSF to the 
modules of the TSF.  
ADV_TDS.3-7 The evaluator shall examine the TOE design to determine that the mapping 
between the subsystems of the TSF and the modules of the TSF is complete. 
860 If the design is presented solely in terms of modules, then this work unit is 
considered satisfied. 
861 For TOEs that are complex enough to warrant a subsystem -level description 
of the TSF in addition to the modular description, the developer provides a 
simple mapping showing how the modules of the TSF are allocated to the 
subsystems. This will p rovide the evaluator a guide in performing their 
module-level assessment. To determine completeness, the evaluator 
examines each mapping and determines that all subsystems map to at least 
one module, and that all modules map to exactly one subsystem. 
ADV_TDS.3-8 The evaluator shall examine the TOE design to determine that the mapping 
between the subsystems of the TSF and the modules of the TSF is accurate. 
862 If the design is presented solely in terms of modules, the n this work unit is 
considered satisfied. 
863 For TOEs that are complex enough to warrant a subsystem -level description 
of the TSF in addition to the modular description, the developer provides a 
simple mapping showing how the modules of the TSF are allocated to the 
subsystems. This will provide the evaluator a guide in performing their 
module-level assessment. The evaluator may choose to check the accuracy of 
the mapping in conjunction with performing other work units. An 
“inaccurate” mapping is one where the module is mistakenly associated with 
a subsystem where its functions are not used within the subsystem. Because 
the mapping is intended to be a guide supporting more detailed analysis, the 
evaluator is cautioned to apply appropriate effort to this work uni t. 
Expending extensive evaluator resources verifying the accuracy of the 
mapping is not necessary. Inaccuracies that lead to mis -understandings 
Class ADV: Development 
Page 186 of 430 Version 3.1 April 2017 
related to the design that are uncovered as part of this or other work units are 
the ones that should be associated with this work unit and corrected. 
ADV_TDS.3.7C The design shall describe each SFR -enforcing module in terms of its 
purpose and relationship with other modules.  
ADV_TDS.3-9 The evaluator shall examine  the TOE design to determine that the 
description of the purpose of each SFR -enforcing module and relationship 
with other modules is complete and accurate. 
864 The developer may designate modules as SFR -enforcing, SFR -supporting, 
and SFR non -interfering, but these “tags” are used only to describe the 
amount and type of information the developer must provide, and can be used 
to limit the amount of information the developer has to develop if their 
engineering process does not produce the documentation required. Whether 
the modules have been categorised by the developer or not, it is the 
evaluator's responsibility to determine that the modules have the appropriate 
information for their role (SFR-enforcing, etc.) in the TOE, and to obtain the 
appropriate information from the developer should the developer fail to 
provide the required information for a particular module. 
865 The purpose of a module provides a description indicating what function the 
module is fulfilling. A word of caution to evaluator is in order. The focus of 
this work unit should be to provide the evaluator an understanding of how 
the module works so that determinations can be made about the soundness of 
the implementation of the SFRs, as well as to support archit ectural analysis 
performed for ADV_ARC component. As long as the evaluator has a sound 
understanding of the module's operation, and its relationship to other 
modules and the TOE as a whole, the evaluator should consider the o bjective 
of the work achieved and not engage in a documentation exercise for the 
developer (by requiring, for example, a complete algorithmic description for 
a self-evident implementation representation). 
866 Because the modules are at such a low level, it may  be difficult determine 
completeness and accuracy impacts from other documentation, such as 
operational user guidance, the functional specification, the TSF internals, or 
the security architecture description. However, the evaluator uses the 
information present in those documents to the extent possible to help ensure 
that the purpose is accurately and completely described. This analysis can be 
aided by the analysis performed for the work units for the ADV_TDS.3.10C 
element, which maps the TSFI in the functional specification to the modules 
of the TSF. 
ADV_TDS.3.8C The design shall describe each SFR -enforcing module in terms of its SFR -
related interfaces, return values from those interfa ces, interaction with 
other modules and called SFR -related interfaces to other SFR -enforcing 
modules.  
ADV_TDS.3-10 The evaluator shall examine  the TOE design to determine that the 
description of the interface s presented by each SFR -enforcing module 
contain an accurate and complete description of the SFR -related parameters, 
Class ADV: Development 
April 2017 Version 3.1 Page 187 of 430 
the invocation conventions for each interface, and any values returned 
directly by the interface. 
867 The SFR -related interfaces of a module ar e those interfaces used by other 
modules as a means to invoke the SFR -related operations provided, and to 
provide inputs to or receive outputs from the module. The purpose in the 
specification of these interfaces is to permit the exercise of them during 
testing. Inter -module interfaces that are not SFR -related need not be 
specified or described, since they are not a factor in testing. Likewise, other 
internal interfaces that are not a factor in traversing SFR -related paths of 
execution (such as those intern al paths that are fixed) need not be specified 
or described, since they are not a factor in testing. 
868 SFR-related interfaces are described in terms of how they are invoked, and 
any values that are returned. This description would include a list of SFR -
related parameters, and descriptions of these parameters. Note that global 
data would also be considered parameters if used by the module (either as 
inputs or outputs) when invoked. If a parameter were expected to take on a 
set of values (e.g., a “flag” paramet er), the complete set of values the 
parameter could take on that would have an effect on module processing 
would be specified. Likewise, parameters representing data structures are 
described such that each field of the data structure is identified and desc ribed. 
Note that different programming languages may have additional “interfaces” 
that would be non -obvious; an example would be operator/function 
overloading in C++. This “implicit interface” in the class description would 
also be described as part of the  low-level TOE design. Note that although a 
module could present only one interface, it is more common that a module 
presents a small set of related interfaces. 
869 In terms of the assessment of parameters (inputs and outputs) to a module, 
any use of global data must also be considered. A module “uses” global data 
if it either reads or writes the data. In order to assure the description of such 
parameters (if used) is complete, the evaluator uses other information 
provided about the module in the TOE design (in terfaces, algorithmic 
description, etc.), as well as the description of the particular set of global data 
assessed in work unit ADV_TDS.3-10. For instance, the evaluator could first 
determine the processing the module performs by ex amining its function and 
interfaces presented (particularly the parameters of the interfaces). They 
could then check to see if the processing appears to “touch” any of the global 
data areas identified in the TOE design. The evaluator then determines that, 
for each global data area that appears to be “touched”, that global data area is 
listed as a means of input or output by the module the evaluator is examining.  
870 Invocation conventions are a programming -reference-type description that 
one could use to correc tly invoke a module's interface if one were writing a 
program to make use of the module's functionality through that interface. 
This includes necessary inputs and outputs, including any set -up that may 
need to be performed with respect to global variables. 
871 Values returned through the interface refer to values that are either passed 
through parameters or messages; values that the function call itself returns in 
Class ADV: Development 
Page 188 of 430 Version 3.1 April 2017 
the style of a “C” program function call; or values passed through global 
means (such as certain error routines in *ix-style operating systems). 
872 In order to assure the description is complete, the evaluator uses other 
information provided about the module in the TOE design (e.g., algorithmic 
description, global data used) to ensure that it appears all data necessary for 
performing the functions of the module is presented to the module, and that 
any values that other modules expect the module under examination to 
provide are identified as being returned by the module. The evaluator 
determines accuracy by  ensuring that the description of the processing 
matches the information listed as being passed to or from an interface. 
ADV_TDS.3.9C The design shall describe each SFR -supporting or SFR -non-interfering 
module in terms of its purpose and interaction with other modules.  
ADV_TDS.3-11 The evaluator shall examine  the TOE design to determine that SFR -
supporting and SFR-non-interfering modules are correctly categorised. 
873 In the cases where the developer has provided different amounts of 
information for different modules, an implicit categorisation has been done. 
That is, modules (for instance) with detail presented on their SFR -related 
interfaces (see ADV_TDS.3.10C) are candidate SFR -enforcing modules, 
although examination by the evaluator may lead to a determination that some 
set of them are SFR -supporting or SFR -non-interfering. Those with only a 
description of their purpose and interaction with other modules (for instance) 
are “implicitly categorised” as SFR-supporting or SFR-non-interfering. 
874 In these cases, a key focus of the evaluator for this work unit is attempting to 
determine from the evidence provided for each module implicitly categorised 
as SFR -supporting or SFR -non-interfering and the evaluation information 
about other modules (in the TOE design, the functional specification, the 
security architecture description, and the operational user guidance), whether 
the module is indeed SFR-supporting or SFR-non-interfering. At this level of 
assurance some error should be tolerated; the evaluator does not have to be 
absolutely sure that a given module is SFR -supporting or SFR -non-
interfering, even though it is labelled as such. However, if the ev idence 
provided indicates that a SFR -supporting or SFR -non-interfering module is 
SFR-enforcing, the evaluator requests additional information from the 
developer in order to resolve the apparent inconsistency. For instance, 
suppose the documentation for Mod ule A (an SFR -enforcing module) 
indicates that it calls Module B to perform an access check on a certain type 
of construct. When the evaluator examines the information associated with 
Module B, they find that all the developer has provided is a purpose and a set 
of interactions (thus implicitly categorising Module B as SFR -supporting or 
SFR-non-interfering). On examining the purpose and interactions from 
Module A, the evaluator finds no mention of Module B performing any 
access checks, and Module A is not l isted as a module with which Module B 
interacts. At this point the evaluator should approach the developer to resolve 
the discrepancies between the information provided in Module A and that in 
Module B. 
Class ADV: Development 
April 2017 Version 3.1 Page 189 of 430 
875 Another example would be where the evaluator examines  the mapping of the 
TSFI to the modules as provided by ADV_TDS.3.2D. This examination 
shows that Module C is associated with an SFR requiring identification of 
the user. Again, when the evaluator examines the information associated 
with Module C, they find that all the developer has provided is a purpose and 
a set of interactions (thus implicitly categorising Module C as SFR -
supporting or SFR -non-interfering). Examining the purpose and interactions 
presented for Module C, the evaluator is unable to determine why Module C, 
listed as mapping to a TSFI concerned with user identification, would not be 
classified as SFR -enforcing. Again, the evaluator should approach the 
developer to resolve this discrepancy. 
876 A final example is from the op posite point of view. As before, the developer 
has provided information associated with Module D consisting of a purpose 
and a set of interactions (thus implicitly categorising Module D as SFR -
supporting or SFR -non-interfering). The evaluator examines all of the 
evidence provided, including the purpose and interactions for Module D. The 
purpose appears to give a meaningful description of Module D's function in 
the TOE, the interactions are consistent with that description, and there is 
nothing to indicate t hat Module D is SFR -enforcing. In this case, the 
evaluator should not demand more information about Module D “just be to 
sure” it is correctly categorised. The developer has met their obligations and 
the resulting assurance the evaluator has in the implici t categorisation of 
Module D is (by definition) appropriate for this assurance level. 
ADV_TDS.3-12 The evaluator shall examine  the TOE design to determine that the 
description of the purpose of each SFR -supporting or SFR -non-interfering 
module is complete and accurate. 
877 The description of the purpose of a module indicates what function the 
module is fulfilling. From the description, the evaluator should be able to 
obtain a general idea of the module's role. In o rder to assure the description 
is complete, the evaluator uses the information provided about the module's 
interactions with other modules to assess whether the reasons for the module 
being called are consistent with the module's purpose. If the interactio n 
description contains functionality that is not apparent from, or in conflict 
with, the module's purpose, the evaluator needs to determine whether the 
problem is one of accuracy or of completeness. The evaluator should be wary 
of purposes that are too sho rt, since meaningful analysis based on a one -
sentence purpose is likely to be impossible. 
878 Because the modules are at such a low level, it may be difficult determine 
completeness and accuracy impacts from other documentation, such as 
administrative guidance , the functional specification, the security 
architecture description, or the TSF internals document. However, the 
evaluator uses the information present in those documents to the extent 
possible to help ensure that the function is accurately and completel y 
described. This analysis can be aided by the analysis performed for the work 
units for the ADV_TDS.3.10C element, which maps the TSFI in the 
functional specification to the modules of the TSF. 
Class ADV: Development 
Page 190 of 430 Version 3.1 April 2017 
ADV_TDS.3-13 The evaluator shall examine  the TOE design to determine that the 
description of a SFR -supporting or SFR-non-interfering module's interaction 
with other modules is complete and accurate. 
879 It is important to note that, in terms of the Part 3 requirement and th is work 
unit, the term interaction is intended to convey less rigour than interface. An 
interaction does not need to be characterised at the implementation level (e.g., 
parameters passed from one routine in a module to a routine in a different 
module; global variables; hardware signals (e.g., interrupts) from a hardware 
subsystem to an interrupt -handling subsystem), but the data elements 
identified for a particular module that are going to be used by another 
module should be covered in this discussion. Any control relationships 
between modules (e.g., a module responsible for configuring a rule base for a 
firewall system and the module that actually implements these rules) should 
also be described. 
880 Because the modules are at such a low level, it may be diffic ult determine 
completeness and accuracy impacts from other documentation, such as 
operational user guidance, the functional specification, the security 
architecture description, or the TSF internals document. However, the 
evaluator uses the information pre sent in those documents to the extent 
possible to help ensure that the function is accurately and completely 
described. This analysis can be aided by the analysis performed for the work 
units for the ADV_TDS.3.10C element, which ma ps the TSFI in the 
functional specification to the modules of the TSF. 
881 A module's interaction with other modules goes beyond just a call -tree-type 
document. The interaction is described from a functional perspective of why 
a module interacts with other mod ules. The module's purpose describes what 
functions the module provides to other modules; the interactions should 
describe what the module depends on from other modules in order to 
accomplish this function. 
ADV_TDS.3.10C The mapping shall demonstrate that all TSFIs trace to the behaviour 
described in the TOE design that they invoke.  
ADV_TDS.3-14 The evaluator shall examine the TOE design to determine that it c ontains a 
complete and accurate mapping from the TSFI described in the functional 
specification to the modules of the TSF described in the TOE design. 
882 The modules described in the TOE design provide a description of the 
implementation of the TSF. The TSFI provide a description of how the 
implementation is exercised. The evidence from the developer identifies the 
module that is initially invoked when an operation is requested at the TSFI, 
and identifies the chain of modules invoked up to the module that is 
primarily responsible for implementing the functionality. However, a 
complete call tree for each TSFI is not required for this work unit. The cases 
in which more than one module would have to be identified are where there 
are “entry point” modules or wrappe r modules that have no functionality 
other than conditioning inputs or de -multiplexing an input. Mapping to one 
of these modules would not provide any useful information to the evaluator. 
Class ADV: Development 
April 2017 Version 3.1 Page 191 of 430 
883 The evaluator assesses the completeness of the mapping by ensuring t hat all 
of the TSFI map to at least one module. The verification of accuracy is more 
complex. 
884 The first aspect of accuracy is that each TSFI is mapped to a module at the 
TSF boundary. This determination can be made by reviewing the module 
description and its interfaces/interactions. The next aspect of accuracy is that 
each TSFI identifies a chain of modules between the initial module identified 
and a module that is primarily responsible for implementing the function 
presented at the TSF. Note that this may be the initial module, or there may 
be several modules, depending on how much pre -conditioning of the inputs 
is done. It should be noted that one indicator of a pre -conditioning module is 
that it is invoked for a large number of the TSFI, where the TSFI ar e all of 
similar type (e.g., system call). The final aspect of accuracy is that the 
mapping makes sense. For instance, mapping a TSFI dealing with access 
control to a module that checks passwords is not accurate. The evaluator 
should again use judgement in  making this determination. The goal is that 
this information aids the evaluator in understanding the system and 
implementation of the SFRs, and ways in which entities at the TSF boundary 
can interact with the TSF. The bulk of the assessment of whether the  SFRs 
are described accurately by the modules is performed in other work units. 
12.8.3.5 Action ADV_TDS.3.2E 
ADV_TDS.3-15 The evaluator shall examine  the TOE security funct ional requirements and 
the TOE design, to determine that all ST security functional requirements are 
covered by the TOE design. 
885 The evaluator may construct a map between the TOE security functional 
requirements and the TOE design. This map will likely be f rom a functional 
requirement to a set of subsystems, and later to modules. Note that this map 
may have to be at a level of detail below the component or even element 
level of the requirements, because of operations (assignments, refinements, 
selections) performed on the functional requirement by the ST author. 
886 For example, the FDP_ACC.1 Subset access control  component contains an 
element with assignments. If the ST contained, for instance, ten rules in the 
FDP_ACC.1 Subset access control  assignment, and these ten rules were 
implemented in specific places within fifteen modules, it would be 
inadequate for the evaluator to map FDP_ACC.1 Subset access control  to 
one subsystem and claim the work unit  had been completed. Instead, the 
evaluator would map FDP_ACC.1 Subset access control  (rule 1) to modules 
x, y, and z of subsystem A; FDP_ACC.1 Subset access control  (rule 2) to 
modules x, p, and q of subsystem A; etc. 
ADV_TDS.3-16 The evaluator shall examine  the TOE design to determine that it is an 
accurate instantiation of all security functional requirements. 
887 The evaluator may construct a map between the TOE securit y functional 
requirements and the TOE design. This map will likely be from a functional 
requirement to a set of subsystems. Note that this map may have to be at a 
Class ADV: Development 
Page 192 of 430 Version 3.1 April 2017 
level of detail below the component or even element level of the 
requirements, because of ope rations (assignments, refinements, selections) 
performed on the functional requirement by the ST author. 
888 As an example, if the ST requirements specified a role -based access control 
mechanism, the evaluator would first identify the subsystems, and modules 
that contribute to this mechanism's implementation. This could be done by 
in-depth knowledge or understanding of the TOE design or by work done in 
the previous work unit. Note that this trace is only to identify the subsystems, 
and modules, and is not the complete analysis. 
889 The next step would be to understand what mechanism the subsystems, and 
modules implemented. For instance, if the design described an 
implementation of access control based on UNIX -style protection bits, the 
design would not be an accurat e instantiation of those access control 
requirements present in the ST example used above. If the evaluator could 
not determine that the mechanism was accurately implemented because of a 
lack of detail, the evaluator would have to assess whether all of the  SFR-
enforcing subsystems and modules have been identified, or if adequate detail 
had been provided for those subsystems and modules. 
12.8.4 Evaluation of sub-activity (ADV_TDS.4) 
12.8.4.1 Objectives 
890 The objective of this sub -activity is to determine whether the TOE desig n 
provides a description of the TOE in terms of subsystems sufficient to 
determine the TSF boundary, and provides a description of the TSF internals 
in terms of modules (and optionally higher -level abstractions). It provides a 
detailed description of the S FR-enforcing and SFR -supporting modules and 
enough information about the SFR -non-interfering modules for the evaluator 
to determine that the SFRs are completely and accurately implemented; as 
such, the TOE design provides an explanation of the implementati on 
representation. 
12.8.4.2 Input 
891 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the functional specification;  
c) security architecture description;  
d) the TOE design.  
12.8.4.3 Application notes 
892 There are three types of activity that the evaluator must undertake w ith 
respect to the TOE design. First, the evaluator determines that the TSF 
boundary has been adequately described. Second, the evaluator determines 
Class ADV: Development 
April 2017 Version 3.1 Page 193 of 430 
that the developer has provided documentation that conforms to the content 
and presentation requirements th is subsystem, and that is consistent with 
other documentation provided for the TOE. Finally, the evaluator must 
analyse the design information provided for the SFR -enforcing modules (at a 
detailed level) and the SFR -supporting and SFR-non-interfering modules (at 
a less detailed level) to understand how the system is implemented, and with 
that knowledge ensure that the TSFI in the functional specification are 
adequately described, and that the test information adequately tests the TSF 
(done in the Class ATE: Tests work units). 
12.8.4.4 Action ADV_TDS.4.1E 
ADV_TDS.4.1C The design shall describe the structure of the TOE in terms of subsystems.  
ADV_TDS.4-1 The evaluator shall examine the TOE design to determine that the structure 
of the entire TOE is described in terms of subsystems. 
893 The evaluator ensures that all of the subsystems of the TOE are identified. 
This description of the TOE will be used as input to work unit ADV_TDS.4-
4, where the parts of the TOE that make up the TSF are identified. That is, 
this requirement is on the entire TOE rather than on only the TSF. 
894 The TOE (and TSF) may be desc ribed in multiple layers of abstraction (i.e. 
subsystems and modules) Depending upon the complexity of the TOE, its 
design may be described in terms of subsystems and modules, as described 
in CC Part 3 Annex A.4, ADV_TD S: Subsystems and Modules . For a very 
simple TOE that can be described solely at the “module” level (see 
ADV_TDS.4-2), this work unit is not applicable and therefore considered to 
be satisfied. 
895 In performing this activity, the evaluator examines oth er evidence presented 
for the TOE (e.g., ST, operator user guidance) to determine that the 
description of the TOE in such evidence is consistent with the description 
contained in the TOE design. 
ADV_TDS.4.2C The design shall describe the TSF in terms of modules, designating each 
module as SFR-enforcing, SFR-supporting, or SFR-non-interfering.  
ADV_TDS.4-2 The evaluator shall examine  the TOE design to determine that t he entire 
TSF is described in terms of modules. 
896 The evaluator will examine the modules for specific properties in other work 
units; in this work unit the evaluator determines that the modular description 
covers the entire TSF, and not just a portion of the  TSF. The evaluator uses 
other evidence provided for the evaluation (e.g., functional specification, 
architectural description) in making this determination. For example, if the 
functional specification contains interfaces to functionality that does not 
appear to be described in the TOE design description, it may be the case that 
a portion of the TSF has not been included appropriately. Making this 
determination will likely be an iterative process, where as more analysis is 
Class ADV: Development 
Page 194 of 430 Version 3.1 April 2017 
done on the other evidence, more confidence can be gained with respect to 
the completeness of the documentation. 
897 Unlike subsystems, modules describe the implementation in a level of detail 
that can serve as a guide to reviewing the implementation representation. A 
description of a module should be such that one could create an 
implementation of the module from the description, and the resulting 
implementation would be 1) identical to the actual TSF implementation in 
terms of the interfaces presented, 2) identical in the use of interfaces t hat are 
mentioned in the design, and 3) functionally equivalent to the description of 
the purpose of the TSF module. For instance, RFC 793 provides a high -level 
description of the TCP protocol. It is necessarily implementation 
independent. While it provide s a wealth of detail, it is not a suitable design 
description because it is not specific to an implementation. An actual 
implementation can add to the protocol specified in the RFC, and 
implementation choices (for instance, the use of global data vs. local  data in 
various parts of the implementation) may have an impact on the analysis that 
is performed. The design description of the TCP module would list the 
interfaces presented by the implementation (rather than just those defined in 
RFC 793), as well as a n algorithm description of the processing associated 
with the modules implementing TCP (assuming it was part of the TSF). 
ADV_TDS.4-3 The evaluator shall check  the TOE design to determine that the TSF 
modules are  identified as either SFR -enforcing, SFR -supporting, or SFR -
non-interfering. 
898 The purpose of designating each module (according to the role a particular 
module plays in the enforcement of the SFRs) is to allow developers to 
provide less information about th e parts of the TSF that have little role in 
security. It is always permissible for the developer to provide more 
information or detail than the requirements demand, as might occur when the 
information has been gathered outside the evaluation context. In su ch cases 
the developer must still designate the modules as either SFR-enforcing, SFR-
supporting, or SFR-non-interfering. 
899 The accuracy of these designations is continuously reviewed as the 
evaluation progresses. The concern is the mis -designation of modules  as 
being less important (and hence, having less information) than is really the 
case. While blatant mis -designations may be immediately apparent (e.g., 
designating an authentication module as anything but SFR -enforcing when 
User identification (FIA_UID) is one of the SFRs being claimed), other mis -
designations might not be discovered until the TSF is better understood. The 
evaluator must therefore keep in mind that these designations are the 
developer's initial best effort, but are subje ct to change. Further guidance is 
provided under work unit ADV_TDS.4-17, which examines the accuracy of 
these designations. 
ADV_TDS.4.3C The design shall identify all subsystems of the TSF.  
ADV_TDS.4-4 The evaluator shall examine  the TOE design to determine that all 
subsystems of the TSF are identified. 
Class ADV: Development 
April 2017 Version 3.1 Page 195 of 430 
900 If the design is presented solely in terms of modules, then subsystems in 
these requiremen ts are equivalent to modules and the activity should be 
performed at the module level. 
901 In work unit ADV_TDS.4-1 all of the subsystems of the TOE were identified, 
and a determination made that the non -TSF subsystems were correctly 
characterised. Building on that work, the subsystems that were not 
characterised as non -TSF subsystems should be precisely identified. The 
evaluator determines that, of the hardware and software installed and 
configured according to the Preparative procedures (AGD_PRE)  guidance, 
each subsystem has been accounted for as either one that is part of the TSF, 
or one that is not. 
ADV_TDS.4.4C The design shall provide a semiformal description of each subsystem of the 
TSF, supported by informal, explanatory text where appropriate.  
ADV_TDS.4-5 The evaluator shall examine  the TDS documentation to determine that the 
semiformal notation used for describing the su bsystems, modules and their 
interfaces is defined or referenced. 
902 A semiformal notation can be either defined by the sponsor or a 
corresponding standard be referenced. The evaluator should provide a 
mapping of security functions and their interfaces outlini ng in what part of 
the documentation a function or interface is semiformal described and what 
notation is used. The evaluator examines all semiformal notations used to 
make sure that they are of a semiformal style and to justify the 
appropriateness of the manner how the semiformal notations are used for the 
TOE. 
903 The evaluator is reminded that a semi-formal presentation is characterised by 
a standardised format with a well -defined syntax that reduces ambiguity that 
may occur in informal presentations. The sy ntax of all semiformal notations 
used in the functional specification shall be defined or a corresponding 
standard be referenced. The evaluator verifies that the semiformal notations 
used for expressing the functional specification are capable of expressin g 
features relevant to security. In order to determine this, the evaluator can 
refer to the SFR and compare the TSF security features stated in the ST and 
those described in the FSP using the semiformal notations. 
ADV_TDS.4-6 The evaluator shall examine  the TOE design to determine that each 
subsystem of the TSF describes its role in the enforcement of SFRs described 
in the ST. 
904 If the design is presented solely in terms of modules, then this work unit will 
be considered satisfied by the assessment done in subsequent work units; no 
explicit action on the part of the evaluator is necessary in this case. 
905 On systems that are complex enough to warrant a subsystem -level 
description of the TSF in addition to the modular de scription, the goal of the 
subsystem-level description is to give the evaluator context for the modular 
description that follows. Therefore, the evaluator ensures that the subsystem -
Class ADV: Development 
Page 196 of 430 Version 3.1 April 2017 
level description contains a description of how the security functional 
requirements are achieved in the design, but at a level of abstraction above 
the modular description. This description should discuss the mechanisms 
used at a level that is aligned with the module description; this will provide 
the evaluators the road map ne eded to intelligently assess the information 
contained in the module description. A well -written set of subsystem 
descriptions will help guide the evaluator in determining the modules that are 
most important to examine, thus focusing the evaluation activit y on the 
portions of the TSF that have the most relevance with respect to the 
enforcement of the SFRs. 
906 The evaluator ensures that all subsystems of the TSF have a description. 
While the description should focus on the role that the subsystem plays in 
enforcing or supporting the implementation of the SFRs, enough information 
must be present so that a context for understanding the SFR -related 
functionality is provided. 
ADV_TDS.4-7 The evaluator shall examine  the TOE  design to determine that each SFR -
non-interfering subsystem of the TSF is described such that the evaluator can 
determine that the subsystem is SFR-non-interfering. 
907 If the design is presented solely in terms of modules, then this work unit will 
be considered satisfied by the assessment done in subsequent work units; no 
explicit action on the part of the evaluator is necessary in this case. 
908 An SFR-non-interfering subsystem is one on which the SFR -enforcing and 
SFR-supporting subsystems have no dependence; that is, they play no role in 
implementing SFR functionality. 
909 The evaluator ensures that all subsystems of the TSF have a description. 
While the description should focus on the role that the subsystem do not 
plays in enforcing or supporting the implementati on of the SFRs, enough 
information must be present so that a context for understanding the SFR -
non-interfering functionality is provided. 
ADV_TDS.4.5C The design shall provide a description of the interaction s among all 
subsystems of the TSF.  
ADV_TDS.4-8 The evaluator shall examine  the TOE design to determine that interactions 
between the subsystems of the TSF are described. 
910 If the design is presented solely in term s of modules, then this work unit will 
be considered satisfied by the assessment done in subsequent work units; no 
explicit action on the part of the evaluator is necessary in this case. 
911 On systems that are complex enough to warrant a subsystem -level 
description of the TSF in addition to the modular description, the goal of 
describing the interactions between the subsystems is to help provide the 
reader a better understanding of how the TSF performs it functions. These 
interactions do not need to be charact erised at the implementation level (e.g., 
parameters passed from one routine in a subsystem to a routine in a different 
Class ADV: Development 
April 2017 Version 3.1 Page 197 of 430 
subsystem; global variables; hardware signals (e.g., interrupts) from a 
hardware subsystem to an interrupt -handling subsystem), but the data 
elements identified for a particular subsystem that are going to be used by 
another subsystem need to be covered in this discussion. Any control 
relationships between subsystems (e.g., a subsystem responsible for 
configuring a rule base for a firewall  system and the subsystem that actually 
implements these rules) should also be described. 
912 It should be noted while the developer should characterise all interactions 
between subsystems, the evaluators need to use their own judgement in 
assessing the completeness of the description. If the reason for an interaction 
is unclear, or if there are SFR -related interactions (discovered, for instance, 
in examining the module -level documentation) that do not appear to be 
described, the evaluator ensures that this inf ormation is provided by the 
developer. However, if the evaluator can determine that interactions among a 
particular set of subsystems, while incompletely described by the developer, 
and a complete description will not aid in understanding the overall 
functionality nor security functionality provided by the TSF, then the 
evaluator may choose to consider the description sufficient, and not pursue 
completeness for its own sake. 
ADV_TDS.4.6C The design shall provide a mapping from the subsystems of the TSF to the 
modules of the TSF.  
ADV_TDS.4-9 The evaluator shall examine the TOE design to determine that the mapping 
between the subsystems of the TSF and the modules of the TSF is complete. 
913 If the design is presented solely in terms of modules, then this work unit is 
considered satisfied. 
914 For TOEs that are complex enough to warrant a subsystem -level description 
of the TSF in addition to the modular description, the develope r provides a 
simple mapping showing how the modules of the TSF are allocated to the 
subsystems. This will provide the evaluator a guide in performing their 
module-level assessment. To determine completeness, the evaluator 
examines each mapping and determin es that all subsystems map to at least 
one module, and that all modules map to exactly one subsystem. 
ADV_TDS.4-10 The evaluator shall examine the TOE design to determine that the mapping 
between the subsystems of the TSF to the modules of the TSF is accurate. 
915 If the design is presented solely in terms of modules, then this work unit is 
considered satisfied. 
916 For TOEs that are complex enough to warrant a subsystem -level description 
of the TSF in addition to the modular description, the developer provides a 
simple mapping showing how the modules of the TSF are allocated to the 
subsystems. This will provide the evaluator a guide in performing their 
module-level assessment. The evaluator may choose to check the accuracy of 
the mapping in conjunction with performing other work units. An 
“inaccurate” mapping is one where the module is mistakenly associated with 
Class ADV: Development 
Page 198 of 430 Version 3.1 April 2017 
a subsystem where its functions are not used within the subsystem. Because 
the mapping is intended to be a gu ide supporting more detailed analysis, the 
evaluator is cautioned to apply appropriate effort to this work unit. 
Expending extensive evaluator resources verifying the accuracy of the 
mapping is not necessary. Inaccuracies that lead to mis -understandings 
related to the design that are uncovered as part of this or other work units are 
the ones that should be associated with this work unit and corrected. 
ADV_TDS.4.7C The design shall describe each SFR -enforcing a nd SFR -supporting 
module in terms of its purpose and relationship with other modules.  
ADV_TDS.4-11 The evaluator shall examine  the TOE design to determine that the 
description of the purpose of each SFR -enforcing and SFR -supporting 
module, and relationship with other modules is complete and accurate. 
917 The developer may designate modules as SFR -enforcing, SFR -supporting, 
and SFR non -interfering, but these “tags” are used only to describe the 
amount and type of information the developer must provide, and can be used 
to limit the amount of information the developer has to develop if their 
engineering process does not produce the documentation required. Whether 
the modules have been categorised by the developer or n ot, it is the 
evaluator's responsibility to determine that the modules have the appropriate 
information for their role (SFR-enforcing, etc.) in the TOE, and to obtain the 
appropriate information from the developer should the developer fail to 
provide the required information for a particular module. 
918 The purpose of a module provides a description indicating what function the 
module is fulfilling. A word of caution to evaluator is in order. The focus of 
this work unit should be to provide the evaluator an und erstanding of how 
the module works so that determinations can be made about the soundness of 
the implementation of the SFRs, as well as to support architectural analysis 
performed for ADV_ARC subsystems. As long as the evalua tor has a sound 
understanding of the module's operation, and its relationship to other 
modules and the TOE as a whole, the evaluator should consider the objective 
of the work achieved and not engage in a documentation exercise for the 
developer (by requiring, for example, a complete algorithmic description for 
a self-evident implementation representation). 
919 Because the modules are at such a low level, it may be difficult determine 
completeness and accuracy impacts from other documentation, such as 
operational user guidance, the functional specification, the TSF internals, or 
the security architecture description. However, the evaluator uses the 
information present in those documents to the extent possible to help ensure 
that the purpose is accurately and comp letely described. This analysis can be 
aided by the analysis performed for the work units for the ADV_TDS.4.10C 
element, which maps the TSFI in the functional specification to the modules 
of the TSF. 
ADV_TDS.4.8C The design shall describe each SFR -enforcing and SFR -supporting 
module in terms of its SFR -related interfaces, return values from those 
Class ADV: Development 
April 2017 Version 3.1 Page 199 of 430 
interfaces, interaction with other modules and called SFR -related 
interfaces to other SFR-enforcing or SFR-supporting modules.  
ADV_TDS.4-12 The evaluator shall examine  the TOE design to determine that the 
description of the interfaces presented by each SFR -enforcing and SFR -
supporting module contain an accurate and complete description of the SFR -
related parameters, the invocation conventions for each interface, and any 
values returned directly by the interface. 
920 The SFR -related interfaces of a module are those interfaces used by other 
modules as a means to invoke the SFR -related operations provided, and to 
provide inputs to or receive outputs from the module. The purpose in the 
specification of these interfaces is to permit the exercise of them during 
testing. Inter -module interfaces that are not SF R-related need not be 
specified or described, since they are not a factor in testing. Likewise, other 
internal interfaces that are not a factor in traversing SFR -related paths of 
execution (such as those internal paths that are fixed). 
921 SFR-related interfaces of SFR-supporting modules are all interfaces of SFR -
supporting modules that are called directly or indirectly from SFR -enforcing 
modules. Those interfaces need to be described with all the parameter used in 
such a call. This allows the evaluator to unde rstand the purpose of the call to 
the SFR-supporting module in the context of operation of the SFR -enforcing 
modules. 
922 SFR-related interfaces are described in terms of how they are invoked, and 
any values that are returned. This description would include a list of 
parameters, and descriptions of these parameters. Note that global data 
would also be considered parameters if used by the module (either as inputs 
or outputs) when invoked. If a parameter were expected to take on a set of 
values (e.g., a “flag” pa rameter), the complete set of values the parameter 
could take on that would have an effect on module processing would be 
specified. Likewise, parameters representing data structures are described 
such that each field of the data structure is identified and described. Note that 
different programming languages may have additional “interfaces” that 
would be non -obvious; an example would be operator/function overloading 
in C++. This “implicit interface” in the class description would also be 
described as part o f the low -level TOE design. Note that although a module 
could present only one interface, it is more common that a module presents a 
small set of related interfaces. 
923 In terms of the assessment of parameters (inputs and outputs) to a module, 
any use of global data must also be considered. A module “uses” global data 
if it either reads or writes the data. In order to assure the description of such 
parameters (if used) is complete, the evaluator uses other information 
provided about the module in the TOE desig n (interfaces, algorithmic 
description, etc.), as well as the description of the particular set of global data 
assessed in work unit ADV_TDS.4-12. For instance, the evaluator could first 
determine the processing the module performs by examining its function and 
interfaces presented (particularly the parameters of the interfaces). They 
could then check to see if the processing appears to “touch” any of the global 
Class ADV: Development 
Page 200 of 430 Version 3.1 April 2017 
data areas identified in the TDS design. The evaluator then determines t hat, 
for each global data area that appears to be “touched”, that global data area is 
listed as a means of input or output by the module the evaluator is examining.  
924 Invocation conventions are a programming -reference-type description that 
one could use to c orrectly invoke a module's interface if one were writing a 
program to make use of the module's functionality through that interface. 
This includes necessary inputs and outputs, including any set -up that may 
need to be performed with respect to global variables. 
925 Values returned through the interface refer to values that are either passed 
through parameters or messages; values that the function call itself returns in 
the style of a “C” program function call; or values passed through global 
means (such as certain error routines in *ix-style operating systems). 
926 In order to assure the description is complete, the evaluator uses other 
information provided about the module in the TOE design (e.g., algorithmic 
description, global data used) to ensure that it appears  all data necessary for 
performing the functions of the module is presented to the module, and that 
any values that other modules expect the module under examination to 
provide are identified as being returned by the module. The evaluator 
determines accura cy by ensuring that the description of the processing 
matches the information listed as being passed to or from an interface. 
ADV_TDS.4.9C The design shall describe each SFR -non-interfering module in terms of  its 
purpose and interaction with other modules.  
ADV_TDS.4-13 The evaluator shall examine  the TOE design to determine that SFR -non-
interfering modules are correctly categorised. 
927 As mentioned in work unit ADV_TDS.4-2, less information is required 
about modules that are SFR-non-interfering. A key focus of the evaluator for 
this work unit is attempting to determine from the evidence provided for 
each module implicitly categorised as SFR -non-interfering and the 
evaluation (information about other modules in the TOE design, the 
functional specification, the security architecture description, the operational 
user guidance, the TSF internals document, and perhaps even the 
implementation represen tation) whether the module is indeed SFR -non-
interfering. At this level of assurance some error should be tolerated; the 
evaluator does not have to be absolutely sure that a given module is SFR -
non-interfering, even though it is labelled as such. However, if the evidence 
provided indicates that a SFR -non-interfering module is SFR -enforcing or 
SFR-supporting, the evaluator requests additional information from the 
developer in order to resolve the apparent inconsistency. For example, 
suppose the documentation  for Module A (an SFR -enforcing module) 
indicates that it calls Module B to perform an access check on a certain type 
of construct. When the evaluator examines the information associated with 
Module B, it is discovered that the only information the develop er has 
provided is a purpose and a set of interactions (thus implicitly categorising 
Module B as SFR -supporting or SFR -non-interfering). On examining the 
purpose and interactions from Module A, the evaluator finds no mention of 
Class ADV: Development 
April 2017 Version 3.1 Page 201 of 430 
Module B performing any acce ss checks, and Module A is not listed as a 
module with which Module B interacts. At this point the evaluator should 
approach the developer to resolve the discrepancies between the information 
provided in Module A and that in Module B. 
928 Another example would be where the evaluator examines the mapping of the 
TSFI to the modules as provided by ADV_TDS.4.2D. This examination 
shows that Module C is associated with an SFR requiring identification of 
the user. Again, when the evaluator exam ines the information associated 
with Module C, they find that all the developer has provided is a purpose and 
a set of interactions (thus implicitly categorising Module C as SFR -non-
interfering). Examining the purpose and interactions presented for Module C, 
the evaluator is unable to determine why Module C, listed as mapping to a 
TSFI concerned with user identification, would not be classified as SFR -
enforcing or SFR -supporting. Again, the evaluator should approach the 
developer to resolve this discrepancy. 
929 A final example illustrates the opposite situation. As before, the developer 
has provided information associated with Module D consisting of a purpose 
and a set of interactions (thus implicitly categorising Module D as SFR -non-
interfering). The evaluator  examines all of the evidence provided, including 
the purpose and interactions for Module D. The purpose appears to give a 
meaningful description of Module D's function in the TOE, the interactions 
are consistent with that description, and there is nothing  to indicate that 
Module D is SFR -enforcing or SFR -supporting. In this case, the evaluator 
should not demand more information about Module D “just be to sure” it is 
correctly categorised. The developer has met the obligations and the resulting 
assurance the evaluator has in the implicit categorisation of Module D is (by 
definition) appropriate for this assurance level. 
ADV_TDS.4-14 The evaluator shall examine  the TOE design to determine that the 
description of the purpose of each SFR -non-interfering module is complete 
and accurate. 
930 The description of the purpose of a module indicates what function the 
module is fulfilling. From the description, the evaluator should be able to 
obtain a general idea of the module' s role. In order to assure the description 
is complete, the evaluator uses the information provided about the module's 
interactions with other modules to assess whether the reasons for the module 
being called are consistent with the module's purpose. If th e interaction 
description contains functionality that is not apparent from, or in conflict 
with, the module's purpose, the evaluator needs to determine whether the 
problem is one of accuracy or of completeness. The evaluator should be wary 
of purposes that  are too short, since meaningful analysis based on a one -
sentence purpose is likely to be impossible. 
931 Because the modules are at such a low level, it may be difficult determine 
completeness and accuracy impacts from other documentation, such as 
operational user guidance, the functional specification, the security 
architecture description, or the TSF internals document. However, the 
evaluator uses the information present in those documents to the extent 
Class ADV: Development 
Page 202 of 430 Version 3.1 April 2017 
possible to help ensure that the function is accurately  and completely 
described. This analysis can be aided by the analysis performed for the work 
units for the ADV_TDS.4.10C element, which maps the TSFI in the 
functional specification to the modules of the TSF. 
ADV_TDS.4-15 The evaluator shall examine  the TOE design to determine that the 
description of a SFR-non-interfering module's interaction with other modules 
is complete and accurate. 
932 It is important to note that, in terms of the Part  3 requirement and this work 
unit, the term interaction is intended to convey less rigour than interface. An 
interaction does not need to be characterised at the implementation level (e.g., 
parameters passed from one routine in a module to a routine in a d ifferent 
module; global variables; hardware signals (e.g., interrupts) from a hardware 
subsystem to an interrupt -handling subsystem), but the data elements 
identified for a particular module that are going to be used by another 
module should be covered in this discussion. Any control relationships 
between modules (e.g., a module responsible for configuring a rule base for a 
firewall system and the module that actually implements these rules) should 
also be described. 
933 A module's interaction with other module s can be captured in many ways. 
The intent for the TOE design is to allow the evaluator to understand (in part 
through analysis of module interactions) the role of the SFR -supporting and 
SFR-non-interfering modules in the overall TOE design. Understanding of 
this role will aid the evaluator in performing work unit ADV_TDS.4-8. 
934 A module's interaction with other modules goes beyond just a call -tree-type 
document. The interaction is described from a functional perspective of why 
a module interacts with other modules. The module's purpose describes what 
functions the module provides to other modules; the interactions should 
describe what the module depends on from other modules in order to 
accomplish this function. 
935 Because the modules are at such a low level, it may be difficult determine 
completeness and accuracy impacts from other documentation, such as 
operational user guidance, the functional specification, the security 
architecture description, or the TSF internals document. However, t he 
evaluator uses the information present in those documents to the extent 
possible to help ensure that the interactions are accurately and completely 
described. 
ADV_TDS.4.10C The mapping shall demonstrate  that all TSFIs trace to the behaviour 
described in the TOE design that they invoke.  
ADV_TDS.4-16 The evaluator shall examine the TOE design to determine that it contains a 
complete and accurate mapping from the TSFI described in the functional 
specification to the modules of the TSF described in the TOE design. 
936 The modules described in the TOE design provide a description of the 
implementation of the TSF. The TSFI provide a description of how the 
Class ADV: Development 
April 2017 Version 3.1 Page 203 of 430 
implementation is exercised. The evidence from the developer identifies the 
module that is initially invoked when an operation is requested at the TSFI, 
and identify the chain of modules invoked up to the module that is primarily 
responsible for implementing the funct ionality. However, a complete call 
tree for each TSFI is not required for this work unit. The cases in which more 
than one module would have to be identified are where there are “entry 
point” modules or wrapper modules that have no functionality other than  
conditioning inputs or de -multiplexing an input. Mapping to one of these 
modules would not provide any useful information to the evaluator. 
937 The evaluator assesses the completeness of the mapping by ensuring that all 
of the TSFI map to at least one module.  The verification of accuracy is more 
complex. 
938 The first aspect of accuracy is that each TSFI is mapped to a module at the 
TSF boundary. This determination can be made by reviewing the module 
description and its interfaces/interactions. The next aspect of accuracy is that 
each TSFI identifies a chain of modules between the initial module identified 
and a module that is primarily responsible for implementing the function 
presented at the TSF. Note that this may be the initial module, or there may 
be several modules, depending on how much pre -conditioning of the inputs 
is done. It should be noted that one indicator of a pre -conditioning module is 
that it is invoked for a large number of the TSFI, where the TSFI are all of 
similar type (e.g., system call). The final aspect of accuracy is that the 
mapping makes sense. For instance, mapping a TSFI dealing with access 
control to a module that checks passwords is not accurate. The evaluator 
should again use judgement in making this determination. The goal is that 
this information aids the evaluator in understanding the system and 
implementation of the SFRs, and ways in which entities at the TSF boundary 
can interact with the TSF. The bulk of the assessment of whether the SFRs 
are described accurately by the modules is performed in other work units. 
12.8.4.5 Action ADV_TDS.4.2E 
ADV_TDS.4-17 The evaluator shall examine  the TOE security functional requirements and 
the TOE design, to determine that all ST security functional requirements are 
covered by the TOE design. 
939 The evaluator may construct a map between the TOE security functional 
requirements and the TOE design. This map will likely be from a functional 
requirement to a set of subsys tems, and later to modules. Note that this map 
may have to be at a level of detail below the component or even element 
level of the requirements, because of operations (assignments, refinements, 
selections) performed on the functional requirement by the ST author. 
940 For example, the FDP_ACC.1 Subset access control  component contains an 
element with assignments. If the ST contained, for instance, ten rules in the 
FDP_ACC.1 Subset access control  assignment, and these te n rules were 
implemented in specific places within fifteen modules, it would be 
inadequate for the evaluator to map FDP_ACC.1 Subset access control  to 
one subsystem and claim the work unit had been completed. Instead, the 
Class ADV: Development 
Page 204 of 430 Version 3.1 April 2017 
evaluator would map FDP_ACC.1 Subset access control  (rule 1) to modules 
x, y and z of subsystem A; FDP_ACC.1 Subset access control (rule 2) to x, p, 
and q of subsystem A; etc. 
ADV_TDS.4-18 The evaluator shall examine  the TOE design to determine that it is an 
accurate instantiation of all security functional requirements. 
941 The evaluator may construct a map between the TOE security functional 
requirements and the TOE design. This map w ill likely be from a functional 
requirement to a set of subsystems. Note that this map may have to be at a 
level of detail below the component or even element level of the 
requirements, because of operations (assignments, refinements, selections) 
performed on the functional requirement by the ST author. 
942 As an example, if the ST requirements specified a role -based access control 
mechanism, the evaluator would first identify the subsystems, and modules 
that contribute to this mechanism's implementation. This could be done by 
in-depth knowledge or understanding of the TOE design or by work done in 
the previous work unit. Note that this trace is only to identify the subsystems, 
and modules, and is not the complete analysis. 
943 The next step would be to understand w hat mechanism the subsystems, and 
modules implemented. For instance, if the design described an 
implementation of access control based on UNIX -style protection bits, the 
design would not be an accurate instantiation of those access control 
requirements present in the ST example used above. If the evaluator could 
not determine that the mechanism was accurately implemented because of a 
lack of detail, the evaluator would have to assess whether all of the SFR -
enforcing subsystems and modules have been identifi ed, or if adequate detail 
had been provided for those subsystems and modules. 
12.8.5 Evaluation of sub-activity (ADV_TDS.5) 
944 There is no general guidance; the scheme should be consulted for guidance 
on this sub-activity. 
12.8.6 Evaluation of sub-activity (ADV_TDS.6) 
945 There is no general guidance; the scheme should be consulted for guidance 
on this sub-activity. 
Class AGD: Guidance documents 
April 2017 Version 3.1 Page 205 of 430 
13 Class AGD: Guidance documents 
13.1 Introduction 
946 The purpose of the guidance document activity is to judge the adequacy of 
the documentation describing how the user can handle the TOE in a secure 
manner. Such documentation should take into account the various types of 
users (e.g. those who accept, install, administrate or operate the TOE) whose 
incorrect actions could adversely affect the security of the TOE or of their 
own data. 
947 The guidance documents class is subdivided into two families which are 
concerned firstly with the preparative procedures (all that has to be done to 
transform the delivered TOE into its evaluated configuration in the 
environment as described in th e ST, i.e. accepting and installing the TOE) 
and secondly with the operational user guidance (all that has to be done 
during the operation of the TOE in its evaluated configuration, i.e. operation 
and administration). 
13.2 Application notes 
948 The guidance documen ts activity applies to those functions and interfaces 
which are related to the security of the TOE. The secure configuration of the 
TOE is described in the ST. 
Class AGD: Guidance documents 
Page 206 of 430 Version 3.1 April 2017 
13.3 Operational user guidance (AGD_OPE) 
13.3.1 Evaluation of sub-activity (AGD_OPE.1) 
13.3.1.1 Objectives 
949 The objec tives of this sub -activity are to determine whether the user 
guidance describes for each user role the security functionality and interfaces 
provided by the TSF, provides instructions and guidelines for the secure use 
of the TOE, addresses secure procedure s for all modes of operation, 
facilitates prevention and detection of insecure TOE states, or whether it is 
misleading or unreasonable. 
13.3.1.2 Input 
950 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the functional specification;  
c) the TOE design, if applicable;  
d) the user guidance;  
13.3.1.3 Action AGD_OPE.1.1E 
AGD_OPE.1.1C The operational user guidance shall describe, for each user role, the user -
accessible functions and privileges that should be controlled in a secure 
processing environment, including appropriate warnings.  
AGD_OPE.1-1 The evaluator shall examine the operational user guidance to determine that 
it describes, for each user role, the user -accessible functions and privileges 
that should be controlled in a secure processing environment, including 
appropriate warnings. 
951 The configuration of the TOE may allow different user roles to have 
dissimilar privileges in making u se of the different functions of the TOE. 
This means that some users are authorised to perform certain functions, 
while other users may not be so authorised. These functions and privileges 
should be described, for each user role, by the user guidance. 
952 The user guidance identifies, for each user role, the functions and privileges 
that must be controlled, the types of commands required for them, and the 
reasons for such commands. The user guidance should contain warnings 
regarding the use of these functions a nd privileges. Warnings should address 
expected effects, possible side effects, and possible interactions with other 
functions and privileges. 
AGD_OPE.1.2C The operational user guidance shall describe, for ea ch user role, how to 
use the available interfaces provided by the TOE in a secure manner.  
Class AGD: Guidance documents 
April 2017 Version 3.1 Page 207 of 430 
AGD_OPE.1-2 The evaluator shall examine the operational user guidance to determine that 
it describes, for each user role,  the secure use of the available interfaces 
provided by the TOE. 
953 The user guidance should provide advice regarding effective use of the TSF 
(e.g. reviewing password composition practises, suggested frequency of user 
file backups, discussion on the effects of changing user access privileges). 
AGD_OPE.1.3C The operational user guidance shall describe, for each user role, the 
available functions and interfaces, in particular all security parameters 
under the control of the user, indicating secure values as appropriate.  
AGD_OPE.1-3 The evaluator shall examine the operational user guidance to determine that 
it describes, for each user role, the available security function ality and 
interfaces, in particular all security parameters under the control of the user, 
indicating secure values as appropriate. 
954 The user guidance should contain an overview of the security functionality 
that is visible at the user interfaces. 
955 The user guidance should identify and describe the purpose, behaviour, and 
interrelationships of the security interfaces and functionality. 
956 For each user-accessible interface, the user guidance should:  
a) describe the method(s) by which the interface is invoked (e.g.  
command-line, programming -language system call, menu selection, 
command button);  
b) describe the parameters to be set by the user, their particular purposes, 
valid and default values, and secure and insecure use settings of such 
parameters, both individually or in combination;  
c) describe the immediate TSF response, message, or code returned.  
957 The evaluator should consider the functional specification and the ST to 
determine that the TSF described in these documents is consistent to the 
operational user guidan ce. The evaluator has to ensure that the operational 
user guidance is complete to allow the secure use through the TSFI available 
to all types of human users. The evaluator may, as an aid, prepare an 
informal mapping between the guidance and these document s. Any 
omissions in this mapping may indicate incompleteness. 
AGD_OPE.1.4C The operational user guidance shall, for each user role, clearly present 
each type of security-relevant event relative to the user-accessible functions 
that need to be performed, including changing the security characteristics 
of entities under the control of the TSF.  
AGD_OPE.1-4 The evaluator shall examine the operational user guidance to de termine that 
it describes, for each user role, each type of security -relevant event relative 
to the user functions that need to be performed, including changing the 
Class AGD: Guidance documents 
Page 208 of 430 Version 3.1 April 2017 
security characteristics of entities under the control of the TSF and operation 
following failure or operational error. 
958 All types of security-relevant events are detailed for each user role, such that 
each user knows what events may occur and what action (if any) he may 
have to take in order to maintain security. Security -relevant events that ma y 
occur during operation of the TOE (e.g. audit trail overflow, system crash, 
updates to user records, such as when a user account is removed when the 
user leaves the organisation) are adequately defined to allow user 
intervention to maintain secure operation. 
AGD_OPE.1.5C The operational user guidance shall identify all possible modes of 
operation of the TOE (including operation following failure or operational 
error), their consequences and implications for maintaining secure 
operation.  
AGD_OPE.1-5 The evaluator shall examine  the operational user guidance and other 
evaluation evidence to determine that the guidance identifies all possible 
modes of operation of the TOE (including, if applicable, operation following 
failure or operational error), their consequences and implications for 
maintaining secure operation. 
959 Other evaluation evidence, particularly the functional specification, provide 
an information source that  the evaluator should use to determine that the 
guidance contains sufficient guidance information. 
960 If test documentation is included in the assurance package, then the 
information provided in this evidence can also be used to determine that the 
guidance contains sufficient guidance documentation. The detail provided in 
the test steps can be used to confirm that the guidance provided is sufficient 
for the use and administration of the TOE. 
961 The evaluator should focus on a single human visible TSFI at a time, 
comparing the guidance for securely using the TSFI with other evaluation 
evidence, to determine that the guidance related to the TSFI is sufficient for 
the secure usage (i.e. consistent with the SFRs) of that TSFI. The evaluator 
should also consider the re lationships between interfaces, searching for 
potential conflicts. 
AGD_OPE.1.6C The operational user guidance shall, for each user role, describe the 
security measures to be followed in order to fulfil the security objectives for 
the operational environment as described in the ST.  
AGD_OPE.1-6 The evaluator shall examine the operational user guidance to determine that 
it describes, for each user role, the security me asures to be followed in order 
to fulfil the security objectives for the operational environment as described 
in the ST. 
962 The evaluator analyses the security objectives for the operational 
environment in the ST and determines that for each user role, the re levant 
security measures are described appropriately in the user guidance. 
Class AGD: Guidance documents 
April 2017 Version 3.1 Page 209 of 430 
963 The security measures described in the user guidance should include all 
relevant external procedural, physical, personnel and connectivity measures. 
964 Note that those measures relevan t for secure installation of the TOE are 
examined in Preparative procedures (AGD_PRE). 
AGD_OPE.1.7C The operational user guidance shall be clear and reasonable.  
AGD_OPE.1-7 The evaluator shall examine the operational user guidance to determine that 
it is clear. 
965 The guidance is unclear if it can reasonably be misconstrued by an 
administrator or user, and used in a way detrimental to the TOE, or to the 
security provided by the TOE. 
AGD_OPE.1-8 The evaluator shall examine the operational user guidance to determine that 
it is reasonable. 
966 The guidance is unreasonable if it makes demands on the TOE's usage or 
operational environment that are inconsistent with the ST or unduly onerous 
to maintain security. 
Class AGD: Guidance documents 
Page 210 of 430 Version 3.1 April 2017 
13.4 Preparative procedures (AGD_PRE) 
13.4.1 Evaluation of sub-activity (AGD_PRE.1) 
13.4.1.1 Objectives 
967 The objective of this sub-activity is to determine whether the procedures a nd 
steps for the secure preparation of the TOE have been documented and result 
in a secure configuration. 
13.4.1.2 Input 
968 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the TOE including its preparative procedures;  
c) the description of developer's delivery procedures, if applicable;  
13.4.1.3 Application notes 
969 The preparative procedures refer to all acceptance and installation procedures, 
that are necessary to progress the TOE to the secure configuration as 
described in the ST. 
13.4.1.4 Action AGD_PRE.1.1E 
AGD_PRE.1.1C The preparative procedures shall describe all the steps necessary for secure 
acceptance of the delivered TOE in accordance with the developer's 
delivery procedures.  
AGD_PRE.1-1 The evaluator shall examine  the provided acceptance procedures to 
determine that they describe the steps necessary for secure acceptance of the 
TOE in accordance with the developer's delivery procedures. 
970 If it is not anticipated by the developer's delivery procedures that acceptance 
procedures will or can be applied, this work unit is not applicable, and is 
therefore considered to be satisfied. 
971 The acceptance procedures should include as a minimum, that the user has to 
check that all parts of the TOE as indicated in the ST have been delivered in 
the correct version. 
972 The acceptance procedures should reflect the steps the user has to perform in 
order to accept the delivered TOE that are implied by the de veloper's 
delivery procedures. 
973 The acceptance procedures should provide detailed information about the 
following, if applicable:  
Class AGD: Guidance documents 
April 2017 Version 3.1 Page 211 of 430 
a) making sure that the delivered TOE is the complete evaluated 
instance;  
b) detecting modification/masquerading of the delivered TOE.  
AGD_PRE.1.2C The preparative procedures shall describe all the steps necessary for secure 
installation of the TOE and for the secure preparation of the operational 
environment in accordance with the secu rity objectives for the operational 
environment as described in the ST.  
AGD_PRE.1-2 The evaluator shall examine  the provided installation procedures to 
determine that they describe the steps necessary for secure  installation of the 
TOE and the secure preparation of the operational environment in 
accordance with the security objectives in the ST. 
974 If it is not anticipated that installation procedures will or can be applied (e.g. 
because the TOE may already be delivered in an operational state), this work 
unit is not applicable, and is therefore considered to be satisfied. 
975 The installation procedures should provide detailed information about the 
following, if applicable:  
a) minimum system requirements for secure installation;  
b) requirements for the operational environment in accordance with the 
security objectives provided by the ST;  
c) the steps the user has to perform in order to get to an operational TOE 
being commensurate with its evaluated configuration. Such a 
description shall include - for each step - a clear scheme for the 
decision on the next step depended on success, failure or problems at 
the current step;  
d) changing the installation specific security characteristics of entities 
under the control of the TSF (for example parameters, settings, 
passwords);  
e) handling exceptions and problems.  
13.4.1.5 Action AGD_PRE.1.2E 
AGD_PRE.1-3 The evaluator shall perform  all user procedures necessar y to prepare the 
TOE to determine that the TOE and its operational environment can be 
prepared securely using only the supplied preparative procedures. 
976 Preparation requires the evaluator to advance the TOE from a deliverable 
state to the state in which it is operational, including acceptance and 
installation of the TOE, and enforcing the SFRs consistent with the security 
objectives for the TOE specified in the ST. 
977 The evaluator should follow only the developer's procedures and may 
perform the activities tha t customers are usually expected to perform to 
Class AGD: Guidance documents 
Page 212 of 430 Version 3.1 April 2017 
accept and install the TOE, using the supplied preparative procedures only. 
Any difficulties encountered during such an exercise may be indicative of 
incomplete, unclear or unreasonable guidance. 
978 This work uni t may be performed in conjunction with the evaluation 
activities under Independent testing (ATE_IND). 
979 If it is known that the TOE will be used as a dependent component for a 
composed TOE evaluation, then the evaluator should ensure that the 
operational environment is satisfied by the base component used in the 
composed TOE. 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 213 of 430 
14 Class ALC: Life-cycle support 
14.1 Introduction 
980 The purpose of the life-cycle support activity is to determine the adequacy of 
the security procedures that the developer u ses during the development and 
maintenance of the TOE. These procedures include the life -cycle model used 
by the developer, the configuration management, the security measures used 
throughout TOE development, the tools used by the developer throughout 
the life-cycle of the TOE, the handling of security flaws, and the delivery 
activity. 
981 Poorly controlled development and maintenance of the TOE can result in 
vulnerabilities in the implementation. Conformance to a defined life -cycle 
model can help to improve co ntrols in this area. A measurable life -cycle 
model used for the TOE can remove ambiguity in assessing the development 
progress of the TOE. 
982 The purpose of the configuration management activity is to assist the 
consumer in identifying the evaluated TOE, to e nsure that configuration 
items are uniquely identified, and the adequacy of the procedures that are 
used by the developer to control and track changes that are made to the TOE. 
This includes details on what changes are tracked, how potential changes are 
incorporated, and the degree to which automation is used to reduce the scope 
for error. 
983 Developer security procedures are intended to protect the TOE and its 
associated design information from interference or disclosure. Interference in 
the development proce ss may allow the deliberate introduction of 
vulnerabilities. Disclosure of design information may allow vulnerabilities to 
be more easily exploited. The adequacy of the procedures will depend on the 
nature of the TOE and the development process. 
984 The use of  well-defined development tools and the application of 
implementation standards by the developer and by third parties involved in 
the development process help to ensure that vulnerabilities are not 
inadvertently introduced during refinement. 
985 The flaw remed iation activity is intended to track security flaws, to identify 
corrective actions, and to distribute the corrective action information to TOE 
users. 
986 The purpose of the delivery activity is to judge the adequacy of the 
documentation of the procedures used  to ensure that the TOE is delivered to 
the consumer without modification. 
Class ALC: Life-cycle support 
Page 214 of 430 Version 3.1 April 2017 
14.2 CM capabilities (ALC_CMC) 
14.2.1 Evaluation of sub-activity (ALC_CMC.1) 
14.2.1.1 Objectives 
987 The objectives of this sub -activity are to determine whether the developer 
has clearly identified the TOE. 
14.2.1.2 Input 
988 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the TOE suitable for testing.  
14.2.1.3 Action ALC_CMC.1.1E 
ALC_CMC.1.1C The TOE shall be labelled with its unique reference.  
ALC_CMC.1-1 The evaluator shall check that the TOE provided for evaluation is labelled 
with its reference. 
989 The evaluator should ensure that the TOE contains the unique reference 
which is stated in the ST. This could be achieved through labelled packaging 
or media, or by a label displayed by the operational TOE. This is to ensure 
that it would be possible for consumers to identify the TOE (e.g. at the point 
of purchase or use). 
990 The TOE may provide a method by which it can be easily identified. For 
example, a software TOE may display its name and version number during 
the start up routine, or in response to a command line entry. A hardware or 
firmware TOE may be identified by a part number ph ysically stamped on the 
TOE. 
991 Alternatively, the unique reference provided for the TOE may be the 
combination of the unique reference of each component from which the TOE 
is comprised (e.g. in the case of a composed TOE). 
ALC_CMC.1-2 The evaluator shall check that the TOE references used are consistent. 
992 If the TOE is labelled more than once then the labels have to be consistent. 
For example, it should be possible to relate any labelled guidance 
documentation supplied as part of the TOE to the evaluated operational TOE. 
This ensures that consumers can be confident that they have purchased the 
evaluated version of the TOE, that they have installed this version, and that 
they have the correct version of the guidance to  operate the TOE in 
accordance with its ST. 
993 The evaluator also verifies that the TOE reference is consistent with the ST. 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 215 of 430 
994 If this work unit is applied to a composed TOE, the following will apply. The 
composed IT TOE will not be labelled with its unique (co mposite) reference, 
but only the individual components will be labelled with their appropriate 
TOE reference. It would require further development for the IT TOE to be 
labelled, i.e. during start -up and/or operation, with the composite reference. 
If the co mposed TOE is delivered as the constituent component TOEs, then 
the TOE items delivered will not contain the composite reference. However, 
the composed TOE ST will include the unique reference for the composed 
TOE and will identify the components comprisin g the composed TOE 
through which the consumers will be able to determine whether they have 
the appropriate items. 
14.2.2 Evaluation of sub-activity (ALC_CMC.2) 
14.2.2.1 Objectives 
995 The objectives of this sub -activity are to determine whether the developer 
uses a CM system that uniquely identifies all configuration items. 
14.2.2.2 Input 
996 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the TOE suitable for testing;  
c) the configuration management documentation.  
14.2.2.3 Application notes 
997 This component contains an implicit evaluator action to determine that the 
CM system is being used. As the requirements here are limited to 
identification of the TOE and provision of a configuration list, this action is 
already covered by, and limited to, the existing work units. At Evaluation of 
sub-activity (ALC_CMC.3) the requirements are expanded beyond these two 
items, and more explicit evidence of operation is required. 
14.2.2.4 Action ALC_CMC.2.1E 
ALC_CMC.2.1C The TOE shall be labelled with its unique reference.  
ALC_CMC.2-1 The evaluator shall check that the TOE provided for evaluation is labelled 
with its reference. 
998 The evaluator should ensure tha t the TOE contains the unique reference 
which is stated in the ST. This could be achieved through labelled packaging 
or media, or by a label displayed by the operational TOE. This is to ensure 
that it would be possible for consumers to identify the TOE (e. g. at the point 
of purchase or use). 
Class ALC: Life-cycle support 
Page 216 of 430 Version 3.1 April 2017 
999 The TOE may provide a method by which it can be easily identified. For 
example, a software TOE may display its name and version number during 
the start up routine, or in response to a command line entry. A hardware or 
firmware TOE may be identified by a part number physically stamped on the 
TOE. 
1000 Alternatively, the unique reference provided for the TOE may be the 
combination of the unique reference of each component from which the TOE 
is comprised (e.g. in the case of a composed TOE). 
ALC_CMC.2-2 The evaluator shall check that the TOE references used are consistent. 
1001 If the TOE is labelled more than once then the labels have to be consistent. 
For example, it should be possible to relate any labelled guidance 
documentation supplied as part of the TOE to the evaluated operational TOE. 
This ensures that consumers can be confident that they have purchased the 
evaluated version of the TOE, that they have installed this version, and that  
they have the correct version of the guidance to operate the TOE in 
accordance with its ST. 
1002 The evaluator also verifies that the TOE reference is consistent with the ST. 
1003 If this work unit is applied to a composed TOE, the following will apply. The 
composed IT TOE will not be labelled with its unique (composite) reference, 
but only the individual components will be labelled with their appropriate 
TOE reference. It would require further development for the IT TOE to be 
labelled, i.e. during start -up and/or o peration, with the composite reference. 
If the composed TOE is delivered as the constituent component TOEs, then 
the TOE items delivered will not contain the composite reference. However, 
the composed TOE ST will include the unique reference for the compos ed 
TOE and will identify the components comprising the composed TOE 
through which the consumers will be able to determine whether they have 
the appropriate items. 
ALC_CMC.2.2C The CM documentation shall describe the method used to uniquely identify 
the configuration items.  
ALC_CMC.2-3 The evaluator shall examine  the method of identifying configuration items 
to determine that it describes how configuration items are uniquely identified. 
1004 Procedures should describe how the status of each configuration item can be 
tracked throughout the life -cycle of the TOE. The procedures may be 
detailed in the CM plan or throughout the CM documentation. The 
information included should describe:  
a) the method how each configuration item is uniquely identified, such 
that it is possible to track versions of the same configuration item; 
b) the method how configuration items are assigned unique identifiers 
and how they are entered into the CM system; 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 217 of 430 
c) the method to be used to identify superseded versions of a 
configuration item. 
ALC_CMC.2.3C The CM system shall uniquely identify all configuration items.  
ALC_CMC.2-4 The evaluator shall examine the configuration items to determine that they 
are identified in a way that is consistent with the CM documentation. 
1005 Assurance that the CM system uniquely identifies all configuration items is 
gained by examining the i dentifiers for the configuration items. For both 
configuration items that comprise the TOE, and drafts of configuration items 
that are submitted by the developer as evaluation evidence, the evaluator 
confirms that each configuration item possesses a unique  identifier in a 
manner consistent with the unique identification method that is described in 
the CM documentation. 
14.2.3 Evaluation of sub-activity (ALC_CMC.3) 
14.2.3.1 Objectives 
1006 The objectives of this sub -activity are to determine whether the developer 
uses a CM syste m that uniquely identifies all configuration items, and 
whether the ability to modify these items is properly controlled. 
14.2.3.2 Input 
1007 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the TOE suitable for testing;  
c) the configuration management documentation.  
14.2.3.3 Action ALC_CMC.3.1E 
ALC_CMC.3.1C The TOE shall be labelled with its unique reference.  
ALC_CMC.3-1 The evaluator shall check that the TOE provided for evaluation is labelled 
with its reference. 
1008 The evaluator should ensure that the TOE contains the unique reference 
which is stated in the ST. This could be achieved through labelled packaging 
or media, or by a label displayed by the operational TOE. This is to ensure 
that it would be possible for consumers to identify the TOE (e.g. at the point 
of purchase or use). 
1009 The TOE may provide a method by which it can be easily identified. For 
example, a software TOE may displ ay its name and version number during 
the start up routine, or in response to a command line entry. A hardware or 
firmware TOE may be identified by a part number physically stamped on the 
TOE. 
Class ALC: Life-cycle support 
Page 218 of 430 Version 3.1 April 2017 
1010 Alternatively, the unique reference provided for the TOE may be  the 
combination of the unique reference of each component from which the TOE 
is comprised (e.g. in the case of a composed TOE). 
ALC_CMC.3-2 The evaluator shall check that the TOE references used are consistent. 
1011 If the TOE is labelled more than once then the labels have to be consistent. 
For example, it should be possible to relate any labelled guidance 
documentation supplied as part of the TOE to the evaluated operational TOE. 
This ensures that consumers can be c onfident that they have purchased the 
evaluated version of the TOE, that they have installed this version, and that 
they have the correct version of the guidance to operate the TOE in 
accordance with its ST. 
1012 The evaluator also verifies that the TOE reference is consistent with the ST. 
1013 If this work unit is applied to a composed TOE, the following will apply. The 
composed IT TOE will not be labelled with its unique (composite) reference, 
but only the individual components will be labelled with their appropria te 
TOE reference. It would require further development for the IT TOE to be 
labelled, i.e. during start -up and/or operation, with the composite reference. 
If the composed TOE is delivered as the constituent component TOEs, then 
the TOE items delivered will  not contain the composite reference. However, 
the composed TOE ST will include the unique reference for the composed 
TOE and will identify the components comprising the composed TOE 
through which the consumers will be able to determine whether they have 
the appropriate items. 
ALC_CMC.3.2C The CM documentation shall describe the method used to uniquely identify 
the configuration items.  
ALC_CMC.3-3 The evaluator shall examine the method of identifying configuration items 
to determine that it describes how configuration items are uniquely identified.  
1014 Procedures should describe how the status of each configuration item can be 
tracked throughout the life -cycle of the TOE . The procedures may be 
detailed in the CM plan or throughout the CM documentation. The 
information included should describe:  
a) the method how each configuration item is uniquely identified, such 
that it is possible to track versions of the same configuration item; 
b) the method how configuration items are assigned unique identifiers 
and how they are entered into the CM system; 
c) the method to be used to identify superseded versions of a 
configuration item. 
ALC_CMC.3.3C The CM system shall uniquely identify all configuration items.  
ALC_CMC.3-4 The evaluator shall examine the configuration items to determine that they 
are identified in a way that is consistent with the CM documentation. 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 219 of 430 
1015 Assurance that the CM system uniquely identifies all configuration items is 
gained by examining the identifiers for the configuration items. For both 
configuration items that comprise the TOE, and drafts of configuration items 
that are submit ted by the developer as evaluation evidence, the evaluator 
confirms that each configuration item possesses a unique identifier in a 
manner consistent with the unique identification method that is described in 
the CM documentation. 
ALC_CMC.3.4C The CM system shall provide measures such that only authorised changes 
are made to the configuration items.  
ALC_CMC.3-5 The evaluator shall examine  the CM access control measu res described in 
the CM plan to determine that they are effective in preventing unauthorised 
access to the configuration items. 
1016 The evaluator may use a number of methods to determine that the CM access 
control measures are effective. For example, the evalu ator may exercise the 
access control measures to ensure that the procedures could not be bypassed. 
The evaluator may use the outputs generated by the CM system procedures 
required by ALC_CMC.3.8C. The evaluator may also witness a 
demonstration of the CM system to ensure that the access control measures 
employed are operating effectively. 
ALC_CMC.3.5C The CM documentation shall include a CM plan.  
ALC_CMC.3-6 The evaluator shall check  that the CM documentation provided includes a 
CM plan. 
1017 The CM plan needs not to be a connected document, but it is recommended 
that there is a single document that describes where the various parts of the 
CM plan can be found. If the CM plan is no single document, the list in the 
following work unit gives hints regarding which context is expected. 
ALC_CMC.3.6C The CM plan shall describe how the CM system is used for th e 
development of the TOE.  
ALC_CMC.3-7 The evaluator shall examine the CM plan to determine that it describes how 
the CM system is used for the development of the TOE. 
1018 The descriptions contained in a CM plan include, if applicable:  
a) all activities performed in the TOE development that are subject to 
configuration management procedures (e.g. creation, modification or 
deletion of a configuration item, data-backup, archiving);  
b) which means (e.g. CM tools, forms) have to be made available;  
c) the usage of the CM tools: the necessary details for a user of the CM 
system to be able to operate the CM tools correctly in order to 
maintain the integrity of the TOE;  
Class ALC: Life-cycle support 
Page 220 of 430 Version 3.1 April 2017 
d) which other objects (development components, tools, assessment  
environments, etc) are taken under CM control;  
e) the roles and responsibilities of individuals required to perform 
operations on individual configuration items (different roles may be 
identified for different types of configuration items (e.g. design 
documentation or source code));  
f) how CM instances (e.g. change control boards, interface control 
working groups) are introduced and staffed;  
g) the description of the change management;  
h) the procedures that are used to ensure that only authorised individuals 
can make changes to configuration items;  
i) the procedures that are used to ensure that concurrency problems do 
not occur as a result of simultaneous changes to configuration items;  
j) the evidence that is generated as a result of application of the 
procedures. Fo r example, for a change to a configuration item, the 
CM system might record a description of the change, accountability 
for the change, identification of all configuration items affected, 
status (e.g. pending or completed), and date and time of the change.  
This might be recorded in an audit trail of changes made or change 
control records;  
k) the approach to version control and unique referencing of TOE 
versions (e.g. covering the release of patches in operating systems, 
and the subsequent detection of their application).  
ALC_CMC.3.7C The evidence shall demonstrate that all configuration items are being 
maintained under the CM system.  
ALC_CMC.3-8 The evaluator shall ch eck that the configuration items identified in the 
configuration list are being maintained by the CM system. 
1019 The CM system employed by the developer should maintain the integrity of 
the TOE. The evaluator should check that for each type of configuration it em 
(e.g. design documents or source code modules) contained in the 
configuration list there are examples of the evidence generated by the 
procedures described in the CM plan. In this case, the approach to sampling 
will depend upon the level of granularity used in the CM system to control 
CM items. Where, for example, 10,000 source code modules are identified in 
the configuration list, a different sampling strategy needs to be applied 
compared to the case in which there are only 5, or even 1. The emphasis of  
this activity should be on ensuring that the CM system is being operated 
correctly, rather than on the detection of any minor error. 
1020 For guidance on sampling see A.2, Sampling. 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 221 of 430 
ALC_CMC.3.8C The evidence shall demonstrate that the CM system is being operated in 
accordance with the CM plan.  
ALC_CMC.3-9 The evaluator shall check the CM documentation to ascertain that it includes 
the CM system records identified by the CM plan. 
1021 The output produced by the CM system should provide the evidence that the 
evaluator needs to be confident that the CM plan is being applied, and also 
that all configuration i tems are being maintained by the CM system as 
required by ALC_CMC.3.7C. Example output could include change control 
forms, or configuration item access approval forms. 
ALC_CMC.3-10 The evaluator shall examine the evidence to determine that the CM system 
is being operated in accordance with the CM plan. 
1022 The evaluator should select and examine a sample of evidence covering each 
type of CM -relevant operation that has been performed on a con figuration 
item (e.g. creation, modification, deletion, reversion to an earlier version) to 
confirm that all operations of the CM system have been carried out in line 
with documented procedures. The evaluator confirms that the evidence 
includes all the inf ormation identified for that operation in the CM plan. 
Examination of the evidence may require access to a CM tool that is used. 
The evaluator may choose to sample the evidence. 
1023 For guidance on sampling see A.2, Sampling. 
1024 Further confidence in the correct operation of the CM system and the 
effective maintenance of configuration items may be established by means of 
interviews with selected development staff. In conducting such interviews , 
the evaluator aims to gain a deeper understanding of how the CM system is 
used in practise as well as to confirm that the CM procedures are being 
applied as described in the CM documentation. Note that such interviews 
should complement rather than replac e the examination of documentary 
evidence, and may not be necessary if the documentary evidence alone 
satisfies the requirement. However, given the wide scope of the CM plan it is 
possible that some aspects (e.g. roles and responsibilities) may not be clea r 
from the CM plan and records alone. This is one case where clarification 
may be necessary through interviews. 
1025 It is expected that the evaluator will visit the development site in support of 
this activity. 
1026 For guidance on site visits see A.4, Site Visits. 
14.2.4 Evaluation of sub-activity (ALC_CMC.4) 
14.2.4.1 Objectives 
1027 The objectives of this sub -activity are to determine whether the developer 
has clearly identified the TOE and its associated co nfiguration items, and 
whether the ability to modify these items is properly controlled by automated 
Class ALC: Life-cycle support 
Page 222 of 430 Version 3.1 April 2017 
tools, thus making the CM system less susceptible to human error or 
negligence. 
14.2.4.2 Input 
1028 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the TOE suitable for testing;  
c) the configuration management documentation.  
14.2.4.3 Action ALC_CMC.4.1E 
ALC_CMC.4.1C The TOE shall be labelled with its unique reference.  
ALC_CMC.4-1 The evaluator shall check that the TOE provided for evaluation is labelled 
with its reference. 
1029 The evaluator should ensure that the TOE contains the unique reference 
which is stated in the ST. This could be a chieved through labelled packaging 
or media, or by a label displayed by the operational TOE. This is to ensure 
that it would be possible for consumers to identify the TOE (e.g. at the point 
of purchase or use). 
1030 The TOE may provide a method by which it can be easily identified. For 
example, a software TOE may display its name and version number during 
the start up routine, or in response to a command line entry. A hardware or 
firmware TOE may be identified by a part number physically stamped on the 
TOE. 
1031 Alternatively, the unique reference provided for the TOE may be the 
combination of the unique reference of each component from which the TOE 
is comprised (e.g. in the case of a composed TOE). 
ALC_CMC.4-2 The evaluator shall check that the TOE references used are consistent. 
1032 If the TOE is labelled more than once then the labels have to be consistent. 
For example, it should be possible to relate any labelled guidance 
documentation supplied as part of the TOE to the evaluated operational TOE. 
This ensures that consumers can be confident that they have purchased the 
evaluated version of the TOE, that they have installed this version, and that 
they have the correct version of the guidance to operate the TOE in 
accordance with its ST. 
1033 The evaluator also verifies that the TOE reference is consistent with the ST. 
1034 If this work unit is applied to a composed TOE, the following will apply. The 
composed TOE will not be labelled with its unique (composite) reference, 
but only the ind ividual components will be labelled with their appropriate 
TOE reference. It would require further development for the composed TOE 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 223 of 430 
to be labelled, i.e. during start -up and/or operation, with the composite 
reference. If the composed TOE is delivered as the  constituent component 
TOEs, then the TOE items delivered will not contain the composite reference. 
However, the composed TOE ST will include the unique reference for the 
composed TOE and will identify the components comprising the composed 
TOE through whi ch the consumers will be able to determine whether they 
have the appropriate items. 
ALC_CMC.4.2C The CM documentation shall describe the method used to uniquely identify 
the configuration items.  
ALC_CMC.4-3 The evaluator shall examine  the method of identifying configuration items 
to determine that it describes how configuration items are uniquely identified.  
1035 Procedures should describe how the status of each configur ation item can be 
tracked throughout the life -cycle of the TOE. The procedures may be 
detailed in the CM plan or throughout the CM documentation. The 
information included should describe:  
a) the method how each configuration item is uniquely identified, such  
that it is possible to track versions of the same configuration item; 
b) the method how configuration items are assigned unique identifiers 
and how they are entered into the CM system; 
c) the method to be used to identify superseded versions of a 
configuration item. 
ALC_CMC.4.3C The CM system shall uniquely identify all configuration items.  
ALC_CMC.4-4 The evaluator shall examine the configuration items to determine that  they 
are identified in a way that is consistent with the CM documentation. 
1036 Assurance that the CM system uniquely identifies all configuration items is 
gained by examining the identifiers for the configuration items. For 
configuration items identified unde r ALC_CMS, the evaluator confirms that 
each configuration item possesses a unique identifier in a manner consistent 
with the unique identification method that is described in the CM 
documentation. 
ALC_CMC.4.4C The CM system shall provide automated measures such that only 
authorised changes are made to the configuration items.  
ALC_CMC.4-5 The evaluator shall examine  the CM access contro l measures described in 
the CM plan (cf. ALC_CMC.4.6C) to determine that they are automated and 
effective in preventing unauthorised access to the configuration items. 
1037 The evaluator may use a number of methods to determine that the CM access 
control measures are effective. For example, the evaluator may exercise the 
access control measures to ensure that the procedures could not be bypassed. 
The evaluator may use the outputs generated by the CM system procedures 
required by ALC_CMC.4.10C. The evaluator may also witness a 
Class ALC: Life-cycle support 
Page 224 of 430 Version 3.1 April 2017 
demonstration of the CM system to ensure that the access control measures 
employed are operating effectively. 
ALC_CMC.4.5C The CM system shall s upport the production of the TOE by automated 
means.  
ALC_CMC.4-6 The evaluator shall check the CM plan (cf. ALC_CMC.4.6C) for automated 
procedures for supporting the production of the TOE. 
1038 The term “production” applies to those processes adopted by the developer to 
progress the TOE from the implementation representation to a state 
acceptable for delivery to the end customer. 
1039 The evaluator verifies the existence of automated production supp ort 
procedures within the CM plan. 
1040 The following are examples for automated means supporting the production 
of the TOE:  
 a “make” tool (as provided with many software development tools) in 
the case of a software TOE;  
 a tool ensuring automatically (for exa mple by means of bar codes) 
that only parts are combined which indeed belong together in the case 
of a hardware TOE.  
ALC_CMC.4-7 The evaluator shall examine  the TOE production support procedures to 
determine tha t they are effective in ensuring that a TOE is generated that 
reflects its implementation representation. 
1041 The production support procedures should describe which tools have to be 
used to produce the final TOE from the implementation representation in a 
clearly defined way. The conventions, directives, or other necessary 
constructs are described under ALC_TAT. 
1042 The evaluator determines that by following the production support 
procedures the correct configuration items would be u sed to generate the 
TOE. For example, in a software TOE this may include checking that the 
automated production procedures ensure that all source files and related 
libraries are included in the compiled object code. Moreover, the procedures 
should ensure t hat compiler options and comparable other options are 
defined uniquely. For a hardware TOE, this work unit may include checking 
that the automatic production procedures ensure that the belonging parts are 
built together and no parts are missing. 
1043 The customer can then be confident that the version of the TOE delivered for 
installation is derived from the implementation representation in an 
unambiguous way and implements the SFRs as described in the ST. 
1044 The evaluator should bear in mind that the CM system nee d not necessarily 
possess the capability to produce the TOE, but should provide support for the 
process that will help reduce the probability of human error. 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 225 of 430 
ALC_CMC.4.6C The CM documentation shall include a CM plan.  
ALC_CMC.4-8 The evaluator shall check  that the CM documentation provided includes a 
CM plan. 
1045 The CM plan does not need to be contained within a single document, but it 
is recommended that there is a sep arate document that describes where the 
various parts of the CM plan can be found. If the CM plan is provided by a 
set of documents, the list in the following work unit gives guidance 
regarding the required content. 
ALC_CMC.4.7C The CM plan shall describe how the CM system is used for the 
development of the TOE.  
ALC_CMC.4-9 The evaluator shall examine the CM plan to determine that it describes how 
the CM system is used for the development of the TOE. 
1046 The descriptions contained in a CM plan include, if applicable:  
a) all activities performed in the TOE development that are subject to 
configuration management procedures (e.g. creation, modification or 
deletion of a configuration item, data-backup, archiving);  
b) which means (e.g. CM tools, forms) have to be made available;  
c) the usage of the CM tools: the necessary details for a user of the CM 
system to be able to operate the CM tools correctly in order to 
maintain the integrity of the TOE;  
d) the production support procedures;  
e) which other objects (development components, tools, assessment 
environments, etc) are taken under CM control;  
f) the roles and responsibilities of individuals required to perform 
operations on individual configuration items (different roles may be 
identified for different types of configuration items (e.g. design 
documentation or source code));  
g) how CM instances (e.g. change control boards, interface control 
working groups) are introduced and staffed;  
h) the description of the change management;  
i) the procedures that are used to ensure that only authorised individuals 
can make changes to configuration items;  
j) the procedures that are used to ensure that concurrency problems do 
not occur as a result of simultaneous changes to configuration items;  
k) the evidence that is generated as a result of application of the 
procedures. For example, for a change to a configuration item, the 
Class ALC: Life-cycle support 
Page 226 of 430 Version 3.1 April 2017 
CM system might record a description of the change, accountability 
for the change, iden tification of all configuration items affected, 
status (e.g. pending or completed), and date and time of the change. 
This might be recorded in an audit trail of changes made or change 
control records;  
l) the approach to version control and unique referencing  of TOE 
versions (e.g. covering the release of patches in operating systems, 
and the subsequent detection of their application).  
ALC_CMC.4.8C The CM plan shall describe the procedures used to accept modified  or 
newly created configuration items as part of the TOE.  
ALC_CMC.4-10 The evaluator shall examine the CM plan to determine that it describes the 
procedures used to accept modified or newly created configurat ion items as 
parts of the TOE. 
1047 The descriptions of the acceptance procedures in the CM plan should include 
the developer roles or individuals responsible for the acceptance and the 
criteria to be used for acceptance. They should take into account all 
acceptance situations that may occur, in particular:  
a) accepting an item into the CM system for the first time, in particular 
inclusion of software, firmware and hardware components from other 
manufacturers into the TOE (“integration”);  
b) moving configuration items to the next life -cycle phase at each stage 
of the construction of the TOE (e.g. module, subsystem, system);  
c) subsequent to transports between different development sites.  
1048 If this work unit is applied to a dependent component that is going to be 
integrated in a composed TOE, the CM plan should consider the control of 
base components obtained by the dependent TOE developer. 
1049 When obtaining the components the evaluators are to verify the following:  
a) Transfer of each base component from the base component de veloper 
to the integrator (dependent TOE developer) was performed in 
accordance with the base component TOE's secure delivery 
procedures, as reported in the base component TOE certification 
report.  
b) The component received has the same identifiers as those stated in 
the ST and Certification Report for the component TOE.  
c) All additional material required by a developer for composition 
(integration) is provided. This is to include the necessary extract of 
the component TOE's functional specification.  
ALC_CMC.4.9C The evidence shall demonstrate that all configuration items are being 
maintained under the CM system.  
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 227 of 430 
ALC_CMC.4-11 The evaluator shall check  that the confi guration items identified in the 
configuration list are being maintained by the CM system. 
1050 The CM system employed by the developer should maintain the integrity of 
the TOE. The evaluator should check that for each type of configuration item 
(e.g. design do cuments or source code modules) contained in the 
configuration list there are examples of the evidence generated by the 
procedures described in the CM plan. In this case, the approach to sampling 
will depend upon the level of granularity used in the CM sys tem to control 
CM items. Where, for example, 10,000 source code modules are identified in 
the configuration list, a different sampling strategy needs to be applied 
compared to the case in which there are only 5, or even 1. The emphasis of 
this activity sho uld be on ensuring that the CM system is being operated 
correctly, rather than on the detection of any minor error. 
1051 For guidance on sampling see A.2, Sampling. 
ALC_CMC.4.10C The evidence shall demonstrate that the CM system is being operated in 
accordance with the CM plan.  
ALC_CMC.4-12 The evaluator shall check the CM documentation to ascertain that it includes 
the CM system records identified by the CM plan. 
1052 The output produced by the CM system should provide the evidence that the 
evaluator needs to be confident that the CM plan is being applied, and also 
that all configuration items are b eing maintained by the CM system as 
required by ALC_CMC.4.9C. Example output could include change control 
forms, or configuration item access approval forms. 
ALC_CMC.4-13 The evaluator shall examine the evidence to determine that the CM system 
is being operated in accordance with the CM plan. 
1053 The evaluator should select and examine a sample of evidence covering each 
type of CM -relevant operation that has been performed on a configuration  
item (e.g. creation, modification, deletion, reversion to an earlier version) to 
confirm that all operations of the CM system have been carried out in line 
with documented procedures. The evaluator confirms that the evidence 
includes all the information i dentified for that operation in the CM plan. 
Examination of the evidence may require access to a CM tool that is used. 
The evaluator may choose to sample the evidence. 
1054 For guidance on sampling see A.2, Sampling. 
1055 Further confidence in the correct operation of the CM system and the 
effective maintenance of configuration items may be established by means of 
interviews with selected development staff. In conducting such interviews, 
the evaluator aims to gain a deeper understanding of how the CM system is 
used in practise as well as to confirm that the CM procedures are being 
applied as described in the CM documentation. Note that such interviews 
should complement rather than replace the exam ination of documentary 
evidence, and may not be necessary if the documentary evidence alone 
Class ALC: Life-cycle support 
Page 228 of 430 Version 3.1 April 2017 
satisfies the requirement. However, given the wide scope of the CM plan it is 
possible that some aspects (e.g. roles and responsibilities) may not be clear 
from the  CM plan and records alone. This is one case where clarification 
may be necessary through interviews. 
1056 It is expected that the evaluator will visit the development site in support of 
this activity. 
1057 For guidance on site visits see A.4, Site Visits. 
14.2.5 Evaluation of sub-activity (ALC_CMC.5) 
14.2.5.1 Objectives 
1058 The objectives of this sub -activity are to determine whether the developer 
has clearly identified the TOE and its associated configuratio n items, and 
whether the ability to modify these items is properly controlled by automated 
tools, thus making the CM system less susceptible to human error or 
negligence. 
14.2.5.2 Input 
1059 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the TOE suitable for testing;  
c) the configuration management documentation.  
14.2.5.3 Action ALC_CMC.5.1E 
ALC_CMC.5.1C The TOE shall be labelled with its unique reference.  
ALC_CMC.5-1 The evaluator shall check that the TOE provided for evaluation is labelled 
with its reference. 
1060 The evaluator should ensure that the TOE contains the unique reference 
which is stated in the ST. This could be achieved th rough labelled packaging 
or media, or by a label displayed by the operational TOE. This is to ensure 
that it would be possible for consumers to identify the TOE (e.g. at the point 
of purchase or use). 
1061 The TOE may provide a method by which it can be easily identified. For 
example, a software TOE may display its name and version number during 
the start up routine, or in response to a command line entry. A hardware or 
firmware TOE may be identified by a part number physically stamped on the 
TOE. 
1062 Alternatively, the unique reference provided for the TOE may be the 
combination of the unique reference of each component from which the TOE 
is comprised (e.g. in the case of a composed TOE). 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 229 of 430 
ALC_CMC.5-2 The evaluator shall check that the TOE references used are consistent. 
1063 If the TOE is labelled more than once then the labels have to be consistent. 
For example, it should be possible to relate any labelled guidance 
documentation supplied as part of the TOE to the evaluated operational TOE. 
This ensures that consumers can be confident that they have purchased the 
evaluated version of the TOE, that they have installed this version, and that 
they have the correct version of the guidance to operate the TOE in 
accordance with its ST. 
1064 The evaluator also verifies that the TOE reference is consistent with the ST. 
1065 If this work unit is applied to a composed TOE, the following will apply. The 
composed IT TOE will not be labelled with its unique (composite) reference, 
but only the individual  components will be labelled with their appropriate 
TOE reference. It would require further development for the IT TOE to be 
labelled, i.e. during start -up and/or operation, with the composite reference. 
If the composed TOE is delivered as the constituent component TOEs, then 
the TOE items delivered will not contain the composite reference. However, 
the composed TOE ST will include the unique reference for the composed 
TOE and will identify the components comprising the composed TOE 
through which the consum ers will be able to determine whether they have 
the appropriate items. 
ALC_CMC.5.2C The CM documentation shall describe the method used to uniquely identify 
the configuration items.  
ALC_CMC.5-3 The evaluator shall examine  the method of identifying configuration items 
to determine that it describes how configuration items are uniquely identified.  
1066 Procedures should describe how the status of each configuration item ca n be 
tracked throughout the life -cycle of the TOE. The procedures may be 
detailed in the CM plan or throughout the CM documentation. The 
information included should describe:  
a) the method how each configuration item is uniquely identified, such 
that it is possible to track versions of the same configuration item; 
b) the method how configuration items are assigned unique identifiers 
and how they are entered into the CM system; 
c) the method to be used to identify superseded versions of a 
configuration item. 
ALC_CMC.5.3C The CM documentation shall justify that the acceptance procedures 
provide for an adequate and appropriate review of changes to all 
configuration items.  
ALC_CMC.5-4 The evaluator shall examine  the CM documentation to determine that it 
justifies that the acceptance procedures provide for an adequate and 
appropriate review of changes to all configuration items. 
Class ALC: Life-cycle support 
Page 230 of 430 Version 3.1 April 2017 
1067 The CM documentation should make it sufficiently cle ar that by following 
the acceptance procedures only parts of adequate quality are incorporated 
into the TOE. 
ALC_CMC.5.4C The CM system shall uniquely identify all configuration items.  
ALC_CMC.5-5 The evaluator shall examine the configuration items to determine that they 
are identified in a way that is consistent with the CM documentation. 
1068 Assurance that the CM system uniquely identifies all configuration items is 
gained by examining the identifiers for the configuration items. For both 
configuration items that comprise the TOE, and drafts of configuration items 
that are submitted by the developer as evaluation evidence, the evaluator 
confirms that each configuration  item possesses a unique identifier in a 
manner consistent with the unique identification method that is described in 
the CM documentation. 
ALC_CMC.5.5C The CM system shall provide automated measures such tha t only 
authorised changes are made to the configuration items.  
ALC_CMC.5-6 The evaluator shall examine  the CM access control measures described in 
the CM plan (cf. ALC_CMC.5.12C) to dete rmine that they are automated 
and effective in preventing unauthorised access to the configuration items. 
1069 The evaluator may use a number of methods to determine that the CM access 
control measures are effective. For example, the evaluator may exercise the 
access control measures to ensure that the procedures could not be bypassed. 
The evaluator may use the outputs generated by the CM system procedures 
required by ALC_CMC.5.16C. The evaluator may also witness a 
demonstration of the C M system to ensure that the access control measures 
employed are operating effectively. 
ALC_CMC.5.6C The CM system shall support the production of the TOE by automated 
means.  
ALC_CMC.5-7 The evaluator shall check  the CM plan (cf. ALC_CMC.5.12C) for 
automated procedures for supporting the production of the TOE. 
1070 The term “production” applies to those processes adopted by the developer to 
progress the TOE from the implementation representation to a state 
acceptable for delivery to the end customer. 
1071 The evaluator verifies the existence of automated production support 
procedures within the CM plan. 
1072 The following are examples for automated means su pporting the production 
of the TOE:  
 a “make” tool (as provided with many software development tools) in 
the case of a software TOE;  
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 231 of 430 
 a tool ensuring automatically (for example by means of bar codes) 
that only parts are combined which indeed belong together in the case 
of a hardware TOE.  
ALC_CMC.5-8 The evaluator shall examine  the TOE production support procedures to 
determine that they are effective in ensuring that a TOE is generated that 
reflects its implementation representation. 
1073 The production support procedures should describe which tools have to be 
used to produce the final TOE from the implementation representation in a 
clearly defined way. The conventions, directives, or other necessary 
constructs are described under ALC_TAT. 
1074 The evaluator determines that by following the production support 
procedures the correct configuration items would be used to generate the 
TOE. For example, in a software TOE this may include checking th at the 
automated production procedures ensure that all source files and related 
libraries are included in the compiled object code. Moreover, the procedures 
should ensure that compiler options and comparable other options are 
defined uniquely. For a hardwa re TOE, this work unit may include checking 
that the automatic production procedures ensure that the belonging parts are 
built together and no parts are missing. 
1075 The customer can then be confident that the version of the TOE delivered for 
installation is d erived from the implementation representation in an 
unambiguous way and implements the SFRs as described in the ST. 
1076 The evaluator should bear in mind that the CM system need not necessarily 
possess the capability to produce the TOE, but should provide support for the 
process that will help reduce the probability of human error. 
ALC_CMC.5.7C The CM system shall ensure that the person responsible for accepting a 
configuration item into CM is not the person who developed it.  
ALC_CMC.5-9 The evaluator shall examine the CM system to determine that it ensures that 
the person responsible for accepting a configuration item is not the person 
who developed it. 
1077 The acceptance p rocedures describe who is responsible for accepting a 
configuration item. From these descriptions, the evaluator should be able to 
determine that the person who developed a configuration item is in no case 
responsible for its acceptance. 
ALC_CMC.5.8C The CM system shall identify the configuration items that comprise the 
TSF.  
ALC_CMC.5-10 The evaluator shall examine  the CM system to determine that it identifies 
the configuration items that comprise the TSF. 
1078 The CM documentation should describe how the CM system identifies the 
configuration items that comprise the TSF. The evaluator should select a 
Class ALC: Life-cycle support 
Page 232 of 430 Version 3.1 April 2017 
sample of configuration items covering each type of items, particula rly 
containing TSF and non -TSF items, and check that they are correctly 
classified by the CM system. 
1079 For guidance on sampling see A.2, Sampling. 
ALC_CMC.5.9C The CM system shall support the audit of all changes to the TOE by 
automated means, including the originator, date, and time in the audit trail.  
ALC_CMC.5-11 The evaluator shall examine the CM system to determine that it supports the 
audit of all changes to the TOE by automated means, including the originator, 
date, and time in the audit trail. 
1080 The evaluator should inspect a sample of audit trails and check, if they 
contain the minimum information. 
ALC_CMC.5.10C The CM system shall provide an automated means to identify all other 
configuration items that are affected by the change of a given 
configuration item.  
ALC_CMC.5-12 The evaluator shall examine the CM system to determine that it provides an 
automated means to identify all other configuration items that are affected by 
the change of a given configuration item. 
1081 The CM documentation should  describe how the CM system identifies all 
other configuration items that are affected by the change of a given 
configuration item. The evaluator should select a sample of configuration 
items, covering all types of items, and exercise the automated means t o 
determine that it identifies all items that are affected by the change of the 
selected item. 
1082 For guidance on sampling see A.2, Sampling. 
ALC_CMC.5.11C The CM system shall be able to identify the version of the implementation 
representation from which the TOE is generated.  
ALC_CMC.5-13 The evaluator shall examine  the CM system to determin e that it is able to 
identify the version of the implementation representation from which the 
TOE is generated. 
1083 The CM documentation should describe how the CM system identifies the 
version of the implementation representation from which the TOE is 
generated. The evaluator should select a sample of the parts used to produce 
the TOE and should apply the CM system to verify that it identifies the 
corresponding implementation representation in the correct version. 
1084 For guidance on sampling see A.2, Sampling. 
ALC_CMC.5.12C The CM documentation shall include a CM plan.  
ALC_CMC.5-14 The evaluator shall check  that the CM documentation provided includes a 
CM plan. 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 233 of 430 
1085 The CM plan needs not to be a connected document, but it is recommended 
that there is a single document that describes where the various parts of the 
CM plan can be found. If the CM plan is  no single document, the list in the 
following work unit gives hints regarding which context is expected. 
ALC_CMC.5.13C The CM plan shall describe how the CM system is used for the 
development of the TOE.  
ALC_CMC.5-15 The evaluator shall examine the CM plan to determine that it describes how 
the CM system is used for the development of the TOE. 
1086 The descriptions contained in a CM plan include, if applicable:  
a) all activities performed in the TOE development that are subject to 
configuration management procedures (e.g. creation, modification or 
deletion of a configuration item, data-backup, archiving);  
b) which means (e.g. CM tools, forms) have to be made available;  
c) the usage of the CM tools: the necessary details for a user of the CM 
system to be able to operate the CM tools correctly in order to 
maintain the integrity of the TOE;  
d) the production support procedures;  
e) which other objects (development components, too ls, assessment 
environments, etc) are taken under CM control;  
f) the roles and responsibilities of individuals required to perform 
operations on individual configuration items (different roles may be 
identified for different types of configuration items (e.g . design 
documentation or source code));  
g) how CM instances (e.g. change control boards, interface control 
working groups) are introduced and staffed;  
h) the description of the change management;  
i) the procedures that are used to ensure that only authorised individuals 
can make changes to configuration items;  
j) the procedures that are used to ensure that concurrency problems do 
not occur as a result of simultaneous changes to configuration items;  
k) the evidence that is generated as a result of application of the 
procedures. For example, for a change to a configuration item, the 
CM system might record a description of the change, accountability 
for the change, identification of all configuration items affected, 
status (e.g. pending or completed), and date and time of the change. 
This might be recorded in an audit trail of changes made or change 
control records;  
Class ALC: Life-cycle support 
Page 234 of 430 Version 3.1 April 2017 
l) the approach to version control and unique referencing of TOE 
versions (e.g. covering the release of patches in operating systems, 
and the subsequent detection of their application).  
ALC_CMC.5.14C The CM plan shall describe the procedures used to accept modified or 
newly created configuration items as part of the TOE.  
ALC_CMC.5-16 The evaluator shall examine the CM plan to determine that it describes the 
procedures used to accept modified or newly created configuration items as 
parts of the TOE. 
1087 The descriptions of the acceptance procedures in the CM plan should  include 
the developer roles or individuals responsible for the acceptance and the 
criteria to be used for acceptance. They should take into account all 
acceptance situations that may occur, in particular:  
a) accepting an item into the CM system for the firs t time, in particular 
inclusion of software, firmware and hardware components from other 
manufacturers into the TOE (“integration”);  
b) moving configuration items to the next life -cycle phase at each stage 
of the construction of the TOE (e.g. module, subsystem, system);  
c) subsequent to transports between different development sites.  
ALC_CMC.5.15C The evidence shall demonstrate that all configuration items are being 
maintained under the CM system.  
ALC_CMC.5-17 The evaluator shall check  that the configuration items identified in the 
configuration list are being maintained by the CM system. 
1088 The CM system employed by the developer should maintain the integrity of 
the TOE. The evaluator should check that for each type of configuration item 
(e.g. design documents or source code modules) contained in the 
configuration list there are examples of the evidence generated by the 
procedures described in the CM plan. In this ca se, the approach to sampling 
will depend upon the level of granularity used in the CM system to control 
CM items. Where, for example, 10,000 source code modules are identified in 
the configuration list, a different sampling strategy needs to be applied 
compared to the case in which there are only 5, or even 1. The emphasis of 
this activity should be on ensuring that the CM system is being operated 
correctly, rather than on the detection of any minor error. 
1089 For guidance on sampling see A.2, Sampling. 
ALC_CMC.5.16C The evidence shall demonstrate that the CM system is being operated in 
accordance with the CM plan.  
ALC_CMC.5-18 The evaluator shall check the CM documentation to ascertain that it includes 
the CM system records identified by the CM plan. 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 235 of 430 
1090 The output produced by the CM system should provide the evidence that the 
evaluator needs to be  confident that the CM plan is being applied, and also 
that all configuration items are being maintained by the CM system as 
required by ALC_CMC.5.15C. Example output could include change control 
forms, or configuration item access approval forms. 
ALC_CMC.5-19 The evaluator shall examine the evidence to determine that the CM system 
is being operated in accordance with the CM plan. 
1091 The evaluator should select and examine a sample of evid ence covering each 
type of CM -relevant operation that has been performed on a configuration 
item (e.g. creation, modification, deletion, reversion to an earlier version) to 
confirm that all operations of the CM system have been carried out in line 
with doc umented procedures. The evaluator confirms that the evidence 
includes all the information identified for that operation in the CM plan. 
Examination of the evidence may require access to a CM tool that is used. 
The evaluator may choose to sample the evidence. 
1092 For guidance on sampling see A.2, Sampling. 
1093 Further confidence in the correct operation of the CM system and the 
effective maintenance of configuration items may be established by means of 
interviews with selected development staff. In conducting such interviews, 
the evaluator aims to gain a deeper understanding of how the CM system is 
used in practise as well as to confirm that the CM procedures are being 
applied as described in the  CM documentation. Note that such interviews 
should complement rather than replace the examination of documentary 
evidence, and may not be necessary if the documentary evidence alone 
satisfies the requirement. However, given the wide scope of the CM plan it is 
possible that some aspects (e.g. roles and responsibilities) may not be clear 
from the CM plan and records alone. This is one case where clarification 
may be necessary through interviews. 
1094 It is expected that the evaluator will visit the development si te in support of 
this activity. 
1095 For guidance on site visits see A.4, Site Visits. 
14.2.5.4 Action ALC_CMC.5.2E 
ALC_CMC.5-20 The evaluator shall examine the production support procedures to determine 
that by following these procedures a TOE would be produced like that one 
provided by the developer for testing activities. 
1096 If the TOE is a small softwa re TOE and production consists of compiling 
and linking, the evaluator might confirm the adequacy of the production 
support procedures by reapplying them himself. 
1097 If the production process of the TOE is more complicated (as for example in 
the case of a smart card), but has already started, the evaluator should inspect 
the application of the production support procedures during a visit of the 
Class ALC: Life-cycle support 
Page 236 of 430 Version 3.1 April 2017 
development site. He might compare a copy of the TOE produced in his 
presence with the samples used for his testing activities. 
1098 For guidance on site visits see A.4, Site Visits. 
1099 Otherwise the evaluator's determination should be based on the documentary 
evidence provided by the developer. 
1100 This w ork unit may be performed in conjunction with the evaluation 
activities under Implementation representation (ADV_IMP). 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 237 of 430 
14.3 CM scope (ALC_CMS) 
14.3.1 Evaluation of sub-activity (ALC_CMS.1) 
14.3.1.1 Objectives 
1101 The objective of this sub -activity is to determi ne whether the developer 
performs configuration management on the TOE and the evaluation evidence. 
These configuration items are controlled in accordance with CM capabilities 
(ALC_CMC). 
14.3.1.2 Input 
1102 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the configuration list.  
14.3.1.3 Action ALC_CMS.1.1E 
ALC_CMS.1.1C The configuration list shall include the following: the TOE itself; and the 
evaluation evidence required by the SARs.  
ALC_CMS.1-1 The evaluator shall check that the configuration list includes the following 
set of items:  
a) the TOE itself;  
b) the evaluation evidence required by the SARs in the ST.  
ALC_CMS.1.2C The configuration list shall uniquely identify the configuration items.  
ALC_CMS.1-2 The evaluator shall examine  the configuration list to determine that i t 
uniquely identifies each configuration item. 
1103 The configuration list contains sufficient information to uniquely identify 
which version of each item has been used (typically a version number). Use 
of this list will enable the evaluator to check that the c orrect configuration 
items, and the correct version of each item, have been used during the 
evaluation. 
14.3.2 Evaluation of sub-activity (ALC_CMS.2) 
14.3.2.1 Objectives 
1104 The objective of this sub -activity is to determine whether the configuration 
list includes the TOE, th e parts that comprise the TOE, and the evaluation 
evidence. These configuration items are controlled in accordance with CM 
capabilities (ALC_CMC). 
Class ALC: Life-cycle support 
Page 238 of 430 Version 3.1 April 2017 
14.3.2.2 Input 
1105 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the configuration list.  
14.3.2.3 Action ALC_CMS.2.1E 
ALC_CMS.2.1C The configuration list shall include the following: the TOE itself; the 
evaluation evidence required by the SARs; and the parts that comprise the 
TOE.  
ALC_CMS.2-1 The evaluator shall check that the configuration list includes the following 
set of items:  
a) the TOE itself;  
b) the parts that comprise the TOE;  
c) the evaluation evidence required by the SARs.  
ALC_CMS.2.2C The configuration list shall uniquely identify the configuration items.  
ALC_CMS.2-2 The evaluator shall examine  the configuration list t o determine that it 
uniquely identifies each configuration item. 
1106 The configuration list contains sufficient information to uniquely identify 
which version of each item has been used (typically a version number). Use 
of this list will enable the evaluator t o check that the correct configuration 
items, and the correct version of each item, have been used during the 
evaluation. 
ALC_CMS.2.3C For each TSF relevant configuration item, the configuration list shall 
indicate the developer of the item.  
ALC_CMS.2-3 The evaluator shall check that the configuration list indicates the developer 
of each TSF relevant configuration item. 
1107 If only one developer is involved in the devel opment of the TOE, this work 
unit is not applicable, and is therefore considered to be satisfied. 
14.3.3 Evaluation of sub-activity (ALC_CMS.3) 
14.3.3.1 Objectives 
1108 The objective of this sub -activity is to determine whether the configuration 
list includes the TOE, the part s that comprise the TOE, the TOE 
implementation representation, and the evaluation evidence. These 
configuration items are controlled in accordance with CM capabilities 
(ALC_CMC). 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 239 of 430 
14.3.3.2 Input 
1109 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the configuration list.  
14.3.3.3 Action ALC_CMS.3.1E 
ALC_CMS.3.1C The configuration list shall include the following: the TOE itself; the 
evaluation evidence req uired by the SARs; the parts that comprise the 
TOE; and the implementation representation.  
ALC_CMS.3-1 The evaluator shall check that the configuration list includes the following 
set of items:  
a) the TOE itself;  
b) the parts that comprise the TOE;  
c) the TOE implementation representation;  
d) the evaluation evidence required by the SARs in the ST.  
ALC_CMS.3.2C The configuration list shall uniquely identify the configuration items.  
ALC_CMS.3-2 The evaluator shall examine  the configuration list to determine that it 
uniquely identifies each configuration item. 
1110 The configuration list contains sufficient information to uniquely identi fy 
which version of each item has been used (typically a version number). Use 
of this list will enable the evaluator to check that the correct configuration 
items, and the correct version of each item, have been used during the 
evaluation. 
ALC_CMS.3.3C For each TSF relevant configuration item, the configuration list shall 
indicate the developer of the item.  
ALC_CMS.3-3 The evaluator shall check that the configuratio n list indicates the developer 
of each TSF relevant configuration item. 
1111 If only one developer is involved in the development of the TOE, this work 
unit is not applicable, and is therefore considered to be satisfied. 
14.3.4 Evaluation of sub-activity (ALC_CMS.4) 
14.3.4.1 Objectives 
1112 The objective of this sub -activity is to determine whether the configuration 
list includes the TOE, the parts that comprise the TOE, the TOE 
implementation representation, security flaws, and the evaluation evidence. 
Class ALC: Life-cycle support 
Page 240 of 430 Version 3.1 April 2017 
These configuration items are  controlled in accordance with CM capabilities 
(ALC_CMC). 
14.3.4.2 Input 
1113 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the configuration list.  
14.3.4.3 Action ALC_CMS.4.1E 
ALC_CMS.4.1C The configuration list shall include the following: the TOE itself; the 
evaluation evidence required by the SARs; the parts that comprise the 
TOE; the implementation representation; and security flaw reports and 
resolution status.  
ALC_CMS.4-1 The evaluator shall check that the configuration list includes the following 
set of items:  
a) the TOE itself;  
b) the parts that comprise the TOE;  
c) the TOE implementation representation;  
d) the evaluation evidence required by the SARs in the ST;  
e) the documentation used to record details of reported security flaws 
associated with the implementation (e.g., problem status reports 
derived from a developer's problem database).  
ALC_CMS.4.2C The configuration list shall uniquely identify the configuration items.  
ALC_CMS.4-2 The evaluator shall examine  the configuration list to determine that it 
uniquely identifies each configuration item. 
1114 The configuration list contains sufficient information to uniquely identify 
which version of each item has been used (typically a version number). Use 
of this list will enable the evaluator to check that the correct configurat ion 
items, and the correct version of each item, have been used during the 
evaluation. 
ALC_CMS.4.3C For each TSF relevant configuration item, the configuration list shall 
indicate the developer of the item.  
ALC_CMS.4-3 The evaluator shall check that the configuration list indicates the developer 
of each TSF relevant configuration item. 
1115 If only one developer is involved in the development of the TOE, this work 
unit is not applicable, and is therefore considered to be satisfied. 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 241 of 430 
14.3.5 Evaluation of sub-activity (ALC_CMS.5) 
14.3.5.1 Objectives 
1116 The objective of this sub -activity is to determine whether the configuration 
list includes the TOE, the parts that comprise the TOE, the TOE 
implementation representation, security flaws, development tools and related 
information, and the evaluation evidence. These configuration items are 
controlled in accordance with CM capabilities (ALC_CMC). 
14.3.5.2 Input 
1117 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the configuration list.  
14.3.5.3 Action ALC_CMS.5.1E 
ALC_CMS.5.1C The configuration list shall include the following: the TOE itself; the  
evaluation evidence required by the SARs; the parts that comprise the 
TOE; the implementation representation; security flaw reports and 
resolution status; and development tools and related information.  
ALC_CMS.5-1 The evaluator shall check that the configuration list includes the following 
set of items:  
a) the TOE itself;  
b) the parts that comprise the TOE;  
c) the TOE implementation representation;  
d) the evaluation evidence required by the SARs in the ST;  
e) the document ation used to record details of reported security flaws 
associated with the implementation (e.g., problem status reports 
derived from a developer's problem database);  
f) all tools (incl. test software, if applicable) involved in the 
development and productio n of the TOE including the names, 
versions, configurations and roles of each development tool, and 
related documentation.  
1118 For a software TOE, “development tools” are usually programming 
languages and compiler and “related documentation” comprises compiler  
and linker options. For a hardware TOE, “development tools” might be 
hardware design languages, simulation and synthesis tools, compilers, and 
“related documentation” might comprise compiler options again. 
ALC_CMS.5.2C The configuration list shall uniquely identify the configuration items.  
Class ALC: Life-cycle support 
Page 242 of 430 Version 3.1 April 2017 
ALC_CMS.5-2 The evaluator shall examine  the configuration list to determine that it 
uniquely identifies each configuration item. 
1119 The configuration list contains sufficient information to uniquely identify 
which version of each item has been used (typically a version number). Use 
of this list will enable the evaluator to check that the correct configuration 
items, and the correct v ersion of each item, have been used during the 
evaluation. 
ALC_CMS.5.3C For each TSF relevant configuration item, the configuration list shall 
indicate the developer of the item.  
ALC_CMS.5-3 The evaluator shall check that the configuration list indicates the developer 
of each TSF relevant configuration item. 
1120 If only one developer is involved in the development of the TOE, this work 
unit is not applicable, and is therefore considered to be satisfied. 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 243 of 430 
14.4 Delivery (ALC_DEL) 
14.4.1 Evaluation of sub-activity (ALC_DEL.1) 
14.4.1.1 Objectives 
1121 The objective of this sub -activity is to determine whether the delivery 
documentation describes all procedures used to maintain security of the TOE 
when distributing the TOE to the user. 
14.4.1.2 Input 
1122 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the delivery documentation.  
14.4.1.3 Action ALC_DEL.1.1E 
ALC_DEL.1.1C The delivery documentation shall describe all procedures that are 
necessary to maintain security when distributing versions of the TOE to 
the consumer.  
ALC_DEL.1-1 The evaluator shall examine the delivery documentation to determine that it 
describes all procedures that are necessary to maintain security when 
distributing versions of the TOE or parts of it to the consumer. 
1123 The delivery documentation describes proper procedures to maintain security 
of the TOE dur ing transfer of the TOE or its component parts and to 
determine the identification of the TOE. 
1124 The delivery documentation should cover the entire TOE, but may contain 
different procedures for different parts of the TOE. The evaluation should 
consider the totality of procedures. 
1125 The delivery procedures should be applicable across all phases of delivery 
from the production environment to the installation environment (e.g. 
packaging, storage and distribution). Standard commercial practise for 
packaging and del ivery may be acceptable. This includes shrink wrapped 
packaging, a security tape or a sealed envelope. For the distribution, physical 
(e.g. public mail or a private distribution service) or electronic (e.g. 
electronic mail or downloading off the Internet) procedures may be used. 
1126 Cryptographic checksums or a software signature may be used by the 
developer to ensure that tampering or masquerading can be detected. Tamper 
proof seals additionally indicate if the confidentiality has been broken. For 
software TOE s, confidentiality might be assured by using encryption. If 
availability is of concern, a secure transportation might be required. 
1127 Interpretation of the term “necessary to maintain security” will need to 
consider:  
Class ALC: Life-cycle support 
Page 244 of 430 Version 3.1 April 2017 
 The nature of the TOE (e.g. whether it is software or hardware).  
 The overall security level stated for the TOE by the chosen level of 
the Vulnerability Assessment. If the TOE is required to be resistant 
against attackers of a certain potential in its intended environment, 
this should also apply to the delivery of the TOE. The evaluator 
should determine that a balanced approach has been taken, such that 
delivery does not present a weak point in an otherwise secure 
development process.  
 The security objectives provided by the ST. The emphasis in th e 
delivery documentation is likely to be on measures related to integrity, 
as integrity of the TOE is always important. However, confidentiality 
and availability of the delivery will be of concern in the delivery of 
some TOEs; procedures relating to these aspects of the secure 
delivery should also be discussed in the procedures.  
14.4.1.4 Implied evaluator action 
ALC_DEL.1.2D The developer shall use the delivery procedures.  
ALC_DEL.1-2 The evaluator shall examine aspects of the delivery process to determine that 
the delivery procedures are used. 
1128 The approach taken by the evaluator to check the application of delivery 
procedures will depend on the nature of the TOE, and the delivery process 
itself. In addition to examination of the procedures themselves, the evaluator 
seeks some assurance that they are applied in practise. Some possible 
approaches are:  
a) a visit to the distribution  site(s) where practical application of the 
procedures may be observed;  
b) examination of the TOE at some stage during delivery, or after the 
user has received it (e.g. checking for tamper proof seals);  
c) observing that the process is applied in practise when  the evaluator 
obtains the TOE through regular channels;  
d) questioning end users as to how the TOE was delivered.  
1129 For guidance on site visits see A.4, Site Visits. 
1130 It may be the case of a newly developed TOE that the delivery procedures 
have yet to be exercised. In these cases, the evaluator has to be satisfied that 
appropriate procedures and facilities are in place for future deliveries and 
that all personnel involved are aware o f their responsibilities. The evaluator 
may request a “dry run” of a delivery if this is practical. If the developer has 
produced other similar products, then an examination of procedures in their 
use may be useful in providing assurance. 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 245 of 430 
14.5 Development security (ALC_DVS) 
14.5.1 Evaluation of sub-activity (ALC_DVS.1) 
14.5.1.1 Objectives 
1131 The objective of this sub -activity is to determine whether the developer's 
security controls on the development environment are adequate to provide 
the confidentiality and integrity of the TO E design and implementation that 
is necessary to ensure that secure operation of the TOE is not compromised. 
14.5.1.2 Input 
1132 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the development security documentation.  
1133 In addition, the evaluator may need to e xamine other deliverables to 
determine that the security controls are well -defined and followed. 
Specifically, the evaluator may need to examine the developer's 
configuration management documentation (the input for the Evaluation of 
sub-activity (ALC_CMC.4) “Production support and acceptance procedures” 
and the Evaluation of sub -activity (ALC_CMS.4)  “Problem tracking CM 
coverage”). Evidence that the procedures are being applied is also required. 
14.5.1.3 Action ALC_DVS.1.1E 
ALC_DVS.1.1C The development security documentation shall describe all the physical, 
procedural, personnel, and other security measures that are necessary to 
protect the confidentiality and integrity of the TOE design and 
implementation in its development environment.  
ALC_DVS.1-1 The evaluator shall examine  the development security documentation to 
determine that it deta ils all security measures used in the development 
environment that are necessary to protect the confidentiality and integrity of 
the TOE design and implementation. 
1134 The evaluator determines what is necessary by first referring to the ST for 
any information that may assist in the determination of necessary protection. 
1135 If no explicit information is available from the ST the evaluator will need to 
make a determination of the necessary measures. In cases where the 
developer's measures are considered less than wh at is necessary, a clear 
justification should be provided for the assessment, based on a potential 
exploitable vulnerability. 
1136 The following types of security measures are considered by the evaluator 
when examining the documentation:  
Class ALC: Life-cycle support 
Page 246 of 430 Version 3.1 April 2017 
a) physical, for example physical access controls used to prevent 
unauthorised access to the TOE development environment (during 
normal working hours and at other times);  
b) procedural, for example covering:  
 granting of access to the development environment or to 
specific parts of the environment such as development 
machines  
 revocation of access rights when a person leaves the 
development team  
 transfer of protected material within and out of the 
development environment and between different development 
sites in accordance with defined acceptance procedures  
 admitting and escorting visitors to the development 
environment  
 roles and responsibilities in ensuring the continued 
application of security measures, and the detection of security 
breaches.  
c) personnel, for example any controls  or checks made to establish the 
trustworthiness of new development staff;  
d) other security measures, for example the logical protections on any 
development machines.  
1137 The development security documentation should identify the locations at 
which development  occurs, and describe the aspects of development 
performed, along with the security measures applied at each location and for 
transports between different locations. For example, development could 
occur at multiple facilities within a single building, mult iple buildings at the 
same site, or at multiple sites. Transports of parts of the TOE or the 
unfinished TOE between different development sites are to be covered by 
Development secu rity (ALC_DVS) , whereas the transport of the finished 
TOE to the consumer is dealt with in Delivery (ALC_DEL). 
1138 Development includes the production of the TOE. 
ALC_DVS.1-2 The evaluator shall examine  the development confidentiality and integrity 
policies in order to determine the sufficiency of the security measures 
employed. 
1139 The evaluator should examine whether the following is included in the 
policies:  
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 247 of 430 
a) what information relating to the TOE development needs to be kept 
confidential, and which members  of the development staff are 
allowed to access such material;  
b) what material must be protected from unauthorised modification in 
order to preserve the integrity of the TOE, and which members of the 
development staff are allowed to modify such material.  
1140 The evaluator should determine that these policies are described in the 
development security documentation, that the security measures employed 
are consistent with the policies, and that they are complete. 
1141 It should be noted that configuration management pr ocedures will help 
protect the integrity of the TOE and the evaluator should avoid overlap with 
the work-units conducted for the CM capabilities (ALC_CMC). For example, 
the CM documentation may describe the security procedures necessary for 
controlling the roles or individuals who should have access to the 
development environment and who may modify the TOE. 
1142 Whereas the CM capabilities (ALC_CMC) requirements are fixed, those for 
the Development security (ALC_DVS), mandating only necessary measures, 
are dependent on the nature of the TOE, and on information that may be 
provided in the ST. The evaluators would then determine that such a policy 
had been applied under this sub-activity. 
14.5.1.4 Action ALC_DVS.1.2E 
ALC_DVS.1-3 The evaluator shall examine  the development security documentation and 
associated evidence to determine that the security measures are being applied. 
1143 This work unit requires the evaluator to determine that the security measures 
described in the development security documentation are being followed, 
such that the integrity of the TOE and the confidentiality of associated 
documentation is being adequately pro tected. For example, this could be 
determined by examination of the documentary evidence provided. 
Documentary evidence should be supplemented by visiting the development 
environment. A visit to the development environment will allow the 
evaluator to:  
a) observe the application of security measures (e.g. physical measures);  
b) examine documentary evidence of application of procedures;  
c) interview development staff to check awareness of the development 
security policies and procedures, and their responsibilities.  
1144 A development site visit is a useful means of gaining confidence in the 
measures being used. Any decision not to make such a visit should be 
determined in consultation with the evaluation authority. 
1145 For guidance on site visits see A.4, Site Visits. 
Class ALC: Life-cycle support 
Page 248 of 430 Version 3.1 April 2017 
14.5.2 Evaluation of sub-activity (ALC_DVS.2) 
14.5.2.1 Objectives 
1146 The objective of this sub -activity is to determine whether the developer's 
security controls on the development environment are adequ ate to provide 
the confidentiality and integrity of the TOE design and implementation that 
is necessary to ensure that secure operation of the TOE is not compromised. 
Additionally, sufficiency of the measures as applied is intended be justified. 
14.5.2.2 Input 
1147 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the development security documentation.  
1148 In addition, the evaluator may need to examine other deliverables to 
determine that the security controls are well -defined and followed. 
Specifically, the eval uator may need to examine the developer's 
configuration management documentation (the input for the Evaluation of 
sub-activity (ALC_CMC.4) “Production support and acceptance procedures” 
and the Evaluation of sub -activity (ALC_CMS.4)  “Problem tracking CM 
coverage”). Evidence that the procedures are being applied is also required. 
14.5.2.3 Action ALC_DVS.2.1E 
ALC_DVS.2.1C The developm ent security documentation shall describe all the physical, 
procedural, personnel, and other security measures that are necessary to 
protect the confidentiality and integrity of the TOE design and 
implementation in its development environment.  
ALC_DVS.2-1 The evaluator shall examine  the development security documentation to 
determine that it details all security measures used in the development 
environment that are necessary to protect the confidentiality and int egrity of 
the TOE design and implementation. 
1149 The evaluator determines what is necessary by first referring to the ST for 
any information that may assist in the determination of necessary protection. 
1150 If no explicit information is available from the ST the e valuator will need to 
make a determination of the necessary measures. In cases where the 
developer's measures are considered less than what is necessary, a clear 
justification should be provided for the assessment, based on a potential 
exploitable vulnerability. 
1151 The following types of security measures are considered by the evaluator 
when examining the documentation:  
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 249 of 430 
a) physical, for example physical access controls used to prevent 
unauthorised access to the TOE development environment (during 
normal working hours and at other times);  
b) procedural, for example covering:  
 granting of access to the development environment or to 
specific parts of the environment such as development 
machines  
 revocation of access rights when a person leaves the 
development team  
 transfer of protected material out of the development 
environment and between different development sites in 
accordance with defined acceptance procedures  
 admitting and escorting visitors to the development 
environment  
 roles and responsibilities in ensurin g the continued 
application of security measures, and the detection of security 
breaches.  
c) personnel, for example any controls or checks made to establish the 
trustworthiness of new development staff;  
d) other security measures, for example the logical prote ctions on any 
development machines.  
1152 The development security documentation should identify the locations at 
which development occurs, and describe the aspects of development 
performed, along with the security measures applied at each location and for 
transports between different locations. For example, development could 
occur at multiple facilities within a single building, multiple buildings at the 
same site, or at multiple sites. Transports of parts of the TOE or the 
unfinished TOE between different development sites are to be covered by the 
Development secu rity (ALC_DVS) , whereas the transport of the finished 
TOE to the consumer is dealt with in the Delivery (ALC_DEL). 
1153 Development includes the production of the TOE. 
ALC_DVS.2.2C The development security documentation shall justify that the security 
measures provide the necessary level of protection to maintain the 
confidentiality and integrity of the TOE.  
ALC_DVS.2-2 The evaluator shall examine  the development security documentation to 
determine that an appropriate justification is given why the security measures 
provide the necessary level of protection to maintain the confide ntiality and 
integrity of the TOE. 
Class ALC: Life-cycle support 
Page 250 of 430 Version 3.1 April 2017 
1154 Since attacks on the TOE or its related information are assumed in different 
design and production stages, measures and procedures need to have an 
appropriate level necessary to prevent those attacks or to make them more 
difficult. 
1155 Since this level depends on the overall attack potential claimed for the TOE 
(cf. the Vulnerability analysis (AVA_VAN)  component chosen), the 
development security documentation should justify the necessary level of 
protection to maintain the confidentiality and integrity of the TOE. This level 
has to be achieved by the security measures applied. 
1156 The concept of protection measures should be consistent, and the 
justification should include an analysis of how the measures are mutu ally 
supportive. All aspects of development and production on all the different 
sites with all roles involved up to delivery of the TOE should be analysed. 
1157 Justification may include an analysis of potential vulnerabilities taking the 
applied security measures into account. 
1158 There may be a convincing argument showing that e.g.  
 The technical measures and mechanisms of the developer's 
infrastructure are sufficient for keeping the appropriate security level 
(e.g. cryptographic mechanisms as well as physical pro tection 
mechanisms, properties of the CM system (cf. ALC_CMC.4-5)); 
 The system containing the implementation representation of the TOE 
(including concerning guidance documents) provides effective 
protection against logical attacks e. g. by “Trojan” code or viruses. It 
might be adequate, if the implementation representation is kept on an 
isolated system where only the software necessary to maintain it is 
installed and where no additional software is installed afterwards. 
 Data brought in to this system need to be carefully considered to 
prevent the installation of hidden functionality onto the system. The 
effectiveness of these measures need to be tested, e.g. by 
independently trying to get access to the machine, install some 
additional executable (program, macro etc.) or get some information 
out of the machine using logical attacks. 
 The appropriate organisational (procedural and personal) measures 
are unconditionally enforced. 
ALC_DVS.2-3 The eva luator shall examine  the development confidentiality and integrity 
policies in order to determine the sufficiency of the security measures 
employed. 
1159 The evaluator should examine whether the following is included in the 
policies:  
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 251 of 430 
a) what information relating to the TOE development needs to be kept 
confidential, and which members of the development staff are 
allowed to access such material;  
b) what material must be protected from unauthorised modification in 
order to preserve the integrity of the TOE, and which m embers of the 
development staff are allowed to modify such material.  
1160 The evaluator should determine that these policies are described in the 
development security documentation, that the security measures employed 
are consistent with the policies, and that they are complete. 
1161 It should be noted that configuration management procedures will help 
protect the integrity of the TOE and the evaluator should avoid overlap with 
the work-units conducted for the CM capabilities (ALC_CMC). For example, 
the CM documentation may describe the security procedures necessary for 
controlling the roles or individuals who should have access to the 
development environment and who may modify the TOE. 
1162 Whereas the CM capabilities (ALC_CMC) requirements are fixed, those for 
the Development security (ALC_DVS), mandating only necessary measures, 
are dependent on the nature of the TOE, and on information that may be 
provided in the ST. For example, the ST may identify a security objective for 
the development environment that requires the TOE to be developed by staff 
that has security clearance. The evaluators would then determine that such a 
policy had been applied under this sub-activity. 
14.5.2.4 Action ALC_DVS.2.2E 
ALC_DVS.2-4 The evaluator shall examine  the development security documentation and 
associated evidence to determine that the security measures are being applied. 
1163 This work unit requires the evaluator to determine that the security measures 
described in the development security documentation are being followed, 
such that the integrity of the TOE and the confidentiality of associated 
documentation is being adequately protected. For example, th is could be 
determined by examination of the documentary evidence provided. 
Documentary evidence should be supplemented by visiting the development 
environment. A visit to the development environment will allow the 
evaluator to:  
a) observe the application of security measures (e.g. physical measures);  
b) examine documentary evidence of application of procedures;  
c) interview development staff to check awareness of the development 
security policies and procedures, and their responsibilities.  
1164 A development site vi sit is a useful means of gaining confidence in the 
measures being used. Any decision not to make such a visit should be 
determined in consultation with the evaluation authority. 
Class ALC: Life-cycle support 
Page 252 of 430 Version 3.1 April 2017 
1165 For guidance on site visits see A.4, Site Visits. 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 253 of 430 
14.6 Flaw remediation (ALC_FLR) 
14.6.1 Evaluation of sub-activity (ALC_FLR.1) 
14.6.1.1 Objectives 
1166 The objective of this sub -activity is to determine whether the developer has 
established flaw remediation procedures that describe the tracking of security 
flaws, the identification of corrective actions, and the distribution of 
corrective action information to TOE users. 
14.6.1.2 Input 
1167 The evaluation evidence for this sub-activity is:  
a) the flaw remediation procedures documentation.  
14.6.1.3 Action ALC_FLR.1.1E 
ALC_FLR.1.1C The flaw remediation procedures documentation shall describe the 
procedures used to track all reported security flaws in each release o f the 
TOE.  
ALC_FLR.1-1 The evaluator shall examine the flaw remediation procedures documentation 
to determine that it describes the procedures used to track all reported 
security flaws in each release of the TOE. 
1168 The procedures describe the actions that are taken by the developer from the 
time each suspected security flaw is reported to the time that it is resolved. 
This includes the flaw's entire time frame, from initial detection through 
ascertaining that the flaw is a security flaw, to resolution of the security flaw. 
1169 If a flaw is discovered not to be security -relevant, there is no need (for the 
purposes of the Flaw remediation (ALC_FLR)  requirements) for the flaw 
remediation procedures to tr ack it further; only that there be an explanation 
of why the flaw is not security-relevant. 
1170 While these requirements do not mandate that there be a publicised means 
for TOE users to report security flaws, they do mandate that all security 
flaws that are reported be tracked. That is, a reported security flaw cannot be 
ignored simply because it comes from outside the developer's organisation. 
ALC_FLR.1.2C The flaw remediation procedures shall require that a desc ription of the 
nature and effect of each security flaw be provided, as well as the status of 
finding a correction to that flaw.  
ALC_FLR.1-2 The evaluator shall examine  the flaw remediation procedures to determin e 
that the application of these procedures would produce a description of each 
security flaw in terms of its nature and effects. 
1171 The procedures identify the actions that are taken by the developer to 
describe the nature and effects of each security flaw in  sufficient detail to be 
Class ALC: Life-cycle support 
Page 254 of 430 Version 3.1 April 2017 
able to reproduce it. The description of the nature of a security flaw 
addresses whether it is an error in the documentation, a flaw in the design of 
the TSF, a flaw in the implementation of the TSF, etc. The description of the 
security flaw's effects identifies the portions of the TSF that are affected and 
how those portions are affected. For example, a security flaw in the 
implementation might be found that affects the identification and 
authentication enforced by the TSF by permi tting authentication with the 
password “BACK DOOR”. 
ALC_FLR.1-3 The evaluator shall examine  the flaw remediation procedures to determine 
that the application of these procedures would identify the status of findi ng a 
correction to each security flaw. 
1172 The flaw remediation procedures identify the different stages of security 
flaws. This differentiation includes at least: suspected security flaws that 
have been reported, suspected security flaws that have been confir med to be 
security flaws, and security flaws whose solutions have been implemented. It 
is permissible that additional stages (e.g. flaws that have been reported but 
not yet investigated, flaws that are under investigation, security flaws for 
which a solution has been found but not yet implemented) be included. 
ALC_FLR.1.3C The flaw remediation procedures shall require that corrective actions be 
identified for each of the security flaws.  
ALC_FLR.1-4 The evaluator shall check the flaw remediation procedures to determine that 
the application of these procedures would identify the corrective action for 
each security flaw. 
1173 Corrective action  may consist of a repair to the hardware, firmware, or 
software portions of the TOE, a modification of TOE guidance, or both. 
Corrective action that constitutes modifications to TOE guidance (e.g. details 
of procedural measures to be taken to obviate the security flaw) includes 
both thos e measures serving as only an interim solution (until the repair is 
issued) as well as those serving as a permanent solution (where it is 
determined that the procedural measure is the best solution). 
1174 If the source of the security flaw is a documentation er ror, the corrective 
action consists of an update of the affected TOE guidance. If the corrective 
action is a procedural measure, this measure will include an update made to 
the affected TOE guidance to reflect these corrective procedures. 
ALC_FLR.1.4C The flaw remediation procedures documentation shall describe the 
methods used to provide flaw information, corrections and guidance on 
corrective actions to TOE users.  
ALC_FLR.1-5 The evaluator shall examine the flaw remediation procedures documentation 
to determine that it describes a means of providing the TOE users with the 
necessary information on each security flaw. 
1175 The necessary information  about each security fla w consists of its 
description (not necessarily at the same level of detail as that provided as part 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 255 of 430 
of work unit ALC_FLR.1-2), the prescribed corrective action, and any 
associated guidance on implementing the correction. 
1176 TOE users ma y be provided with such information, correction, and 
documentation updates in any of several ways, such as their posting to a 
website, their being sent to TOE users, or arrangements made for the 
developer to install the correction. In cases where the means of providing this 
information requires action to be initiated by the TOE user, the evaluator 
examines any TOE guidance to ensure that it contains instructions for 
retrieving the information. 
1177 The only metric for assessing the adequacy of the method used fo r providing 
the information, corrections and guidance is that there be a reasonable 
expectation that TOE users can obtain or receive it. For example, consider 
the method of dissemination where the requisite data is posted to a website 
for one month, and th e TOE users know that this will happen and when this 
will happen. This may not be especially reasonable or effective (as, say, a 
permanent posting to the website), yet it is feasible that the TOE user could 
obtain the necessary information. On the other ha nd, if the information were 
posted to the website for only one hour, yet TOE users had no way of 
knowing this or when it would be posted, it is infeasible that they would ever 
get the necessary information. 
14.6.2 Evaluation of sub-activity (ALC_FLR.2) 
14.6.2.1 Objectives 
1178 The objective of this sub -activity is to determine whether the developer has 
established flaw remediation procedures that describe the tracking of security 
flaws, the identification of corrective actions, and the distribution of 
corrective action informat ion to TOE users. Additionally, this sub -activity 
determines whether the developer's procedures provide for the corrections of 
security flaws, for the receipt of flaw reports from TOE users, and for 
assurance that the corrections introduce no new security flaws. 
1179 In order for the developer to be able to act appropriately upon security flaw 
reports from TOE users, TOE users need to understand how to submit 
security flaw reports to the developer, and developers need to know how to 
receive these reports. Flaw r emediation guidance addressed to the TOE user 
ensures that TOE users are aware of how to communicate with the 
developer; flaw remediation procedures describe the developer's role is such 
communication 
14.6.2.2 Input 
1180 The evaluation evidence for this sub-activity is:  
a) the flaw remediation procedures documentation;  
b) flaw remediation guidance documentation.  
Class ALC: Life-cycle support 
Page 256 of 430 Version 3.1 April 2017 
14.6.2.3 Action ALC_FLR.2.1E 
ALC_FLR.2.1C The flaw remediation procedures docum entation shall describe the 
procedures used to track all reported security flaws in each release of the 
TOE.  
ALC_FLR.2-1 The evaluator shall examine the flaw remediation procedures documentation 
to determine tha t it describes the procedures used to track all reported 
security flaws in each release of the TOE. 
1181 The procedures describe the actions that are taken by the developer from the 
time each suspected security flaw is reported to the time that it is resolved. 
This includes the flaw's entire time frame, from initial detection through 
ascertaining that the flaw is a security flaw, to resolution of the security flaw. 
1182 If a flaw is discovered not to be security -relevant, there is no need (for the 
purposes of the Flaw remediation (ALC_FLR)  requirements) for the flaw 
remediation procedures to track it further; only that there be an explanation 
of why the flaw is not security-relevant. 
ALC_FLR.2.2C The f law remediation procedures shall require that a description of the 
nature and effect of each security flaw be provided, as well as the status of 
finding a correction to that flaw.  
ALC_FLR.2-2 The evaluator shall examine the flaw remediation procedures to determine 
that the application of these procedures would produce a description of each 
security flaw in terms of its nature and effects. 
1183 The procedures identify the actions that are taken by the developer to 
describe the nature and effects of each security flaw in sufficient detail to be 
able to reproduce it. The description of the nature of a security flaw 
addresses whether it is an error in the documentation, a flaw in the design of 
the TSF, a flaw in the implem entation of the TSF, etc. The description of the 
security flaw's effects identifies the portions of the TSF that are affected and 
how those portions are affected. For example, a security flaw in the 
implementation might be found that affects the identifica tion and 
authentication enforced by the TSF by permitting authentication with the 
password “BACKDOOR”. 
ALC_FLR.2-3 The evaluator shall examine  the flaw remediation procedures to determine 
that the application of these procedures would identify the status of finding a 
correction to each security flaw. 
1184 The flaw remediation procedures identify the different stages of security 
flaws. This differentiation includes at least: suspected security flaws that 
have been reported, suspected security flaws that have been confirmed to be 
security flaws, and security flaws whose solutions have been implemented. It 
is permissible that additional stages (e.g. flaws that have been reported but 
not yet investigated, flaws that are und er investigation, security flaws for 
which a solution has been found but not yet implemented) be included. 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 257 of 430 
ALC_FLR.2.3C The flaw remediation procedures shall require that corrective actions be 
identified for each of the security flaws.  
ALC_FLR.2-4 The evaluator shall check the flaw remediation procedures to determine that 
the application of these procedures would identify the corrective action for 
each security flaw. 
1185 Corrective action  may consist of a repair to the hardware, firmware, or 
software portions of the TOE, a modification of TOE guidance, or both. 
Corrective action that constitutes modifications to TOE guidance (e.g. details 
of procedural measures to be tak en to obviate the security flaw) includes 
both those measures serving as only an interim solution (until the repair is 
issued) as well as those serving as a permanent solution (where it is 
determined that the procedural measure is the best solution). 
1186 If th e source of the security flaw is a documentation error, the corrective 
action consists of an update of the affected TOE guidance. If the corrective 
action is a procedural measure, this measure will include an update made to 
the affected TOE guidance to reflect these corrective procedures. 
ALC_FLR.2.4C The flaw remediation procedures documentation shall describe the 
methods used to provide flaw information, corrections and guidance on 
corrective actions to TOE users.  
ALC_FLR.2-5 The evaluator shall examine the flaw remediation procedures documentation 
to determine that it describes a means of providing the TOE users with the 
necessary information on each security flaw. 
1187 The necessary information  about each security flaw consists of its 
description (not necessarily at the same level of detail as that provided as part 
of work unit ALC_FLR.2-2), the prescribed corrective action, and any 
associated guidance on implementing the correction. 
1188 TOE users may be provided with such information, correction, and 
documentation updates in any of several ways, such as their posting to a 
website, their being sent to TOE users, or arrangements made for the 
developer to install the correction. In cases where the means of providing this 
information requires action to be initiated by the TOE user, the evaluator 
examines any TOE guidance to ensure that it contains instructions for 
retrieving the information. 
1189 The only metric for assessing the adequacy of the method used for providing 
the information, corrections and guidance is that there be a reasonable 
expectation that TOE users can obtain or receive it. For example, consider 
the method of dissemination where the requisit e data is posted to a website 
for one month, and the TOE users know that this will happen and when this 
will happen. This may not be especially reasonable or effective (as, say, a 
permanent posting to the website), yet it is feasible that the TOE user coul d 
obtain the necessary information. On the other hand, if the information were 
posted to the website for only one hour, yet TOE users had no way of 
Class ALC: Life-cycle support 
Page 258 of 430 Version 3.1 April 2017 
knowing this or when it would be posted, it is infeasible that they would ever 
get the necessary information. 
ALC_FLR.2.5C The flaw remediation procedures shall describe a means by which the 
developer receives from TOE users reports and enquiries of suspected 
security flaws in the TOE.  
ALC_FLR.2-6 The evaluator shall examine  the flaw remediation procedures to determine 
that they describe procedures for the developer to accept reports of security 
flaws or requests for corrections to such flaws. 
1190 The procedures ensure that T OE users have a means by which they can 
communicate with the TOE developer. By having a means of contact with 
the developer, the user can report security flaws, enquire about the status of 
security flaws, or request corrections to flaws. This means of cont act may be 
part of a more general contact facility for reporting non -security related 
problems. 
1191 The use of these procedures is not restricted to TOE users; however, only the 
TOE users are actively supplied with the details of these procedures. Others 
who m ight have access to or familiarity with the TOE can use the same 
procedures to submit reports to the developer, who is then expected to 
process them. Any means of submitting reports to the developer, other than 
those identified by the developer, are beyond  the scope of this work unit; 
reports generated by other means need not be addressed. 
ALC_FLR.2.6C The procedures for processing reported security flaws shall ensure that any 
reported flaws are remediated and  the remediation procedures issued to 
TOE users.  
ALC_FLR.2-7 The evaluator shall examine  the flaw remediation procedures to determine 
that the application of these procedures would help to ensure every reported 
flaw is corrected. 
1192 The flaw remediation procedures cover not only those security flaws 
discovered and reported by developer personnel, but also those reported by 
TOE users. The procedures are sufficiently detailed so that they describe 
how it is ensured th at each reported security flaw is corrected. The 
procedures contain reasonable steps that show progress leading to the 
eventual, inevitable resolution. 
1193 The procedures describe the process that is taken from the point at which the 
suspected security flaw is  determined to be a security flaw to the point at 
which it is resolved. 
ALC_FLR.2-8 The evaluator shall examine  the flaw remediation procedures to determine 
that the application of these procedures would help to ensure that the TOE 
users are issued remediation procedures for each security flaw. 
1194 The procedures describe the process that is taken from the point at which a 
security flaw is resolved to the point at which the remediation procedures are 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 259 of 430 
provided. The pro cedures for delivering corrective actions should be 
consistent with the security objectives; they need not necessarily be identical 
to the procedures used for delivering the TOE, as documented to meet 
ALC_DEL, if included in the assurance requirements. For example, if the 
hardware portion of a TOE were originally delivered by bonded courier, 
updates to hardware resulting from flaw remediation would likewise be 
expected to be distributed by bonded courier. Updates unrelated to flaw 
remediation would follow the procedures set forth in the documentation 
meeting the Delivery (ALC_DEL) requirements. 
ALC_FLR.2.7C The procedures for processing reported security flaws s hall provide 
safeguards that any corrections to these security flaws do not introduce 
any new flaws.  
ALC_FLR.2-9 The evaluator shall examine  the flaw remediation procedures to determine 
that the application of t hese procedures would result in safeguards that the 
potential correction contains no adverse effects. 
1195 Through analysis, testing, or a combination of the two, the developer may 
reduce the likelihood that adverse effects will be introduced when a security 
flaw is corrected. The evaluator assesses whether the procedures provide 
detail in how the necessary mix of analysis and testing actions is to be 
determined for a given correction. 
1196 The evaluator also determines that, for instances where the source of the 
security flaw is a documentation problem, the procedures include the means 
of safeguarding against the introduction of contradictions with other 
documentation. 
ALC_FLR.2.8C The flaw remediation guidance shall de scribe a means by which TOE 
users report to the developer any suspected security flaws in the TOE.  
ALC_FLR.2-10 The evaluator shall examine the flaw remediation guidance to determine that 
the application of these procedures would result in a means for the TOE user 
to provide reports of suspected security flaws or requests for corrections to 
such flaws. 
1197 The guidance ensures that TOE users have a means by which they can 
communicate with the TOE developer. By hav ing a means of contact with 
the developer, the user can report security flaws, enquire about the status of 
security flaws, or request corrections to flaws. 
14.6.3 Evaluation of sub-activity (ALC_FLR.3) 
14.6.3.1 Objectives 
1198 The objective of this sub -activity is to determine  whether the developer has 
established flaw remediation procedures that describe the tracking of security 
flaws, the identification of corrective actions, and the distribution of 
corrective action information to TOE users. Additionally, this sub -activity 
determines whether the developer's procedures provide for the corrections of 
Class ALC: Life-cycle support 
Page 260 of 430 Version 3.1 April 2017 
security flaws, for the receipt of flaw reports from TOE users, for assurance 
that the corrections introduce no new security flaws, for the establishment of 
a point of contact for each TOE user, and for the timely issue of corrective 
actions to TOE users. 
1199 In order for the developer to be able to act appropriately upon security flaw 
reports from TOE users, TOE users need to understand how to submit 
security flaw reports to the develo per, and developers need to know how to 
receive these reports. Flaw remediation guidance addressed to the TOE user 
ensures that TOE users are aware of how to communicate with the 
developer; flaw remediation procedures describe the developer's role is such 
communication. 
14.6.3.2 Input 
1200 The evaluation evidence for this sub-activity is:  
a) the flaw remediation procedures documentation;  
b) flaw remediation guidance documentation.  
14.6.3.3 Action ALC_FLR.3.1E 
ALC_FLR.3.1C The flaw remediation procedures documentation shall describe the 
procedures used to track all reported security flaws in each release of the 
TOE.  
ALC_FLR.3-1 The evaluator shall examine the flaw remediation procedures documentation 
to determine that it describes the procedures used to track all reported 
security flaws in each release of the TOE. 
1201 The procedures describe the actions that are taken by the developer from the 
time each suspected security flaw is reported to the time that it is resolved. 
This includes the flaw's entire time frame, from initial detection through 
ascertaining that the flaw is a security flaw, to resolution of the security flaw. 
1202 If a flaw is discovered not to be security -relevant, there is no need (for the 
purposes of the Flaw remediation (ALC_FLR)  requirements) for the flaw 
remediation procedures to track it further; only that there be an explanation 
of why the flaw is not security-relevant. 
ALC_FLR.3.2C The flaw remediation procedures shall require that a description of the 
nature and effect of each security flaw be provided, as well as the status of 
finding a correction to that flaw.  
ALC_FLR.3-2 The evaluator shall examine  the flaw remediation procedures to determine 
that the application of these procedures would produce a description of each 
security flaw in terms of its nature and effects. 
1203 The p rocedures identify the actions that are taken by the developer to 
describe the nature and effects of each security flaw in sufficient detail to be 
able to reproduce it. The description of the nature of a security flaw 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 261 of 430 
addresses whether it is an error in th e documentation, a flaw in the design of 
the TSF, a flaw in the implementation of the TSF, etc. The description of the 
security flaw's effects identifies the portions of the TSF that are affected and 
how those portions are affected. For example, a security  flaw in the 
implementation might be found that affects the identification and 
authentication enforced by the TSF by permitting authentication with the 
password “BACKDOOR”. 
ALC_FLR.3-3 The evaluator shall examine  the flaw remediation procedures to determine 
that the application of these procedures would identify the status of finding a 
correction to each security flaw. 
1204 The flaw remediation procedures identify the different stages of security 
flaws. This differenti ation includes at least: suspected security flaws that 
have been reported, suspected security flaws that have been confirmed to be 
security flaws, and security flaws whose solutions have been implemented. It 
is permissible that additional stages (e.g. flaw s that have been reported but 
not yet investigated, flaws that are under investigation, security flaws for 
which a solution has been found but not yet implemented) be included. 
ALC_FLR.3.3C The flaw remediati on procedures shall require that corrective actions be 
identified for each of the security flaws.  
ALC_FLR.3-4 The evaluator shall check the flaw remediation procedures to determine that 
the application of these procedures would identify the corrective action for 
each security flaw. 
1205 Corrective action  may consist of a repair to the hardware, firmware, or 
software portions of the TOE, a modification of TOE guidance, or both. 
Corrective action that constitutes modifications to TOE guidance (e.g. details 
of procedural measures to be taken to obviate the security flaw) includes 
both those measures serving as only an interim solution (until the repair is 
issued) as well as those serving as a permanent solution (where it is 
determined that the procedural measure is the best solution). 
1206 If the source of the security flaw is a documentation error, the corrective 
action consists of an update of the affected TOE guidance. If the corrective 
action is a procedural measure, this m easure will include an update made to 
the affected TOE guidance to reflect these corrective procedures. 
ALC_FLR.3.4C The flaw remediation procedures documentation shall describe the 
methods used to provide fl aw information, corrections and guidance on 
corrective actions to TOE users.  
ALC_FLR.3-5 The evaluator shall examine the flaw remediation procedures documentation 
to determine that it describes a means of provid ing the TOE users with the 
necessary information on each security flaw. 
1207 The necessary information  about each security flaw consists of its 
description (not necessarily at the same level of detail as that provided as part 
Class ALC: Life-cycle support 
Page 262 of 430 Version 3.1 April 2017 
of work unit ALC_FLR.3-2), the prescribed corrective action, and any 
associated guidance on implementing the correction. 
1208 TOE users may be provided with such information, correction, and 
documentation updates in any of several ways, such as their posting to a 
website, their being sent to TOE users, or arrangements made for the 
developer to install the correction. In cases where the means of providing this 
information requires action to be initiated by the TOE user, the evaluator 
examines any TOE guidance to ensure that it contains instructions for 
retrieving the information. 
1209 The only metric for assessing the adequacy of the method used for providing 
the information, corrections and guidance is that there be a reasonable 
expectation that TOE users can obtain or receive it . For example, consider 
the method of dissemination where the requisite data is posted to a website 
for one month, and the TOE users know that this will happen and when this 
will happen. This may not be especially reasonable or effective (as, say, a 
permanent posting to the website), yet it is feasible that the TOE user could 
obtain the necessary information. On the other hand, if the information were 
posted to the website for only one hour, yet TOE users had no way of 
knowing this or when it would be posted, it is infeasible that they would ever 
get the necessary information. 
1210 For TOE users who register with the developer (see work unit ALC_FLR.3-
12), the passive availability of this information is not sufficient. Developers 
must acti vely send the information (or a notification of its availability) to 
registered TOE users. 
ALC_FLR.3.5C The flaw remediation procedures shall describe a means by which the 
developer receives from TOE users re ports and enquiries of suspected 
security flaws in the TOE.  
ALC_FLR.3-6 The evaluator shall examine  the flaw remediation procedures to determine 
that the application of these procedures would result in a means f or the 
developer to receive from TOE user reports of suspected security flaws or 
requests for corrections to such flaws. 
1211 The procedures ensure that TOE users have a means by which they can 
communicate with the TOE developer. By having a means of contact wi th 
the developer, the user can report security flaws, enquire about the status of 
security flaws, or request corrections to flaws. This means of contact may be 
part of a more general contact facility for reporting non -security related 
problems. 
1212 The use of these procedures is not restricted to TOE users; however, only the 
TOE users are actively supplied with the details of these procedures. Others 
who might have access to or familiarity with the TOE can use the same 
procedures to submit reports to the develo per, who is then expected to 
process them. Any means of submitting reports to the developer, other than 
those identified by the developer, are beyond the scope of this work unit; 
reports generated by other means need not be addressed. 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 263 of 430 
ALC_FLR.3.6C The flaw remediation procedures shall include a procedure requiring 
timely response and the automatic distribution of security flaw reports and 
the associated corrections to registered users who might be affected by the 
security flaw.  
ALC_FLR.3-7 The evaluator shall examine  the flaw remediation procedures to determine 
that the application of these procedures would result in a timely means of 
providing the registered TOE users who might be affected with reports about, 
and associated corrections to, each security flaw. 
1213 The issue of timeliness applies to the issuance of both security flaw reports 
and the associated corrections. However, these need not be issued at the 
same time. It is recognised that flaw reports should be generated and issued 
as soon as an interim solution is found, even if that solution is as drastic as 
turn off the TOE. Likewise, when a more permanent (and less drastic) 
solution is found, it should be issued without undue delay. 
1214 It is unnecessary to restrict the recipients of the reports and associated 
corrections to only those TOE users who might be affected by the security 
flaw; it is permissible that all TOE users be given such reports and 
corrections for all security flaws, provided such is done in a timely manner. 
ALC_FLR.3-8 The evaluator shall examine  the flaw remediation procedures to determine 
that the application of these procedures would result in automatic distribution 
of the reports and associated corrections to the registered TOE users who 
might be affected. 
1215 Automatic distribution  does not mean that human interaction with the 
distribution method is not permitted. In fact, the distribution method could 
consist entirely of manual procedures, perhaps through a closely monitored 
procedure with prescribed escalation upon the lack of issue of reports or 
corrections. 
1216 It is unnecessary to restrict the recipients of the reports and associated 
corrections to only th ose TOE users who might be affected by the security 
flaw; it is permissible that all TOE users be given such reports and 
corrections for all security flaws, provided such is done automatically. 
ALC_FLR.3.7C The procedures for processing reported security flaws shall ensure that any 
reported flaws are remediated and the remediation procedures issued to 
TOE users.  
ALC_FLR.3-9 The evaluator shall examine  the flaw remed iation procedures to determine 
that the application of these procedures would help to ensure that every 
reported flaw is corrected. 
1217 The flaw remediation procedures cover not only those security flaws 
discovered and reported by developer personnel, but also  those reported by 
TOE users. The procedures are sufficiently detailed so that they describe 
how it is ensured that each reported security flaw is remediated. The 
Class ALC: Life-cycle support 
Page 264 of 430 Version 3.1 April 2017 
procedures contain reasonable steps that show progress leading to the 
eventual, inevitable resolution. 
1218 The procedures describe the process that is taken from the point at which the 
suspected security flaw is determined to be a security flaw to the point at 
which it is resolved. 
ALC_FLR.3-10 The evaluator shall examine  the flaw remediation procedures to determine 
that the application of these procedures would help to ensure that the TOE 
users are issued remediation procedures for each security flaw. 
1219 The procedures describe the process that is taken from  the point at which a 
security flaw is resolved to the point at which the remediation procedures are 
provided. The procedures for delivering remediation procedures should be 
consistent with the security objectives; they need not necessarily be identical 
to the procedures used for delivering the TOE, as documented to meet 
Delivery (ALC_DEL) , if included in the assurance requirements. For 
example, if the hardware portion of a TOE were originally delivered by 
bonded courier, updates to hardw are resulting from flaw remediation would 
likewise be expected to be distributed by bonded courier. Updates unrelated 
to flaw remediation would follow the procedures set forth in the 
documentation meeting the Delivery (ALC_DEL) requirements. 
ALC_FLR.3.8C The procedures for processing reported security flaws shall provide 
safeguards that any corrections to these security flaws do not introduce 
any new flaws.  
ALC_FLR.3-11 The evaluator shall examine  the flaw remediation procedures to determine 
that the application of these procedures would result in safeguards that the 
potential correction contains no adverse effects. 
1220 Through analysis, testing, or  a combination of the two, the developer may 
reduce the likelihood that adverse effects will be introduced when a security 
flaw is corrected. The evaluator assesses whether the procedures provide 
detail in how the necessary mix of analysis and testing acti ons is to be 
determined for a given correction. 
1221 The evaluator also determines that, for instances where the source of the 
security flaw is a documentation problem, the procedures include the means 
of safeguarding against the introduction of contradictions with other 
documentation. 
ALC_FLR.3.9C The flaw remediation guidance shall describe a means by which TOE 
users report to the developer any suspected security flaws in the TOE.  
ALC_FLR.3-12 The evaluator shall examine the flaw remediation guidance to determine that 
the application of these procedures would result in a means for the TOE user 
to provide reports of suspected security flaws or requests for corrections  to 
such flaws. 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 265 of 430 
1222 The guidance ensures that TOE users have a means by which they can 
communicate with the TOE developer. By having a means of contact with 
the developer, the user can report security flaws, enquire about the status of 
security flaws, or request corrections to flaws. 
ALC_FLR.3.10C The flaw remediation guidance shall describe a means by which TOE 
users may register with the developer, to be eligible to receive security flaw 
reports and corrections.  
ALC_FLR.3-13 The evaluator shall examine the flaw remediation guidance to determine that 
it describes a means of enabling the TOE users to register with the developer. 
1223 Enabling the TOE users to register w ith the developer simply means having 
a way for each TOE user to provide the developer with a point of contact; 
this point of contact is to be used to provide the TOE user with information 
related to security flaws that might affect that TOE user, along wi th any 
corrections to the security flaw. Registering the TOE user may be 
accomplished as part of the standard procedures that TOE users undergo to 
identify themselves to the developer, for the purposes of registering a 
software licence, or for obtaining update and other useful information. 
1224 There need not be one registered TOE user per installation of the TOE; it 
would be sufficient if there were one registered TOE user for an organisation. 
For example, a corporate TOE user might have a centralised acquisiti on 
office for all of its sites. In this case, the acquisition office would be a 
sufficient point of contact for all of that TOE user's sites, so that all of the 
TOE user's installations of the TOE have a registered point of contact. 
1225 In either case, it must  be possible to associate each TOE that is delivered 
with an organisation in order to ensure that there is a registered user for each 
TOE. For organisations that have many different addresses, this assures that 
there will be no user who is erroneously pres umed to be covered by a 
registered TOE user. 
1226 It should be noted that TOE users need not register; they must only be 
provided with a means of doing so. However, users who choose to register 
must be directly sent the information (or a notification of its availability). 
ALC_FLR.3.11C The flaw remediation guidance shall identify the specific points of contact 
for all reports and enquiries about security issues involving the TOE.  
ALC_FLR.3-14 The evaluator shall examine the flaw remediation guidance to determine that 
it identifies specific points of contact for user reports and enquiries about 
security issues involving the TOE. 
1227 The guidance includes a means whereby registered TOE users can interact 
with the developer to report discovered security flaws in the TOE or to make 
enquiries regarding discovered security flaws in the TOE. 
Class ALC: Life-cycle support 
Page 266 of 430 Version 3.1 April 2017 
14.7 Life-cycle definition (ALC_LCD) 
14.7.1 Evaluation of sub-activity (ALC_LCD.1) 
14.7.1.1 Objectives 
1228 The objective of this sub -activity is to determine whether the developer has 
used a documented model of the TOE life-cycle. 
14.7.1.2 Input 
1229 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the life-cycle definition documentation.  
14.7.1.3 Action ALC_LCD.1.1E 
ALC_LCD.1.1C The life -cycle definition documentation shall describe the model used to 
develop and maintain the TOE.  
ALC_LCD.1-1 The evaluator shall examine  the documented description of the life -cycle 
model used to determine that it covers the development and maintenance 
process. 
1230 The description of the life-cycle model should include:  
a) information on the life -cycle phases of the  TOE and the boundaries 
between the subsequent phases;  
b) information on the procedures, tools and techniques used by the 
developer (e.g. for design, coding, testing, bug-fixing);  
c) overall management structure governing the application of the 
procedures (e.g . an identification and description of the individual 
responsibilities for each of the procedures required by the 
development and maintenance process covered by the life -cycle 
model);  
d) information on which parts of the TOE are delivered by 
subcontractors, if subcontractors are involved.  
1231 Evaluation of sub-activity (ALC_LCD.1) does not require the model used to 
conform to any standard life-cycle model. 
ALC_LCD.1.2C The life -cycle model shal l provide for the necessary control over the 
development and maintenance of the TOE.  
ALC_LCD.1-2 The evaluator shall examine the life-cycle model to determine that use of the 
procedures, tools and techniques described by the life-cycle model will make 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 267 of 430 
the necessary positive contribution to the development and maintenance of 
the TOE. 
1232 The information provided in the life -cycle model gives the evaluator 
assurance that the development and maintenance procedures adopt ed would 
minimise the likelihood of security flaws. For example, if the life -cycle 
model described the review process, but did not make provision for 
recording changes to components, then the evaluator may be less confident 
that errors will not be introduc ed into the TOE. The evaluator may gain 
further assurance by comparing the description of the model against an 
understanding of the development process gleaned from performing other 
evaluator actions relating to the TOE development (e.g. those covered unde r 
the CM capabilities (ALC_CMC) ). Identified deficiencies in the life -cycle 
model will be of concern if they might reasonably be expected to give rise to 
the introduction of flaws into the TOE, either accidentally or deliberately. 
1233 The CC  does not mandate any particular development approach, and each 
should be judged on merit. For example, spiral, rapid -prototyping and 
waterfall approaches to design can all be used to produce a quality TOE if 
applied in a controlled environment. 
14.7.2 Evaluation of sub-activity (ALC_LCD.2) 
14.7.2.1 Objectives 
1234 The objective of this sub -activity is to determine whether the developer has 
used a documented and measurable model of the TOE life-cycle. 
14.7.2.2 Input 
1235 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the life-cycle definition documentation;  
c) information about the standard used;  
d) the life-cycle output documentation.  
14.7.2.3 Action ALC_LCD.2.1E 
ALC_LCD.2.1C The life -cycle definit ion documentation shall describe the model used to 
develop and maintain the TOE, including the details of its arithmetic 
parameters and/or metrics used to measure the quality of the TOE and/or 
its development.  
ALC_LCD.2-1 The evaluator shall examine  the documented description of the life -cycle 
model used to determine that it covers the development and maintenance 
process, including the details of its arithmetic parameters and/or metrics used 
to measure the TOE development. 
Class ALC: Life-cycle support 
Page 268 of 430 Version 3.1 April 2017 
1236 The description of the life-cycle model includes:  
a) information on the life -cycle phases of the TOE and the boundaries 
between the subsequent phases;  
b) information on the procedures, tools and techniques used by the 
developer (e.g. for design, coding, testing, bug-fixing);  
c) overall management structure governing the application of the 
procedures (e.g. an identification and description of the individual 
responsibilities for each of the procedures required by the 
development and maintenance process c overed by the life -cycle 
model);  
d) information on which parts of the TOE are delivered by 
subcontractors, if subcontractors are involved;  
e) information on the parameters/metrics that are used to measure the 
TOE development. Metrics standards typically includ e guides for 
measuring and producing reliable products and cover the aspects 
reliability, quality, performance, complexity and cost. For the 
evaluation all those metrics are of relevance, which are used to 
increase quality by decreasing the probability of faults and thereby in 
turn increase assurance in the security of the TOE.  
ALC_LCD.2.2C The life -cycle model shall provide for the necessary control over the 
development and maintenance of the TOE.  
ALC_LCD.2-2 The evaluator shall examine the life-cycle model to determine that use of the 
procedures, tools and techniques described by the life-cycle model will make 
the necessary positive contribution to the development  and maintenance of 
the TOE. 
1237 The information provided in the life -cycle model gives the evaluator 
assurance that the development and maintenance procedures adopted would 
minimise the likelihood of security flaws. For example, if the life -cycle 
model descri bed the review process, but did not make provision for 
recording changes to components, then the evaluator may be less confident 
that errors will not be introduced into the TOE. The evaluator may gain 
further assurance by comparing the description of the m odel against an 
understanding of the development process gleaned from performing other 
evaluator actions relating to the TOE development (e.g. those covered under 
the CM capabilities (ALC_CMC) ). Identified deficiencies in the life -cycle 
model will be of concern if they might reasonably be expected to give rise to 
the introduction of flaws into the TOE, either accidentally or deliberately. 
1238 The CC does not mandate any particular development approach, and each 
should be judged on merit. For example, spiral, rapid -prototyping and 
waterfall approaches to design can all be used to produce a quality TOE if 
applied in a controlled environment. 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 269 of 430 
1239 For the metrics/measurements used in the life -cycle model, evidence has to 
be provided that shows how tho se metrics/measurements usefully contribute 
to the minimisation of the likelihood of flaws. This can be viewed as the 
overall goal for measurement in an ALC context. As a consequence the 
metrics/measurements have to be selected b ased on their capability to 
achieve that overall goal or contribute to that. In the first place a 
metric/measure is suitable with respect to ALC if a correlation between the 
metric/measure and the number of flaws can be stated wi th a certain degree 
of reliability. But also a metric/measure useful for management purposes as 
for planning and monitoring the TOE development are helpful since badly 
managed projects are endangered to produce bad quality and to introduce 
flaws. 
1240 It may be possible to use metrics for quality improvement, for which this use 
is not obvious. For example a metric to estimate the expected cost of a 
product development may help quality, if the developer can show that this is 
used to provide an adequate budget for  development projects and that this 
helps to avoid quality problems arising from resource shortages. 
1241 It is not required that every single step in the life cycle of the TOE is 
measurable. However the evaluator should see from the description of the 
measures and procedures that the metrics are appropriate to control the 
overall quality of the TOE and to minimise possible security flaws by this. 
ALC_LCD.2.3C The life -cycle output documentation shall provide the r esults of the 
measurements of the TOE development using the measurable life -cycle 
model.  
ALC_LCD.2-3 The evaluator shall examine  the life -cycle output documentation to 
determine that it provides the results of t he measurements of the TOE 
development using the measurable life-cycle model. 
1242 The results of the measurements and the life -cycle progress of the TOE 
should be in accordance with the life-cycle model. 
1243 The output documentation not only includes numeric value s of the metrics 
but also documents actions taken as a result of the measurements and in 
accordance with the model. For example there may be a requirement that a 
certain design phase needs to be repeated, if some error rates measured 
during testing are out side of a defined threshold. In this case the 
documentation should show that such action was taken, if indeed the 
thresholds were not met. 
1244 If the evaluation is conducted in parallel with the development of the TOE it 
may be possible that quality measurements have not been used in the past. In 
this case the evaluator should use the documentation of the planned 
procedures in order to gain confidence that corrective actions are defined if 
results of quality measurements deviate from some threshold. 
Class ALC: Life-cycle support 
Page 270 of 430 Version 3.1 April 2017 
14.8 Tools and techniques (ALC_TAT) 
14.8.1 Evaluation of sub-activity (ALC_TAT.1) 
14.8.1.1 Objectives 
1245 The objective of this sub -activity is to determine whether the developer has 
used well -defined development tools (e.g. programming languages or 
computer-aided design (CAD) systems) that  yield consistent and predictable 
results. 
14.8.1.2 Input 
1246 The evaluation evidence for this sub-activity is:  
a) the development tool documentation;  
b) the subset of the implementation representation.  
14.8.1.3 Application notes 
1247 This work may be performed in parallel with the eva luation activities under 
Implementation representation (ADV_IMP) , specifically with regard to 
determining the use of features in the tools that will affect the object code 
(e.g. compilation options). 
14.8.1.4 Action ALC_TAT.1.1E 
ALC_TAT.1.1C Each development tool used for implementation shall be well-defined.  
ALC_TAT.1-1 The evaluator shall examine  the development tool documentation provided 
to determine that each development tools is well-defined. 
1248 For example, a well -defined language, compiler or CAD system may be 
considered to be one that conforms to a recognised standard, such as the ISO 
standards. A well -defined language is one that has a clear and complete 
description of its syntax, and a detailed description of the semantics of each 
construct. 
ALC_TAT.1.2C The documentation of each development tool shall unamb iguously define 
the meaning of all statements as well as all conventions and directives used 
in the implementation.  
ALC_TAT.1-2 The evaluator shall examine the documentation of each development tool to 
determine that it unambiguously defines the meaning of all statements as 
well as all conventions and directives used in the implementation. 
1249 The development tool documentation (e.g. programming language 
specifications and user manuals) should cover all statements us ed in the 
implementation representation of the TOE, and for each such statement 
should provide a clear and unambiguous definition of the purpose and effect 
of that statement. This work may be performed in parallel with the 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 271 of 430 
evaluator's examination of the im plementation representation performed 
during the ADV_IMP sub-activity. The key test the evaluator should apply is 
whether or not the documentation is sufficiently clear for the evaluator to be 
able to understand the implement ation representation. The documentation 
should not assume (for example) that the reader is an expert in the 
programming language used. 
1250 Reference to the use of a documented standard is an acceptable approach to 
meet this requirement, provided that the standard is available to the evaluator. 
Any differences from the standard should be documented. 
1251 The critical test is whether the evaluator can understand the TOE source code 
when performing source code analysis covered in the ADV_IMP sub-activity. 
However, the following checklist can additionally be used in searching for 
problem areas:  
a) In the language definition, phrases such as “the effect of this 
construct is undefined” and terms such as “implementation 
dependent” or “erroneous” may indicate ill-defined areas.  
b) Aliasing (allowing the same piece of memory to be referenced in 
different ways) is a common source of ambiguity problems.  
c) Exception handling (e.g. what happens after memory exhaustion or 
stack overflow) is often poorly defined.  
1252 Most languages in common use, however well designed, will have some 
problematic constructs. If the implementation language is mostly well 
defined, but some problematic constructs exist, then an inconclusive verdict 
should be assigned, pending examination of the source code. 
1253 The evaluator should verify, during the examination of source code, that any 
use of the problematic constructs does not introduce vulnerabilities. The 
evaluator should also ensure that constructs precluded by the documented 
standard are not used. 
1254 The development tool documentation should define all conventions and 
directives used in the implementation. 
ALC_TAT.1.3C The documentation of each development tool shall unambiguously define  
the meaning of all implementation-dependent options.  
ALC_TAT.1-3 The evaluator shall examine  the development tool documentation to 
determine that it unambiguously defines the meaning of all implementation -
dependent options. 
1255 The documentation of software development tools should include definitions 
of implementation -dependent options that may affect the meaning of the 
executable code, and those that are different from the standard language as 
documented. Where so urce code is provided to the evaluator, information 
should also be provided on compilation and linking options used. 
Class ALC: Life-cycle support 
Page 272 of 430 Version 3.1 April 2017 
1256 The documentation for hardware design and development tools should 
describe the use of all options that affect the output from the tools (e .g. 
detailed hardware specifications, or actual hardware). 
14.8.2 Evaluation of sub-activity (ALC_TAT.2) 
14.8.2.1 Objectives 
1257 The objective of this sub -activity is to determine whether the developer has 
used well -defined development tools (e.g. programming languages or 
computer-aided design (CAD) systems) that yield consistent and predictable 
results, and whether implementation standards have been applied. 
14.8.2.2 Input 
1258 The evaluation evidence for this sub-activity is:  
a) the development tool documentation;  
b) the implementation standards description;  
c) the provided implementation representation of the TSF.  
14.8.2.3 Application notes 
1259 This work may be performed in parallel with the evaluation activities under 
ADV_IMP, specifically with regard to determining the use of features in the 
tools that will affect the object code (e.g. compilation options). 
14.8.2.4 Action ALC_TAT.2.1E 
ALC_TAT.2.1C Each development tool used for implementation shall be well-defined.  
ALC_TAT.2-1 The evaluator shall examine  the development tool documentation provided 
to determine that each development tool is well-defined. 
1260 For example, a well -defined language, compil er or CAD system may be 
considered to be one that conforms to a recognised standard, such as the ISO 
standards. A well -defined language is one that has a clear and complete 
description of its syntax, and a detailed description of the semantics of each 
construct. 
ALC_TAT.2.2C The documentation of each development tool shall unambiguously define 
the meaning of all statements as well as all conventions and directives used 
in the implementation.  
ALC_TAT.2-2 The evaluator shall examine the documentation of each development tool to 
determine that it unambiguously defines the meaning of all statements as 
well as all conventions and directives used in the implementation. 
1261 The development tool documentation (e.g. programming language 
specifications and user manuals) should cover all statements used in the 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 273 of 430 
implementation representation of the TOE, and for each such statement 
should provide a clear and unambiguous definition of t he purpose and effect 
of that statement. This work may be performed in parallel with the 
evaluator's examination of the implementation representation performed 
during the ADV_IMP sub-activity. The key test the evaluator should apply is 
whether or not the documentation is sufficiently clear for the evaluator to be 
able to understand the implementation representation. The documentation 
should not assume (for example) that the reader is an expert in the 
programming language used. 
1262 Reference to the use of a documented standard is an acceptable approach to 
meet this requirement, provided that the standard is available to the evaluator. 
Any differences from the standard should be documented. 
1263 The critical test is whether the evaluator can understand the TOE source code 
when performing source code analysis covered in the ADV_IMP sub-activity. 
However, the following checklist can additionally be used in searching for 
problem areas:  
a) In the language definitio n, phrases such as “the effect of this 
construct is undefined” and terms such as “implementation 
dependent” or “erroneous” may indicate ill-defined areas.  
b) Aliasing (allowing the same piece of memory to be referenced in 
different ways) is a common source of ambiguity problems.  
c) Exception handling (e.g. what happens after memory exhaustion or 
stack overflow) is often poorly defined.  
1264 Most languages in common use, however well designed, will have some 
problematic constructs. If the implementation language is mostly well 
defined, but some problematic constructs exist, then an inconclusive verdict 
should be assigned, pending examination of the source code. 
1265 The evaluator should verify, during the examination of source code, that any 
use of the problematic constru cts does not introduce vulnerabilities. The 
evaluator should also ensure that constructs precluded by the documented 
standard are not used. 
1266 The development tool documentation should define all conventions and 
directives used in the implementation. 
ALC_TAT.2.3C The documentation of each development tool shall unambiguously define 
the meaning of all implementation-dependent options.  
ALC_TAT.2-3 The evaluator shall exa mine the development tool documentation to 
determine that it unambiguously defines the meaning of all implementation -
dependent options. 
1267 The documentation of software development tools should include definitions 
of implementation -dependent options that may affect the meaning of the 
Class ALC: Life-cycle support 
Page 274 of 430 Version 3.1 April 2017 
executable code, and those that are different from the standard language as 
documented. Where source code is provided to the evaluator, information 
should also be provided on compilation and linking options used. 
1268 The documentation  for hardware design and development tools should 
describe the use of all options that affect the output from the tools (e.g. 
detailed hardware specifications, or actual hardware). 
14.8.2.5 Action ALC_TAT.2.2E 
ALC_TAT.2-4 The evaluator shall examine  aspects of the implementation process to 
determine that documented implementation standards have been applied. 
1269 This work unit requires the evaluator to analyse the provided implemen tation 
representation of the TOE to determine whether the documented 
implementation standards have been applied. 
1270 The evaluator should verify that constructs excluded by the documented 
standard are not used. 
1271 Additionally, the evaluator should verify the dev eloper's procedures which 
ensure the application of the defined standards within the design and 
implementation process of the TOE. Therefore, documentary evidence 
should be supplemented by visiting the development environment. A visit to 
the development environment will allow the evaluator to:  
a) observe the application of defined standards; 
b) examine documentary evidence of application of procedures 
describing the use of defined standards; 
c) interview development staff to check awareness of the application of 
defined standards and procedures. 
1272 A development site visit is a useful means of gaining confidence in the 
procedures being used. Any decision not to make such a visit should be 
determined in consultation with the evaluation authority. 
1273 The evaluator compares the provided implementation representation with the 
description of the applied implementation standards and verifies their use. 
1274 At this level it is not required that the complete provided implementation 
representation of the TSF is based on implementation standards, but only 
those parts that are developed by the TOE developer himself. The evaluator 
may consult the configuration list required by the CM scope (ALC_CMS) to 
get the information which parts are developed by the TOE developer, a nd 
which by third party developers. 
1275 If the referenced implementation standards are not applied for at least parts 
of the provided implementation representation, the evaluator action related to 
this work unit is assigned a fail verdict. 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 275 of 430 
1276 Note that parts of t he TOE which are not TSF relevant do not need to be 
examined. 
1277 This work unit may be performed in conjunction with the evaluation 
activities under ADV_IMP. 
14.8.3 Evaluation of sub-activity (ALC_TAT.3) 
14.8.3.1 Objectives 
1278 The objective of thi s sub-activity is to determine whether the developer and 
his subcontractors have used well -defined development tools (e.g. 
programming languages or computer-aided design (CAD) systems) that yield 
consistent and predictable results, and whether implementati on standards 
have been applied. 
14.8.3.2 Input 
1279 The evaluation evidence for this sub-activity is:  
a) the development tool documentation;  
b) the implementation standards description;  
c) the provided implementation representation of the TSF.  
14.8.3.3 Application notes 
1280 This work may  be performed in parallel with the evaluation activities under 
ADV_IMP, specifically with regard to determining the use of features in the 
tools that will affect the object code (e.g. compilation options). 
14.8.3.4 Action ALC_TAT.3.1E 
ALC_TAT.3.1C Each development tool used for implementation shall be well-defined.  
ALC_TAT.3-1 The evaluator shall examine the development tool documentation provided 
to determine that each development tool is well-defined. 
1281 For example, a well -defined language, compiler or CAD system may be 
considered to be one that conforms to a recognised standard, such as the ISO 
standards. A well -defined language is one that has a clear and complete 
description of its syntax, and a detailed description of the semantics of each 
construct. 
1282 At this level, the documentation of development tools used by third party 
contributors to the TOE has to be included in the evaluator's examination. 
ALC_TAT.3.2C The documentation of each development tool shall unambiguously define 
the meaning of all statements as well as all conventions and directives us ed 
in the implementation.  
Class ALC: Life-cycle support 
Page 276 of 430 Version 3.1 April 2017 
ALC_TAT.3-2 The evaluator shall examine the documentation of each development tool to 
determine that it unambiguously defines the meaning of all statements as 
well as all conventions and directives used in the implementation. 
1283 The development tool documentation (e.g. programming language 
specifications and user manuals) should cover all statements used in the 
implementation representation of the TOE, and for each such statement 
should provide a clear and unambiguous definition of the purpose and effect 
of that statement. This work may be performed in parallel with the 
evaluator's examination of the implementation representation performed 
during the ADV_IMP sub-activity. The key test the evaluator should apply is 
whether or not the documentation is sufficiently clear for the evaluator to be 
able to understand the implementation representation. The documentation 
should not assume (for example) that the reader is  an expert in the 
programming language used. 
1284 Reference to the use of a documented standard is an acceptable approach to 
meet this requirement, provided that the standard is available to the evaluator. 
Any differences from the standard should be documented. 
1285 The critical test is whether the evaluator can understand the TOE source code 
when performing source code analysis covered in the ADV_IMP sub-activity. 
However, the following checklist can additionally be used in searching f or 
problem areas:  
a) In the language definition, phrases such as “the effect of this 
construct is undefined” and terms such as “implementation 
dependent” or “erroneous” may indicate ill-defined areas.  
b) Aliasing (allowing the same piece of memory to be refere nced in 
different ways) is a common source of ambiguity problems.  
c) Exception handling (e.g. what happens after memory exhaustion or 
stack overflow) is often poorly defined.  
1286 Most languages in common use, however well designed, will have some 
problematic co nstructs. If the implementation language is mostly well 
defined, but some problematic constructs exist, then an inconclusive verdict 
should be assigned, pending examination of the source code. 
1287 The evaluator should verify, during the examination of source c ode, that any 
use of the problematic constructs does not introduce vulnerabilities. The 
evaluator should also ensure that constructs precluded by the documented 
standard are not used. 
1288 The development tool documentation should define all conventions and 
directives used in the implementation. 
1289 At this level, the documentation of development tools used by third party 
contributors to the TOE has to be included in the evaluator's examination. 
Class ALC: Life-cycle support 
April 2017 Version 3.1 Page 277 of 430 
ALC_TAT.3.3C The documentation of each development tool shall unambiguously define 
the meaning of all implementation-dependent options.  
ALC_TAT.3-3 The evaluator shall examine  the development tool documentation to 
determine that it un ambiguously defines the meaning of all implementation -
dependent options. 
1290 The documentation of software development tools should include definitions 
of implementation -dependent options that may affect the meaning of the 
executable code, and those that are d ifferent from the standard language as 
documented. Where source code is provided to the evaluator, information 
should also be provided on compilation and linking options used. 
1291 The documentation for hardware design and development tools should 
describe the use of all options that affect the output from the tools (e.g. 
detailed hardware specifications, or actual hardware). 
1292 At this level, the documentation of development tools used by third party 
contributors to the TOE has to be included in the evaluator's examination. 
14.8.3.5 Action ALC_TAT.3.2E 
ALC_TAT.3-4 The evaluator shall examine  aspects of the implementation process to 
determine that documented implementation standards have been applied. 
1293 This work unit requires the evaluator to analyse the provided implementation 
representation of the TOE to determine whether the documented 
implementation standards have been applied. 
1294 The evaluator should verify that constructs excluded by t he documented 
standard are not used. 
1295 Additionally, the evaluator should verify the developer's procedures which 
ensure the application of the defined standards within the design and 
implementation process of the TOE. Therefore, documentary evidence 
should be supplemented by visiting the development environment. A visit to 
the development environment will allow the evaluator to:  
a) observe the application of defined standards; 
b) examine documentary evidence of application of procedures 
describing the use of defined standards; 
c) interview development staff to check awareness of the application of 
defined standards and procedures. 
1296 A development site visit is a useful means of gaining confidence in the 
procedures being used. Any decision not to make such a visit shoul d be 
determined in consultation with the evaluation authority. 
1297 The evaluator compares the provided implementation representation with the 
description of the applied implementation standards and verifies their use. 
Class ALC: Life-cycle support 
Page 278 of 430 Version 3.1 April 2017 
1298 At this level it is required that the comp lete provided implementation 
representation of the TSF is based on implementation standards, including 
third party contributions. This may require the evaluator to visit the sites of 
contributors. The evaluator may consult the configuration list required b y the 
CM scope (ALC_CMS) to see who has developed which part of the TOE. 
1299 Note that parts of the TOE which are not TSF relevant do not need to be 
examined. 
1300 This work unit may be performed in conjunction with the evaluation 
activities under ADV_IMP. 
Class ATE: Tests 
April 2017 Version 3.1 Page 279 of 430 
15 Class ATE: Tests 
15.1 Introduction 
1301 The goal of this activity is to determine whether the TOE behaves as 
described in the ST and as specified in the evaluation evidence (described in 
the ADV class). This determination is achieved through some combination of 
the developer's own functional testing of the TSF ( Functional tests 
(ATE_FUN)) and independent testing the TSF by the evaluator ( Independent 
testing (ATE_IND) ). At the lowest level of assurance, there is no 
requirement for developer involvement, so the only testing is conducted by 
the evaluator, using the limited available information about the TOE. 
Additional assurance is gained as the developer becomes increasingly 
involved both in testing and in providing additional information about the 
TOE, and as the evaluator increases the independent testing activities. 
15.2 Application notes 
1302 Testing of the TSF is conducted by the evaluator and, in most cases, by the 
developer. The evaluator's testing efforts consist not only of creating and 
running original tests, but also of assessing the adequacy of the developer's 
tests and re-running a subset of them. 
1303 The evaluator analyses the developer's tests to determine the ext ent to which 
they are sufficient to demonstrate that TSFI (see Functional specification 
(ADV_FSP)) perform as specified, and to understand the developer's 
approach to testing. Similarly, the evaluator analyses the developer's tests to 
determine the extent to which they are sufficient to demonstrate the internal 
behaviour and properties of the TSF. 
1304 The evaluator also executes a subset of the developer's tests as documented 
to gain confidence in the developer's test results: the evaluator w ill use the 
results of this analysis as an input to independently testing a subset of the 
TSF. With respect to this subset, the evaluator takes a testing approach that is 
different from that of the developer, particularly if the developer's tests have 
shortcomings. 
1305 To determine the adequacy of developer's test documentation or to create 
new tests, the evaluator needs to understand the desired expected behaviour 
of the TSF, both internally and as seen at the TSFI, in the context of the 
SFRs it is to satisfy.  The evaluator may choose to divide the TSF and TSFI 
into subsets according to functional areas of the ST (audit subsystem, audit -
related TSFI, authentication module, authentication -related TSFI, etc.) if 
they were not already divided in the ST, and focus on one subset of the TSF 
and TSFI at a time, examining the ST requirement and the relevant parts of 
the development and guidance documentation to gain an understanding of 
the way the TOE is expected to behave. This reliance upon the development 
documentation underscores the need for the dependencies on ADV by 
Coverage (ATE_COV) and Depth (ATE_DPT). 
Class ATE: Tests 
Page 280 of 430 Version 3.1 April 2017 
1306 The CC has separated coverage and depth from functional tests to increase 
the flexibility when a pplying the components of the families. However, the 
requirements of the families are intended to be applied together to confirm 
that the TSF operates according to its specification. This tight coupling of 
families has led to some duplication of evaluator work units across sub -
activities. These application notes are used to minimise duplication of text 
between sub-activities. 
15.2.1 Understanding the expected behaviour of the TOE 
1307 Before the adequacy of test documentation can be accurately evaluated, or 
before new tests can be created, the evaluator has to understand the desired 
expected behaviour of a security function in the context of the requirements 
it is to satisfy. 
1308 As mentioned earlier, the evaluator may choose to subset the TSF and TSFI 
according to SFRs (au dit, authentication, etc.) in the ST and focus on one 
subset at a time. The evaluator examines each ST requirement and the 
relevant parts of the functional specification and guidance documentation to 
gain an understanding of the way the related TSFI is exp ected to behave. 
Similarly, the evaluator examines the relevant parts of the TOE design and 
security architecture documentation to gain an understanding of the way the 
related modules or subsystems of the TSF are expected to behave. 
1309 With an understanding of the expected behaviour, the evaluator examines the 
test plan to gain an understanding of the testing approach. In most cases, the 
testing approach will entail a TSFI being stimulated and its responses 
observed. Externally-visible functionality can be tes ted directly; however, in 
cases where functionality is not visible external to the TOE (for example, 
testing the residual information protection functionality), other means will 
need to be employed. 
15.2.2 Testing vs. alternate approaches to verify the expected 
behaviour of functionality 
1310 In cases where it is impractical or inadequate to test specific functionality 
(where it provides no externally -visible TSFI), the test plan should identify 
the alternate approach to verify expected behaviour. It is the evaluator's  
responsibility to determine the suitability of the alternate approach. However, 
the following should be considered when assessing the suitability of alternate 
approaches:  
a) an analysis of the implementation representation to determine that the 
required behaviour should be exhibited by the TOE is an acceptable 
alternate approach. This could mean a code inspection for a software 
TOE or perhaps a chip mask inspection for a hardware TOE.  
b) it is acceptable to use evidence of developer integration or module 
testing, even if the claimed assurance requirements do not include 
availability of lower level descriptions of the TOE modules (e.g. 
Evaluation of sub -activity (ADV_TDS.3) ) or implementation 
Class ATE: Tests 
April 2017 Version 3.1 Page 281 of 430 
(Implementation representation (ADV_IMP) ). If evidence of 
developer integration or module testing is used in verifying the 
expected behaviour of a security functionality, care should be given 
to confirm that the testing evidence reflects the current 
implementation of the TOE. If the su bsystems or modules have been 
changed since testing occurred, evidence that the changes were 
tracked and addressed by analysis or further testing will usually be 
required.  
1311 It should be emphasised that supplementing the testing effort with alternate 
approaches should only be undertaken when both the developer and 
evaluator determine that there exists no other practical means to test the 
expected behaviour. 
15.2.3 Verifying the adequacy of tests 
1312 Test pre-requisites are necessary to establish the required initial co nditions 
for the test. They may be expressed in terms of parameters that must be set or 
in terms of test ordering in cases where the completion of one test establishes 
the necessary pre -requisites for another test. The evaluator must determine 
that the pre-requisites are complete and appropriate in that they will not bias 
the observed test results towards the expected test results. 
1313 The test steps and expected results specify the actions and parameters to be 
applied to the TSFI as well as how the expected re sults should be verified 
and what they are. The evaluator must determine that the test steps and 
expected results are consistent with the descriptions of the TSFI in the 
functional specification. This means that each characteristic of the TSFI 
behaviour ex plicitly described in the functional specification should have 
tests and expected results to verify that behaviour. 
1314 The overall aim of this testing activity is to determine that each subsystem, 
module, and TSFI has been sufficiently tested against the beha vioural claims 
in the functional specification, TOE design, and architecture description. At 
the higher assurance levels, testing also includes bounds testing and negative 
testing. The test procedures will provide insight as to how the TSFIs, 
modules, and subsystems have been exercised by the developer during 
testing. The evaluator uses this information when developing additional tests 
to independently test the TSF. 
Class ATE: Tests 
Page 282 of 430 Version 3.1 April 2017 
15.3 Coverage (ATE_COV) 
15.3.1 Evaluation of sub-activity (ATE_COV.1) 
15.3.1.1 Objectives 
1315 The objective of this sub-activity is to determine whether the developer has 
tested the TSFIs, and that the developer's test coverage evidence shows 
correspondence between the tests identified in the test documentation and the 
TSFIs described in the functional specification. 
15.3.1.2 Input 
1316 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the functional specification;  
c) the test documentation;  
d) the test coverage evidence.  
15.3.1.3 Application notes 
1317 The coverage analysis provided by the developer is required to show the 
correspondence be tween the tests provided as evaluation evidence and the 
functional specification. However, the coverage analysis need not 
demonstrate that all TSFI have been tested, or that all externally -visible 
interfaces to the TOE have been tested. Such shortcomings are considered by 
the evaluator during the independent testing ( Evaluation of sub -activity 
(ATE_IND.2)) sub-activity. 
15.3.1.4 Action ATE_COV.1.1E 
ATE_COV.1.1C The evidence of the test coverage shall show the correspondence between 
the tests in the test documentation and the TSFIs in the functional 
specification.  
ATE_COV.1-1 The evaluator shall examine the test coverage evidence to determine that the 
correspondence between the tests identified in the test documentation and the 
TSFIs described in the functional specification is accurate. 
1318 Correspondence may take the form of a table or matrix. The coverage 
evidence required for this component will reveal the extent of coverage, 
rather than to show complete coverage. In cases where coverage is shown to 
be poor the evaluator should increase the level of independent testing to 
compensate. 
Class ATE: Tests 
April 2017 Version 3.1 Page 283 of 430 
15.3.2 Evaluation of sub-activity (ATE_COV.2) 
15.3.2.1 Objectives 
1319 The objective of this sub -activity is to determine whether the developer has 
tested all of the TSFIs, and that the developer's test coverage evidence shows 
correspondence between the tests identified in the test documentation and the 
TSFIs described in the functional specification. 
15.3.2.2 Input 
a) the ST;  
b) the functional specification;  
c) the test documentation;  
d) the test coverage analysis.  
15.3.2.3 Action ATE_COV.2.1E 
ATE_COV.2.1C The analysis of the test coverage shall demonstrate the correspondence 
between the tests in the test documentation and the TSFIs in the functional 
specification.  
ATE_COV.2-1 The evaluator shall examine the test coverage analysis to determine that the 
correspondence between the tests in the test documentation and the interfaces 
in the functional specification is accurate. 
1320 A simple cross -table may be sufficient to show test correspondence. The 
identification of the tests and the interfaces presented in the test coverage 
analysis has to be unambiguous. 
1321 The evaluator is reminded that this does not imply that all tests in the test 
documentation must map to interfaces in the functional specification. 
ATE_COV.2-2 The evaluator shall examine  the test plan to determine that the testing 
approach for each interface demonstrates the expected behaviour of that 
interface. 
1322 Guidance on this work unit can be found in:  
a) 15.2.1, Understanding the expected behaviour of the TOE 
b) 15.2.2, Testing vs. alternate approaches to verify the expected 
behaviour of functionality 
ATE_COV.2-3 The evaluator shall examine  the test procedures to determine that the test 
prerequisites, test steps and expected result(s) adequately test each interface. 
1323 Guidance on this work units, as it pertains to the functional specification, can 
be found in:  
Class ATE: Tests 
Page 284 of 430 Version 3.1 April 2017 
a) 15.2.3, Verifying the adequacy of tests 
ATE_COV.2.2C The analysis of the test coverage shall demonstrate that all TS FIs in the 
functional specification have been tested.  
ATE_COV.2-4 The evaluator shall examine the test coverage analysis to determine that the 
correspondence between the interfaces in the functional specificatio n and the 
tests in the test documentation is complete. 
1324 All TSFIs that are described in the functional specification have to be present 
in the test coverage analysis and mapped to tests in order for completeness to 
be claimed, although exhaustive specificat ion testing of interfaces is not 
required. Incomplete coverage would be evident if an interface was identified 
in the functional specification and no test was mapped to it. 
1325 The evaluator is reminded that this does not imply that all tests in the test 
documentation must map to interfaces in the functional specification. 
15.3.3 Evaluation of sub-activity (ATE_COV.3) 
1326 There is no general guidance; the scheme should be consulted for guidance 
on this sub-activity. 
Class ATE: Tests 
April 2017 Version 3.1 Page 285 of 430 
15.4 Depth (ATE_DPT) 
15.4.1 Evaluation of sub-activity (ATE_DPT.1) 
15.4.1.1 Objectives 
1327 The objective of this sub -activity is to determine whether the developer has 
tested the TSF subsystems against the TOE design and the security 
architecture description. 
15.4.1.2 Input 
a) the ST;  
b) the functional specification;  
c) the TOE design;  
d) the security architecture description;  
e) the test documentation;  
f) the depth of testing analysis.  
15.4.1.3 Action ATE_DPT.1.1E 
ATE_DPT.1.1C The analysis of the depth of testing shall de monstrate the correspondence 
between the tests in the test documentation and the TSF subsystems in the 
TOE design.  
ATE_DPT.1-1 The evaluator shall examine the depth of testing analysis to determine that 
the descriptions of the behaviour of TSF subsystems and of their interactions 
is included within the test documentation. 
1328 This work unit verifies the content of the correspondence between the tests 
and the descriptions in the TOE design. In cases where the descript ion of the 
TSF's architectural soundness (in Security Architecture (ADV_ARC) ) cites 
specific mechanisms, this work unit also verifies the correspondence 
between the tests and the descriptions of the behaviour of such mechanisms. 
1329 A simple  cross-table may be sufficient to show test correspondence. The 
identification of the tests and the behaviour/interaction presented in the 
depth-of coverage analysis has to be unambiguous. 
1330 When Evaluation of sub -activity (ATE_DPT.1)  is combined with a 
component of TOE design (ADV_TDS) , which includes descriptions at the 
module level (e.g. Evaluation of sub -activity (ADV_TDS.3) ), the level of 
detail needed to map the test cases to the behaviour of the subsystems may 
require information from the module description to be used. This is because 
Evaluation of sub-activity (ADV_TDS.3) allows the description of details to 
be shifted from the subsystem level to the module level, or even  to omit the 
subsystems altogether. 
Class ATE: Tests 
Page 286 of 430 Version 3.1 April 2017 
1331 In any case, the required level of detail in the provided reference to the tested 
behaviour can be defined as “the level of detail required for the description 
of subsystem behaviour as defined by Evaluation of sub -activity 
(ADV_TDS.2) (in particular work unit ADV_TDS.2-4)”. It states that a 
detailed description of the behaviour typically discusses how the 
functionality is provided, in terms of what key data and data structures re 
present; what control relationships exist within a subsytem and how these 
elements work together to provide the SFR-enforcing behaviour. 
1332 The evaluator is reminded that not all tests in the test documentation must 
map to a subsystem behaviour or interaction description. 
ATE_DPT.1-2 The evaluator shall examine  the test plan, test prerequisites, test steps and 
expected result(s) to determine that the testing approach for the behaviour 
description demonstrates the behaviour of that subsystem as described in the 
TOE design. 
1333 Guidance on this work unit can be found in:  
a) 15.2.1, Understanding the expected behaviour of the TOE 
b) 15.2.2, Testing vs. alternate approaches to verify the expected 
behaviour of functionality 
1334 When Evaluation of sub -activity (ATE_DPT.1)  is combined with a 
component of TOE design (ADV_TDS) , which includes descrip tions at the 
module level (e.g. Evaluation of sub -activity (ADV_TDS.3) ), the level of 
detail needed to map the test cases to the behaviour of the subsystems may 
require information from the module description to be used. This is becaus e 
Evaluation of sub-activity (ADV_TDS.3) allows the description of details to 
be shifted from the subsystem level to the module level, or even to omit the 
subsystems altogether. 
1335 In any case, the required level of detail in the provided reference to the tested 
behaviour can be defined as “the level of detail required for the description 
of subsystem behaviour as defined by Evaluation of sub -activity 
(ADV_TDS.2) (in particular work unit ADV_TDS.2-4)”. It states that a 
detailed description of the behaviour typically discusses how the 
functionality is provided, in terms of what key data and data structures re 
present; what control relationships exist within a subsytem and how these 
elements work together to provide the SFR-enforcing behaviour. 
1336 If TSF subsystem interfaces are described, the behaviour of those subsystems 
may be tested directly from those interfaces. Otherwise, the behaviour of 
those subsystems is tested from the TSFI interfaces. Or a combination of the 
two may be employed. Whatever strategy is used the evaluator will consider 
its appropriateness for adequately testing the behaviour that is described in 
the TOE design. 
ATE_DPT.1-3 The evaluator shall examine  the test plan, test prerequisites, test steps and 
expected result(s) to determine that the testing approach for the behaviour 
Class ATE: Tests 
April 2017 Version 3.1 Page 287 of 430 
description demonstrates the interactions among subsystems as described in 
the TOE design. 
1337 While the previous work  unit addresses behaviour of subsystems, this work 
unit addresses the interactions among subsystems. 
1338 Guidance on this work unit can be found in:  
a) 15.2.1, Understanding the expected behaviour of the TOE 
b) 15.2.2, Testing vs. alternate approaches to verify the expected 
behaviour of functionality 
1339 If TSF subsystem interfaces are described, the interactions with other 
subsystems may be tested directly from those int erfaces. Otherwise, the 
interactions among subsystems must be inferred from the TSFI interfaces. 
Whatever strategy is used the evaluator will consider its appropriateness for 
adequately testing the interactions among subsystems that are described in 
the TOE design. 
ATE_DPT.1.2C The analysis of the depth of testing shall demonstrate that all TSF 
subsystems in the TOE design have been tested.  
ATE_DPT.1-4 The evaluator  shall examine  the test procedures to determine that all 
descriptions of TSF subsystem behaviour and interaction are tested. 
1340 This work unit verifies the completeness of work unit ATE_DPT.1-1. All 
descriptions of TSF subsystem behavio ur and of interactions among TSF 
subsystems that are provided in the TOE design have to be tested. 
Incomplete depth of testing would be evident if a description of TSF 
subsystem behaviour or of interactions among TSF subsystems was 
identified in the TOE design and no tests could be attributed to it. 
1341 When Evaluation of sub -activity (ATE_DPT.1)  is combined with a 
component of TOE design (ADV_TDS) , which includes descriptions at the 
module level (e.g. Evaluation of sub -activity (ADV_TDS.3) ), the level of 
detail needed to map the test cases to the behaviour of the subsystems may 
require information from the module description to be used. This is because 
Evaluation of sub-activity (ADV_TDS.3) allows the description of details to 
be shifted from the subsystem level to the module level, or even to omit the 
subsystems altogether. 
1342 In any case, the required level of detail in the provided reference to the tested 
behaviour can be defined a s “the level of detail required for the description 
of subsystem behaviour as defined by Evaluation of sub -activity 
(ADV_TDS.2) (in particular work unit ADV_TDS.2-4)”. It states that a 
detailed description of the  behaviour typically discusses how the 
functionality is provided, in terms of what key data and data structures re 
present; what control relationships exist within a subsytem and how these 
elements work together to provide the SFR-enforcing behaviour. 
Class ATE: Tests 
Page 288 of 430 Version 3.1 April 2017 
1343 The evaluator is reminded that this does not imply that all tests in the test 
documentation must map to the subsystem behaviour or interaction 
description in the TOE design. 
15.4.2 Evaluation of sub-activity (ATE_DPT.2) 
15.4.2.1 Objectives 
1344 The objective of this sub -activity is to determine whether the developer has 
tested all the TSF subsystems and SFR -enforcing modules against the TOE 
design and the security architecture description. 
15.4.2.2 Input 
a) the ST;  
b) the functional specification;  
c) the TOE design;  
d) the security architecture description;  
e) the test documentation;  
f) the depth of testing analysis.  
15.4.2.3 Action ATE_DPT.2.1E 
ATE_DPT.2.1C The analysis of the depth of testing shall demonstrate the cor respondence 
between the tests in the test documentation and the TSF subsystems and 
SFR-enforcing modules in the TOE design.  
ATE_DPT.2-1 The evaluator shall examine the depth of testing analysis to determine that  
descriptions of the behaviour of TSF subsystems and of their interactions are 
included within the test documentation. 
1345 This work unit verifies the content of the correspondence between the tests 
and the descriptions in the TOE design. In cases where the de scription of the 
TSF's architectural soundness (in Security Architecture (ADV_ARC) ) cites 
specific mechanisms, this work unit also verifies the correspondence 
between the tests and the descriptions of the behaviour of such mechanisms. 
1346 A simple cross -table may be sufficient to show test correspondence. The 
identification of the tests and the behaviour/interaction presented in the 
depth-of coverage analysis has to be unambiguous. 
1347 The evaluator is reminded that not all tests in the test docu mentation must 
map to a subsystem behaviour or interaction description. 
ATE_DPT.2-2 The evaluator shall examine  the test plan, test prerequisites, test steps and 
expected result(s) to determine that the testing a pproach for the behaviour 
Class ATE: Tests 
April 2017 Version 3.1 Page 289 of 430 
description demonstrates the behaviour of that subsystem as described in the 
TOE design. 
1348 Guidance on this work unit can be found in:  
a) 15.2.1, Understanding the expected behaviour of the TOE 
b) 15.2.2, Testing vs. alternate approaches to verify the expected 
behaviour of functionality 
1349 If TSF subsystem interfaces are described, the behaviour of those subsystems 
may be tested directly from those interfaces. Otherwise, the behaviour of 
those subsystems is tested from the TSFI interfaces. Or a combination of the 
two may be employed. Whatever strategy is used the evaluator will consider 
its appropriateness for adequately testing the behaviour t hat is described in 
the TOE design. 
ATE_DPT.2-3 The evaluator shall examine  the test plan, test prerequisites, test steps and 
expected result(s) to determine that the testing approach for the behaviour 
description demonstrates the interactions among subsystems as described in 
the TOE design. 
1350 While the previous work unit addresses behaviour of subsystems, this work 
unit addresses the interactions among subsystems. 
1351 Guidance on this work unit can be found in:  
a) 15.2.1, Understanding the expected behaviour of the TOE 
b) 15.2.2, Testing vs. alternate approaches to verify the expected 
behaviour of functionality 
1352 If TSF subsyste m interfaces are described, the interactions with other 
subsystems may be tested directly from those interfaces. Otherwise, the 
interactions among subsystems must be inferred from the TSFI interfaces. 
Whatever strategy is used the evaluator will consider i ts appropriateness for 
adequately testing the interactions among subsystems that are described in 
the TOE design. 
ATE_DPT.2-4 The evaluator shall examine the depth of testing analysis to determine that 
the interf aces of SFR -enforcing modules are included within the test 
documentation. 
1353 This work unit verifies the content of the correspondence between the tests 
and the descriptions in the TOE design. In cases where the description of the 
TSF's architectural soundnes s (in Security Architecture (ADV_ARC) ) cites 
specific mechanisms at the modular level, this work unit also verifies the 
correspondence between the tests and the descriptions of the behaviour of 
such mechanisms. 
Class ATE: Tests 
Page 290 of 430 Version 3.1 April 2017 
1354 A simple cross -table may b e sufficient to show test correspondence. The 
identification of the tests and the SFR -enforcing modules presented in the 
depth-of coverage analysis has to be unambiguous. 
1355 The evaluator is reminded that not all tests in the test documentation must 
map to the interfaces of SFR-enforcing modules. 
ATE_DPT.2-5 The evaluator shall examine  the test plan, test prerequisites, test steps and 
expected result(s) to determine that the testing approach for each SFR -
enforcing mo dule interface demonstrates the expected behaviour of that 
interface. 
1356 While work unit ATE_DPT.2-2 addresses expected behaviour of subsystems, 
this work unit addresses expected behaviour of the SFR -enforcing module 
interfaces that are covered by ATE_DPT.2-4. 
1357 Guidance on this work unit can be found in:  
a) 15.2.1, Understanding the expected behaviour of the TOE 
b) 15.2.2, Testing vs. alternate approaches to verify the expected 
behaviour of functionality 
1358 Testing of an interface may be performed directly at that interface, or at the 
external interfaces, or a combination of both. Whatever strategy is u sed the 
evaluator will consider its appropriateness for adequately testing the 
interfaces. Specifically the evaluator determines whether testing at the 
internal interfaces is necessary or whether these internal interfaces can be 
adequately tested (albeit i mplicitly) by exercising the external interfaces. 
This determination is left to the evaluator, as is its justification. 
ATE_DPT.2.2C The analysis of the depth of testing shall demonstrate that all TSF 
subsystems in the TOE design have been tested.  
ATE_DPT.2-6 The evaluator shall examine  the test procedures to determine that all 
descriptions of TSF subsystem behaviour and interaction are tested. 
1359 This work unit verifi es the completeness of work unit ATE_DPT.2-1. All 
descriptions of TSF subsystem behaviour and of interactions among TSF 
subsystems that are provided in the TOE design have to be tested. 
Incomplete depth of testing would be evident if  a description of TSF 
subsystem behaviour or of interactions among TSF subsystems was 
identified in the TOE design and no tests could be attributed to it. 
1360 The evaluator is reminded that this does not imply that all tests in the test 
documentation must map to the subsystem behaviour or interaction 
description in the TOE design. 
ATE_DPT.2.3C The analysis of the depth of testing shall demonstrate that the SFR -
enforcing modules in the TOE design have been tested.  
Class ATE: Tests 
April 2017 Version 3.1 Page 291 of 430 
ATE_DPT.2-7 The evaluator shall examine  the test procedures to determine that all 
interfaces of SFR-enforcing modules are tested. 
1361 This work unit verifies the completeness of work unit ATE_DPT.2-4. All 
interfaces of SFR -enforcing modules that are provided in the TOE design 
have to be tested. Incomplete depth of testing would be evident if any 
interface of any SFR -enforcing modules was identified in the TOE design 
and no tests could be attributed to it. 
1362 The evaluator is reminded that this does not imply that all tests in the test 
documentation must map to an interface of an SFR -enforcing module in the 
TOE design. 
15.4.3 Evaluation of sub-activity (ATE_DPT.3) 
15.4.3.1 Objectives 
1363 The objective of this sub -activity is to determine whether the developer has 
tested the all the TSF subsystems and modules against the TOE design and 
the security architecture description. 
15.4.3.2 Input 
a) the ST;  
b) the functional specification;  
c) the TOE design;  
d) the security architecture description;  
e) the test documentation;  
f) the depth of testing analysis.  
15.4.3.3 Action ATE_DPT.3.1E 
ATE_DPT.3.1C The analysis of the depth of testing shall demonstrate the correspo ndence 
between the tests in the test documentation and the TSF subsystems and 
modules in the TOE design.  
ATE_DPT.3-1 The evaluator shall examine the depth of testing analysis to determine that 
descriptions of the behaviour of TSF subsystems and of their interactions are 
included within the test documentation. 
1364 This work unit verifies the content of the correspondence between the tests 
and the descriptions in the TOE design. A simple cross -table may be 
sufficient to show test correspondence. The identification of the tests and the 
behaviour/interaction presented in the depth -of coverage analysis has to be 
unambiguous. 
Class ATE: Tests 
Page 292 of 430 Version 3.1 April 2017 
1365 The evaluator is reminded that not all tests in the test documentation must 
map to a subsystem behaviour or interaction description. 
ATE_DPT.3-2 The evaluator shall examine  the test plan, test prerequisites, test steps and 
expected result(s) to determine that the testing approach for the behaviour 
description demonstrates the behaviour of that subsystem as described in the 
TOE design. 
1366 Guidance on this work unit can be found in:  
a) 15.2.1, Understanding the expected behaviour of the TOE 
b) 15.2.2, Testing vs. alternate approaches to verify the expected 
behaviour of functionality 
1367 If TSF subsystem interfaces are provided, the behaviour of those subsystems 
may be performed directly from those interfaces. Otherwise, the behaviour of 
those subsystems is tested from the TSFI interfaces. Or a combination of the 
two may be employed. Whatever strategy is used the evaluator will consider 
its appropriateness for adequately testing the behaviour that is described in 
the TOE design. 
ATE_DPT.3-3 The evaluator shall examine  the test plan, test prerequisites, test steps and 
expected result(s) to determine that the testing approach for the behaviour 
description demonstrates the interactions amon g subsystems as described in 
the TOE design. 
1368 Guidance on this work unit can be found in:  
a) 15.2.1, Understanding the expected behaviour of the TOE 
b) 15.2.2, Testing vs. alternate approaches to verify the expected 
behaviour of functionality 
1369 While the previous work unit addresses behaviour of subsystems, this work 
unit addresses the interactions among subsystems. 
1370 If TSF subsystem interfaces are provided, the inter actions with other 
subsystems may be performed directly from those interfaces. Otherwise, the 
interactions among subsystems must be inferred from the TSFI interfaces. 
Whatever strategy is used the evaluator will consider its appropriateness for 
adequately testing the interactions among subsystems that are described in 
the TOE design. 
ATE_DPT.3-4 The evaluator shall examine the depth of testing analysis to determine that 
the interfaces of TSF modules are included within the test documentation. 
1371 This work unit verifies the content of the correspondence between the tests 
and the descriptions in the TOE design. A simple cross -table may be 
sufficient to show test correspondence. The identification of the tests and the 
behaviour/interaction presented in the depth -of coverage analysis has to be 
unambiguous. 
Class ATE: Tests 
April 2017 Version 3.1 Page 293 of 430 
1372 The evaluator is reminded that not all tests in the test documentation must 
map to a subsystem behaviour or interaction description. 
ATE_DPT.3-5 The evaluator shall examine  the test plan, test prerequisites, test steps and 
expected result(s) to determine that the testing approach for each TSF 
module interface demonstrates the expected behaviour of that interface. 
1373 Guidance on this work unit can be found in:  
a) 15.2.1, Understanding the expected behaviour of the TOE 
b) 15.2.2, Testing vs. alternate approaches to verify the expected 
behaviour of functionality 
1374 Testing of an interface may be performed directly at that interface, or at the 
external interfaces, or a combination of both. Whatever strategy is used the 
evaluator will consider its appropriateness for adequately testing the 
interfaces. Specifically the evaluator determines whether testing at the 
internal interfaces is necessary or whether these internal interfaces can be 
adequately tested (albeit implicitly) by exercising the external interfaces. 
This determination is left to the evaluator, as is its justification. 
ATE_DPT.3.2C The analysis of the depth of testing shall demonstrate that all TSF 
subsystems in the TOE design have been tested.  
ATE_DPT.3-6 The evaluator shall examine  the test procedures to determine that all 
descriptions of TSF subsystem behaviour and interaction are tested. 
1375 This work unit verifies the completeness of work unit ATE_DPT.3-1. All 
descriptions o f TSF subsystem behaviour and of interactions among TSF 
subsystems that are provided in the TOE design have to be tested. 
Incomplete depth of testing would be evident if a description of TSF 
subsystem behaviour or of interactions among TSF subsystems was 
identified in the TOE design and no tests could be attributed to it. 
1376 The evaluator is reminded that this does not imply that all tests in the test 
documentation must map to the subsystem behaviour or interaction 
description in the TOE design. 
ATE_DPT.3.3C The analysis of the depth of testing shall demonstrate that all TSF modules 
in the TOE design have been tested.  
ATE_DPT.3-7 The evaluator shall examine  the test pro cedures to determine that all 
interfaces of all TSF modules are tested. 
1377 This work unit verifies the completeness of work unit ATE_DPT.3-4. All 
interfaces of TSF modules that are provided in the TOE design have to be 
tested. Incomplete depth of testing would be evident if any interface of any 
TSF module was identified in the TOE design and no tests could be 
attributed to it. 
Class ATE: Tests 
Page 294 of 430 Version 3.1 April 2017 
1378 The evaluator is reminded that this does not imply that all tests in the test 
documentation must map to an interface of a TSF module in the TOE design. 
15.4.4 Evaluation of sub-activity (ATE_DPT.4) 
1379 There is no general guidance; the scheme should be consulted for guidance 
on this sub-activity. 
Class ATE: Tests 
April 2017 Version 3.1 Page 295 of 430 
15.5 Functional tests (ATE_FUN) 
15.5.1 Evaluation of sub-activity (ATE_FUN.1) 
15.5.1.1 Objectives 
1380 The objective of this sub -activity is to determine whether the developer 
correctly performed and documented the tests in the test documentation. 
15.5.1.2 Input 
1381 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the functional specification;  
c) the test documentation.  
15.5.1.3 Application notes 
1382 The extent to which the test documentation is required to cover the TSF is 
dependent upon the coverage assurance component. 
1383 For the developer tests provided, the evaluator determines whether the tests 
are repeatable, and the exten t to which the developer's tests can be used for 
the evaluator's independent testing effort. Any TSFI for which the 
developer's test results indicate that it might not perform as specified should 
be tested independently by the evaluator to determine whether or not it does. 
15.5.1.4 Action ATE_FUN.1.1E 
ATE_FUN.1.1C The test documentation shall consist of test plans, expected test results and 
actual test results.  
ATE_FUN.1-1 The evaluator shall check  that the test documentation includes test plans, 
expected test results and actual test results. 
1384 The evaluator checks that test plans, expected tests results and actual test 
results are included in the test documentation. 
ATE_FUN.1.2C The test plans shall identify the tests to be performed and describe the 
scenarios for performing each test. These scenarios shall include any 
ordering dependencies on the results of other tests.  
ATE_FUN.1-2 The evaluator shall examine the test plan to determine that it describes the 
scenarios for performing each test. 
1385 The evaluator determines that the test plan provi des information about the 
test configuration being used: both on the configuration of the TOE and on 
any test equipment being used. This information should be detailed enough 
to ensure that the test configuration is reproducible. 
Class ATE: Tests 
Page 296 of 430 Version 3.1 April 2017 
1386 The evaluator also determi nes that the test plan provides information about 
how to execute the test: any necessary automated set -up procedures (and 
whether they require privilege to run), inputs to be applied, how these inputs 
are applied, how output is obtained, any automated clea n-up procedures (and 
whether they require privilege to run), etc. This information should be 
detailed enough to ensure that the test is reproducible. 
1387 The evaluator may wish to employ a sampling strategy when performing this 
work unit. 
ATE_FUN.1-3 The evaluator shall examine  the test plan to determine that the TOE test 
configuration is consistent with the ST. 
1388 The TOE referred to in the developer's test plan should have the same unique 
reference as established by th e CM capabilities (ALC_CMC)  sub-activities 
and identified in the ST introduction. 
1389 It is possible for the ST to specify more than one configuration for evaluation. 
The evaluator verifies that all test configurations identified in the deve loper 
test documentation are consistent with the ST. For example, the ST might 
define configuration options that must be set, which could have an impact 
upon what constitutes the TOE by including or excluding additional portions. 
The evaluator verifies that all such variations of the TOE are considered. 
1390 The evaluator should consider the security objectives for the operational 
environment described in the ST that may apply to the test environment. 
There may be some objectives for the operational environment that do not 
apply to the test environment. For example, an objective about user 
clearances may not apply; however, an objective about a single point of 
connection to a network would apply. 
1391 The evaluator may wish to employ a sampling strategy when performin g this 
work unit. 
1392 If this work unit is applied to a component TOE that might be 
used/integrated in a composed TOE (see Class ACO: Composition ), the 
following will apply. In the instances that the component TOE under 
evaluation depends on oth er components in the operational environment to 
support their operation, the developer may wish to consider using the other 
component(s) that will be used in the composed TOE to fulfil the 
requirements of the operational environment as one of the test conf igurations. 
This will reduce the amount an additional testing that will be required for the 
composed TOE evaluation. 
ATE_FUN.1-4 The evaluator shall examine  the test plans to determine that sufficient 
instructions are provided for any ordering dependencies. 
1393 Some steps may have to be performed to establish initial conditions. For 
example, user accounts need to be added before they can be deleted. An 
example of ordering dependencies on the results of other tests is the need to 
perform actions in a test that will result in the generation of audit records, 
Class ATE: Tests 
April 2017 Version 3.1 Page 297 of 430 
before performing a test to consider the searching and sorting of those audit 
records. Another example of an ordering dependency would be where one 
test case generates a file of data to be used as input for another test case. 
1394 The evaluator may wish to employ a sampling strategy when performing this 
work unit. 
ATE_FUN.1.3C The expected test results shall show the anticipa ted outputs from a 
successful execution of the tests.  
ATE_FUN.1-5 The evaluator shall examine  the test documentation to determine that all 
expected tests results are included. 
1395 The expected test results are neede d to determine whether or not a test has 
been successfully performed. Expected test results are sufficient if they are 
unambiguous and consistent with expected behaviour given the testing 
approach. 
1396 The evaluator may wish to employ a sampling strategy when performing this 
work unit. 
ATE_FUN.1.4C The actual test results shall be consistent with the expected test results.  
ATE_FUN.1-6 The evaluator shall check  that the actual test results in the test 
documentation are consistent with the expected test results in the test 
documentation. 
1397 A comparison of the actual and expected test results provided by the 
developer will reveal any inconsistencies between the results. It ma y be that 
a direct comparison of actual results cannot be made until some data 
reduction or synthesis has been first performed. In such cases, the 
developer's test documentation should describe the process to reduce or 
synthesise the actual data. 
1398 For example, the developer may need to test the contents of a message buffer 
after a network connection has occurred to determine the contents of the 
buffer. The message buffer will contain a binary number. This binary number 
would have to be converted to another form of data representation in order to 
make the test more meaningful. The conversion of this binary representation 
of data into a higher -level representation will have to be described by the 
developer in enough detail to allow an evaluator to perform the c onversion 
process (i.e. synchronous or asynchronous transmission, number of stop bits, 
parity, etc.). 
1399 It should be noted that the description of the process used to reduce or 
synthesise the actual data is used by the evaluator not to actually perform the 
necessary modification but to assess whether this process is correct. It is up 
to the developer to transform the expected test results into a format that 
allows an easy comparison with the actual test results. 
Class ATE: Tests 
Page 298 of 430 Version 3.1 April 2017 
1400 The evaluator may wish to employ a sampling str ategy when performing this 
work unit. 
ATE_FUN.1-7 The evaluator shall report the developer testing effort, outlining the testing 
approach, configuration, depth and results. 
1401 The developer testing information recor ded in the ETR allows the evaluator 
to convey the overall testing approach and effort expended on the testing of 
the TOE by the developer. The intent of providing this information is to give 
a meaningful overview of the developer testing effort. It is not intended that 
the information regarding developer testing in the ETR be an exact 
reproduction of specific test steps or results of individual tests. The intention 
is to provide enough detail to allow other evaluators and evaluation 
authorities to gain some  insight about the developer's testing approach, 
amount of testing performed, TOE test configurations, and the overall results 
of the developer testing. 
1402 Information that would typically be found in the ETR section regarding the 
developer testing effort is:  
a) TOE test configurations. The particular configurations of the TOE 
that were tested, including whether any privileged code was required 
to set up the test or clean up afterwards;  
b) testing approach. An account of the overall developer testing strategy 
employed;  
c) testing results. A description of the overall developer testing results.  
1403 This list is by no means exhaustive and is only intended to provide some 
context as to the type of information that should be present in the ETR 
concerning the developer testing effort. 
15.5.2 Evaluation of sub-activity (ATE_FUN.2) 
1404 There is no general guidance; the scheme should be consulted for guidance 
on this sub-activity. 
Class ATE: Tests 
April 2017 Version 3.1 Page 299 of 430 
15.6 Independent testing (ATE_IND) 
15.6.1 Evaluation of sub-activity (ATE_IND.1) 
15.6.1.1 Objectives 
1405 The goal of this activity is to determine, by independently testing a subset of 
the TSFI, whether the TOE behaves as specified in the functional 
specification and guidance documentation. 
15.6.1.2 Input 
1406 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the functional specification;  
c) the operational user guidance;  
d) the preparative user guidance;  
e) the TOE suitable for testing.  
15.6.1.3 Action ATE_IND.1.1E 
ATE_IND.1.1C The TOE shall be suitable for testing.  
ATE_IND.1-1 The evaluator shall examine the TOE to determine that the test configuration 
is consistent with the configuration under evaluation as specified in the ST. 
1407 The TOE provided by the developer should  have the same unique reference 
as established by the CM capabilities (ALC_CMC)  sub-activities and 
identified in the ST introduction. 
1408 It is possible for the ST to specify more than one configuration for evaluation. 
The TOE may comprise a  number of distinct hardware and software entities 
that need to be tested in accordance with the ST. The evaluator verifies that 
all test configurations are consistent with the ST. 
1409 The evaluator should consider the security objectives for the operational 
environment described in the ST that may apply to the test environment and 
ensure they are met in the testing environment. There may be some 
objectives for the operational environment that do not apply to the test 
environment. For example, an objective about user clearances may not apply; 
however, an objective about a single point of connection to a network would 
apply. 
1410 If any test resources are used (e.g. meters, analysers) it will be the evaluator's 
responsibility to ensure that these resources are calibrated correctly. 
Class ATE: Tests 
Page 300 of 430 Version 3.1 April 2017 
ATE_IND.1-2 The evaluator shall examine the TOE to determine that it has been installed 
properly and is in a known state. 
1411 It is possible for the evaluator to determine the state of the TOE in a num ber 
of ways. For example, previous successful completion of the Evaluation of 
sub-activity (AGD_PRE.1)  sub-activity will satisfy this work unit if the 
evaluator still has confidence that the TOE being used for testing was 
installed pro perly and is in a known state. If this is not the case, then the 
evaluator should follow the developer's procedures to install and start up the 
TOE, using the supplied guidance only. 
1412 If the evaluator has to perform the installation procedures because the TOE is 
in an unknown state, this work unit when successfully completed could 
satisfy work unit AGD_PRE.1-3. 
15.6.1.4 Action ATE_IND.1.2E 
ATE_IND.1-3 The evaluator shall devise a test subset. 
1413 The evaluator selects a test subset and testing strategy that is appropriate for 
the TOE. One extreme testing strategy would be to have the test subset 
contain as many interfaces as possible tested with little rigour. Another 
testing strategy would be to have the test subset contain a few interfaces 
based on their perceived relevance and rigorously test these interfaces. 
1414 Typically the testing approach taken by the evaluator should fall somewhere 
between these two extrem es. The evaluator should exercise most of the 
interfaces using at least one test, but testing need not demonstrate exhaustive 
specification testing. 
1415 The evaluator, when selecting the subset of the interfaces to be tested, should 
consider the following factors:  
a) The number of interfaces from which to draw upon for the test subset. 
Where the TSF includes only a small number of relatively simple 
interfaces, it may be practical to rigorously test all of the interfaces. 
In other cases this may not be cost-effective, and sampling is required.  
b) Maintaining a balance of evaluation activities. The evaluator effort 
expended on the test activity should be commensurate with that 
expended on any other evaluation activity.  
1416 The evaluator selects the interfaces to compose the subset. This selection will 
depend on a number of factors, and consideration of these factors may also 
influence the choice of test subset size:  
a) Significance of interfaces. Those interfaces more significant than 
others should be included in the test s ubset. One major factor of 
“significance” is the security -relevance (SFR -enforcing interfaces 
would be more significant than SFR -supporting interfaces, which are 
more significant than SFR -non-interfering interfaces; see CC Part 3 
Class ATE: Tests 
April 2017 Version 3.1 Page 301 of 430 
Section Functional specification (ADV_FSP)). The other major factor 
of “significance” is the number of SFRs mapping to this interface (as 
determined when identifying the correspondence between levels of 
abstraction in ADV).  
b) Complexity of the interface. Complex interfaces may require 
complex tests that impose onerous requirements on the developer or 
evaluator, which may not be conducive to cost -effective evaluations. 
Conversely, they are a likely area to find errors and are good 
candidates for the subset. The evaluator will need to strike a balance 
between these considerations.  
c) Implicit testing. Testing some interfaces may often implicitly test 
other interfaces, and their inclusion in the subset may maximise the 
number of interfaces test ed (albeit implicitly). Certain interfaces will 
typically be used to provide a variety of security functionality, and 
will tend to be the target of an effective testing approach.  
d) Types of interfaces (e.g. programmatic, command -line, protocol). 
The evaluator should consider including tests for all different types of 
interfaces that the TOE supports.  
e) Interfaces that give rise to features that are innovative or unusual. 
Where the TOE contains innovative or unusual features, which may 
feature strongly in mark eting literature and guidance documents, the 
corresponding interfaces should be strong candidates for testing.  
1417 This guidance articulates factors to consider during the selection process of 
an appropriate test subset, but these are by no means exhaustive. 
ATE_IND.1-4 The evaluator shall produce  test documentation for the test subset that is 
sufficiently detailed to enable the tests to be reproducible. 
1418 With an understanding of the expected behaviour of the TSF, fro m the ST 
and the functional specification, the evaluator has to determine the most 
feasible way to test the interface. Specifically the evaluator considers:  
a) the approach that will be used, for instance, whether an external 
interface will be tested, or an internal interface using a test harness, or 
will an alternate test approach be employed (e.g. in exceptional 
circumstances, a code inspection, if the implementation 
representation is available);  
b) the interface(s) that will be used to test and observe responses;  
c) the initial conditions that will need to exist for the test (i.e. any 
particular objects or subjects that will need to exist and security 
attributes they will need to have);  
Class ATE: Tests 
Page 302 of 430 Version 3.1 April 2017 
d) special test equipment that will be required to either stimulate an 
interface (e.g. packet generators) or make observations of an interface 
(e.g. network analysers).  
1419 The evaluator may find it practical to test each interface using a series of test 
cases, where each test case will test a very specific aspect of expected 
behaviour. 
1420 The evaluator's test documentation should specify the derivation of each test, 
tracing it back to the relevant interface(s). 
ATE_IND.1-5 The evaluator shall conduct testing. 
1421 The evaluator uses the test documen tation developed as a basis for executing 
tests on the TOE. The test documentation is used as a basis for testing but 
this does not preclude the evaluator from performing additional ad hoc tests. 
The evaluator may devise new tests based on behaviour of the  TOE 
discovered during testing. These new tests are recorded in the test 
documentation. 
ATE_IND.1-6 The evaluator shall record  the following information about the tests that 
compose the test subset:  
a) identification of the interface behaviour to be tested;  
b) instructions to connect and setup all required test equipment as 
required to conduct the test;  
c) instructions to establish all prerequisite test conditions;  
d) instructions to stimulate the interface;  
e) instructions for observing the behaviour of the interface;  
f) descriptions of all expected results and the necessary analysis to be 
performed on the observed behaviour for comparison against 
expected results;  
g) instructions to conclude the test and establish the necessar y post-test 
state for the TOE;  
h) actual test results.  
1422 The level of detail should be such that another evaluator could repeat the 
tests and obtain an equivalent result. While some specific details of the test 
results may be different (e.g. time and date fie lds in an audit record) the 
overall result should be identical. 
1423 There may be instances when it is unnecessary to provide all the information 
presented in this work unit (e.g. the actual test results of a test may not 
require any analysis before a comparison between the expected results can be 
Class ATE: Tests 
April 2017 Version 3.1 Page 303 of 430 
made). The determination to omit this information is left to the evaluator, as 
is the justification. 
ATE_IND.1-7 The evaluator shall check that all actual test results are co nsistent with the 
expected test results. 
1424 Any differences in the actual and expected test results may indicate that the 
TOE does not perform as specified or that the evaluator test documentation 
may be incorrect. Unexpected actual results may require correc tive 
maintenance to the TOE or test documentation and perhaps require re -
running of impacted tests and modifying the test sample size and 
composition. This determination is left to the evaluator, as is its justification. 
ATE_IND.1-8 The evaluator shall report in the ETR the evaluator testing effort, outlining 
the testing approach, configuration, depth and results. 
1425 The evaluator testing information reported in the ETR allows the evaluator to 
convey the overall test ing approach and effort expended on the testing 
activity during the evaluation. The intent of providing this information is to 
give a meaningful overview of the testing effort. It is not intended that the 
information regarding testing in the ETR be an exact reproduction of specific 
test instructions or results of individual tests. The intention is to provide 
enough detail to allow other evaluators and evaluation authorities to gain 
some insight about the testing approach chosen, amount of testing performed,  
TOE test configurations, and the overall results of the testing activity. 
1426 Information that would typically be found in the ETR section regarding the 
evaluator testing effort is:  
a) TOE test configurations. The particular configurations of the TOE 
that were tested;  
b) subset size chosen. The amount of interfaces that were tested during 
the evaluation and a justification for the size;  
c) selection criteria for the interfaces that compose the subset. Brief 
statements about the factors considered when selecting inte rfaces for 
inclusion in the subset;  
d) interfaces tested. A brief listing of the interfaces that merited 
inclusion in the subset;  
e) verdict for the activity. The overall judgement on the results of 
testing during the evaluation.  
1427 This list is by no means exha ustive and is only intended to provide some 
context as to the type of information that should be present in the ETR 
concerning the testing the evaluator performed during the evaluation. 
Class ATE: Tests 
Page 304 of 430 Version 3.1 April 2017 
15.6.2 Evaluation of sub-activity (ATE_IND.2) 
15.6.2.1 Objectives 
1428 The goal of this activity is to determine, by independently testing a subset of 
the TSF, whether the TOE behaves as specified in the design documentation, 
and to gain confidence in the developer's test results by performing a sample 
of the developer's tests. 
15.6.2.2 Input 
1429 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the functional specification;  
c) the TOE design description;  
d) the operational user guidance;  
e) the preparative user guidance;  
f) the configuration management documentation;  
g) the test documentation;  
h) the TOE suitable for testing.  
15.6.2.3 Action ATE_IND.2.1E 
ATE_IND.2.1C The TOE shall be suitable for testing.  
ATE_IND.2-1 The evaluator shall examine the TOE to determine that the test configuration 
is consistent with the configuration under evaluation as specified in the ST. 
1430 The TOE provided by the developer and identified in the test plan should 
have the same unique reference as establish ed by the CM capabilities 
(ALC_CMC) sub-activities and identified in the ST introduction. 
1431 It is possible for the ST to specify more than one configuration for evaluation. 
The TOE may comprise a number of distinct hardware and software en tities 
that need to be tested in accordance with the ST. The evaluator verifies that 
all test configurations are consistent with the ST. 
1432 The evaluator should consider the security objectives for the operational 
environment described in the ST that may appl y to the test environment and 
ensure they are met in the testing environment. There may be some 
objectives for the operational environment that do not apply to the test 
environment. For example, an objective about user clearances may not apply; 
however, an objective about a single point of connection to a network would 
apply. 
Class ATE: Tests 
April 2017 Version 3.1 Page 305 of 430 
1433 If any test resources are used (e.g. meters, analysers) it will be the evaluator's 
responsibility to ensure that these resources are calibrated correctly. 
ATE_IND.2-2 The evaluator shall examine the TOE to determine that it has been installed 
properly and is in a known state. 
1434 It is possible for the evaluator to determine the state of the TOE in a number 
of ways. For example, previous successfu l completion of the Evaluation of 
sub-activity (AGD_PRE.1)  sub-activity will satisfy this work unit if the 
evaluator still has confidence that the TOE being used for testing was 
installed properly and is in a known state. If this is no t the case, then the 
evaluator should follow the developer's procedures to install and start up the 
TOE, using the supplied guidance only. 
1435 If the evaluator has to perform the installation procedures because the TOE is 
in an unknown state, this work unit wh en successfully completed could 
satisfy work unit AGD_PRE.1-3. 
ATE_IND.2.2C The developer shall provide an equivalent set of resources to those that 
were used in the developer's functional testing of the TSF.  
ATE_IND.2-3 The evaluator shall examine the set of resources provided by the developer 
to determine that they are equivalent to the set of resources used by the 
developer to functionally test the TSF. 
1436 The set of resource used by the developer is documented in the developer test 
plan, as considered in the Functional tests (ATE_FUN) family. The resource 
set may include laboratory access and special test equipment, among ot hers. 
Resources that are not identical to those used by the developer need to be 
equivalent in terms of any impact they may have on test results. 
15.6.2.4 Action ATE_IND.2.2E 
ATE_IND.2-4 The evaluator shall conduct  testing using a sample of tests found in the 
developer test plan and procedures. 
1437 The overall aim of this work unit is to perform a sufficient number of the 
developer tests to confirm the validity of the developer's t est results. The 
evaluator has to decide on the size of the sample, and the developer tests that 
will compose the sample (see A.2). 
1438 All the developer tests can be traced back to specific interfaces. Therefore, 
the factors to consider in the selection of the tests to compose the sample are 
similar to those listed for subset selection in work -unit ATE_IND.2-6. 
Additionally, the evaluator may wish to employ a random sampling method 
to select developer tests to include in the sample. 
ATE_IND.2-5 The evaluator shall check that all the actual test results are consistent with 
the expected test results. 
1439 Inconsistencies between the developer's expected test results  and actual test 
results will compel the evaluator to resolve the discrepancies. Inconsistencies 
Class ATE: Tests 
Page 306 of 430 Version 3.1 April 2017 
encountered by the evaluator could be resolved by a valid explanation and 
resolution of the inconsistencies by the developer. 
1440 If a satisfactory explanation or resolution can not be reached, the evaluator's 
confidence in the developer's test results may be lessened and it may be 
necessary for the evaluator to increase the sample size to the extent that the 
subset identified in work unit ATE_IND.2-4 is adequately tested: 
deficiencies with the developer's tests need to result in either corrective 
action to the TOE by the developer (e.g., if the inconsistency is caused by 
incorrect behaviour) or to the developer's tests (e.g., if the inconsiste ncy is 
caused by an incorrect test), or in the production of new tests by the 
evaluator. 
15.6.2.5 Action ATE_IND.2.3E 
ATE_IND.2-6 The evaluator shall devise a test subset. 
1441 The evaluator selects a test subset and testing strategy that is appropriate for 
the TOE. One extreme testing strategy would be to have the test subset 
contain as many interfaces as possible tested with little rigour. Another 
testing strategy would be to have  the test subset contain a few interfaces 
based on their perceived relevance and rigorously test these interfaces. 
1442 Typically the testing approach taken by the evaluator should fall somewhere 
between these two extremes. The evaluator should exercise most of  the 
interfaces using at least one test, but testing need not demonstrate exhaustive 
specification testing. 
1443 The evaluator, when selecting the subset of the interfaces to be tested, should 
consider the following factors:  
a) The developer test evidence. The de veloper test evidence consists of: 
the test documentation, the available test coverage analysis, and the 
available depth of testing analysis. The developer test evidence will 
provide insight as to how the TSF has been exercised by the 
developer during testing. The evaluator applies this information when 
developing new tests to independently test the TOE. Specifically the 
evaluator should consider:  
1) augmentation of developer testing for interfaces. The 
evaluator may wish to perform more of the same type of t ests 
by varying parameters to more rigorously test the interface.  
2) supplementation of developer testing strategy for interfaces. 
The evaluator may wish to vary the testing approach of a 
specific interface by testing it using another test strategy.  
b) The number of interfaces from which to draw upon for the test subset. 
Where the TSF includes only a small number of relatively simple 
interfaces, it may be practical to rigorously test all of them. In other 
cases this may not be cost-effective, and sampling is required.  
Class ATE: Tests 
April 2017 Version 3.1 Page 307 of 430 
c) Maintaining a balance of evaluation activities. The evaluator effort 
expended on the test activity should be commensurate with that 
expended on any other evaluation activity.  
1444 The evaluator selects the interfaces to compose the subset. This selection will 
depend on a number of factors, and consideration of these factors may also 
influence the choice of test subset size:  
a) Rigour of developer testing of the interfaces. Those interfaces that the 
evaluator determines require additional testing should b e included in 
the test subset.  
b) Developer test results. If the results of developer tests cause the 
evaluator to doubt that an interface is not properly implemented, then 
the evaluator should include such interfaces in the test subset.  
c) Significance of int erfaces. Those interfaces more significant than 
others should be included in the test subset. One major factor of 
“significance” is the security -relevance (SFR -enforcing interfaces 
would be more significant than SFR -supporting interfaces, which are 
more significant than SFR -non-interfering interfaces; see CC Part 3 
Section ADV_FSP). The other major factor of “significance” is the 
number of SFRs mapping to this interface (as determined when 
identifying the correspondence betwee n levels of abstraction in 
ADV).  
d) Complexity of interfaces. Interfaces that require complex 
implementation may require complex tests that impose onerous 
requirements on the developer or evaluator, which may not be 
conducive to cost-effective evaluations. Conversely, they are a likely 
area to find errors and are good candidates for the subset. The 
evaluator will need to strike a balance between these considerations.  
e) Implicit testing. Testing some interfaces may often implicitly te st 
other interfaces, and their inclusion in the subset may maximise the 
number of interfaces tested (albeit implicitly). Certain interfaces will 
typically be used to provide a variety of security functionality, and 
will tend to be the target of an effective testing approach.  
f) Types of interfaces (e.g. programmatic, command -line, protocol). 
The evaluator should consider including tests for all different types of 
interfaces that the TOE supports.  
g) Interfaces that give rise to features that are innovative or u nusual. 
Where the TOE contains innovative or unusual features, which may 
feature strongly in marketing literature and guidance documents, the 
corresponding interfaces should be strong candidates for testing.  
1445 This guidance articulates factors to consider d uring the selection process of 
an appropriate test subset, but these are by no means exhaustive. 
Class ATE: Tests 
Page 308 of 430 Version 3.1 April 2017 
ATE_IND.2-7 The evaluator shall produce  test documentation for the test subset that is 
sufficiently detailed to enable the tests to be reproducible. 
1446 With an understanding of the expected behaviour of the TSF, from the ST, 
the functional specification, and the TOE design description, the evaluator 
has to determine the most feasible way to test the interface. Specificall y the 
evaluator considers:  
a) the approach that will be used, for instance, whether an external 
interface will be tested, or an internal interface using a test harness, or 
will an alternate test approach be employed (e.g. in exceptional 
circumstances, a code inspection);  
b) the interface(s) that will be used to test and observe responses;  
c) the initial conditions that will need to exist for the test (i.e. any 
particular objects or subjects that will need to exist and security 
attributes they will need to have);  
d) special test equipment that will be required to either stimulate an 
interface (e.g. packet generators) or make observations of an interface 
(e.g. network analysers).  
1447 The evaluator may find it practical to test each interface using a series of test 
cases, where each test case will test a very specific aspect of expected 
behaviour of that interface. 
1448 The evaluator's test documentation should specify the derivation of each test, 
tracing it back to the relevant interface(s). 
ATE_IND.2-8 The evaluator shall conduct testing. 
1449 The evaluator uses the test documentation developed as a basis for executing 
tests on the TOE. The test documentation is used as a basis for testing but 
this does not preclude the evaluator from per forming additional ad hoc tests. 
The evaluator may devise new tests based on behaviour of the TOE 
discovered during testing. These new tests are recorded in the test 
documentation. 
ATE_IND.2-9 The evaluator shall record the following information about the tests that 
compose the test subset:  
a) identification of the interface behaviour to be tested;  
b) instructions to connect and setup all required test equipment as 
required to conduct the test;  
c) instructions to establish all prerequisite test conditions;  
d) instructions to stimulate the interface;  
e) instructions for observing the interface;  
Class ATE: Tests 
April 2017 Version 3.1 Page 309 of 430 
f) descriptions of all expected results and the necessary analysis to be 
performed on the observed behaviour for comparison against 
expected results;  
g) instructions to conclude the test and establish the necessary post -test 
state for the TOE;  
h) actual test results.  
1450 The level of detail should be such that another evaluator could repeat the 
tests and obtain an equivalent result. While some s pecific details of the test 
results may be different (e.g. time and date fields in an audit record) the 
overall result should be identical. 
1451 There may be instances when it is unnecessary to provide all the information 
presented in this work unit (e.g. the a ctual test results of a test may not 
require any analysis before a comparison between the expected results can be 
made). The determination to omit this information is left to the evaluator, as 
is the justification. 
ATE_IND.2-10 The evaluator shall check that all actual test results are consistent with the 
expected test results. 
1452 Any differences in the actual and expected test results may indicate that the 
TOE does not perform as specified or that the evaluator t est documentation 
may be incorrect. Unexpected actual results may require corrective 
maintenance to the TOE or test documentation and perhaps require re -
running of impacted tests and modifying the test sample size and 
composition. This determination is left to the evaluator, as is its justification. 
ATE_IND.2-11 The evaluator shall report in the ETR the evaluator testing effort, outlining 
the testing approach, configuration, depth and results. 
1453 The evaluator testing information reported in the ETR allows the evaluator to 
convey the overall testing approach and effort expended on the testing 
activity during the evaluation. The intent of providing this information is to 
give a meaningful overview of the testing eff ort. It is not intended that the 
information regarding testing in the ETR be an exact reproduction of specific 
test instructions or results of individual tests. The intention is to provide 
enough detail to allow other evaluators and evaluation authorities to gain 
some insight about the testing approach chosen, amount of evaluator testing 
performed, amount of developer tests performed, TOE test configurations, 
and the overall results of the testing activity. 
1454 Information that would typically be found in the E TR section regarding the 
evaluator testing effort is:  
a) TOE test configurations. The particular configurations of the TOE 
that were tested.  
Class ATE: Tests 
Page 310 of 430 Version 3.1 April 2017 
b) subset size chosen. The amount of interfaces that were tested during 
the evaluation and a justification for the size.  
c) selection criteria for the interfaces that compose the subset. Brief 
statements about the factors considered when selecting interfaces for 
inclusion in the subset.  
d) Interfaces tested. A brief listing of the interfaces that merited 
inclusion in the subset.  
e) developer tests performed. The amount of developer tests performed 
and a brief description of the criteria used to select the tests.  
f) verdict for the activity. The overall judgement on the results of 
testing during the evaluation.  
1455 This list is by no m eans exhaustive and is only intended to provide some 
context as to the type of information that should be present in the ETR 
concerning the testing the evaluator performed during the evaluation. 
15.6.3 Evaluation of sub-activity (ATE_IND.3) 
1456 There is no general gu idance; the scheme should be consulted for guidance 
on this sub-activity. 
Class AVA: Vulnerability assessment 
April 2017 Version 3.1 Page 311 of 430 
16 Class AVA: Vulnerability assessment 
16.1 Introduction 
1457 The purpose of the vulnerability assessment activity is to determine the 
exploitability of flaws or weaknesses in the TOE in the ope rational 
environment. This determination is based upon analysis of the evaluation 
evidence and a search of publicly available material by the evaluator and is 
supported by evaluator penetration testing. 
Class AVA: Vulnerability assessment 
Page 312 of 430 Version 3.1 April 2017 
16.2 Vulnerability analysis (AVA_VAN) 
16.2.1 Evaluation of sub-activity (AVA_VAN.1) 
16.2.1.1 Objectives 
1458 The objective of this sub -activity is to determine whether the TOE, in its 
operational environment, has easily identifiable exploitable vulnerabilities. 
16.2.1.2 Input 
1459 The evaluation evidence for this sub-activity is:  
a) the ST;  
b) the guidance documentation;  
c) the TOE suitable for testing;  
d) information publicly available to support the identification of 
potential vulnerabilities.  
1460 Other input for this sub-activity is:  
a) current information regarding potential vulnerabilities (e.g. from an 
evaluation authority).  
16.2.1.3 Application notes 
1461 The evaluator should consider performing additional tests as a result of 
potential vulnerabilities encountered during the conduct of other parts of the 
evaluation. 
1462 The use of the term guidance in this sub -activity r efers to the operational 
guidance and the preparative guidance. 
1463 Potential vulnerabilities may be in information that is publicly available, or 
not, and may require skill to exploit, or not. These two aspects are related, 
but are distinct. It should not be assumed that, simply because a potential 
vulnerability is identifiable from information that is publicly available, it can 
be easily exploited. 
16.2.1.4 Action AVA_VAN.1.1E 
AVA_VAN.1.1C The TOE shall be suitable for testing.  
AVA_VAN.1-1 The evaluator shall examine the TOE to determine that the test configuration 
is consistent with the configuration under evaluation as specified in the ST. 
1464 The TOE provided by the developer and identified in the test plan should 
have the same unique reference as established by the CM capabilities 
(ALC_CMC) sub-activities and identified in the ST introduction. 
Class AVA: Vulnerability assessment 
April 2017 Version 3.1 Page 313 of 430 
1465 It is possible for the ST to specify more than one configuration for evaluation. 
The TOE may comprise a number of distinct hardware and software entities 
that need to be tested in accordance with the ST. The evaluator verifies that 
all test configurations are consistent with the ST. 
1466 The evaluator should consider the security objectives for the operational 
environment described in the ST that may apply to the test environment and 
ensure they are met in the testing environment. There may be some 
objectives for the operational env ironment that do not apply to the test 
environment. For example, an objective about user clearances may not apply; 
however, an objective about a single point of connection to a network would 
apply. 
1467 If any test resources are used (e.g. meters, analysers) it will be the evaluator's 
responsibility to ensure that these resources are calibrated correctly. 
AVA_VAN.1-2 The evaluator shall examine the TOE to determine that it has been installed 
properly and is in a known state 
1468 It is possible for the evaluator to determine the state of the TOE in a number 
of ways. For example, previous successful completion of the Evaluation of 
sub-activity (AGD_PRE.1)  sub-activity will satisfy this work unit if the 
evaluator still has confidence that the TOE being used for testing was 
installed properly and is in a known state. If this is not the case, then the 
evaluator should follow the developer's procedures to install and start up the 
TOE, using the supplied guidance only. 
1469 If the evaluator has to perform the installation procedures because the TOE is 
in an unknown state, this work unit when successfully completed could 
satisfy work unit AGD_PRE.1-3. 
16.2.1.5 Action AVA_VAN.1.2E 
AVA_VAN.1-3 The evaluator shall examine  sources of information publicly available to 
identify potential vulnerabilities in the TOE. 
1470 The evaluator examines the sources of information publicly available to 
support the identification of possible potential vulnerabilities in the TOE. 
There are many sources of publicly available information, which should be 
considered, e.g. mailing lists and security forums on the world wide web that 
report known vulnerabilities in specified technologies. 
1471 The evaluator should not constrain their consideration of publicly available 
information to the above, but should consider any other relevant information 
available. 
1472 While examining the evidence provided the evaluat or will use the 
information in the public domain to further search for potential 
vulnerabilities. Where the evaluators have identified areas of concern, the 
evaluator should consider information publicly available that relate to those 
areas of concern. 
Class AVA: Vulnerability assessment 
Page 314 of 430 Version 3.1 April 2017 
1473 The availability of information that may be readily available to an attacker 
that helps to identify and facilitate attacks effectively operates to 
substantially enhance the attack potential of a given attacker. The 
accessibility of vulnerability information a nd sophisticated attack tools on 
the Internet makes it more likely that this information will be used in 
attempts to identify potential vulnerabilities in the TOE and exploit them. 
Modern search tools make such information easily available to the evaluator , 
and the determination of resistance to published potential vulnerabilities and 
well known generic attacks can be achieved in a cost-effective manner. 
1474 The search of the information publicly available should be focused on those 
sources that refer specifically to the product from which the TOE is derived. 
The extensiveness of this search should consider the following factors: TOE 
type, evaluator experience in this TOE type, expected attack potential and the 
level of ADV evidence available. 
1475 The identification process is iterative, where the identification of one 
potential vulnerability may lead to identifying another area of concern that 
requires further investigation. 
1476 The evaluator will report what actions were taken to identify pot ential 
vulnerabilities in the information publicly available. However, in this type of 
search, the evaluator may not be able to describe the steps in identifying 
potential vulnerabilities before the outset of the examination, as the approach 
may evolve as a result of findings during the search. 
1477 The evaluator will report the evidence examined in completing the search for 
potential vulnerabilities. 
AVA_VAN.1-4 The evaluator shall record in the ETR the identified pot ential vulnerabilities 
that are candidates for testing and applicable to the TOE in its operational 
environment. 
1478 It may be identified that no further consideration of the potential 
vulnerability is required if for example the evaluator identifies that meas ures 
in the operational environment, either IT or non -IT, prevent exploitation of 
the potential vulnerability in that operational environment. For instance, 
restricting physical access to the TOE to authorised users only may 
effectively render a potential vulnerability to tampering unexploitable. 
1479 The evaluator records any reasons for exclusion of potential vulnerabilities 
from further consideration if the evaluator determines that the potential 
vulnerability is not applicable in the operational environment.  Otherwise the 
evaluator records the potential vulnerability for further consideration. 
1480 A list of potential vulnerabilities applicable to the TOE in its operational 
environment, which can be used as an input into penetration testing activities, 
shall be reported in the ETR by the evaluators. 
Class AVA: Vulnerability assessment 
April 2017 Version 3.1 Page 315 of 430 
16.2.1.6 Action AVA_VAN.1.3E 
AVA_VAN.1-5 The evaluator shall devise penetration tests, based on the independent search 
for potential vulnerabilities. 
1481 The evaluator prepares for penetration testing as necessary to determine the 
susceptibility of the TOE, in its operational environment, to the potential 
vulnerabilities identified during the search of the sources of information 
publicly availab le. Any current information provided to the evaluator by a 
third party (e.g. evaluation authority) regarding known potential 
vulnerabilities will be considered by the evaluator, together with any 
encountered potential vulnerabilities resulting from the per formance of other 
evaluation activities. 
1482 The evaluator will probably find it practical to carry out penetration test 
using a series of test cases, where each test case will test for a specific 
potential vulnerability. 
1483 The evaluator is not expected to test for potential vulnerabilities (including 
those in the public domain) beyond those which required a Basic attack 
potential. In some cases, however, it will be necessary to carry out a test 
before the exploitability can be determined. Where, as a result of e valuation 
expertise, the evaluator discovers a potential vulnerability that is beyond 
Basic attack potential, this is reported in the ETR as a residual vulnerability. 
AVA_VAN.1-6 The evaluator shall produce  penetration test documentation for the tests 
based on the list of potential vulnerabilities in sufficient detail to enable the 
tests to be repeatable. The test documentation shall include:  
a) identification of the potential vulnerability the TOE is being tested 
for;  
b) instructions to connect and setup all required test equipment as 
required to conduct the penetration test;  
c) instructions to establish all penetration test prerequisite initial 
conditions;  
d) instructions to stimulate the TSF;  
e) instructions for observing the behaviour of the TSF;  
f) descriptions of all expected results and the necessary analysis to be 
performed on the observed behaviour for comparison against 
expected results;  
g) instructions to conclude the test and establish the necessary post -test 
state for the TOE.  
1484 The evaluator prepares for penetration testing based on the list of potential 
vulnerabilities identified during the search of the public domain. 
Class AVA: Vulnerability assessment 
Page 316 of 430 Version 3.1 April 2017 
1485 The evaluator is not expected to determine the exploitability for potential 
vulnerabilities beyond those for which a Basic attack potential is required to 
effect an attack. However, as a result of evaluation expertise, the evaluator 
may discover a potential vulnerability that is exploitable only by an attacker 
with greater than Basic attack potential. S uch vulnerabilities are to be 
reported in the ETR as residual vulnerabilities. 
1486 With an understanding of the potential vulnerability, the evaluator 
determines the most feasible way to test for the TOE's susceptibility. 
Specifically the evaluator considers:  
a) the TSFI or other TOE interface that will be used to stimulate the 
TSF and observe responses;  
b) initial conditions that will need to exist for the test (i.e. any particular 
objects or subjects that will need to exist and security attributes they 
will need to have);  
c) special test equipment that will be required to either stimulate a TSFI 
or make observations of a TSFI (although it is unlikely that specialist 
equipment would be required to exploit a potential vulnerability 
assuming a Basic attack potential);  
d) whether theoretical analysis should replace physical testing, 
particularly relevant where the results of an initial test can be 
extrapolated to demonstrate that repeated attempts of an attack are 
likely to succeed after a given number of attempts.  
1487 The evaluator will probably find it practical to carry out penetration testing 
using a series of test cases, where each test case will test for a specific 
potential vulnerability. 
1488 The intent of specifying this level of detail in the test documentation is to 
allow another evaluator to repeat the tests and obtain an equivalent result. 
AVA_VAN.1-7 The evaluator shall conduct penetration testing. 
1489 The evaluator uses the penetration test documentation resulting from work 
unit AVA_VAN.1-5 as a basis for executing penetration tests on the TOE, 
but this does not preclude the evaluator from performing additional ad hoc 
penetration tests. If required, the evaluator may devise ad hoc tests as a result 
of infor mation learnt during penetration testing that, if performed by the 
evaluator, are to be recorded in the penetration test documentation. Such tests 
may be required to follow up unexpected results or observations, or to 
investigate potential vulnerabilities suggested to the evaluator during the pre-
planned testing. 
1490 The evaluator is not expected to test for potential vulnerabilities (including 
those in the public domain) beyond those which required a Basic attack 
potential. In some cases, however, it will be n ecessary to carry out a test 
before the exploitability can be determined. Where, as a result of evaluation 
Class AVA: Vulnerability assessment 
April 2017 Version 3.1 Page 317 of 430 
expertise, the evaluator discovers a potential vulnerability that is beyond 
Basic attack potential, this is reported in the ETR as a residual vulnerability. 
AVA_VAN.1-8 The evaluator shall record the actual results of the penetration tests. 
1491 While some specific details of the actual test results may be different from 
those expected (e.g. time and date fields i n an audit record) the overall result 
should be identical. Any unexpected test results should be investigated. The 
impact on the evaluation should be stated and justified. 
AVA_VAN.1-9 The evaluator shall report in the ETR the evaluator penetration testing effort, 
outlining the testing approach, configuration, depth and results. 
1492 The penetration testing information reported in the ETR allows the evaluator 
to convey the overall penetration testing approach and effort  expended on 
this sub -activity. The intent of providing this information is to give a 
meaningful overview of the evaluator's penetration testing effort. It is not 
intended that the information regarding penetration testing in the ETR be an 
exact reproduction of specific test steps or results of individual penetration 
tests. The intention is to provide enough detail to allow other evaluators and 
evaluation authorities to gain some insight about the penetration testing 
approach chosen, amount of penetration t esting performed, TOE test 
configurations, and the overall results of the penetration testing activity. 
1493 Information that would typically be found in the ETR section regarding 
evaluator penetration testing efforts is:  
a) TOE test configurations. The particula r configurations of the TOE 
that were penetration tested;  
b) TSFI penetration tested. A brief listing of the TSFI and other TOE 
interfaces that were the focus of the penetration testing;  
c) verdict for the sub -activity. The overall judgement on the results of 
penetration testing.  
1494 This list is by no means exhaustive and is only intended to provide some 
context as to the type of information that should be present in the ETR 
concerning the penetration testing the evaluator performed during the 
evaluation. 
AVA_VAN.1-10 The evaluator shall examine  the results of all penetration testing to 
determine that the TOE, in its operational environment, is resistant to an 
attacker possessing a Basic attack potential. 
1495 If the resul ts reveal that the TOE, in its operational environment, has 
vulnerabilities exploitable by an attacker possessing less than Enhanced -
Basic attack potential, then this evaluator action fails. 
1496 The guidance in B.4 should be used to determine the attack potential required 
to exploit a particular vulnerability and whether it can therefore be exploited 
in the intended environment. It may not be necessary for the attack potential 
Class AVA: Vulnerability assessment 
Page 318 of 430 Version 3.1 April 2017 
to be calculated in every instance, only if there i s some doubt as to whether 
or not the vulnerability can be exploited by an attacker possessing an attack 
potential less than Enhanced-Basic. 
AVA_VAN.1-11 The evaluator shall report  in the ETR all exploitable v ulnerabilities and 
residual vulnerabilities, detailing for each:  
a) its source (e.g. CEM activity being undertaken when it was conceived, 
known to the evaluator, read in a publication);  
b) the SFR(s) not met;  
c) a description;  
d) whether it is exploitable in its o perational environment or not (i.e. 
exploitable or residual).  
e) the amount of time, level of expertise, level of knowledge of the TOE, 
level of opportunity and the equipment required to perform the 
identified vulnerabilities, and the corresponding values us ing the 
tables 3 and 4 of Annex B.4.  
16.2.2 Evaluation of sub-activity (AVA_VAN.2) 
16.2.2.1 Objectives 
1497 The objective of this sub -activity is to determine whether the TOE, in its 
operational envi ronment, has vulnerabilities exploitable by attackers 
possessing Basic attack potential. 
16.2.2.2 Input 
1498 The evaluation evidence for this sub-activity is:  
a) the ST; 
b) the functional specification; 
c) the TOE design; 
d) the security architecture description; 
e) the guidance documentation; 
f) the TOE suitable for testing; 
g) information publicly available to support the identification of 
possible potential vulnerabilities. 
1499 The remaining implicit evaluation evidence for this sub -activity depends on 
the components that have been included in the assurance package. The 
evidence provided for each component is to be used as input in this sub -
activity. 
Class AVA: Vulnerability assessment 
April 2017 Version 3.1 Page 319 of 430 
1500 Other input for this sub-activity is:  
a) current information regarding public domain potential vulnerabilities 
and attacks (e.g. from an evaluation authority).  
16.2.2.3 Application notes 
1501 The evaluator should consider performing additional tests as a result of 
potential vulnerabilities encountered during other parts of the evaluation. 
16.2.2.4 Action AVA_VAN.2.1E 
AVA_VAN.2.1C The TOE shall be suitable for testing.  
AVA_VAN.2-1 The evaluator shall examine the TOE to determine that the test configuration 
is consistent with the configuration under evaluation as specified in the ST. 
1502 The TOE provided by the developer and identified in the test plan should 
have the same unique reference as established by the CM capabilities 
(ALC_CMC) sub-activities and identified in the ST introduction. 
1503 It is possible for the ST to specify more than one configuration for evaluation. 
The TOE may comprise a number of distinct hardware and software entities 
that need to be tested in accordance with the ST. The evaluator verifies that 
all test configurations are consistent with the ST. 
1504 The evaluator should consider the security objectives for the operational 
environment described in the ST that may apply to the test environment and 
ensure they are met in the testing environment. There may be s ome 
objectives for the operational environment that do not apply to the test 
environment. For example, an objective about user clearances may not apply; 
however, an objective about a single point of connection to a network would 
apply. 
1505 If any test resources are used (e.g. meters, analysers) it will be the evaluator's 
responsibility to ensure that these resources are calibrated correctly. 
AVA_VAN.2-2 The evaluator shall examine the TOE to determine that it has been  installed 
properly and is in a known state 
1506 It is possible for the evaluator to determine the state of the TOE in a number 
of ways. For example, previous successful completion of the Evaluation of 
sub-activity (AGD_PRE.1)  sub-activity will satisfy this work unit if the 
evaluator still has confidence that the TOE being used for testing was 
installed properly and is in a known state. If this is not the case, then the 
evaluator should follow the developer's procedures to install and start up the 
TOE, using the supplied guidance only. 
1507 If the evaluator has to perform the installation procedures because the TOE is 
in an unknown state, this work unit when successfully completed could 
satisfy work unit AGD_PRE.1-3. 
Class AVA: Vulnerability assessment 
Page 320 of 430 Version 3.1 April 2017 
16.2.2.5 Action AVA_VAN.2.2E 
AVA_VAN.2-3 The evaluator shall examine  sources of information publicly available to 
identify potential vulnerabilities in the TOE. 
1508 The evaluator examine s the sources of information publicly available to 
support the identification of possible potential vulnerabilities in the TOE. 
There are many sources of publicly available information which the 
evaluator should consider using items such as those available  on the world 
wide web, including:  
a) specialist publications (magazines, books);  
b) research papers.  
1509 The evaluator should not constrain their consideration of publicly available 
information to the above, but should consider any other relevant information 
available. 
1510 While examining the evidence provided the evaluator will use the 
information in the public domain to further search for potential 
vulnerabilities. Where the evaluators have identified areas of concern, the 
evaluator should consider information publ icly available that relate to those 
areas of concern. 
1511 The availability of information that may be readily available to an attacker 
that helps to identify and facilitate attacks may substantially enhance the 
attack potential of a given attacker. The accessi bility of vulnerability 
information and sophisticated attack tools on the Internet makes it more 
likely that this information will be used in attempts to identify potential 
vulnerabilities in the TOE and exploit them. Modern search tools make such 
information easily available to the evaluator, and the determination of 
resistance to published potential vulnerabilities and well known generic 
attacks can be achieved in a cost-effective manner. 
1512 The search of the information publicly available should be focused on those 
sources that refer specifically to the product from which the TOE is derived. 
The extensiveness of this search should consider the following factors: TOE 
type, evaluator experience in this TOE type, expected attack potential and the 
level of ADV evidence available. 
1513 The identification process is iterative, where the identification of one 
potential vulnerability may lead to identifying another area of concern that 
requires further investigation. 
1514 The evaluator will report wh at actions were taken to identify potential 
vulnerabilities in the evidence. However, in this type of search, the evaluator 
may not be able to describe the steps in identifying potential vulnerabilities 
before the outset of the examination, as the approach  may evolve as a result 
of findings during the search. 
Class AVA: Vulnerability assessment 
April 2017 Version 3.1 Page 321 of 430 
1515 The evaluator will report the evidence examined in completing the search for 
potential vulnerabilities. This selection of evidence may be derived from 
those areas of concern identified by the evaluator , linked to the evidence the 
attacker is assumed to be able to obtain, or according to another rationale 
provided by the evaluator. 
16.2.2.6 Action AVA_VAN.2.3E 
AVA_VAN.2-4 The evaluator shall conduct  a search of ST, guidance documentation, 
functional specification, TOE design and security architecture description 
evidence to identify possible potential vulnerabilities in the TOE. 
1516 A search of the evidence should be completed wh ereby specifications and 
documentation for the TOE are analysed and then potential vulnerabilities in 
the TOE are hypothesised, or speculated. The list of hypothesised potential 
vulnerabilities is then prioritised on the basis of the estimated probability that 
a potential vulnerability exists and, assuming an exploitable vulnerability 
does exist the attack potential required to exploit it, and on the extent of 
control or compromise it would provide. The prioritised list of potential 
vulnerabilities is used to direct penetration testing against the TOE. 
1517 The security architecture description provides the developer vulnerability 
analysis, as it documents how the TSF protects itself from interference from 
untrusted subjects and prevents the bypass of security en forcement 
functionality. Therefore, the evaluator should use this description of the 
protection of the TSF as a basis for the search for possible ways to 
undermine the TSF. 
1518 Subject to the SFRs the TOE is to meet in the operational environment, the 
evaluator's independent vulnerability analysis should consider generic 
potential vulnerabilities under each of the following headings:  
a) generic potential vulnerabilities relevant for the type of TOE being 
evaluated, as may be supplied by the evaluation authority; 
b) bypassing; 
c) tampering; 
d) direct attacks; 
e) monitoring; 
f) misuse. 
1519 Items b) - f) are explained in greater detail in Annex B. 
1520 The security architecture description should be considered in light of each of 
the above generic potential vulne rabilities. Each potential vulnerability 
should be considered to search for possible ways in which to defeat the TSF 
protection and undermine the TSF. 
Class AVA: Vulnerability assessment 
Page 322 of 430 Version 3.1 April 2017 
AVA_VAN.2-5 The evaluator shall record in the ETR the identif ied potential vulnerabilities 
that are candidates for testing and applicable to the TOE in its operational 
environment. 
1521 It may be identified that no further consideration of the potential 
vulnerability is required if for example the evaluator identifies th at measures 
in the operational environment, either IT or non -IT, prevent exploitation of 
the potential vulnerability in that operational environment. For instance, 
restricting physical access to the TOE to authorised users only may 
effectively render a potential vulnerability to tampering unexploitable. 
1522 The evaluator records any reasons for exclusion of potential vulnerabilities 
from further consideration if the evaluator determines that the potential 
vulnerability is not applicable in the operational envir onment. Otherwise the 
evaluator records the potential vulnerability for further consideration. 
1523 A list of potential vulnerabilities applicable to the TOE in its operational 
environment, which can be used as an input into penetration testing activities, 
shall be reported in the ETR by the evaluators. 
16.2.2.7 Action AVA_VAN.2.4E 
AVA_VAN.2-6 The evaluator shall devise penetration tests, based on the independent search 
for potential vulnerabilities. 
1524 The evaluator prepares for penetration testing as necessary to determine the 
susceptibility of the TOE, in its operational environment, to the potential 
vulnerabilities identified during the search of the sources of information 
publicly available. Any current information provided to the evaluator by a 
third party (e.g. evaluation authority) regarding known potential 
vulnerabilities will be considered by the evaluator, together with any 
encountered potential vulnerabilities resulting from the performance of other 
evaluation activities. 
1525 The evaluator is reminded that, as for considering the security architecture 
description in the search for vulnerabilities (as detailed in AVA_VAN.2-4), 
testing should be pe rformed to confirm the architectural properties. This is 
likely to require negative tests attempting to disprove the properties of the 
security architecture. In developing the strategy for penetration testing, the 
evaluator will ensure that each of the maj or characteristics of the security 
architecture description are tested, either in functional testing (as considered 
in 15) or evaluator penetration testing. 
1526 The evaluator will probably find it practical to carry out penetration test 
using a series of test cases, where each test case will test for a specific 
potential vulnerability. 
1527 The evaluator is not expected to test for potential vulnerabilities (including 
those in the public domain) beyond those which required a Basic attack 
potential. In some cases, however, it will be necessary to carry out a test 
before the exploitability can be determined. Where, as a result of evaluation 
Class AVA: Vulnerability assessment 
April 2017 Version 3.1 Page 323 of 430 
expertise, the evaluator discovers an exploitable vulnerability that is beyond 
Basic attack potential, this is reported in the ETR as a residual vulnerability. 
1528 Guidance on determining the necessary attack potential to exploit a potential 
vulnerability can be found in Annex B.4. 
1529 Potential vulnerabilities hypothesised as exploitable o nly by attackers 
possessing Enhanced-Basic, Moderate or High attack potential do not result 
in a failure of this evaluator action. Where analysis supports the hypothesis, 
these need not be considered further as an input to penetration testing. 
However, suc h vulnerabilities are reported in the ETR as residual 
vulnerabilities. 
1530 Potential vulnerabilities hypothesised as exploitable by an attacker 
possessing a Basic attack potential and resulting in a violation of the security 
objectives should be the highest pr iority potential vulnerabilities comprising 
the list used to direct penetration testing against the TOE. 
AVA_VAN.2-7 The evaluator shall produce  penetration test documentation for the tests 
based on the list of p otential vulnerabilities in sufficient detail to enable the 
tests to be repeatable. The test documentation shall include:  
a) identification of the potential vulnerability the TOE is being tested 
for;  
b) instructions to connect and setup all required test equip ment as 
required to conduct the penetration test;  
c) instructions to establish all penetration test prerequisite initial 
conditions;  
d) instructions to stimulate the TSF;  
e) instructions for observing the behaviour of the TSF;  
f) descriptions of all expected resul ts and the necessary analysis to be 
performed on the observed behaviour for comparison against 
expected results;  
g) instructions to conclude the test and establish the necessary post -test 
state for the TOE.  
1531 The evaluator prepares for penetration testing bas ed on the list of potential 
vulnerabilities identified during the search of the public domain and the 
analysis of the evaluation evidence. 
1532 The evaluator is not expected to determine the exploitability for potential 
vulnerabilities beyond those for which a Basic attack potential is required to 
effect an attack. However, as a result of evaluation expertise, the evaluator 
may discover a potential vulnerability that is exploitable only by an attacker 
with greater than Basic attack potential. Such vulnerabilitie s are to be 
reported in the ETR as residual vulnerabilities. 
Class AVA: Vulnerability assessment 
Page 324 of 430 Version 3.1 April 2017 
1533 With an understanding of the potential vulnerability, the evaluator 
determines the most feasible way to test for the TOE's susceptibility. 
Specifically the evaluator considers:  
a) the TSFI or other  TOE interface that will be used to stimulate the 
TSF and observe responses (It is possible that the evaluator will need 
to use an interface to the TOE other than the TSFI to demonstrate 
properties of the TSF such as those described in the security 
architecture description (as required by ADV_ARC). It should the 
noted, that although these TOE interfaces provide a means of testing 
the TSF properties, they are not the subject of the test.);  
b) initial conditions that will need to exist for the test (i.e. any particular 
objects or subjects that will need to exist and security attributes they 
will need to have);  
c) special test equipment that will be required to either stimulate a TSFI 
or make observations of a TSFI (although it is unl ikely that specialist 
equipment would be required to exploit a potential vulnerability 
assuming a Basic attack potential);  
d) whether theoretical analysis should replace physical testing, 
particularly relevant where the results of an initial test can be 
extrapolated to demonstrate that repeated attempts of an attack are 
likely to succeed after a given number of attempts.  
1534 The evaluator will probably find it practical to carry out penetration testing 
using a series of test cases, where each test case will test  for a specific 
potential vulnerability. 
1535 The intent of specifying this level of detail in the test documentation is to 
allow another evaluator to repeat the tests and obtain an equivalent result. 
AVA_VAN.2-8 The evaluator shall conduct penetration testing. 
1536 The evaluator uses the penetration test documentation resulting from work 
unit AVA_VAN.2-6 as a basis for executing penetration tests on the TOE, 
but this does not preclude the evaluator f rom performing additional ad hoc 
penetration tests. If required, the evaluator may devise ad hoc tests as a result 
of information learnt during penetration testing that, if performed by the 
evaluator, are to be recorded in the penetration test documentation. Such tests 
may be required to follow up unexpected results or observations, or to 
investigate potential vulnerabilities suggested to the evaluator during the pre-
planned testing. 
1537 Should penetration testing show that a hypothesised potential vulnerabilit y 
does not exist, then the evaluator should determine whether or not the 
evaluator's own analysis was incorrect, or if evaluation deliverables are 
incorrect or incomplete. 
Class AVA: Vulnerability assessment 
April 2017 Version 3.1 Page 325 of 430 
1538 The evaluator is not expected to test for potential vulnerabilities (including 
those in the public domain) beyond those which required a Basic attack 
potential. In some cases, however, it will be necessary to carry out a test 
before the exploitability can be determined. Where, as a result of evaluation 
expertise, the evaluator discovers a n exploitable vulnerability that is beyond 
basic attack potential, this is reported in the ETR as a residual vulnerability. 
AVA_VAN.2-9 The evaluator shall record the actual results of the penetration tests. 
1539 While some specific details of the actual test results may be different from 
those expected (e.g. time and date fields in an audit record) the overall result 
should be identical. Any unexpected test results should be investigated. The 
impact on the evaluation should be stated and justified. 
AVA_VAN.2-10 The evaluator shall report in the ETR the evaluator penetration testing effort, 
outlining the testing approach, configuration, depth and results. 
1540 The penetration testing information reported in the ETR allows the evaluator 
to convey the overall penetration testing approach and effort expended on 
this sub -activity. The intent of providing this information is to give a 
meaningful overview of the evaluator's penetration  testing effort. It is not 
intended that the information regarding penetration testing in the ETR be an 
exact reproduction of specific test steps or results of individual penetration 
tests. The intention is to provide enough detail to allow other evaluator s and 
evaluation authorities to gain some insight about the penetration testing 
approach chosen, amount of penetration testing performed, TOE test 
configurations, and the overall results of the penetration testing activity. 
1541 Information that would typically  be found in the ETR section regarding 
evaluator penetration testing efforts is:  
a) TOE test configurations. The particular configurations of the TOE 
that were penetration tested;  
b) TSFI penetration tested. A brief listing of the TSFI and other TOE 
interfaces that were the focus of the penetration testing;  
c) Verdict for the sub -activity. The overall judgement on the results of 
penetration testing.  
1542 This list is by no means exhaustive and is only intended to provide some 
context as to the type of information tha t should be present in the ETR 
concerning the penetration testing the evaluator performed during the 
evaluation. 
AVA_VAN.2-11 The evaluator shall examine  the results of all penetration testing to 
determine tha t the TOE, in its operational environment, is resistant to an 
attacker possessing a Basic attack potential. 
Class AVA: Vulnerability assessment 
Page 326 of 430 Version 3.1 April 2017 
1543 If the results reveal that the TOE, in its operational environment, has 
vulnerabilities exploitable by an attacker possessing less than an Enhanced -
Basic attack potential, then this evaluator action fails. 
1544 The guidance in B.4 should be used to determine the attack potential required 
to exploit a particular vulnerability and whether it can therefore be exploited 
in the intended environment. It may not be necessary for the attack potential 
to be calculated in every instance, only if there is some doubt as to whether 
or not the vulnerability can be exploited by an attacker possessing an attack 
potential less than Enhanced-Basic. 
AVA_VAN.2-12 The evaluator shall report  in the ETR all exploitable vulnerabilities and 
residual vulnerabilities, detailing for each:  
a) its source (e.g. CEM activity being undertaken when it was conceived, 
known to the evaluator, read in a publication);  
b) the SFR(s) not met;  
c) a description;  
d) whether it is exploitable in its operational environment or not (i.e. 
exploitable or residual).  
e) the amount of time, level of expertise, level of knowledge of the TOE,  
level of opportunity and the equipment required to perform the 
identified vulnerabilities, and the corresponding values using the 
tables 3 and 4 of Annex B.4.  
16.2.3 Evaluation of sub-activity (AVA_VAN.3) 
16.2.3.1 Objectives 
1545 The objective of this sub -activity is to determine whether the TOE, in its 
operational environment, has vulnerabilities exploitable by attackers 
possessing Enhanced-Basic attack potential. 
16.2.3.2 Input 
1546 The evaluation evidence for this sub-activity is:  
a) the ST; 
b) the functional specification; 
c) the TOE design; 
d) the security architecture description; 
e) the implementation subset selected; 
f) the guidance documentation; 
Class AVA: Vulnerability assessment 
April 2017 Version 3.1 Page 327 of 430 
g) the TOE suitable for testing; 
h) information publicly available to support the i dentification of 
possible potential vulnerabilities;  
i) the results of the testing of the basic design.  
1547 The remaining implicit evaluation evidence for this sub -activity depends on 
the components that have been included in the assurance package. The 
evidence provided for each component is to be used as input in this sub -
activity. 
1548 Other input for this sub-activity is:  
a) current information regarding public domain potential vulnerabilities 
and attacks (e.g. from an evaluation authority).  
16.2.3.3 Application notes 
1549 During the conduct of evaluation activities the evaluator may also identify 
areas of concern. These are specific portions of the TOE evidence that the 
evaluator has some reservation about, although the evidence meets the 
requirements for the activity with which  the evidence is associated. For 
example, a particular interface specification looks particularly complex, and 
therefore may be prone to error either in the development of the TOE or in 
the operation of the TOE. There is no potential vulnerability apparent  at this 
stage, further investigation is required. This is beyond the bounds of 
encountered, as further investigation is required. 
1550 The focused approach to the identification of potential vulnerabilities is an 
analysis of the evidence with the aim of identi fying any potential 
vulnerabilities evident through the contained information. It is an 
unstructured analysis, as the approach is not predetermined. Further guidance 
on focused vulnerability analysis can be found in Annex B.2.2.2.2. 
16.2.3.4 Action AVA_VAN.3.1E 
AVA_VAN.3.1C The TOE shall be suitable for testing.  
AVA_VAN.3-1 The evaluator shall examine the TOE to determine that the test configuration 
is consistent with the configuration under evaluation as specified in the ST. 
1551 The TOE provided by the developer and identified in the test plan should 
have the same unique reference as established by the CM capabilities 
(ALC_CMC) sub-activities and identified in the ST introduction. 
1552 It is possible for the ST to specify more than one configuration for evaluation. 
The TOE may comprise a number of distinct hardware and software entities 
that need to  be tested in accordance with the ST. The evaluator verifies that 
all test configurations are consistent with the ST. 
Class AVA: Vulnerability assessment 
Page 328 of 430 Version 3.1 April 2017 
1553 The evaluator should consider the security objectives for the operational 
environment described in the ST that may apply to the test envir onment and 
ensure they are met in the testing environment. There may be some 
objectives for the operational environment that do not apply to the test 
environment. For example, an objective about user clearances may not apply; 
however, an objective about a single point of connection to a network would 
apply. 
1554 If any test resources are used (e.g. meters, analysers) it will be the evaluator's 
responsibility to ensure that these resources are calibrated correctly. 
AVA_VAN.3-2 The evaluator shall examine the TOE to determine that it has been installed 
properly and is in a known state 
1555 It is possible for the evaluator to determine the state of the TOE in a number 
of ways. For example, previous successful completion of the Evaluation of 
sub-activity (AGD_PRE.1)  sub-activity will satisfy this work unit if the 
evaluator still has confidence that the TOE being used for testing was 
installed properly and is in a known state. If this is not the case, then the  
evaluator should follow the developer's procedures to install and start up the 
TOE, using the supplied guidance only. 
1556 If the evaluator has to perform the installation procedures because the TOE is 
in an unknown state, this work unit when successfully comp leted could 
satisfy work unit AGD_PRE.1-3. 
16.2.3.5 Action AVA_VAN.3.2E 
AVA_VAN.3-3 The evaluator shall examine  sources of information publicly availabl e to 
identify potential vulnerabilities in the TOE. 
1557 The evaluator examines the sources of information publicly available to 
support the identification of possible potential vulnerabilities in the TOE. 
There are many sources of publicly available informatio n which the 
evaluator should consider using items such as those available on the world 
wide web, including:  
a) specialist publications (magazines, books);  
b) research papers;  
c) conference proceedings.  
1558 The evaluator should not constrain their consideration of p ublicly available 
information to the above, but should consider any other relevant information 
available. 
1559 While examining the evidence provided the evaluator will use the 
information in the public domain to further search for potential 
vulnerabilities. Whe re the evaluators have identified areas of concern, the 
evaluator should consider information publicly available that relate to those 
areas of concern. 
Class AVA: Vulnerability assessment 
April 2017 Version 3.1 Page 329 of 430 
1560 The availability of information that may be readily available to an attacker 
that helps to identify and facilitate attacks may substantially enhance the 
attack potential of a given attacker. The accessibility of vulnerability 
information and sophisticated attack tools on the Internet makes it more 
likely that this information will be used in attempts to iden tify potential 
vulnerabilities in the TOE and exploit them. Modern search tools make such 
information easily available to the evaluator, and the determination of 
resistance to published potential vulnerabilities and well known generic 
attacks can be achieved in a cost-effective manner. 
1561 The search of the information publicly available should be focused on those 
sources that refer to the technologies used in the development of the product 
from which the TOE is derived. The extensiveness of this search should 
consider the following factors: TOE type, evaluator experience in this TOE 
type, expected attack potential and the level of ADV evidence available. 
1562 The identification process is iterative, where the identification of one 
potential vulnerability may lead to identifying another area of concern that 
requires further investigation. 
1563 The evaluator will report what actions were taken to identify potential 
vulnerabilities in the evidence. However, in this type of search, the evaluator 
may not be able to describe the steps in identifying potential vulnerabilities 
before the outset of the examination, as the approach may evolve as a result 
of findings during the search. 
1564 The evaluator will report the evidence examined in completing the search  for 
potential vulnerabilities. This selection of evidence may be derived from 
those areas of concern identified by the evaluator, linked to the evidence the 
attacker is assumed to be able to obtain, or according to another rationale 
provided by the evaluator. 
16.2.3.6 Action AVA_VAN.3.3E 
AVA_VAN.3-4 The evaluator shall conduct a focused search of ST, guidance documentation, 
functional specification, TOE design, security archit ecture description and 
implementation representation to identify possible potential vulnerabilities in 
the TOE. 
1565 A flaw hypothesis methodology needs to be used whereby specifications and 
development and guidance evidence are analysed and then potential 
vulnerabilities in the TOE are hypothesised, or speculated. 
1566 The evaluator uses the knowledge of the TOE design and operation gained 
from the TOE deliverables to conduct a flaw hypothesis to identify potential 
flaws in the development of the TOE and potential e rrors in the specified 
method of operation of the TOE. 
1567 The security architecture description provides the developer vulnerability 
analysis, as it documents how the TSF protects itself from interference from 
untrusted subjects and prevents the bypass of sec urity enforcement 
Class AVA: Vulnerability assessment 
Page 330 of 430 Version 3.1 April 2017 
functionality. Therefore, the evaluator should build upon the understanding 
of the TSF protection gained from the analysis of this evidence and then 
develop this in the knowledge gained from other development ADV 
evidence. 
1568 The approach taken is directed by areas of concern identified during 
examination of the evidence during the conduct of evaluation activities and 
ensuring a representative sample of the development and guidance evidence 
provided for the evaluation is searched. 
1569 For guidance on sampling see Annex A.2. This guidance should be 
considered when selecting the subset, giving reasons for:  
a) the approach used in selection;  
b) qualification that the evidence to be examined supports that approach.  
1570 The areas of concern may relate to the sufficiency of specific protection 
features detailed in the security architecture description. 
1571 The evidence to be considered during the vulnerability analysis may be 
linked to the evidence the  attacker is assumed to be able to obtain. For 
example, the developer may protect the TOE design and implementation 
representations, so the only information assumed to be available to an 
attacker is the functional specification and guidance (publicly avail able). So, 
although the objectives for assurance in the TOE ensure the TOE design and 
implementation representation requirements are met, these design 
representations may only be searched to further investigate areas of concerns. 
1572 On the other hand, if the source is publicly available it would be reasonable 
to assume that the attacker has access to the source and can use this in 
attempts to attack the TOE. Therefore, the source should be considered in the 
focused examination approach. 
1573 The following indicates examples for the selection of the subset of evidence 
to be considered:  
a) For an evaluation where all levels of design abstraction from 
functional specification to implementation representation are 
provided, examination of information in the functional spec ification 
and the implementation representation may be selected, as the 
functional specification provides detail of interfaces available to an 
attacker, and the implementation representation incorporates the 
design decisions made at all other design abstra ctions. Therefore, the 
TOE design information will be considered as part of the 
implementation representation.  
b) Examination of a particular subset of information in each of the 
design representations provided for the evaluation.  
Class AVA: Vulnerability assessment 
April 2017 Version 3.1 Page 331 of 430 
c) Coverage of particular SFR s through each of the design 
representations provided for the evaluation.  
d) Examination of each of the design representations provided for the 
evaluation, considering different SFRs within each design 
representations.  
e) Examination of aspects of the evidence  provided for the evaluation 
relating to current potential vulnerability information the evaluator 
has received (e.g. from a scheme).  
1574 This approach to identification of potential vulnerabilities is to take an 
ordered and planned approach; applying a syste m to the examination. The 
evaluator is to describe the method to be used in terms of what evidence will 
be considered, the information within the evidence that is to be examined, 
the manner in which this information is to be considered and the hypothesis 
that is to be created. 
1575 The following provide some examples that a hypothesis may take:  
a) consideration of malformed input for interfaces available to an 
attacker at the external interfaces;  
b) examination of a key security mechanism cited in the security 
architecture description, such as process separation, hypothesising 
internal buffer overflows that may lead to degradation of separation;  
c) search to identify any objects created in the TOE implementation 
representation that are then not fully controlled by the TSF, and could 
be used by an attacker to undermine SFRs.  
1576 For example, the evaluator may identify that interfaces are a potential area of 
weakness in the TOE and specify an approach to the search that “all interface 
specifications provided in the functiona l specification and TOE design will 
be searched to hypothesise potential vulnerabilities” and go on to explain the 
methods used in the hypothesis. 
1577 The identification process is iterative, where the identification of one 
potential vulnerability may lead to identifying another area of concern that 
requires further investigation. 
1578 The evaluator will report what actions were taken to identify potential 
vulnerabilities in the evidence. However, in this type of search, the evaluator 
may not be able to describe the  steps in identifying potential vulnerabilities 
before the outset of the examination, as the approach may evolve as a result 
of findings during the search. 
1579 The evaluator will report the evidence examine in completing the search for 
potential vulnerabilitie s. This selection of evidence may be derived from 
those areas of concern identified by the evaluator, linked to the evidence the 
Class AVA: Vulnerability assessment 
Page 332 of 430 Version 3.1 April 2017 
attacker is assumed to be able to obtain, or according to another rationale 
provided by the evaluator. 
1580 Subject to the SFRs the TOE is to meet in the operational environment, the 
evaluator's independent vulnerability analysis should consider generic 
potential vulnerabilities under each of the following headings:  
a) generic potential vulnerabilities relevant for the type of TOE being 
evaluated, as may be supplied by the evaluation authority; 
b) bypassing; 
c) tampering; 
d) direct attacks; 
e) monitoring; 
f) misuse. 
1581 Items b) - f) are explained in greater detail in Annex B. 
1582 The security architecture description should be consi dered in light of each of 
the above generic potential vulnerabilities. Each potential vulnerability 
should be considered to search for possible ways in which to defeat the TSF 
protection and undermine the TSF. 
AVA_VAN.3-5 The evaluator shall record in the ETR the identified potential vulnerabilities 
that are candidates for testing and applicable to the TOE in its operational 
environment. 
1583 It may be identified that no further consideration of the potential 
vulnerability is required if for example the evaluator identifies that measures 
in the operational environment, either IT or non -IT, prevent exploitation of 
the potential vulnerability in that operational environment. For instance, 
restricting physical access to th e TOE to authorised users only may 
effectively render a potential vulnerability to tampering unexploitable. 
1584 The evaluator records any reasons for exclusion of potential vulnerabilities 
from further consideration if the evaluator determines that the potenti al 
vulnerability is not applicable in the operational environment. Otherwise the 
evaluator records the potential vulnerability for further consideration. 
1585 A list of potential vulnerabilities applicable to the TOE in its operational 
environment, which can be used as an input into penetration testing activities, 
shall be reported in the ETR by the evaluators. 
16.2.3.7 Action AVA_VAN.3.4E 
AVA_VAN.3-6 The evaluator shall devise penetration tests, based on the independent search 
for potential vulnerabilities. 
Class AVA: Vulnerability assessment 
April 2017 Version 3.1 Page 333 of 430 
1586 The evaluator prepares for penetration testing as necessary to determine the 
susceptibility of the TOE, in its operational environment, to the potential 
vulnerabilities identifie d during the search of the sources of information 
publicly available. Any current information provided to the evaluator by a 
third party (e.g. evaluation authority) regarding known potential 
vulnerabilities will be considered by the evaluator, together wit h any 
encountered potential vulnerabilities resulting from the performance of other 
evaluation activities. 
1587 The evaluator is reminded that, as for considering the security architecture 
description in the search for vulnerabilities (as detailed in AVA_VAN.3-4), 
testing should be performed to confirm the architectural properties. If 
requirements from ATE_DPT are included in the SARs, the developer 
testing evidence will include testing performed to confirm the correct 
implementation of any specific mechanisms detailed in the security 
architecture description. However, the developer testing will not necessarily 
include testing of all aspects of the architectural properties that protect the 
TSF, as much of this testing will be negative testing in nature, attempting to 
disprove the properties. In developing the strategy for penetration testing, the 
evaluator will ensure that all aspects of the security architecture description 
are tested, either in fu nctional testing (as considered in 15) or evaluator 
penetration testing. 
1588 It will probably be practical to carry out penetration test using a series of test 
cases, where each test case will test for a specific potential vulnerability. 
1589 The evaluator is not expected to test for potential vulnerabilities (including 
those in the public domain) beyond those which required an Enhanced -Basic 
attack potential. In some cases, however, it will be necessary to carry out a 
test before the exploitabilit y can be determined. Where, as a result of 
evaluation expertise, the evaluator discovers an exploitable vulnerability that 
is beyond Enhanced -Basic attack potential, this is reported in the ETR as a 
residual vulnerability. 
1590 Guidance on determining the neces sary attack potential to exploit a potential 
vulnerability can be found in Annex B.4. 
1591 Potential vulnerabilities hypothesised as exploitable only by attackers 
possessing Moderate or High attack potential do not result in a failure of this 
evaluator action. Where analysis supports the hypothesis, these need not be 
considered further as an input to penetration testing. However, such 
vulnerabilities are reported in the ETR as residual vulnerabilities. 
1592 Potential vulnerabilities hypothesised as exploitable by an attacker 
possessing a Basic or Enhanced -Basic attack potential and resulting in a 
violation of the security objectives should be the highest priority potential 
vulnerabilities comprising the list used to direct penetration  testing against 
the TOE. 
Class AVA: Vulnerability assessment 
Page 334 of 430 Version 3.1 April 2017 
AVA_VAN.3-7 The evaluator shall produce  penetration test documentation for the tests 
based on the list of potential vulnerabilities in sufficient detail to enable the 
tests to be repeatable. The test documentation shall include:  
a) identification of the potential vulnerability the TOE is being tested 
for;  
b) instructions to connect and setup all required test equipment as 
required to conduct the penetration test;  
c) instructions to establish al l penetration test prerequisite initial 
conditions;  
d) instructions to stimulate the TSF;  
e) instructions for observing the behaviour of the TSF;  
f) descriptions of all expected results and the necessary analysis to be 
performed on the observed behaviour for com parison against 
expected results;  
g) instructions to conclude the test and establish the necessary post -test 
state for the TOE.  
1593 The evaluator prepares for penetration testing based on the list of potential 
vulnerabilities identified during the search of the  public domain and the 
analysis of the evaluation evidence. 
1594 The evaluator is not expected to determine the exploitability for potential 
vulnerabilities beyond those for which an Enhanced -Basic attack potential is 
required to effect an attack. However, as a  result of evaluation expertise, the 
evaluator may discover a potential vulnerability that is exploitable only by an 
attacker with greater than Enhanced -Basic attack potential. Such 
vulnerabilities are to be reported in the ETR as residual vulnerabilities. 
1595 With an understanding of the potential vulnerability, the evaluator 
determines the most feasible way to test for the TOE's susceptibility. 
Specifically the evaluator considers:  
a) the TSFI or other TOE interface that will be used to stimulate the 
TSF and observe responses (It is possible that the evaluator will need 
to use an interface to the TOE other than the TSFI to demonstrate 
properties of the TSF such as those described in the security 
architecture description (as required by ADV_ARC). It should the 
noted, that although these TOE interfaces provide a means of testing 
the TSF properties, they are not the subject of the test.);  
b) initial conditions that will need to exist for the test (i.e. any particular 
objects or subjects that will need to exist and security attributes they 
will need to have);  
Class AVA: Vulnerability assessment 
April 2017 Version 3.1 Page 335 of 430 
c) special test equipment that will be required to either stimulate a TSFI 
or make observations of a TSFI (although it is unlikely that specialist 
equipment would be required to exploit  a potential vulnerability 
assuming an Enhanced-Basic attack potential);  
d) whether theoretical analysis should replace physical testing, 
particularly relevant where the results of an initial test can be 
extrapolated to demonstrate that repeated attempts of an attack are 
likely to succeed after a given number of attempts.  
1596 The evaluator will probably find it practical to carry out penetration testing 
using a series of test cases, where each test case will test for a specific 
potential vulnerability. 
1597 The inten t of specifying this level of detail in the test documentation is to 
allow another evaluator to repeat the tests and obtain an equivalent result. 
AVA_VAN.3-8 The evaluator shall conduct penetration testing. 
1598 The e valuator uses the penetration test documentation resulting from work 
unit AVA_VAN.3-6 as a basis for executing penetration tests on the TOE, 
but this does not preclude the evaluator from performing additional ad hoc 
penetration tests. If required, the evaluator may devise ad hoc tests as a result 
of information learnt during penetration testing that, if performed by the 
evaluator, are to be recorded in the penetration test documentation. Such tests 
may be required to follow up unexpec ted results or observations, or to 
investigate potential vulnerabilities suggested to the evaluator during the pre-
planned testing. 
1599 Should penetration testing show that a hypothesised potential vulnerability 
does not exist, then the evaluator should determ ine whether or not the 
evaluator's own analysis was incorrect, or if evaluation deliverables are 
incorrect or incomplete. 
1600 The evaluator is not expected to test for potential vulnerabilities (including 
those in the public domain) beyond those which required  an Enhanced-Basic 
attack potential. In some cases, however, it will be necessary to carry out a 
test before the exploitability can be determined. Where, as a result of 
evaluation expertise, the evaluator discovers an exploitable vulnerability that 
is beyond Enhanced-Basic attack potential, this is reported in the ETR as a 
residual vulnerability. 
AVA_VAN.3-9 The evaluator shall record the actual results of the penetration tests. 
1601 While some specific details of the actual test results may be different from 
those expected (e.g. time and date fields in an audit record) the overall result 
should be identical. Any unexpected test results should be investigated. The 
impact on the evaluation should be stated and justified. 
AVA_VAN.3-10 The evaluator shall report in the ETR the evaluator penetration testing effort, 
outlining the testing approach, configuration, depth and results. 
Class AVA: Vulnerability assessment 
Page 336 of 430 Version 3.1 April 2017 
1602 The penetration testing information reported in t he ETR allows the evaluator 
to convey the overall penetration testing approach and effort expended on 
this sub -activity. The intent of providing this information is to give a 
meaningful overview of the evaluator's penetration testing effort. It is not 
intended that the information regarding penetration testing in the ETR be an 
exact reproduction of specific test steps or results of individual penetration 
tests. The intention is to provide enough detail to allow other evaluators and 
evaluation authorities to  gain some insight about the penetration testing 
approach chosen, amount of penetration testing performed, TOE test 
configurations, and the overall results of the penetration testing activity. 
1603 Information that would typically be found in the ETR section re garding 
evaluator penetration testing efforts is:  
a) TOE test configurations. The particular configurations of the TOE 
that were penetration tested;  
b) TSFI penetration tested. A brief listing of the TSFI and other TOE 
interfaces that were the focus of the penetration testing;  
c) Verdict for the sub -activity. The overall judgement on the results of 
penetration testing.  
1604 This list is by no means exhaustive and is only intended to provide some 
context as to the type of information that should be present in the ETR 
concerning the penetration testing the evaluator performed during the 
evaluation. 
AVA_VAN.3-11 The evaluator shall examine  the results of all penetration testing to 
determine that the TOE, in its operational e nvironment, is resistant to an 
attacker possessing an Enhanced-Basic attack potential. 
1605 If the results reveal that the TOE, in its operational environment, has 
vulnerabilities exploitable by an attacker possessing less than Moderate 
attack potential, then this evaluator action fails. 
1606 The guidance in B.4 should be used to determine the attack potential required 
to exploit a particular vulnerability and whether it can therefore be exploited 
in the intended environment. It may not be necessary for the attack potential 
to be calculated in every instance, only if there is some doubt as to whether 
or not the vulnerability can be exploited by an attacker possessing an attack 
potential less than Moderate. 
AVA_VAN.3-12 The evaluator shall report  in the ETR all exploitable vulnerabilities and 
residual vulnerabilities, detailing for each:  
a) its source (e.g. CEM activity being undertaken when it was conceived, 
known to the evaluator, read in a publication);  
b) the SFR(s) not met;  
c) a description;  
Class AVA: Vulnerability assessment 
April 2017 Version 3.1 Page 337 of 430 
d) whether it is exploitable in its operational environment or not (i.e. 
exploitable or residual).  
e) the amount of time, level of expertise, level of knowledge of the TOE, 
level of opportunity and the equipm ent required to perform the 
identified vulnerabilities, and the corresponding values using the 
tables 3 and 4 of Annex B.4.  
16.2.4 Evaluation of sub-activity (AVA_VAN.4) 
16.2.4.1 Objectives 
1607 The objective of this sub -activity is to determine whether the TOE, in its 
operational environment, has vulnerabilities exploitable by attackers 
possessing Moderate attack potential. 
16.2.4.2 Input 
1608 The evaluation evidence for this sub-activity is:  
a) the ST; 
b) the functional specification; 
c) the TOE design; 
d) the security architecture description; 
e) the implementation representation; 
f) the guidance documentation; 
g) the TOE suitable for testing; 
h) information publicly available to support the identification of 
possible potential vulnerabilities;  
i) the results of the testing of the basic design.  
1609 The remaining implicit evaluation evidence for this sub -activity depends on 
the components that have been included in the assurance package. The 
evidence provided for each component is to be used as input in this sub -
activity. 
1610 Other input for this sub-activity is:  
a) current information regarding public domain potential vulnerabilities 
and attacks (e.g. from an evaluation authority).  
16.2.4.3 Application notes 
1611 The methodical analysis approach takes the form of a structured examination 
of the evidence. This method requires the evaluator to specify the structure 
Class AVA: Vulnerability assessment 
Page 338 of 430 Version 3.1 April 2017 
and form the analysis will take (i.e. the manner in which the analysis is 
performed is predetermined, unlike the focused analysis). The method is 
specified in terms of the information that will be considered and how/why it 
will be considered. Further guidance on methodical vulnerability analysis 
can be found in Annex B.2.2.2.3. 
16.2.4.4 Action AVA_VAN.4.1E 
AVA_VAN.4.1C The TOE shall be suitable for testing.  
AVA_VAN.4-1 The evaluator shall examine the TOE to determine that the test configuration 
is consistent with the configuration under evaluation as specified in the ST. 
1612 The TOE provided by the developer and identified in the test plan should 
have the same unique reference as established by the CM capabilities 
(ALC_CMC) sub-activities and identified in the ST introduction. 
1613 It is possible for the ST to specify more than one configuration for evaluation. 
The TOE may comprise a number of distinct hardware and software entities 
that need to be tested in accordance with the ST. The evaluator  verifies that 
all test configurations are consistent with the ST. 
1614 The evaluator should consider the security objectives for the operational 
environment described in the ST that may apply to the test environment and 
ensure they are met in the testing envir onment. There may be some 
objectives for the operational environment that do not apply to the test 
environment. For example, an objective about user clearances may not apply; 
however, an objective about a single point of connection to a network would 
apply. 
1615 If any test resources are used (e.g. meters, analysers) it will be the evaluator's 
responsibility to ensure that these resources are calibrated correctly. 
AVA_VAN.4-2 The evaluator shall examine the TOE to dete rmine that it has been installed 
properly and is in a known state 
1616 It is possible for the evaluator to determine the state of the TOE in a number 
of ways. For example, previous successful completion of the Evaluation of 
sub-activity (AGD_PRE.1)  sub-activity will satisfy this work unit if the 
evaluator still has confidence that the TOE being used for testing was 
installed properly and is in a known state. If this is not the case, then the 
evaluator should follow the developer's procedures  to install and start up the 
TOE, using the supplied guidance only. 
1617 If the evaluator has to perform the installation procedures because the TOE is 
in an unknown state, this work unit when successfully completed could 
satisfy work unit AGD_PRE.1-3. 
16.2.4.5 Action AVA_VAN.4.2E 
AVA_VAN.4-3 The evaluator shall examine  sources of information publicly available to 
identify potential vulnerabilities in the TOE. 
Class AVA: Vulnerability assessment 
April 2017 Version 3.1 Page 339 of 430 
1618 The evaluator examines the sources of information publicly available to 
support the identification of possible potential vulnerabilities in the TOE. 
There are many sources of publicly available information which the 
evaluator should consider using items s uch as those available on the world 
wide web, including:  
a) specialist publications (magazines, books);  
b) research papers;  
c) conference proceedings.  
1619 The evaluator should not constrain their consideration of publicly available 
information to the above, but sho uld consider any other relevant information 
available. 
1620 While examining the evidence provided the evaluator will use the 
information in the public domain to further search for potential 
vulnerabilities. Where the evaluators have identified areas of concern,  the 
evaluator should consider information publicly available that relate to those 
areas of concern. 
1621 The availability of information that may be readily available to an attacker 
that helps to identify and facilitate attacks may substantially enhance the 
attack potential of a given attacker. The accessibility of vulnerability 
information and sophisticated attack tools on the Internet makes it more 
likely that this information will be used in attempts to identify potential 
vulnerabilities in the TOE and explo it them. Modern search tools make such 
information easily available to the evaluator, and the determination of 
resistance to published potential vulnerabilities and well known generic 
attacks can be achieved in a cost-effective manner. 
1622 The search of the in formation publicly available should be focused on those 
sources that refer to the technologies used in the development of the product 
from which the TOE is derived. The extensiveness of this search should 
consider the following factors: TOE type, evaluator  experience in this TOE 
type, expected attack potential and the level of ADV evidence available. 
1623 The identification process is iterative, where the identification of one 
potential vulnerability may lead to identifying another are a of concern that 
requires further investigation. 
1624 The evaluator will describe the approach to be taken to identify potential 
vulnerabilities in the publicly available material, detailing the search to be 
performed. This may be driven by factors such as are as of concern identified 
by the evaluator, linked to the evidence the attacker is assumed to be able to 
obtain. However, it is recognised that in this type of search the approach may 
further evolve as a result of findings during the search. Therefore, the 
evaluator will also report any actions taken in addition to those described in 
the approach to further investigate issues thought to lead to potential 
Class AVA: Vulnerability assessment 
Page 340 of 430 Version 3.1 April 2017 
vulnerabilities, and will report the evidence examined in completing the 
search for potential vulnerabilities. 
16.2.4.6 Action AVA_VAN.4.3E 
AVA_VAN.4-4 The evaluator shall conduct  a methodical analysis of ST, guidance 
documentation, functional specification, TOE design, security architecture 
description and implementation representation to identify possible potential 
vulnerabilities in the TOE. 
1625 Guidance on methodical vulnerability analysis is provided in Annex 
B.2.2.2.3. 
1626 This approach to identification of potential vulnerabilities is to take an 
ordered and planned approach. A system is to be applied in the examination. 
The evaluator is to describe the method to be used in terms of the manner in 
which this information is to be considered and the hypothesis t hat is to be 
created. 
1627 A flaw hypothesis methodology needs to be used whereby the ST, 
development (functional specification, TOE design and implementation 
representation) and guidance evidence are analysed and then vulnerabilities 
in the TOE are hypothesised, or speculated. 
1628 The evaluator uses the knowledge of the TOE design and operation gained 
from the TOE deliverables to conduct a flaw hypothesis to identify potential 
flaws in the development of the TOE and potential errors in the specified 
method of operation of the TOE. 
1629 The security architecture description provides the developer vulnerability 
analysis, as it documents how the TSF protects itself from interference from 
untrusted subjects and prevents the bypass of security enforcement 
functionality. Therefore, the evaluator should build upon the understanding 
of the TSF protection gained from the analysis of this evidence and then 
develop this in the knowledge gained from other development ADV 
evidence. 
1630 The approach taken to the methodical search for vulnerabilities is to consider 
any areas of concern identified in the results of the evaluator's assessment of 
the development and guidance evidence. However, the evaluator should also 
consider each aspect of the security architecture  analysis to search for any 
ways in which the protection of the TSF can be undermined. It may be 
helpful to structure the methodical analysis on the basis of the material 
presented in the security architecture description, introducing concerns from 
other ADV evidence as appropriate. The analysis can then be further 
developed to ensure all other material from the ADV evidence is considered. 
1631 The following provide some examples of hypotheses that may be cre ated 
when examining the evidence:  
Class AVA: Vulnerability assessment 
April 2017 Version 3.1 Page 341 of 430 
a) consideration of malformed input for interfaces available to an 
attacker at the external interfaces;  
b) examination of a key security mechanism cited in the security 
architecture description, such as process separation, hyp othesising 
internal buffer overflows that may lead to degradation of separation;  
c) search to identify any objects created in the TOE implementation 
representation that are then not fully controlled by the TSF, and could 
be used by an attacker to undermine SFRs.  
1632 For example, the evaluator may identify that interfaces are a potential area of 
weakness in the TOE and specify an approach to the search that 'all interface 
specifications in the evidence provided will be searched to hypothesise 
potential vulnerabil ities' and go on to explain the methods used in the 
hypothesis. 
1633 In addition, areas of concern the evaluator has identified during examination 
of the evidence during the conduct of evaluation activities. Areas of concern 
may also be identified during the conduct of other work units associated with 
this component, in particular AVA_VAN.4-7, AVA_VAN.4-5 and 
AVA_VAN.4-6 where the development and conduct of penetration tests may 
identify furthe r areas of concerns for investigation, or potential 
vulnerabilities. 
1634 However, examination of only a subset of the development and guidance 
evidence or their contents is not permitted in this level of rigour. The 
approach description should provide a demons tration that the methodical 
approach used is complete, providing confidence that the approach used to 
search the deliverables has considered all of the information provided in 
those deliverables. 
1635 This approach to identification of potential vulnerabilities  is to take an 
ordered and planned approach; applying a system to the examination. The 
evaluator is to describe the method to be used in terms of how the evidence 
will be considered; the manner in which this information is to be considered 
and the hypothesis that is to be created. This approach should be agreed with 
the evaluation authority, and the evaluation authority may provide detail of 
any additional approaches the evaluator should take to the vulnerability 
analysis and identify any additional information that should be considered by 
the evaluator. 
1636 Although a system to identifying potential vulnerabilities is predefined, the 
identification process may still be iterative, where the identification of one 
potential vulnerability may lead to identifying an other area of concern that 
requires further investigation. 
1637 Subject to the SFRs the TOE is to meet in the operational environment, the 
evaluator's independent vulnerability analysis should consider generic 
potential vulnerabilities under each of the following headings:  
Class AVA: Vulnerability assessment 
Page 342 of 430 Version 3.1 April 2017 
a) generic potential vulnerabilities relevant for the type of TOE being 
evaluated, as may be supplied by the evaluation authority; 
b) bypassing; 
c) tampering; 
d) direct attacks; 
e) monitoring; 
f) misuse. 
1638 Items b) - f) are explained in greater detail in Annex B. 
1639 The security architecture description should be considered in light of each of 
the above generic potential vulnerabilities. Each potential vulnerability 
should be considered to search for possible ways in which to defeat the T SF 
protection and undermine the TSF. 
AVA_VAN.4-5 The evaluator shall record in the ETR the identified potential vulnerabilities 
that are candidates for testing and applicable to the TOE in its operational 
environment. 
1640 It may be identified that no further consideration of the potential 
vulnerability is required if for example the evaluator identifies that measures 
in the operational environment, either IT or non -IT, prevent exploitation of 
the potential vulnerabili ty in that operational environment. For instance, 
restricting physical access to the TOE to authorised users only may 
effectively render a potential vulnerability to tampering unexploitable. 
1641 The evaluator records any reasons for exclusion of potential vuln erabilities 
from further consideration if the evaluator determines that the potential 
vulnerability is not applicable in the operational environment. Otherwise the 
evaluator records the potential vulnerability for further consideration. 
1642 A list of potential  vulnerabilities applicable to the TOE in its operational 
environment, which can be used as an input into penetration testing activities, 
shall be reported in the ETR by the evaluators. 
16.2.4.7 Action AVA_VAN.4.4E 
AVA_VAN.4-6 The evaluator shall devise penetration tests, based on the independent search 
for potential vulnerabilities. 
1643 The evaluator prepares for penetration testing as necessary to determine the 
susceptibility of the TOE, in its operational environment, to the potential 
vulnerabilities identified during the search of the sources of information 
publicly available. Any current information provided to the evaluator by a 
third party (e.g. evaluation authority) regardin g known potential 
vulnerabilities will be considered by the evaluator, together with any 
Class AVA: Vulnerability assessment 
April 2017 Version 3.1 Page 343 of 430 
encountered potential vulnerabilities resulting from the performance of other 
evaluation activities. 
1644 The evaluator is reminded that, as for considering the security ar chitecture 
description in the search for vulnerabilities (as detailed in AVA_VAN.4-3), 
testing should be performed to confirm the architectural properties. If 
requirements from ATE_DPT are i ncluded in the SARs, the developer 
testing evidence will include testing performed to confirm the correct 
implementation of any specific mechanisms detailed in the security 
architecture description. However, the developer testing will not necessarily 
include testing of all aspects of the architectural properties that protect the 
TSF, as much of this testing will be negative testing in nature, attempting to 
disprove the properties. In developing the strategy for penetration testing, the 
evaluator will ensure  that all aspects of the security architecture description 
are tested, either in functional testing (as considered in 15) or evaluator 
penetration testing. 
1645 The evaluator will probably find it practical to carry out penetration test 
using a series of test cases, where each test case will test for a specific 
potential vulnerability. 
1646 The evaluator is not expected to test for potential vulnerabilities (including 
those in the public domain) beyond those which required a Moderate attack 
potential. In some cases, however, it will be necessary to carry out a test 
before the exploitability can be determined. Where, as a result of evaluation 
expertise, the evaluator discovers an exploitable vulnerability that is beyond 
Moderate attack potential, this  is reported in the ETR as a residual 
vulnerability. 
1647 Guidance on determining the necessary attack potential to exploit a potential 
vulnerability can be found in Annex B.4. 
1648 Potential vulnerabilities hypothesised as exploita ble by an attacker 
possessing a Moderate (or less) attack potential and resulting in a violation of 
the security objectives should be the highest priority potential vulnerabilities 
comprising the list used to direct penetration testing against the TOE. 
AVA_VAN.4-7 The evaluator shall produce  penetration test documentation for the tests 
based on the list of potential vulnerabilities in sufficient detail to enable the 
tests to be repeatable. The test documentation shall include:  
a) identification of the potential vulnerability the TOE is being tested 
for;  
b) instructions to connect and setup all required test equipment as 
required to conduct the penetration test;  
c) instructions to establish all penetration test prerequisi te initial 
conditions;  
d) instructions to stimulate the TSF;  
Class AVA: Vulnerability assessment 
Page 344 of 430 Version 3.1 April 2017 
e) instructions for observing the behaviour of the TSF;  
f) descriptions of all expected results and the necessary analysis to be 
performed on the observed behaviour for comparison against 
expected results;  
g) instructions to conclude the test and establish the necessary post -test 
state for the TOE.  
1649 The evaluator prepares for penetration testing based on the list of potential 
vulnerabilities identified during the search of the public domain and the 
analysis of the evaluation evidence. 
1650 The evaluator is not expected to determine the exploitability for potential 
vulnerabilities beyond those for which a Moderate attack potential is 
required to effect an attack. However, as a result of evaluation expertise, the  
evaluator may discover a potential vulnerability that is exploitable only by an 
attacker with greater than Moderate attack potential. Such vulnerabilities are 
to be reported in the ETR as residual vulnerabilities. 
1651 With an understanding of the potential vu lnerability, the evaluator 
determines the most feasible way to test for the TOE's susceptibility. 
Specifically the evaluator considers:  
a) the TSFI or other TOE interface that will be used to stimulate the 
TSF and observe responses (It is possible that the e valuator will need 
to use an interface to the TOE other than the TSFI to demonstrate 
properties of the TSF such as those described in the security 
architecture description (as required by ADV_ARC). It should the 
noted, that although these TOE interfaces provide a means of testing 
the TSF properties, they are not the subject of the test.);  
b) initial conditions that will need to exist for the test (i.e. any particular 
objects or subjects that will need to exist and security attri butes they 
will need to have);  
c) special test equipment that will be required to either stimulate a TSFI 
or make observations of a TSFI;  
d) whether theoretical analysis should replace physical testing, 
particularly relevant where the results of an initial tes t can be 
extrapolated to demonstrate that repeated attempts of an attack are 
likely to succeed after a given number of attempts.  
1652 The evaluator will probably find it practical to carry out penetration testing 
using a series of test cases, where each test c ase will test for a specific 
potential vulnerability. 
1653 The intent of specifying this level of detail in the test documentation is to 
allow another evaluator to repeat the tests and obtain an equivalent result. 
AVA_VAN.4-8 The evaluator shall conduct penetration testing. 
Class AVA: Vulnerability assessment 
April 2017 Version 3.1 Page 345 of 430 
1654 The evaluator uses the penetration test documentation resulting from work 
unit AVA_VAN.4-6 as a basis for executing penetration tests on the TOE, 
but this does not preclude th e evaluator from performing additional ad hoc 
penetration tests. If required, the evaluator may devise ad hoc tests as a result 
of information learnt during penetration testing that, if performed by the 
evaluator, are to be recorded in the penetration test documentation. Such tests 
may be required to follow up unexpected results or observations, or to 
investigate potential vulnerabilities suggested to the evaluator during the pre-
planned testing. 
1655 Should penetration testing show that a hypothesised potential  vulnerability 
does not exist, then the evaluator should determine whether or not the 
evaluator's own analysis was incorrect, or if evaluation deliverables are 
incorrect or incomplete. 
1656 The evaluator is not expected to test for potential vulnerabilities (in cluding 
those in the public domain) beyond those which required a Moderate attack 
potential. In some cases, however, it will be necessary to carry out a test 
before the exploitability can be determined. Where, as a result of evaluation 
expertise, the evalu ator discovers an exploitable vulnerability that is beyond 
Moderate attack potential, this is reported in the ETR as a residual 
vulnerability. 
AVA_VAN.4-9 The evaluator shall record the actual results of the penetration tests. 
1657 While some specific details of the actual test results may be different from 
those expected (e.g. time and date fields in an audit record) the overall result 
should be identical. Any unexpected test results should be investigated. The 
impact on the evaluation should be stated and justified. 
AVA_VAN.4-10 The evaluator shall report in the ETR the evaluator penetration testing effort, 
outlining the testing approach, configuration, depth and results. 
1658 The penetration testing information reported in the ETR allows the evaluator 
to convey the overall penetration testing approach and effort expended on 
this sub -activity. The intent of providing this information is to give a 
meaningful overview of the eval uator's penetration testing effort. It is not 
intended that the information regarding penetration testing in the ETR be an 
exact reproduction of specific test steps or results of individual penetration 
tests. The intention is to provide enough detail to al low other evaluators and 
evaluation authorities to gain some insight about the penetration testing 
approach chosen, amount of penetration testing performed, TOE test 
configurations, and the overall results of the penetration testing activity. 
1659 Information t hat would typically be found in the ETR section regarding 
evaluator penetration testing efforts is:  
a) TOE test configurations. The particular configurations of the TOE 
that were penetration tested;  
Class AVA: Vulnerability assessment 
Page 346 of 430 Version 3.1 April 2017 
b) TSFI penetration tested. A brief listing of the TSFI and o ther TOE 
interfaces that were the focus of the penetration testing;  
c) Verdict for the sub -activity. The overall judgement on the results of 
penetration testing.  
1660 This list is by no means exhaustive and is only intended to provide some 
context as to the type  of information that should be present in the ETR 
concerning the penetration testing the evaluator performed during the 
evaluation. 
AVA_VAN.4-11 The evaluator shall examine  the results of all penetration testi ng to 
determine that the TOE, in its operational environment, is resistant to an 
attacker possessing a Moderate attack potential. 
1661 If the results reveal that the TOE, in its operational environment, has 
vulnerabilities exploitable by an attacker possessing less than a High attack 
potential, then this evaluator action fails. 
1662 The guidance in B.4 should be used to determine the attack potential required 
to exploit a particular vulnerability and whether it can therefore be explo ited 
in the intended environment. It may not be necessary for the attack potential 
to be calculated in every instance, only if there is some doubt as to whether 
or not the vulnerability can be exploited by an attacker possessing an attack 
potential less than High. 
AVA_VAN.4-12 The evaluator shall report  in the ETR all exploitable vulnerabilities and 
residual vulnerabilities, detailing for each:  
a) its source (e.g. CEM activity being undertaken when it was conceived, 
known to the evaluator, read in a publication);  
b) the SFR(s) not met;  
c) a description;  
d) whether it is exploitable in its operational environment or not (i.e. 
exploitable or residual).  
e) the amount of time, level of expertise, level of knowledge of the TOE , 
level of opportunity and the equipment required to perform the 
identified vulnerabilities, and the corresponding values using the 
tables 3 and 4 of Annex B.4.  
16.2.5 Evaluation of sub-activity (AVA_VAN.5) 
1663 There is no general guidance; the scheme should be consulted for guidance 
on this sub-activity. 
Class ACO: Composition 
April 2017 Version 3.1 Page 347 of 430 
17 Class ACO: Composition 
17.1 Introduction 
1664 The goal of this activity is to determine whether the components can be 
integrated in a secure manner , as defined in the ST for the composed TOE. 
This is achieved through examination and testing of the interfaces between 
the components, supported by examination of the design of the components 
and the conduct of vulnerability analysis. 
17.2 Application notes 
1665 The Reliance of dependent component (ACO_REL)  family identifies where 
the dependent component is reliant upon IT in its operational environment 
(satisfied by a base component in the composed TOE evaluation) in order to 
provide its own secu rity services. This reliance is identified in terms of the 
interfaces expected by the dependent component to be provided by the base 
component. Development evidence (ACO_DE V) then determines which 
interfaces of the base component were co nsidered (as TSFI) during the 
component evaluation of the base component. 
1666 It should be noted that Reliance of dependent component (ACO_REL)  does 
not cover other evidence that may be needed to address the technical 
integration problem of composing components (e.g. descriptions of non -TSF 
interfaces of the operating system, rules for integration, etc.). This is outside 
the security assessment of the composition and is a functional composition 
issue. 
1667 As part of Composed TOE testing (ACO_CTT)  the evaluator will perform 
testing of the composed TOE SFRs at the composed TOE interfaces and of 
the interfaces of the base component relied upon by the dependent 
component to confirm they operate as specified. The subset selected will  
consider the possible effects of changes to the configuration/use of the base 
component as used in the composed TOE. These changes are identified from 
the configuration of the base component determined during the base 
component evaluation. The developer w ill provide test evidence for each of 
the base component interfaces (the requirements for coverage are consistent 
with those applied to the evaluation of the base component). 
1668 Composition rationale (ACO_COR)  requires the evaluator to dete rmine 
whether the appropriate assurance measures have been applied to the base 
component, and whether the base component is being used in its evaluated 
configuration. This includes determination of whether all security 
functionality required by the depende nt component was within the TSF of 
the base component. The Composition rationale (ACO_COR)  requirement 
may be met through the production of evidence that each of these is 
demonstrated to be upheld. This evidence may be in the form of the  security 
target and a public report of the component evaluation (e.g. certification 
report). 
Class ACO: Composition 
Page 348 of 430 Version 3.1 April 2017 
1669 If, on the other hand, one of the above have not been upheld, then it may be 
possible that an argument can be made as to why the assurance gained during 
an origin al evaluation is unaffected. If this is not possible then additional 
evaluation evidence for those aspects of the base component not covered 
may have to be provided. This material is then assessed in Development 
evidence (ACO_DEV). 
1670 For e xample, it may be the case as described in the Interactions between 
entities (see Annex B.3, Interactions between composed IT entities  in CC 
Part 3) that the dependent component requires the base component to provide 
more security functionality in the composed TOE than included in the base 
component evaluation. This would be determined during the application of 
the Reliance of dependent component (ACO_REL)  and Development 
evidence (ACO_DE V) families. In this case the composition rationale 
evidence provided for Composition rationale (ACO_COR)  would 
demonstrate that the assurance gained from the base component evaluation is 
unaffected. This may be achieved by means including:  
a) Performing a re -evaluation of the base component focusing on the 
evidence relating to the extended part of the TSF; 
b) Demonstrating that the extended part of the TSF cannot affect other 
portions of the TSF, and providing evidence that the extend ed part of 
the TSF provides the necessary security functionality. 
Class ACO: Composition 
April 2017 Version 3.1 Page 349 of 430 
17.3 Composition rationale (ACO_COR) 
17.3.1 Evaluation of sub-activity (ACO_COR.1) 
17.3.1.1 Input 
1671 The evaluation evidence for this sub-activity is:  
a) the composed ST;  
b) the composition rationale;  
c) the reliance information; 
d) the development information; 
e) unique identifier.  
17.3.1.2 Action ACO_COR.1.1E 
ACO_COR.1.1C The composition rationale shall demonstrate that a level of assurance  at 
least as high as that of the dependent component has been obtained for the 
support functionality of the base component, when the base component is 
configured as required to support the TSF of the dependent component.  
ACO_COR.1-1 The evaluator shall examine  the correspondence analysis with the 
development information and the reliance information to identify the 
interfaces that are relied upon by the dependent component which are not 
detailed in the development information. 
1672 The evaluator's goal in this work unit is two fold:  
a) to determine which interfaces relied upon by the dependent 
component have had the appropriate assurance measures applied. 
b) to determine that the assurance package applied to the base 
component during the base component evaluation contained either 
the same assurance requirements as those in the package applied to 
the dependent component during its' evaluation, or hierarchically 
higher assurance requirements. 
1673 The evaluator may use the correspon dence tracing in the development 
information developed during the Development evidence (ACO_DE V) 
activities (e.g. ACO_DEV.1-2, ACO_DEV.2-4, ACO_DEV.3-6) to help 
identify the interfaces identified in the reliance information that are not 
considered in the development information. 
1674 The evaluator will record the SFR -enforcing interfaces described in the 
reliance information that are not included in the development informatio n. 
These will provide input to ACO_COR.1-3 work unit, helping to identify the 
portions of the base component in which further assurance is required. 
Class ACO: Composition 
Page 350 of 430 Version 3.1 April 2017 
1675 If the both the base and dependent components were evaluated against the 
same assura nce package, then the determination of whether the level of 
assurance in the portions within the base component evaluation is at least as 
high as that of the dependent component is trivial. If however, the assurance 
packages applied to the components during the component evaluations differ, 
the evaluator needs to determine that the assurance requirements applied to 
the base component are all hierarchically higher to the assurance 
requirements applied to the dependent component. 
ACO_COR.1-2 The evaluator shall examine  the composition rationale to determine, for 
those included base component interfaces on which the dependent TSF relies, 
whether the interface was considered during the evaluation of the base 
component. 
1676 The ST, component public evaluation report (e.g. certification report) and 
guidance documents for the base component all provide information on the 
scope and boundary of the base component. The ST provides details of the 
logical scope and boundary of the composed TOE, allowing the evaluator to 
determine whether an interface relates to a portion of the product that was 
within the scope of the evaluation. The guidance documentation provides 
details of use of all interfaces for the composed TOE. Although the guidance 
documentation may include details of interfaces in the product that are not 
within the scope of the evaluation, any such interfaces should be identifiable, 
either from the scoping information in the ST or through a portion of the 
guidance that dea ls with the evaluated configuration. The public evaluation 
report may provide any additional constraints on the use of the composed 
TOE that are necessary. 
1677 Therefore, the combination of these inputs allows the evaluator to determine 
whether an interface described in the composition rationale has the necessary 
assurance associated with it, or whether further assurance is required. The 
evaluator will record those interfaces of the base component for which 
additional assurance is required, for consideration during ACO_COR.1-3. 
ACO_COR.1-3 The evaluator shall examine the composition rationale to determine that the 
necessary assurance measures have been applied to the base component. 
1678 The evaluation verdicts, and resultant assurance, for the base component can 
be reused provided the same portions of the base component are used in the 
composed TOE and they are used in a consistent manner. 
1679 In order to determine whether the necessary assurance measures have already 
been applied to the component, and the portions of the component for which 
assurance measures still need to be applied, the evaluator should use the 
output of the ACO_DEV.*.2E action and the work units ACO_COR.1-1 and 
ACO_COR.1-2: 
a) For those interfaces identified in the reliance information (Reliance of 
dependent component (ACO_REL) ), but not discussed in 
development information ( Development evidence (ACO_DE V)), 
additional information is required. (Identified in ACO_COR.1-1.) 
Class ACO: Composition 
April 2017 Version 3.1 Page 351 of 430 
b) For those interfaces used inconsistently in the composed TOE from 
the base component (difference between the information provided in 
Development evidence (ACO_DE V) and Reliance of dependent 
component (ACO_REL) the impact of the differences in use need to 
be considered. (Identified in ACO_DEV.*.2E.) 
c) For those interfaces id entified in composition rationale for which no 
assurance has previously been gained, additional information is 
required. (Identified in ACO_COR.1-2.) 
d) For those interfaces consistently described in the reliance information, 
composition rationale and the development information, no further 
action is required as the results from the base component evaluation 
can be re-used. 
1680 The interfaces of the base component reported to be required by the reliance 
information but not included in the de velopment information indicate the 
portions of the base component where further assurance is required. The 
interfaces identify the entry points into the base component. 
1681 For those interfaces included in both the development information and 
reliance information, the evaluator is to determine whether the interfaces are 
being used in the composed TOE in a manner that is consistent with the base 
component evaluation. The method of use of the interface will be considered 
during the Development evidence (ACO_DE V) activities to determine that 
the use of the interface is consistent in both the base component and the 
composed TOE. The remaining consideration is the determination of whether 
the configurations of the base component and the composed TO E are 
consistent. To determine this, the evaluator will consider the guidance 
documentation of each to ensure they are consistent (see further guidance 
below regarding consistent guidance documentation). Any deviation in the 
documentation will be further a nalysed by the evaluation to determine the 
possible effects. 
1682 For those interfaces that are consistently described in the reliance 
information and development information, and for which the guidance is 
consistent for the base component and the composed TOE,  the required level 
of assurance has been provided. 
1683 The following subsections provide guidance on how to determine 
consistency between assurance gained in the base component, the evidence 
provided for the composed TOE, and the analysis performed by the evaluator 
in the instances where inconsistencies are identified. 
17.3.1.2.1 Development 
1684 The reliance information identifies the interfaces in the dependent 
component that are to be matched by the base component. If an interface 
identified in the reliance information is not identified in the development 
information, then the composition rationale is to provide a justification of 
how the base component provides the required interfaces. 
Class ACO: Composition 
Page 352 of 430 Version 3.1 April 2017 
1685 If an interface identified in the reliance information is identified in the 
development information, but there are inconsistencies between the 
descriptions, further analysis is required. The evaluator identifies the 
differences in use of the base component as considered in the base 
component evaluation and the composed TOE evaluation. The eva luator will 
devise testing to be performed (during the conduct of Composed TOE testing 
(ACO_CTT)) to test the interface. 
1686 The patch status of the base and dependent components as used in the 
composed TOE should be compared to the patch st atus of the components 
during the component evaluations. If any patches have been applied to the 
components, the composition rationale is to include details of the patches, 
including any potential impact to the SFRs of the evaluated component. The 
evaluator should consider the details of the changes provided and verify the 
accuracy of the potential impact of the change on the component SFRs. The 
evaluator should then consider whether the changes made by the patch 
should be verified through testing, and will  identify the necessary testing 
approach. The testing may take the form of repeating the applicable 
evaluator/developer testing performed for the component evaluation of the 
component or it may be necessary for the evaluator to devise new tests to 
confirm the modified component. 
1687 If any of the individual components have been the subject of assurance 
continuity activities since the completion of the component evaluation, the 
evaluator will consider the changes assessed in the assurance continuity 
activities d uring the independent vulnerability analysis activity for the 
composed TOE (in Composition vulnerability analysis (ACO_VUL)). 
17.3.1.2.2 Guidance 
1688 The guidance for the composed TOE is likely to make substantial reference 
out to the guidance for the individual components. The minimal guidance 
expected to be necessary is the identification of any ordering dependencies in 
the application of guidance for the dependent and base components, 
particularly during the preparation (installation) of the composed TOE. 
1689 In addition to the application of the Preparative procedures (AGD_PRE) and 
Operational user guidance (AGD_OPE)  families to the guidance for the 
composed TOE, it is necessary to analyse the consistency between the  
guidance for the components and the composed TOE, to identify any 
deviations. 
1690 If the composed TOE guidance refers out to the base component and 
dependent component guidance, then the consideration for consistency is 
limited to consistency between the guid ance documentation provided for 
each of the components (i.e. consistency between the base component 
guidance and the dependent component guidance). However, if additional 
guidance is provided for the composed TOE, to that provided for the 
components, great er analysis is required, as consistency is also required 
between the guidance documentation for the components and guidance 
documentation for the composed TOE. 
Class ACO: Composition 
April 2017 Version 3.1 Page 353 of 430 
1691 Consistent in this instance is understood to mean that either the guidance is 
the same or it pla ces additional constraints on the operation of the individual 
components when combined, in a similar manner to refinement of 
functional/assurance components. 
1692 With the information available (that used as input for Development evidence 
(ACO_DEV) or the development aspects discussed above) the evaluator may 
be able to determine all possible impacts of the deviation from the 
configuration of the base component specified in the component evaluation. 
However, for high EALs (where evaluation of the base component included 
TOE design (ADV_TDS)  requirements) it is possible that, unless detailed 
design abstractions for the base component are delivered as part of the 
development information for the composed TOE, the possible impact s of the 
modification to the guidance cannot be fully determined as the internals are 
unknown. In this case the evaluator will report the residual risk of the 
analysis. 
1693 These residual risks are to be included in any public evaluation report for the 
composed TOE. 
1694 The evaluator will note these variances in the guidance for input into 
evaluator independent testing activities ( Composed TOE testing 
(ACO_CTT)). 
1695 The guidance for the composed TOE may add to the guidance for the 
components, partic ularly in terms of installation and the ordering of 
installation steps for the base component in relation to the installation steps 
for the dependent component. The ordering of the steps for the installation of 
the individual components should not change, however they may need to be 
interleaved. The evaluator will examine this guidance to ensure that it still 
meets the requirement of the AGD_PRE activity performed during the 
evaluations of the components. 
1696 It may be the case th at the reliance information identifies that interfaces of 
the base component, in addition to those identified as TSFIs of the base 
component, are relied upon by the dependent component are identified in the 
reliance information. It may be necessary for gui dance to be provided for the 
use of any such additional interfaces in the base component. Provided the 
consumer of the composed TOE is to receive the guidance documentation for 
the base component, then the results of the AGD_PRE and AGD_OPE 
verdicts for the base component can be reused for those interfaces considered 
in the evaluation of the base component. However, for the additional 
interfaces relied upon by the dependent component, the evaluat or will need 
to determine that the guidance documentation for the base component meets 
the requirements of AGD_PRE and AGD_OPE, as applied in the base 
component evaluations. 
1697 For those interfaces  considered during the base component evaluation, and 
therefore, for which assurance has already been gained, the evaluator will 
ensure that the guidance for the use of each interface for the composed TOE 
is consistent with that provided for the base compo nent. To determine the 
Class ACO: Composition 
Page 354 of 430 Version 3.1 April 2017 
guidance for the composed TOE is consistent with that for the base 
component, the evaluator should perform a mapping for each interface to the 
guidance provided for both the composed TOE and the base component. The 
evaluator then compares the guidance to determine consistency. 
1698 Examples of additional constraints provided in composed TOE guidance that 
would be considered to be consistent with component guidance are (guidance 
for a component is given followed by an example of guidance fo r a 
composed TOE that would be considered to provide additional constraints):  
 Component: The password length must be set to a minimum of 8 
characters length, including alphabetic and numeric characters. 
 Composed TOE: The password length must be set to a m inimum of 
10 characters in length, including alphabetic and numeric characters 
and at least one of the following special characters: ( ) { } ^ < > - _ 
 NOTE: It would only be acceptable to increase the password length 
to [ integer > 8 ] characters while remov ing the mandate for the 
inclusion of both alphabetic and numeric characters for the composed 
TOE, if the same or a higher metric was achieved for the strength 
rating (taking into account the likelihood of the password being 
guessed). 
 Component: The following services are to be disabled in the registry 
settings: WWW Publishing Service and ICDBReporter service. 
 Composed TOE: The following services are to be disabled in the 
registry settings: Publishing Service, ICDBReporter service, Remote 
Procedure Call (RPC) Locator and Procedure Call (RPC) Service. 
 Component: Select the following attributes to be included in the 
accounting log files: date, time, type of event, subject identity and 
success/failure. 
 Composed TOE: Select the following attributes to be included  in the 
accounting log files: date, time, type of event, subject identity, 
success/failure, event message and process thread. 
1699 If the guidance for the composed TOE deviates (is not a refinement) from 
that provided for the base component, the evaluator will assess the potential 
risks of the modification to the guidance. The evaluator will use the 
information available (including that provided in the public domain, the 
architectural description of the base component in the public evaluation 
report (e.g. certif ication report), the context of the guidance from the 
remainder of the guidance documentation) to identify likely impact of the 
modification to the guidance on the SFRs of the composed TOE. 
1700 If during the dependent component evaluation the trial installatio n used the 
base component to satisfy the environment requirements of the dependent 
component this work unit for the composed TOE is considered to be satisfied. 
Class ACO: Composition 
April 2017 Version 3.1 Page 355 of 430 
If the base component was not used in satisfaction of the work unit 
AGD_PRE.1-3 during the dependent component evaluation, the evaluator 
will apply the user procedures provided for the composed TOE to prepare the 
composed TOE, in accordance with the guidance specified in AGD_PRE.1-3. 
This will allow the e valuator to determine that the preparative guidance 
provided for the composed TOE is sufficient to prepare the composed TOE 
and its operational environment securely. 
17.3.1.2.3 Life-cycle 
Delivery 
1701 If there is a different delivery mechanism used for the delivery of th e 
composed TOE (i.e. the components are not delivered to the consumer in 
accordance with the secure delivery procedures defined and assessed during 
the evaluation of the components), the delivery procedures for the composed 
TOE will require evaluation agai nst the Delivery (ALC_DEL) requirements 
applied during the components evaluations. 
1702 The composed TOE may be delivered as an integrated product or may 
require the components to be delivered separately. 
1703 If the components are delivered separ ately, the results of the delivery of the 
base component and dependent component are reused. The delivery of the 
base component is checked during the evaluator trial installation of the 
dependent component, using the specified guidance and checking the asp ects 
of delivery that are the responsibility of the user, as described in the guidance 
documentation for the base component. 
1704 If the composed TOE is delivered as a new entity, then the method of 
delivery of that entity must be considered in the composed TOE  evaluation 
activities. 
1705 The assessment of the delivery procedures for composed TOE items is to be 
performed in accordance with the methodology for Delivery (ALC_DEL) as 
for any other [component] TOE, ensuring any additional items (e.g. 
additional guidance documents for the composed TOE) are considered in the 
delivery procedures. 
CM Capabilities 
1706 The unique identification of the composed TOE is considered during the 
application of Evaluation of sub -activity (ALC_CMC.1) and the items from 
which that composed TOE is comprised are considered during the 
application of Evaluation of sub-activity (ALC_CMS.2). 
1707 Although additional guidance may be produced for the composed TOE, the 
unique identification of th is guidance (considered as part of the unique 
identification of the composed TOE during Evaluation of sub -activity 
(ALC_CMC.1)) is considered sufficient control of the guidance. 
Class ACO: Composition 
Page 356 of 430 Version 3.1 April 2017 
1708 The verdicts of the remaining (not considered above) Class ALC: Life-cycle 
support activities can be reused from the base component evaluation, as no 
further development is performed during integration of the composed TOE. 
1709 There are no additional considerations for development security as the 
integration is assumed to take place at either the consumer's site or, in the 
instance that the composed TOE is delivered as an integrated product, at the 
site of the dependent component developer. Control at the consumer's site is 
outside the consideration of  the CC. No additional requirements or guidance 
are necessary if integration is at the same site as that for the dependent 
component, as all components are considered to be configuration items for 
the composed TOE, and should therefore be considered under the dependent 
component developer's security procedures anyway. 
1710 Tools and techniques adopted during integration will be considered in the 
evidence provided by the dependent component developer. Any 
tools/techniques relevant to the base component will have been considered 
during the evaluation of the base component. For example, if the base 
component is delivered as source code and requires compilation by the 
consumer (e.g. dependent component developer who is performing 
integration) the compiler would have been specified and assessed, along with 
the appropriate arguments, during evaluation of the base component. 
1711 There is no life -cycle definition applicable to the composed TOE, as no 
further development of items is taking place. 
1712 The results of flaw remediatio n for a component are not applicable to the 
composed TOE. If flaw remediation is included in the assurance package for 
the composed TOE, then the Flaw remediation (ALC_FLR) requirements are 
to be applied during the composed TOE evaluation (as for any augmentation). 
17.3.1.2.4 Tests 
1713 The composed TOE will have been tested during the conduct of the Class 
ATE: Tests  activities for evaluation of the dependent component, as the 
configurations used for testing of the dependent component shou ld have 
included the base component to satisfy the requirements for IT in the 
operational environment. If the base component was not used in the testing 
of the dependent component for the dependent component evaluation, or the 
configuration of either component varied from their evaluated configurations, 
then the developer testing performed for evaluation of the dependent 
component to satisfy the Class ATE: Tests requirements is to be repeated on 
the composed TOE. 
Class ACO: Composition 
April 2017 Version 3.1 Page 357 of 430 
17.4 Development evidence (ACO_DEV) 
17.4.1 Evaluation of sub-activity (ACO_DEV.1) 
17.4.1.1 Objectives 
1714 The objective of this sub-activity is to determine that the appropriate security 
functionality is provided by the base component to support the dependent 
component. This is achieved through examination o f the interfaces of the 
base component to determine that they are consistent with the interfaces 
specified in the reliance information; those required by the dependent 
component. 
1715 The description of the interfaces into the base component is to be provided a t 
a level of detail consistent with Evaluation of sub -activity (ADV_FSP.2)  
although not all of the aspects necessary for satisfaction of Evaluation of 
sub-activity (ADV_FSP.2)  are required for Evaluation of sub -activity 
(ACO_DEV.1), as once the interface has been identified and the purpose 
described the remaining detail of the interface specification can be reused 
from evaluation of the base component. 
17.4.1.2 Input 
1716 The evaluation evidence for this sub-activity is:  
a) the composed ST;  
b) the development information;  
c) the reliance information.  
17.4.1.3 Action ACO_DEV.1.1E 
ACO_DEV.1.1C The development information shall descri be the purpose of each interface 
of the base component used in the composed TOE.  
ACO_DEV.1-1 The evaluator shall examine the development information to determine that 
it describes the purpose of each interface. 
1717 The base component provides interfaces to support interaction with the 
dependent component in the provision of the dependent TSF. The purpose of 
each interface is to be described at the same level as the description of the 
interfaces to the dependent compo nent TSF functionality, as would be 
provided between subsystems in the TOE design ( Evaluation of sub-activity 
(ADV_TDS.1)). This description is to provide the reader with an 
understanding of how the base component provides the services  required by 
the dependent component TSF. 
1718 This work unit may be satisfied by the provision of the functional 
specification for the base component for those interfaces that are TSFIs of 
the base component. 
Class ACO: Composition 
Page 358 of 430 Version 3.1 April 2017 
ACO_DEV.1.2C The development information shall show correspondence between the 
interfaces, used in the composed TOE, of the base component and the 
dependent component to support the TSF of the dependent component.  
ACO_DEV.1-2 The evaluator shall examine the development information to determine the 
correspondence, between the interfaces of the base component and the 
interfaces on which the dependent component relies, is accurate. 
1719 The correspondence between the interf aces of the base component and the 
interfaces on which the dependent component relies may take the form of a 
matrix or table. The interfaces that are relied upon by the dependent 
component are identified in the reliance information (as examined during 
Reliance of dependent component (ACO_REL) activity). 
1720 There is, during this activity, no requirement to determine completeness of 
the coverage of interfaces that are relied upon by the dependent component, 
only that the correspondence is corr ect and ensuring that interfaces of the 
base component are mapped to interfaces required by the dependent 
component wherever possible. The completeness of the coverage is 
considered in Composition rationale (ACO_COR) activities. 
17.4.1.4 Action ACO_DEV.1.2E 
ACO_DEV.1-3 The evaluator shall examine  the development information and the reliance 
information to determine that the interfaces are described consistently. 
1721 The evaluator's goal in this work unit is to determine that the interfaces 
described in the development information for the base component and the 
reliance information for the dependent component are represented 
consistently. 
17.4.2 Evaluation of sub-activity (ACO_DEV.2) 
17.4.2.1 Objectives 
1722 The objective of this sub-activity is to determine that the appropriate security 
functionality is provided by the base component to support the dependent 
component. This is achieved through examination of the interfaces and 
associated security behaviour of the base component to determine that they 
are consistent with the interfaces specified in the reliance information; those 
required by the dependent component. 
17.4.2.2 Input 
1723 The evaluation evidence for this sub-activity is:  
a) the composed ST;  
b) the development information;  
c) reliance information.  
Class ACO: Composition 
April 2017 Version 3.1 Page 359 of 430 
17.4.2.3 Action ACO_DEV.2.1E 
ACO_DEV.2.1C The development information shall describe the purpose and method of use 
of each interface of the base component used in the composed TOE.  
ACO_DEV.2-1 The evaluator shall examine the development information to determine that 
it describes the purpose of each interface. 
1724 The base compon ent provides interfaces to support interaction with the 
dependent component in the provision of the dependent TSF. The purpose of 
each interface is to be described at the same level as the description of the 
interfaces to the dependent component TSF functi onality, as would be 
provided between subsystems in the TOE design ( Evaluation of sub-activity 
(ADV_TDS.1)). This description is to provide the reader with an 
understanding of how the base component provides the services required by 
the dependent component TSF. 
1725 This work unit may be satisfied by the provision of the functional 
specification for the base component for those interfaces that are TSFIs of 
the base component. 
ACO_DEV.2-2 The evaluator shall examine the development information to determine that 
it describes the method of use for each interface. 
1726 The method of use for an interface summarises how the interface is 
manipulated in order to invoke the operations and obtain results associate d 
with the interface. The evaluator should be able to determine from reading 
this material in the development information how to use each interface. This 
does not necessarily mean that there needs to be a separate method of use for 
each interface, as it ma y be possible to describe in general how APIs are 
invoked, for instance, and then identify each interface using that general style. 
1727 This work unit may be satisfied by the provision of the functional 
specification for the base component for those interfaces  that are TSFIs of 
the base component. 
ACO_DEV.2.2C The development information shall provide a high -level description of the 
behaviour of the base component, which supports the enforcement of the 
dependent component SFRs.  
ACO_DEV.2-3 The evaluator shall examine the development information to determine that 
it describes the behaviour of the base component that supports the 
enforcement of the dependent component SFRs. 
1728 The dependent component invokes interfaces of the base component for the 
provision of services by the base component. For the interfaces of the base 
component that are invoked, the development information shall provide a 
high-level description of the ass ociated security behaviour of the base 
component. The description of the base component security behaviour will 
outline how the base component provides the necessary service when the call 
to the interface is made. This description is to be at a level simil ar to that 
Class ACO: Composition 
Page 360 of 430 Version 3.1 April 2017 
provided for ADV_TDS.1.4C. Therefore, the provision of the TOE design 
evidence from the base component evaluation would satisfy this work unit, 
where the interfaces invoked by the dependent component are TSFI of the 
base component. If the interfaces invoked by the dependent component are 
not TSFIs of the base component it is the associated security behaviour will 
not necessarily be described in the base component TOE design evidence. 
ACO_DEV.2.3C The development information shall show correspondence between the 
interfaces, used in the composed TOE, of the base component and the 
dependent component to support the TSF of the dependent component.  
ACO_DEV.2-4 The evaluator shall examine the development information to determine the 
correspondence, between the interfaces of the base component and the 
interfaces on which the dependent component relies, is accurate. 
1729 The correspondence between the interfaces of the base component and the 
interfaces on which the dependent component relies may take the form of a 
matrix or table. The interfaces that are relied upon by the dependent 
component are identified in the reliance information (as examined during 
Reliance of dependent component (ACO_REL)). 
1730 There is, during this activity, no requirement to determine completeness of 
the coverage of interfaces that are relied upon by the dependent component, 
only that the corresp ondence is correct and ensuring that interfaces of the 
base component are mapped to interfaces required by the dependent 
component wherever possible. The completeness of the coverage is 
considered in Composition rationale (ACO_COR) activities. 
17.4.2.4 Action ACO_DEV.2.2E 
ACO_DEV.2-5 The evaluator shall examine  the development information and the reliance 
information to determine that the interfaces are described consistently. 
1731 The evaluator's goal in this work unit is to determine that the interfaces 
described in the development information for the base component and the 
reliance information for the dependent component are represented 
consistently. 
17.4.3 Evaluation of sub-activity (ACO_DEV.3) 
17.4.3.1 Objectives 
1732 The objective of this sub-activity is to determine that the appropriate security 
functionality is provided by the base component to support the dependent 
component. This is achieved through examination of the interfac es and 
associated security behaviour of the base component to determine that they 
are consistent with the interfaces specified in the reliance information; those 
required by the dependent component. 
1733 In addition to the interface description, the subsystems of the base 
component that provide the security functionality required by the dependent 
Class ACO: Composition 
April 2017 Version 3.1 Page 361 of 430 
component will be described to enable the evaluator to determine whether or 
not that interface formed part of the TSF of the base component. 
17.4.3.2 Input 
1734 The evaluation evidence for this sub-activity is:  
a) the composed ST;  
b) the development information;  
c) reliance information.  
17.4.3.3 Action ACO_DEV.3.1E 
ACO_DEV.3.1C The development information shall describe the purpose and method of use 
of each interface of the base component used in the composed TOE.  
ACO_DEV.3-1 The evaluator shall examine the development information to determine that 
it describes the purpose of each interface. 
1735 The base component provides interfaces to support interaction with the 
dependent component in the provision of the dependent TSF. The purpose of 
each interface is to be described at the same level as the description of the 
interfaces to the dependent component TSF functionality, as would be 
provided between subsystems in the TOE design ( Evaluation of sub-activity 
(ADV_TDS.1)). This description is to provide the reader with an 
understanding of how the base c omponent provides the services required by 
the dependent component TSF. 
1736 This work unit may be satisfied by the provision of the functional 
specification for the base component for those interfaces that are TSFIs of 
the base component. 
ACO_DEV.3-2 The evaluator shall examine the development information to determine that 
it describes the method of use for each interface. 
1737 The method of use for an interface summarises how the interface is 
manipulated in order to invok e the operations and obtain results associated 
with the interface. The evaluator should be able to determine from reading 
this material in the development information how to use each interface. This 
does not necessarily mean that there needs to be a separa te method of use for 
each interface, as it may be possible to describe in general how APIs are 
invoked, for instance, and then identify each interface using that general style. 
1738 This work unit may be satisfied by the provision of the functional 
specification for the base component for those interfaces that are TSFIs of 
the base component. 
ACO_DEV.3.2C The development information shall identify the subsystems of the base 
component that provide interfaces of the base component used in the 
composed TOE.  
Class ACO: Composition 
Page 362 of 430 Version 3.1 April 2017 
ACO_DEV.3-3 The evaluator shall examine the development information to determine that 
all subsystems of the base component that provide interfaces to the 
dependent component are identified. 
1739 For those interfaces that are considered to form part of the TSFI of the base 
component, the subsystems associated with the interface will be subsystems 
considered in the TOE design (ADV_TDS)  activity during the base 
component evaluation. The interfaces on which the dependent component 
relies that did not form part of the TSFI of the base component will map to 
subsystems outside of the base component TSF. 
ACO_DEV.3.3C The development information shall provide a high -level description of the 
behaviour of the base component subsystems, which support the 
enforcement of the dependent component SFRs.  
ACO_DEV.3-4 The evaluator shall examine the development information to determine that 
it describes the behaviour of the base component subsystems that support the 
enforcement of the dependent component SFRs. 
1740 The dependent component invokes interfaces of the base component for the 
provision of services by the base component. For the interfaces of the base 
component that are invoked, the development information shall provide a 
high-level description of the associated security behaviour of the base 
component. The description of the base compo nent security behaviour will 
outline how the base component provides the necessary service when the call 
to the interface is made. This description is to be at a level similar to that 
provided for ADV_TDS.1.4C. Therefore , the provision of the TOE design 
evidence from the base component evaluation would satisfy this work unit, 
where the interfaces invoked by the dependent component are TSFI of the 
base component. If the interfaces invoked by the dependent component are 
not TSFIs of the base component it is the associated security behaviour will 
not necessarily be described in the base component TOE design evidence. 
ACO_DEV.3.4C The development information shall provide a mappi ng from the interfaces 
to the subsystems of the base component.  
ACO_DEV.3-5 The evaluator shall examine the development information to determine that 
the correspondence between the interfaces and subsystems of t he base 
component is accurate. 
1741 If the TOE design and functional specification evidence from the base 
component evaluation is available, this can be used to verify the accuracy of 
the correspondence between the interfaces and subsystems of the base 
component as used in the composed TOE. Those interfaces of the base 
component, which formed part of the base component TSFI will be described 
in the base component functional specification, and the associated 
subsystems will be described in the base component TOE design evidence. 
The tracing between the two will be provided in the base component TOE 
design evidence. 
Class ACO: Composition 
April 2017 Version 3.1 Page 363 of 430 
1742 If, however, the base component interface did not form part of the TSFI of 
the base component, the description of the subsystem behaviour provided in 
the development information will be used to verify the accuracy of the 
correspondence. 
ACO_DEV.3.5C The development information shall show correspondence between the 
interfaces, used in the composed TOE, of th e base component and the 
dependent component to support the TSF of the dependent component.  
ACO_DEV.3-6 The evaluator shall examine the development information to determine the 
correspondence, between the interf aces of the base component and the 
interfaces on which the dependent component relies, is accurate. 
1743 The correspondence between the interfaces of the base component and the 
interfaces on which the dependent component relies may take the form of a 
matrix or table. The interfaces that are relied upon by the dependent 
component are identified in the reliance information (as examined during 
Reliance of dependent component (ACO_REL)). 
1744 There is, during this activity, no requirement to determine completeness of 
the coverage of interfaces that are relied upon by the dependent component, 
only that the correspondence is correct and ensuring that interfaces of the 
base component are mapped to interfaces required by the dependent 
component wherever pos sible. The completeness of the coverage is 
considered in Composition rationale (ACO_COR) activities. 
17.4.3.4 Action ACO_DEV.3.2E 
ACO_DEV.3-7 The evaluator shall examine  the development information and the reliance 
information to determine that the interfaces are described consistently. 
1745 The evaluator's goal in this work unit is to determine that the interfaces 
described in the development information for the base component and the 
reliance information for the dependent component are represented 
consistently. 
Class ACO: Composition 
Page 364 of 430 Version 3.1 April 2017 
17.5 Reliance of dependent component (ACO_REL) 
17.5.1 Evaluation of sub-activity (ACO_REL.1) 
17.5.1.1 Objectives 
1746 The objectives of this sub -activity are to determine whether the developer's 
reliance evidence provides sufficient information to determine that the 
necessary functionality is available in the base component, and the means by 
which that functionality is invoked. These are provided in terms of a high -
level description. 
17.5.1.2 Input 
1747 The evaluation evidence for this sub-activity is:  
a) the composed ST;  
b) the dependent component functional specification;  
c) the dependent component design;  
d) the dependent component architectural design;  
e) the reliance information.  
17.5.1.3 Application notes 
1748 A dependent component whose TSF interacts with the base component 
requires functionality provided by that base component (e.g., remote 
authentication, remote audit data storage). In these cases, those invoked 
services need to be described for those charged w ith configuring the 
composed TOE for end users. The rationale for requiring this documentation 
is to aid integrators of the composed TOE to determine what services in the 
base component might have adverse effects on the dependent component, 
and to provide information against which to determine the compatibility of 
the components when applying the Development evidence (ACO_DE V) 
family. 
17.5.1.4 Action ACO_REL.1.1E 
ACO_REL.1.1C The reliance information shall describe the functionality of the base 
component hardware, firmware and/or software that is relied upon by the 
dependent component TSF.  
ACO_REL.1-1 The evalua tor shall check  the reliance information to determine that it 
describes the functionality of the base dependent hardware, firmware and/or 
software that is relied upon by the dependent component TSF. 
1749 The evaluator assesses the description of the security fu nctionality that the 
dependent component TSF requires to be provided by the base component's 
hardware, firmware and software. The emphasis of this work unit is on the 
Class ACO: Composition 
April 2017 Version 3.1 Page 365 of 430 
level of detail of this description, rather than on an assessment of the 
information's accuracy. (The assessment of the accuracy of the information is 
the focus of the next work unit.) 
1750 This description of the base component's functionality need not be any more 
detailed than the level of the description of a component of the TSF, as 
would be provided in the TOE Design (TOE design (ADV_TDS)) 
ACO_REL.1-2 The evaluator shall examine  the reliance information to determine that it 
accurately reflects the objectives specified for the operational environment of 
the dependent component. 
1751 The reliance information contains the description of the base component's 
security functionality relied upon by the dependent component. To ensure 
that the reliance information is consistent with the expectatio ns of the 
operational environment of the dependent component, the evaluator 
compares the reliance information with the statement of objectives for the 
environment in the ST for the dependent component. 
1752 For example, if the reliance information claims that t he dependent 
component TSF relies upon the base component to store and protect audit 
data, yet other evaluation evidence (e.g. the dependent component design) 
makes it clear that the dependent component TSF itself is storing and 
protecting the audit data, this would indicate an inaccuracy. 
1753 It should be noted that the objectives for the operational environment may 
include objectives that can be met by non -IT measures. While the services 
that the base component environment is expected to provide may be 
described in the description of IT objectives for the operational environment 
in the dependent component ST, it is not required that all such expectations 
on the environment be described in the reliance information. 
ACO_REL.1.2C The reliance information shall describe all interactions through which the 
dependent component TSF requests services from the base component.  
ACO_REL.1-3 The evaluator shall examine  the reliance i nformation to determine that it 
describes all interactions between the dependent component and the base 
component, through which the dependent component TSF requests services 
from the base component. 
1754 The dependent component TSF may request services of the base component 
that were not within the TSF of the base component (see B.3, Interactions 
between composed IT entities in CC Part 3). 
1755 The interfaces to the base component's functionality are described at the 
same level as the description of the interfaces to the dependent component 
TSF functionality, as would be provided between subsystems in the TOE 
design (Evaluation of sub-activity (ADV_TDS.1)). 
1756 The purpose of describing the interactions between the dependent component 
and the base component is to provide an understanding of how the dependent 
Class ACO: Composition 
Page 366 of 430 Version 3.1 April 2017 
component TSF relies upon the base component for the provision of services 
to support the operation of security functionality of the dependent component. 
These interactions do not need to be characterised at the implementation 
level (e.g. parameters passed from one routine in a component to a routine in 
another component), but the data elements identified for a particular 
component that are going to be used b y another component should be 
covered in this description. The statement should help the reader understand 
in general why the interaction is necessary. 
1757 Accuracy and completeness of the interfaces is based on the security 
functionality that the TSF requires  to be provided by the base component, as 
assessed in work units ACO_REL.1-1 and ACO_REL.1-2. It should be 
possible to map all of the functionality described in the earlier work units to 
the interfaces identifi ed in this work unit, and vice versa. An interface that 
does not correspond to described functionality would also indicate an 
inadequacy. 
ACO_REL.1.3C The reliance information shall describe how the dependent  TSF protects 
itself from interference and tampering by the base component.  
ACO_REL.1-4 The evaluator shall examine  the reliance information to determine that it 
describes how the dependent TSF protects itself f rom interference and 
tampering by the base component. 
1758 The description of how the dependent component protects itself from 
interference and tampering by the base component is to be provided at the 
same level of detail as necessary for ADV_ARC.1-4. 
17.5.2 Evaluation of sub-activity (ACO_REL.2) 
17.5.2.1 Objectives 
1759 The objectives of this sub -activity are to determine whether the developer's 
reliance evidence provides sufficient information to determine that the 
necessary functionality is available in the base component, and the means by 
which that functionality is invoked. This is provided in terms of the 
interfaces between the dependent and base component and the return values 
from those interfaces called by the dependent component. 
17.5.2.2 Input 
1760 The evaluation evidence for this sub-activity is:  
a) the composed ST;  
b) the dependent component functional specification;  
c) the dependent component design;  
d) the dependent component implementation representation;  
e) the dependent component architectural design;  
Class ACO: Composition 
April 2017 Version 3.1 Page 367 of 430 
f) the reliance information.  
17.5.2.3 Application notes 
1761 A dependent component whose TSF interacts with the base component 
requires functionality provided by that base component (e.g., remote 
authentication, remote audit data storage). In these cases, those invoked 
services need to be described for those charged with configuring the 
composed TOE for end users. The rationale for requiring this documentation 
is to aid integrators of the composed TOE to determine what services in the 
base component might have adverse effects  on the dependent component, 
and to provide information against which to determine the compatibility of 
the components when applying the Development evidence (ACO_DE V) 
family. 
17.5.2.4 Action ACO_REL.2.1E 
ACO_REL.2.1C The reliance information shall describe the functionality of the base 
component hardware, firmware and/or software that is relied upon by the 
dependent component TSF.  
ACO_REL.2-1 The evaluator shall check  the reliance information to determine that it 
describes the functionality of the base dependent hardware, firmware and/or 
software that is relied upon by the dependent component TSF. 
1762 The evaluator assesses the description of the security functionality that the 
dependent component TSF requires to be provided by the base component's 
hardware, firmware and software. The emphasis of this work unit is on the 
level of detail of this description, rather t han on an assessment of the 
information's accuracy. (The assessment of the accuracy of the information is 
the focus of the next work unit.) 
1763 This description of the base component's functionality need not be any more 
detailed than the level of the descripti on of a component of the TSF, as 
would be provided in the TOE Design (TOE design (ADV_TDS)) 
ACO_REL.2-2 The evaluator shall examine  the reliance information to determine that it 
accurately reflects the objectives specified for the operational environment of 
the dependent component. 
1764 The reliance information contains the description of the base component's 
security functionality relied upon by the dependent component. To ensure 
that the reliance i nformation is consistent with the expectations of the 
operational environment of the dependent component, the evaluator 
compares the reliance information with the statement of objectives for the 
environment in the ST for the dependent component. 
1765 For exampl e, if the reliance information claims that the dependent 
component TSF relies upon the base component to store and protect audit 
data, yet other evaluation evidence (e.g. the dependent component design) 
Class ACO: Composition 
Page 368 of 430 Version 3.1 April 2017 
makes it clear that the dependent component TSF itsel f is storing and 
protecting the audit data, this would indicate an inaccuracy. 
1766 It should be noted that the objectives for the operational environment may 
include objectives that can be met by non -IT measures. While the services 
that the base component envi ronment is expected to provide may be 
described in the description of IT objectives for the operational environment 
in the dependent component ST, it is not required that all such expectations 
on the environment be described in the reliance information. 
ACO_REL.2.2C The reliance information shall describe all interactions through which the 
dependent component TSF requests services from the base component.  
ACO_REL.2-3 The evaluator shall examine  the reliance information to determine that it 
describes all interactions between the dependent component and the base 
component, through which the dependent component TSF requests services 
from the base component. 
1767 The dependent component TSF may request services of the base component 
that were not within the TSF of the base component (see Annex B.3, 
Interactions between composed IT entities in CC Part 3). 
1768 The interfaces to the base compon ent's functionality are described at the 
same level as the description of the interfaces to the dependent component 
TSF functionality, as would be provided between subsystems in the TOE 
design (Evaluation of sub-activity (ADV_TDS.1)). 
1769 The purpose of describing the interactions between the dependent component 
and the base component is to provide an understanding of how the dependent 
component TSF relies upon the base component for the provision of services 
to support the operation of security functionality of the dependent component. 
These interactions do not need to be characterised at the implementation 
level (e.g. parameters passed from one routine in a component to a routine in 
another component), but the data elements identified for a particular 
component that are going to be used by another component should be 
covered in this description. The statement should help the reader understand 
in general why the interaction is necessary. 
1770 Accuracy and completeness of the interfaces is based o n the security 
functionality that the TSF requires to be provided by the base component, as 
assessed in work units ACO_REL.2-1 and ACO_REL.2-2. It should be 
possible to map all of the functionality described in  the earlier work units to 
the interfaces identified in this work unit, and vice versa. An interface that 
does not correspond to described functionality would also indicate an 
inadequacy. 
ACO_REL.2.3C The rel iance information shall describe each interaction in terms of the 
interface used and the return values from those interfaces.  
ACO_REL.2-4 The reliance information shall describe each interaction in terms of the 
interface used and the return values from those interfaces. 
Class ACO: Composition 
April 2017 Version 3.1 Page 369 of 430 
1771 The identification of the interfaces used by the dependent component TSF 
when making services requests of the base component allows an integrator to 
determine whether the base component provides a ll the necessary 
corresponding interfaces. This understanding is further gained through the 
specification of the return values expected by the dependent component. The 
evaluator ensures that interfaces are described for each interaction specified 
(as analysed in ACO_REL.2-3). 
ACO_REL.2.4C The reliance information shall describe how the dependent TSF protects 
itself from interference and tampering by the base component.  
ACO_REL.2-5 The evaluator shall examine  the reliance information to determine that it 
describes how the dependent TSF protects itself from interference and 
tampering by the base component. 
1772 The description of how the d ependent component protects itself from 
interference and tampering by the base component is to be provided at the 
same level of detail as necessary for ADV_ARC.1-4. 
Class ACO: Composition 
Page 370 of 430 Version 3.1 April 2017 
17.6 Composed TOE testing (ACO_CTT) 
17.6.1 Evaluation of sub-activity (ACO_CTT.1) 
17.6.1.1 Objectives 
1773 The objective of this sub -activity is to determine whether the developer 
correctly performed and documented tests for each of the base component 
interfaces on which the dependent component relies. As part of this 
determination the  evaluator repeats a sample of the tests performed by the 
developer and performs any additional tests required to ensure the expected 
behaviour of all composed TOE SFRs and interfaces of the base component 
relied upon by the dependent component is demonstrated. 
17.6.1.2 Input 
1774 The evaluation evidence for this sub-activity is:  
a) the composed TOE suitable for testing;  
b) the composed TOE testing evidence;  
c) the reliance information;  
d) the development information.  
17.6.1.3 Action ACO_CTT.1.1E 
ACO_CTT.1.1C The composed TOE and base component interface test documentation 
shall consist of test plans, expected test results and actual test results.  
ACO_CTT.1-1 The evaluator shall examine  the composed TOE test documentation to 
determine that it consists of test plans, expected test results and actual test 
results. 
1775 This work unit may be satisfied by provision of the test evidence from the 
evaluation of th e dependent component if the base component was used to 
satisfy the requirements for IT in the operational environment of the 
dependent component. 
1776 All work units necessary for the satisfaction of ATE_FUN.1.1E will be 
applied to determine:  
a) that the test documentation consist of test plans expected test results 
and actual test results; 
b) that the test documentation contains the information necessary to 
ensure the tests are repeatable; 
c) the level of developer effort that was applied to te sting of the base 
component. 
Class ACO: Composition 
April 2017 Version 3.1 Page 371 of 430 
ACO_CTT.1-2 The evaluator shall examine  the base component interface test 
documentation to determine that it consists of test plans, expected test results 
and actual test results. 
1777 This work unit may be satisfied by provision of the test evidence from the 
evaluation of the base component for those interfaces relied upon in the 
composed TOE by the dependent component are TSFIs of the successfully 
evaluated base component. The determinati on of whether the interfaces of 
the base component relied upon by the dependent component were in fact 
TSFIs of the evaluated base component is made during the ACO_COR 
activity. 
1778 All work units necessary for the satisfaction o f ATE_FUN.1.1E will be 
applied to determine:  
a) that the test documentation consist of test plans expected test results 
and actual test results; 
b) that the test documentation contains the information necessary to 
ensure the tests are repeatable; 
c) the level of developer effort that was applied to testing of the base 
component. 
ACO_CTT.1.2C The test documentation from the developer execution of the composed 
TOE tests shall demonstrate that the TSF behaves as specified.  
ACO_CTT.1-3 The evaluator shall examine  the test documentation to determine that the 
developer execution of the composed TOE tests shall demonstrate that the 
TSF behaves as specified. 
1779 The evaluator should construct a mapping between the tests described in the 
test plan and the SFRs specified for the composed TOE to identify which 
SFRs have been tested by the developer. 
1780 Guidance on this work unit can be found in:  
a) Chapter 15.2.1. 
b) Chapter 15.2.2. 
1781 The outputs from the successful execution of the tests (as assessed for 
ATE_FUN.1.3C can be compared with the mapping to determine that the 
SFRs of the composed TOE, as tested by the developer, behave as expected. 
ACO_CTT.1.3C The test documentation from the developer execution of the base 
component interface tests shall demonstrate that the base component 
interface relied upon by the dependent component behaves as specified.  
ACO_CTT.1-4 The evaluator shall examine  the test documentation to determine that the 
developer execution of the base component interface tests shall  demonstrate 
Class ACO: Composition 
Page 372 of 430 Version 3.1 April 2017 
that the base component interfaces relied upon by the dependent component 
behave as specified. 
1782 The evaluator should construct a mapping between the tests described in the 
test plan and the interfaces of the base component relied upon by the 
dependent component (as specified in the reliance information, examined 
under ACO_REL) to identify which base component interfaces have been 
tested by the developer. 
1783 Guidance on this work unit can be found in:  
a) Chapter 15.2.1. 
b) Chapter 15.2.2. 
1784 The outputs from the successful execution of the tests (as assessed for 
ATE_FUN.1.3C can be compared with the mapping to determine that the 
interfaces o f the base component, as tested by the developer, behave as 
expected. 
ACO_CTT.1.4C The base component shall be suitable for testing.  
ACO_CTT.1-5 The evaluator shall examine  the composed TOE to determine that it has 
been installed properly and is in a known state. 
1785 To determine that the composed TOE has been installed properly and is in a 
known state the ATE_IND.2-1 and ATE_IND.2-2 work units will be applied 
to the TOE provided by the developer for testing. 
ACO_CTT.1-6 The evaluator shall examine the set of resources provided by the developer 
to determine that they are equivalent to the set of resources used by the base 
component developer to functionally test the base component. 
1786 To determine that the set of resources provided are equivalent to those used 
to functionally test the base component as used in the composed TOE, the 
ATE_IND.2-3 work unit will be applied. 
17.6.1.4 Action ACO_CTT.1.2E 
ACO_CTT.1-7 The evaluator shall perform testing in accordance with ATE_IND.2.2E, for a 
subset of the SFRs specified in the composed security target, to verify the 
developer test results. 
1787 The evaluator will apply all work units necessary for the satisfaction of 
ATE_IND.2.2E, reporting in the ETR for the composed TOE all analysis, 
results and verdicts as dictated by the associated work units. 
17.6.1.5 Action ACO_CTT.1.3E 
ACO_CTT.1-8 The evaluator shall perform testing in accordance with ATE_IND.2.3E, for a 
subset of the SFRs specified in the composed security target, to confirm that 
the TSF operates as specified. 
Class ACO: Composition 
April 2017 Version 3.1 Page 373 of 430 
1788 The evaluator will apply all work units necessary for the satisfaction of 
ATE_IND.2.3E, reporting in the ETR for the composed TOE all analysis, 
results and verdicts as dictated by the work units. 
1789 When selecting interfaces of the TSF of the composed TOE to test, the 
evaluator should take into account any modifications to the components from 
the evaluated version or configuration. Modifications to the component from 
that evaluated may include patches introduced, a different configuration as a 
result of modified guidance documentation, reliance an additional portion of  
the component that was not within the TSF of the component. These 
modifications will have been identified during the Composition rationale 
(ACO_COR) activity. 
17.6.2 Evaluation of sub-activity (ACO_CTT.2) 
17.6.2.1 Objectives 
1790 The objective of this sub -activity is to determine whether the developer 
correctly performed and documented tests for each of the base component 
interfaces on which the dependent component relies. As part of this 
determination the evaluator repeats a sample of the tests performed by  the 
developer and performs any additional tests required to fully demonstrate the 
expected behaviour of the composed TOE and the interfaces of the base 
component relied upon by the dependent component. 
17.6.2.2 Input 
1791 The evaluation evidence for this sub-activity is:  
a) the composed TOE suitable for testing;  
b) the composed TOE testing evidence;  
c) the reliance information;  
d) the development information.  
17.6.2.3 Action ACO_CTT.2.1E 
ACO_CTT.2.1C The composed TOE and base component interface test documentation 
shall consist of test plans, expected test results and actual test results.  
ACO_CTT.2-1 The evaluator shall examine  the composed TOE test documentation to 
determine that it consists of test plans, expected test results and actual test 
results. 
1792 This work unit may be satisfied by provision of the test evidence from the 
evaluation of the dependent component if the base component was used to 
satisfy the requirements for IT in the operational environment of the 
dependent component. 
Class ACO: Composition 
Page 374 of 430 Version 3.1 April 2017 
1793 All work units necessary for the satisfaction of ATE_FUN.1.1E will be 
applied to determine:  
a) that the test documentation consist of test plans e xpected test results 
and actual test results; 
b) that the test documentation contains the information necessary to 
ensure the tests are repeatable; 
c) the level of developer effort that was applied to testing of the base 
component. 
ACO_CTT.2-2 The evaluator shall examine  the base component interface test 
documentation to determine that it consists of test plans, expected test results 
and actual test results. 
1794 This work unit may be satisfied by provision of the test evide nce from the 
evaluation of the base component for those interfaces relied upon in the 
composed TOE by the dependent component are TSFIs of the successfully 
evaluated base component. The determination of whether the interfaces of 
the base component relied u pon by the dependent component were in fact 
TSFIs of the evaluated base component is made during the ACO_COR 
activity. 
1795 All work units necessary for the satisfaction of ATE_FUN.1.1E will be 
applied to determine:  
a) that the test documentation consist of test plans expected test results 
and actual test results; 
b) that the test documentation contains the information necessary to 
ensure the tests are repeatable; 
c) the level of developer effort that was applied to  testing of the base 
component.  
ACO_CTT.2.2C The test documentation from the developer execution of the composed 
TOE tests shall demonstrate that the TSF behaves as specified and is 
complete.  
ACO_CTT.2-3 The evaluator shall examine  the test documentation to determine that it 
provides accurate correspondence between the tests in the test documentation 
relating to the testing of the composed TOE and the composed TOE SFRs in 
the composed TOE security target. 
1796 A simple cross -table may be sufficient to show test correspondence. The 
identification of correspondence between the tests and SFRs presented in the 
test documentation has to be unambiguous. 
ACO_CTT.2-4 The evaluator shall examine  the test documentation to determine that the 
developer execution of the composed TOE tests shall demonstrate that the 
TSF behaves as specified. 
Class ACO: Composition 
April 2017 Version 3.1 Page 375 of 430 
1797 Guidance on this work unit can be found in:  
a) Chapter 15.2.1. 
b) Chapter 15.2.2.  
1798 The outputs from the successful execution of the tests (as assessed for 
ATE_FUN.1.3C can be compared with the mapping to determine that the 
SFRs of the composed TOE, as tested by the developer, behave as expected. 
ACO_CTT.2.3C The test documentation from the developer execution of the base 
component interface tests shall demonstrate that the base component 
interface relied upon by the dependent component behaves as specified and 
is complete.  
ACO_CTT.2-5 The evaluator shall examine  the test documentation to determine that it 
provides accurate correspondence between the tests in the test documentation 
relating to the testing of the base component interfaces relied upon by the 
dependent component and the interfaces specified in the reliance information.  
1799 A simple cross -table may be sufficient to show test cor respondence. The 
identification of correspondence between the tests and interfaces presented in 
the test documentation has to be unambiguous. 
ACO_CTT.2-6 The evaluator shall examine  the test documentation to dete rmine that the 
developer execution of the base component interface tests shall demonstrate 
that the base component interfaces relied upon by the dependent component 
behave as specified. 
1800 Guidance on this work unit can be found in:  
a) Chapter 15.2.1. 
b) Chapter 15.2.2. 
1801 The outputs from the successful execution of the tests (as assessed for 
ATE_FUN.1.3C can be compared with the mapping to determine that the 
interfaces of the bas e component, as tested by the developer, behave as 
expected. 
ACO_CTT.2.4C The base component shall be suitable for testing.  
ACO_CTT.2-7 The evaluator shall examine  the composed TOE to determine that it has 
been installed properly and is in a known state. 
1802 To determine that the composed TOE has been installed properly and is in a 
known state the ATE_IND.2-1 and ATE_IND.2-2 work units will be applied 
to the TOE provided by the developer for testing. 
ACO_CTT.2-8 The evaluator shall examine the set of resources provided by the developer 
to determine that they are equivalent to the se t of resources used by the base 
component developer to functionally test the base component. 
Class ACO: Composition 
Page 376 of 430 Version 3.1 April 2017 
1803 To determine that the set of resources provided are equivalent to those used 
to functionally test the base component as used in the composed TOE, the 
ATE_IND.2-3 work unit will be applied. 
17.6.2.4 Action ACO_CTT.2.2E 
ACO_CTT.2-9 The tests are to be selected and executed in accordance with ATE_IND.2.2E, 
to demonstrate the correct behaviour of the SFRs specified in the composed 
TOE security target. 
1804 The evaluator will apply all work units necessary for the satisfaction of 
ATE_IND.2.2E, reporting in the ETR for the compo sed TOE all analysis, 
results and verdicts as dictated by the associated work units. 
17.6.2.5 Action ACO_CTT.2.3E 
ACO_CTT.2-10 The evaluator shall perform testing in accordance with ATE_IND.2.3E, for a 
subset of the SFRs specified in the composed security target, to confirm that 
the TSF operates as specified. 
1805 The evaluator will apply all work units necessary for the satisfaction of 
ATE_IND.2.3E, reporting in the ETR for the composed TOE all analysis, 
results and verdicts as dictated by the work units. 
1806 When selecting interfaces of the TSF of the composed TOE to test, the 
evaluator should take into account any modifications to the components from 
the evaluated version or configuration. Modifications to the component from 
that evaluated may include patches introduced, a different configuration as a 
result of modified guidance documentation, reliance an additional portion of 
the comp onent that was not within the TSF of the component. These 
modifications will have been identified during the Composition rationale 
(ACO_COR) activity. 
ACO_CTT.2-11 The evaluator shall perfor m testing, in accordance with Evaluation of sub -
activity (ATE_IND.2), for a subset of the interfaces to the base component to 
confirm they operate as specified. 
1807 The evaluator will apply all work units necessary for the satisfaction of 
ATE_IND.2.3E, reporting in the ETR for the composed TOE all analysis, 
results and verdicts as dictated by the work units. 
1808 When selecting interfaces of the base component to test, the evaluator should 
take into account any modificati ons to the base component from the 
evaluated version or configuration. In particular, the evaluator should 
consider the development of tests to demonstrate the correct behaviour of 
interfaces of the base component that were not considered during the 
evaluation of the base component. These additional interfaces and other 
modifications to the base component will have been identified during the 
Composition rationale (ACO_COR) activity. 
Class ACO: Composition 
April 2017 Version 3.1 Page 377 of 430 
17.7 Composition vulnerability analysis (ACO_VUL) 
17.7.1 Evaluation of sub-activity (ACO_VUL.1) 
17.7.1.1 Objectives 
1809 The objective of this sub-activity is to determine whether the composed TOE, 
in its operational environment, has easily exploitable vulnerabilities. 
1810 The developer provides details of any residual vulnerabilities repo rted from 
evaluation of the components. The evaluator performs an analysis of the 
disposition the residual vulnerabilities reported and also performs a search of 
the public domain, to identify any new potential vulnerabilities in the 
components (i.e. those  issues that have been reported in the public domain 
since evaluation of the base component). The evaluator then performs 
penetration testing to demonstrate that the potential vulnerabilities cannot be 
exploited in the TOE, in its operational environment, by an attacker with 
basic attack potential. 
17.7.1.2 Input 
1811 The evaluation evidence for this sub-activity is:  
a) the composed TOE suitable for testing;  
b) the composed ST;  
c) the composition rationale;  
d) the guidance documentation;  
e) information publicly available to suppor t the identification of 
possible security vulnerabilities;  
f) residual vulnerabilities reported during evaluation of each component.  
17.7.1.3 Application notes 
1812 See the application notes for Evaluation of sub-activity (AVA_VAN.1). 
17.7.1.4 Action ACO_VUL.1.1E 
ACO_VUL.1.1C The composed TOE shall be suitable for testing.  
ACO_VUL.1-1 The evaluator shall examine  the compose d TOE to determine that it has 
been installed properly and is in a known state. 
1813 To determine that the composed TOE has been installed properly and is in a 
known state the ATE_IND.2-1 and ATE_IND.2-2 work units will be applied 
to the composed TOE. 
Class ACO: Composition 
Page 378 of 430 Version 3.1 April 2017 
1814 If the assurance package includes a component from the ACO_CTT family, 
then the evaluator may refer to the result of the work unit ACO_CTT*-1 to 
demonstrate this has been satisfied. 
ACO_VUL.1-2 The evaluator shall examine the composed TOE configuration to determine 
that any assumptions and objectives in the STs the components relating to IT 
entities for are fulfilled by the other components. 
1815 The STs for the component may include assumptions about other 
components that may use the component to which the ST relates, e.g. the ST 
for an operating system used as a base component may include an 
assumption that any applicati ons loaded on the operating system do not run 
in privileged mode. These assumptions and objectives are to be fulfilled by 
other components in the composed TOE. 
17.7.1.5 Action ACO_VUL.1.2E 
ACO_VUL.1-3 The evaluator shall examine  the residual vulnerabilities from the base 
component evaluation to determine that they are not exploitable in the 
composed TOE in its operational environment. 
1816 The list of vulnerabilities identified in t he product during the evaluation of 
the base component, which were demonstrated to be non -exploitable in the 
base component, is to be used as an input into this activity. The evaluator 
will determine that the premise(s) on which a vulnerability was deemed to be 
non-exploitable is upheld in the composed TOE, or whether the combination 
has re -introduced the potential vulnerability. For example, if during 
evaluation of the base component it was assumed that a particular operating 
system service was disabled, w hich is enabled in the composed TOE 
evaluation, any potential vulnerabilities relating to that service previously 
scoped out should now be considered. 
1817 Also, this list of known, non -exploitable vulnerabilities resulting from the 
evaluation of the base compo nent should be considered in the light of any 
known, non -exploitable vulnerabilities for the other components (e.g. 
dependent component) within the composed TOE. This is to consider the 
case where a potential vulnerability that is non -exploitable in isolat ion is 
exploitable when integrated with an IT entity containing another potential 
vulnerability. 
ACO_VUL.1-4 The evaluator shall examine the residual vulnerabilities from the dependent 
component evaluation to det ermine that they are not exploitable in the 
composed TOE in its operational environment. 
1818 The list of vulnerabilities identified in the product during the evaluation of 
the dependent component, which were demonstrated to be non -exploitable in 
the dependent component, is to be used as an input into this activity. The 
evaluator will determine that the premise(s) on which a vulnerability was 
deemed to be non-exploitable is upheld in the composed TOE, or whether the 
combination has re -introduced the potential vu lnerability. For example, if 
during evaluation of the dependent component it was assumed that IT 
Class ACO: Composition 
April 2017 Version 3.1 Page 379 of 430 
meeting the operational environment requirements would not return a certain 
value in response to a service request, which is provided by the base 
component in the composed TOE evaluation, any potential vulnerabilities 
relating to that return value previously scoped out should now be considered. 
1819 Also, this list of known, non -exploitable vulnerabilities resulting from the 
evaluation of the dependent component shou ld be considered in the light of 
any known, non -exploitable vulnerabilities for the other components (e.g. 
base component) within the composed TOE. This is to consider the case 
where a potential vulnerability that is non -exploitable in isolation is 
exploitable when integrated with an IT entity containing another potential 
vulnerability. 
17.7.1.6 Action ACO_VUL.1.3E 
ACO_VUL.1-5 The evaluator shall examine the sources of information publicly available to 
support the identification of possible security vulnerabilities in the base 
component that have become known since the completion of evaluation of 
the base component. 
1820 The evaluator will use the information in the public domain as described in 
AVA_VAN.1-2 to search for vulnerabilities in the base component. 
1821 Those potential vulnerabilities that were publicly available prior to the 
evaluation of the base component do not have to be further investigated 
unless it is apparent to the evaluator that the attack potential required by an 
attacker to exploit the potential vulnerability has been significantly reduced. 
This may be through the introduction of some new technology since the base 
component evaluation that mean s the exploitation of the potential 
vulnerability has been simplified. 
ACO_VUL.1-6 The evaluator shall examine the sources of information publicly available to 
support the identification of possible security vulnerabilities in the dependent 
component that have become known since the completion of the dependent 
component evaluation. 
1822 The evaluator will use the information in the public domain as described in 
AVA_VAN.1-2 to search for vulnerabilities in the dependent component. 
1823 Those potential vulnerabilities that were publicly available prior to the 
evaluation of the dependent component do not have to be further investigated 
unless it is apparent to the evaluator that the attack potential requi red by an 
attacker to exploit the potential vulnerability has been significantly reduced. 
This may be through the introduction of some new technology since 
evaluation of the dependent component that means the exploitation of the 
potential vulnerability has been simplified. 
ACO_VUL.1-7 The evaluator shall record  in the ETR the identified potential security 
vulnerabilities that are candidates for testing and applicable to the composed 
TOE in its operational environment. 
Class ACO: Composition 
Page 380 of 430 Version 3.1 April 2017 
1824 The ST, guidance documentation and functional specification are used to 
determine whether the vulnerabilities are relevant to the composed TOE in 
its operational environment. 
1825 The evaluator records any reasons for exclusion of vulnerabilities from 
further consideration if the evaluator determines that the vulnerability is not 
applicable in the operational environment. Otherwise the evaluator records 
the potential vulnerability for further consideration. 
1826 A list of potential vulnerabilities applicable to the composed TOE in its 
operational environment, which can be used as an input into penetration 
testing activities (i.e. ACO_VUL.1.4E), shall be reported in the ETR by the 
evaluators. 
17.7.1.7 Action ACO_VUL.1.4E 
ACO_VUL.1-8 The evaluator shall conduct  penetration testing as detailed for 
AVA_VAN.1.3E. 
1827 The evaluator will apply all work units necessary for the satisfacti on of 
evaluator action AVA_VAN.1.3E, reporting in the ETR for the composed 
TOE all analysis and verdicts as dictated by the work units. 
1828 The evaluator will also apply the work units for the evaluator action 
AVA_VAN.1.1E to determine that the composed TOE provided by the 
developer is suitable for testing. 
17.7.2 Evaluation of sub-activity (ACO_VUL.2) 
17.7.2.1 Objectives 
1829 The objective of this sub-activity is to determine whether the composed TOE, 
in its operational environment, has vulnerabilities exploitable by attackers 
possessing basic attack potential. 
1830 The developer provides an analysis of the disposition of any residual 
vulnerabilities reported for the components and of any vulnerabilities 
introduced through the combination of the base and dependent components. 
The evaluator performs a search of the public domain to identify any new 
potential vulnerabilities in the components (i.e. those issues that have been 
reported in the public domain since the completion of the evaluatio n of the 
components). The evaluator will also perform an independent vulnerability 
analysis of the composed TOE and penetration testing. 
17.7.2.2 Input 
1831 The evaluation evidence for this sub-activity is:  
a) the composed TOE suitable for testing;  
b) the composed ST;  
Class ACO: Composition 
April 2017 Version 3.1 Page 381 of 430 
c) the composition rationale;  
d) the reliance information;  
e) the guidance documentation;  
f) information publicly available to support the identification of 
possible security vulnerabilities.  
g) residual vulnerabilities reported during evaluation of each component.  
17.7.2.3 Application notes 
1832 See the application notes for Evaluation of sub-activity (AVA_VAN.2). 
17.7.2.4 Action ACO_VUL.2.1E 
ACO_VUL.2.1C The composed TOE shall be suitable for testing.  
ACO_VUL.2-1 The evaluator shall examine  the composed TOE to determine that it has 
been installed properly and is in a known state. 
1833 To determine that the composed TOE has been installed pr operly and is in a 
known state the ATE_IND.2-1 and ATE_IND.2-2 work units will be applied 
to the composed TOE. 
1834 If the assurance package includes ACO_CTT family, then the evaluator may 
refer to the result of the work unit Composed TOE testing (ACO_CTT)*-1 to 
demonstrate this has been satisfied. 
ACO_VUL.2-2 The evaluator shall examine the composed TOE configuration to det ermine 
that any assumptions and objectives in the STs the components relating to IT 
entities for are fulfilled by the other components. 
1835 The STs for the component may include assumptions about other 
components that may use the component to which the ST rela tes, e.g. the ST 
for an operating system used as a base component may include an 
assumption that any applications loaded on the operating system do not run 
in privileged mode. These assumptions and objectives are to be fulfilled by 
other components in the composed TOE. 
17.7.2.5 Action ACO_VUL.2.2E 
ACO_VUL.2-3 The evaluator shall examine  the residual vulnerabilities from the base 
component evaluation to determine that they are n ot exploitable in the 
composed TOE in its operational environment. 
1836 The list of vulnerabilities identified in the product during the evaluation of 
the base component, which were demonstrated to be non -exploitable in the 
base component, is to be used as an i nput into this activity. The evaluator 
will determine that the premise(s) on which a vulnerability was deemed to be 
non-exploitable is upheld in the composed TOE, or whether the combination 
Class ACO: Composition 
Page 382 of 430 Version 3.1 April 2017 
has re -introduced the potential vulnerability. For example, if dur ing 
evaluation of the base component it was assumed that a particular operating 
system service was disabled, which is enabled in the composed TOE 
evaluation, any potential vulnerabilities relating to that service previously 
scoped out should now be considered. 
1837 Also, this list of known, non -exploitable vulnerabilities resulting from the 
evaluation of the base component should be considered in the light of any 
known, non -exploitable vulnerabilities for the other components (e.g. 
dependent component) within th e composed TOE. This is to consider the 
case where a potential vulnerability that is non -exploitable in isolation is 
exploitable when integrated with an IT entity containing another potential 
vulnerability. 
ACO_VUL.2-4 The evaluator shall examine the residual vulnerabilities from the dependent 
component evaluation to determine that they are not exploitable in the 
composed TOE in its operational environment. 
1838 The list of vulnerabilities identified in the product dur ing the evaluation of 
the dependent component, which were demonstrated to be non -exploitable in 
the dependent component, is to be used as an input into this activity. The 
evaluator will determine that the premise(s) on which a vulnerability was 
deemed to be non-exploitable is upheld in the composed TOE, or whether the 
combination has re -introduced the potential vulnerability. For example, if 
during evaluation of the dependent component it was assumed that IT 
meeting the operational environment requirements would not return a certain 
value in response to a service request, which is provided by the base 
component in the composed TOE evaluation, any potential vulnerabilities 
relating to that return value previously scoped out should now be considered. 
1839 Also, thi s list of known, non -exploitable vulnerabilities resulting from the 
evaluation of the dependent component should be considered in the light of 
any known, non -exploitable vulnerabilities for the other components (e.g. 
base component) within the composed TOE . This is to consider the case 
where a potential vulnerability that is non -exploitable in isolation is 
exploitable when integrated with an IT entity containing another potential 
vulnerability. 
17.7.2.6 Action ACO_VUL.2.3E 
ACO_VUL.2-5 The evaluator shall examine the sources of information publicly available to 
support the identification of possible security vulnerabilities in the base 
component that have become known since the c ompletion of the base 
component evaluation. 
1840 The evaluator will use the information in the public domain as described in 
AVA_VAN.2-2 to search for vulnerabilities in the base component. 
1841 Those potential vulnerabilities that were public ly available prior to the 
evaluation of the base component do not have to be further investigated 
unless it is apparent to the evaluator that the attack potential required by an 
Class ACO: Composition 
April 2017 Version 3.1 Page 383 of 430 
attacker to exploit the potential vulnerability has been significantly reduced . 
This may be through the introduction of some new technology since the base 
component evaluation that means the exploitation of the potential 
vulnerability has been simplified. 
ACO_VUL.2-6 The evaluator shall examine the sources of information publicly available to 
support the identification of possible security vulnerabilities in the dependent 
component that have become known since the completion of the dependent 
component evaluation. 
1842 The evaluator will use the information in the public domain as described in 
AVA_VAN.2-2 to search for vulnerabilities in the dependent component. 
1843 Those potential vulnerabilities that were publicly available prior to the 
evaluation of the dependent component do not have to be further investigated 
unless it is apparent to the evaluator that the attack potential required by an 
attacker to exploit the potential vulnerability has been significantly reduced. 
This may be through the introduction of some new technology  since 
evaluation of the dependent component that means the exploitation of the 
potential vulnerability has been simplified. 
ACO_VUL.2-7 The evaluator shall record  in the ETR the identified potential security 
vulnerabilities that are candidates for testing and applicable to the composed 
TOE in its operational environment. 
1844 The ST, guidance documentation and functional specification are used to 
determine whether the vulnerabilities are relevant to the composed TOE i n 
its operational environment. 
1845 The evaluator records any reasons for exclusion of vulnerabilities from 
further consideration if the evaluator determines that the vulnerability is not 
applicable in the operational environment. Otherwise the evaluator record s 
the potential vulnerability for further consideration. 
1846 A list of potential vulnerabilities applicable to the composed TOE in its 
operational environment, which can be used as an input into penetration 
testing activities ( ACO_VUL.2.5E), shall be reported in the ETR by the 
evaluators. 
17.7.2.7 Action ACO_VUL.2.4E 
ACO_VUL.2-8 The evaluator shall conduct  a search of the composed TOE ST, guidanc e 
documentation, reliance information and composition rationale to identify 
possible security vulnerabilities in the composed TOE. 
1847 The consideration of the components of the composed TOE in the 
independent evaluator vulnerability analysis will take a sligh tly different 
form to that documented in AVA_VAN.2.3E for a component evaluation, as 
it will not necessarily consider all layers of design abstraction relevant to the 
assurance package. These will have already been considered during  the 
evaluation of the components, but the evidence may not be available for the 
Class ACO: Composition 
Page 384 of 430 Version 3.1 April 2017 
composed TOE evaluation. However, the general approach described in the 
work units associated with AVA_VAN.2.3E is applicable and should form 
the basis  of the evaluator's search for potential vulnerabilities in the 
composed TOE. 
1848 A vulnerability analysis of the individual components used in the composed 
TOE will have already been performed during evaluation of the individual 
components. The focus of the v ulnerability analysis during the composed 
TOE evaluation is to identify any vulnerabilities introduced as a result of the 
integration of the components or due to any changes in the use of the 
components between the evaluated component configuration to the 
composed TOE configuration. 
1849 The evaluator will use the understanding of the component's construction as 
detailed in the reliance information for the dependent component, and the 
development information and composition rationale for the base component, 
together with the dependent component design information. This information 
will allow the evaluator to gain an understanding of how the base component 
and dependent component interact and identify potential vulnerabilities that 
may be introduced as a result of this interaction. 
1850 The evaluator will consider any new guidance provided for the installation, 
start-up and operation of the composed TOE to identify any potential 
vulnerabilities introduced through this revised guidance. 
1851 If any of the individual component s have been through assurance continuity 
activities since the completion of the component evaluation, the evaluator 
will consider the patch(es) in the independent vulnerability analysis. 
Information related to the change provided in a public report of the assurance 
continuity activities (e.g. Maintenance Report) will be the main source of 
input material of the change. This will be supplemented by any updates to 
the guidance documentation resulting from the change and any information 
regarding the change available in the public domain, e.g. vendor website. 
1852 Any risks identified due to the lack of evidence to establish the full impact of 
any patches or deviations in the configuration of a component from the 
evaluated configuration are to be documented in the ev aluator's vulnerability 
analysis. 
17.7.2.8 Action ACO_VUL.2.5E 
ACO_VUL.2-9 The evaluator shall conduct  penetration testing as detailed for 
AVA_VAN.2.4E. 
1853 The evaluator will apply all work units necessary for the satisfaction of 
evaluator action AVA_VAN.2.4E, reporting in the ETR for the composed 
TOE all analysis and verdicts as dictated by the work units. 
1854 The evaluator will also ap ply the work units for the evaluator action 
AVA_VAN.2.1E to determine that the composed TOE provided by the 
developer is suitable for testing. 
Class ACO: Composition 
April 2017 Version 3.1 Page 385 of 430 
17.7.3 Evaluation of sub-activity (ACO_VUL.3) 
17.7.3.1 Objectives 
1855 The objective of this sub-activity is to determine whether the composed TOE, 
in its operational environment, has vulnerabilities exploitable by attackers 
possessing Enhanced-Basic attack potential. 
1856 The developer provides an analysis of the disposition of any residual 
vulnerabilities reported fo r the components and of any vulnerabilities 
introduced through the combination of the base and dependent components. 
The evaluator performs a search of the public domain to identify any new 
potential vulnerabilities in the components (i.e. those issues tha t have been 
reported in the public domain since the completion of the component 
evaluations). The evaluator will also perform an independent vulnerability 
analysis of the composed TOE and penetration testing. 
17.7.3.2 Input 
1857 The evaluation evidence for this sub-activity is:  
a) the composed TOE suitable for testing;  
b) the composed ST;  
c) the composition rationale;  
d) the reliance information;  
e) the guidance documentation;  
f) information publicly available to support the identification of 
possible security vulnerabilities.  
g) residual vulnerabilities reported during evaluation of each component.  
17.7.3.3 Application notes 
1858 See the application notes for Evaluation of sub-activity (AVA_VAN.3). 
17.7.3.4 Action ACO_VUL.3.1E 
ACO_VUL.3.1C The composed TOE shall be suitable for testing.  
ACO_VUL.3-1 The evaluator shall examine  the composed TOE to determine that it has 
been installed properly and is in a known state. 
1859 To determine that the composed TOE has been installed properly and is in a 
known state the ATE_IND.2-1 and ATE_IND.2-2 work units will be applied 
to the composed TOE. 
Class ACO: Composition 
Page 386 of 430 Version 3.1 April 2017 
1860 If the assurance package in cludes ACO_CTT family, then the evaluator may 
refer to the result of the work unit Composed TOE testing (ACO_CTT)*-1 to 
demonstrate this has been satisfied. 
ACO_VUL.3-2 The evaluator shall examine the composed TOE configuration to determine 
that any assumptions and objectives in the STs the components relating to IT 
entities for are fulfilled by the other components. 
1861 The STs for the component may include assumption s about other 
components that may use the component to which the ST relates, e.g. the ST 
for an operating system used as a base component may include an 
assumption that any applications loaded on the operating system do not run 
in privileged mode. These as sumptions and objectives are to be fulfilled by 
other components in the composed TOE. 
17.7.3.5 Action ACO_VUL.3.2E 
ACO_VUL.3-3 The evaluator shall examine  the residual vulnera bilities from the base 
component evaluation to determine that they are not exploitable in the 
composed TOE in its operational environment. 
1862 The list of vulnerabilities identified in the product during the evaluation of 
the base component, which were demonst rated to be non -exploitable in the 
base component, is to be used as an input into this activity. The evaluator 
will determine that the premise(s) on which a vulnerability was deemed to be 
non-exploitable is upheld in the composed TOE, or whether the combin ation 
has re -introduced the potential vulnerability. For example, if during 
evaluation of the base component it was assumed that a particular operating 
system service was disabled, which is enabled in the composed TOE 
evaluation, any potential vulnerabilit ies relating to that service previously 
scoped out should now be considered. 
1863 Also, this list of known, non -exploitable vulnerabilities resulting from the 
evaluation of the base component should be considered in the light of any 
known, non -exploitable vulne rabilities for the other components (e.g. 
dependent component) within the composed TOE. This is to consider the 
case where a potential vulnerability that is non -exploitable in isolation is 
exploitable when integrated with an IT entity containing another po tential 
vulnerability. 
ACO_VUL.3-4 The evaluator shall examine the residual vulnerabilities from the dependent 
component evaluation to determine that they are not exploitable in the 
composed TOE in its operational environment. 
1864 The list of vulnerabilities identified in the product during the evaluation of 
the dependent component, which were demonstrated to be non -exploitable in 
the dependent component, is to be used as an input into this activity. The 
evaluator wil l determine that the premise(s) on which a vulnerability was 
deemed to be non-exploitable is upheld in the composed TOE, or whether the 
combination has re -introduced the potential vulnerability. For example, if 
during evaluation of the dependent component it was assumed that IT 
Class ACO: Composition 
April 2017 Version 3.1 Page 387 of 430 
meeting the operational environment requirements would not return a certain 
value in response to a service request, which is provided by the base 
component in the composed TOE evaluation, any potential vulnerabilities 
relating to that return value previously scoped out should now be considered. 
1865 Also, this list of known, non -exploitable vulnerabilities resulting from the 
evaluation of the dependent component should be considered in the light of 
any known, non -exploitable vulnerabilitie s for the other components (e.g. 
base component) within the composed TOE. This is to consider the case 
where a potential vulnerability that is non -exploitable in isolation is 
exploitable when integrated with an IT entity containing another potential 
vulnerability. 
17.7.3.6 Action ACO_VUL.3.3E 
ACO_VUL.3-5 The evaluator shall examine the sources of information publicly available to 
support the identification of possible security vulnerabilities in the base 
component that have become known since the completion of the base 
component evaluation. 
1866 The evaluator will use the information in the public domain as described in 
AVA_VAN.3-2 to search for vulnerabilities in the base component. 
1867 Those potential vulnerabilities that were publicly available prior to the 
evaluation of the base component do not have to be further investigated 
unless it is apparent to the evaluator that the attack potential required by an 
attacker to exploit the potential vulnerability has been significantly reduced. 
This may be through the introduction of some new technology since the base 
component evaluation that means the exploitation of the potential 
vulnerability has been simplified. 
ACO_VUL.3-6 The evaluator shall examine the sources of information publicly available to 
support the identification of possible security vulnerabilities in the dependent 
component that have become known since completio n of the dependent 
component evaluation. 
1868 The evaluator will use the information in the public domain as described in 
AVA_VAN.3-2 to search for vulnerabilities in the dependent component. 
1869 Those potential vulnerabilities that were publ icly available prior to the 
evaluation of the dependent component do not have to be further investigated 
unless it is apparent to the evaluator that the attack potential required by an 
attacker to exploit the potential vulnerability has been significantly reduced. 
This may be through the introduction of some new technology since 
evaluation of the dependent component that means the exploitation of the 
potential vulnerability has been simplified. 
ACO_VUL.3-7 The eva luator shall record  in the ETR the identified potential security 
vulnerabilities that are candidates for testing and applicable to the composed 
TOE in its operational environment. 
Class ACO: Composition 
Page 388 of 430 Version 3.1 April 2017 
1870 The ST, guidance documentation and functional specification are used to 
determine whether the vulnerabilities are relevant to the composed TOE in 
its operational environment. 
1871 The evaluator records any reasons for exclusion of vulnerabilities from 
further consideration if the evaluator determines that the vulnerability is not 
applicable in the operational environment. Otherwise the evaluator records 
the potential vulnerability for further consideration. 
1872 A list of potential vulnerabilities applicable to the composed TOE in its 
operational environment, which can be used as an input in to penetration 
testing activities ( ACO_VUL.3.5E), shall be reported in the ETR by the 
evaluators. 
17.7.3.7 Action ACO_VUL.3.4E 
ACO_VUL.3-8 The evaluator shall conduct  a search of the composed TOE ST, guidance 
documentation, reliance information and composition rationale to identify 
possible security vulnerabilities in the composed TOE. 
1873 The consideration of the components in the independent ev aluator 
vulnerability analysis will take a slightly different form to that documented 
in AVA_VAN.3.3E for a component evaluation, as it will not necessarily 
consider all layers of design abstraction relevant to the assurance package . 
These will have already been considered during the evaluation of the base 
component, but the evidence may not be available for the composed TOE 
evaluation. However, the general approach described in the work units 
associated with AVA_VAN.3.3E is applicable and should form the basis of 
the evaluator's search for potential vulnerabilities in the composed TOE. 
1874 A vulnerability analysis of the individual components used in the composed 
TOE will have already been performed during evaluat ion of the components. 
The focus of the vulnerability analysis during the composed TOE evaluation 
is to identify any vulnerabilities introduced as a result of the integration of 
the components or due to any changes in the use of the components between 
the configuration of the component determined during the component 
evaluation and the composed TOE configuration. 
1875 The evaluator will use the understanding of the component's construction as 
detailed in the reliance information for the dependent component, and the 
composition rationale and development information for the base component, 
together with the dependent component design information. This information 
will allow the evaluator to gain an understanding of how the base component 
and dependent component interact. 
1876 The evaluator will consider any new guidance provided for the installation, 
start-up and operation of the composed TOE to identify any potential 
vulnerabilities introduced through this revised guidance. 
1877 If any of the individual components have been through assurance continuity 
activities since the completion of the component evaluation, the evaluator 
Class ACO: Composition 
April 2017 Version 3.1 Page 389 of 430 
will consider the patch in the independent vulnerability analysis. Information 
related to the change provided in a public report of the assurance contin uity 
activities (e.g. Maintenance Report). This will be supplemented by any 
updates to the guidance documentation resulting from the change and any 
information regarding the change available in the public domain, e.g. vendor 
website. 
1878 Any risks identified due to the lack of evidence to establish the full impact of 
any patches or deviations in the configuration of a component from the 
evaluated configuration are to be documented in the evaluator's vulnerability 
analysis. 
17.7.3.8 Action ACO_VUL.3.5E 
ACO_VUL.3-9 The evaluator shall conduct  penetration testing as detailed for 
AVA_VAN.3.4E. 
1879 The evaluator will apply all work units necessary for the satisfaction  of 
evaluator action AVA_VAN.3.4E, reporting in the ETR for the composed 
TOE all analysis and verdicts as dictated by the work units. 
1880 The evaluator will also apply the work units for the evaluator action 
AVA_VAN.3.1E to determine that the composed TOE provided by the 
developer is suitable for testing. 
General evaluation guidance 
Page 390 of 430 Version 3.1 April 2017 
A General evaluation guidance 
(informative) 
A.1 Objectives 
1881 The objective of this chapter is to cover general guidance used to provide 
technical evidence of evaluation  results. The use of such general guidance 
helps in achieving objectivity, repeatability and reproducibility of the work 
performed by the evaluator. 
A.2 Sampling 
1882 This Section provides general guidance on sampling. Specific and detailed 
information is given in those work units under the specific evaluator action 
elements where sampling has to be performed. 
1883 Sampling is a defined procedure of an evaluator whereby some subset of a 
required set of evaluation evidence is examined and assumed to be 
representative for the entire set. It allows the evaluator to gain enough 
confidence in the correctness of particular evaluation evidence without 
analysing the whole evidence. The reason for sampling is to conserve 
resources while maintaining an adequate level of assurance. Sampling of the 
evidence can provide two possible outcomes:  
a) The subset reveals no errors, allowing the evaluator to have some 
confidence that the entire set is correct.  
b) The subset reveals errors and therefore the validity of the entire set is 
called into question. Even the resolution of all errors that were found 
may be insufficient to provide the evaluator the necessary confidence 
and as a result the evaluator may have to increase the size of the 
subset, or stop using sampling for this particular evidence.  
1884 Sampling is a technique which can be used to reach a reliable conclusion if a 
set of evidence is relatively homogeneous in nature, e.g. if the evidence has 
been produced during a well defined process. 
1885 Sampling in the cases identified in the CC, and in cases specifically covered 
in CEM work items, is recognised as a cost -effective approach to performing 
evaluator actions. Sampling in other areas is permitted only in exceptional 
cases, where performance of a particular activity in its entirety would requi re 
effort disproportionate to the other evaluation activities, and where this 
would not add correspondingly to assurance. In such cases a rationale for the 
use of sampling in that area will need to be made. Neither the fact that the 
TOE is large and comple x, nor that it has many security functional 
requirements, is sufficient justification, since evaluations of large, complex 
TOEs can be expected to require more effort. Rather it is intended that this 
exception be limited to cases such as that where the TOE  development 
General evaluation guidance 
April 2017 Version 3.1 Page 391 of 430 
approach yields large quantities of material for a particular CC requirement 
that would normally all need to be checked or examined, and where such an 
action would not be expected to raise assurance correspondingly. 
1886 Sampling needs to be justified taking into account the possible impact on the 
security objectives and threats of the TOE. The impact depends on what 
might be missed as a result of sampling. Consideration also needs to be given 
to the nature of the evidence to be sampled, and the req uirement not to 
diminish or ignore any security functions. 
1887 It should be recognised that sampling of evidence directly related to the 
implementation of the TOE (e.g. developer test results) requires a different 
approach to sampling, then sampling related to  the determination of whether 
a process is being followed. In many cases the evaluator is required to 
determine that a process is being followed, and a sampling strategy is 
recommended. The approach for sampling a developer's test results will 
differ. This  is because the former case is concerned with ensuring that a 
process is in place, and the latter deals with determining correct 
implementation of the TOE. Typically, larger sample sizes should be 
analysed in cases related to the correct implementation of the TOE than 
would be necessary to ensure that a process is in place. 
1888 In certain cases it may be appropriate for the evaluator to give greater 
emphasis to the repetition of developer testing. For example if the 
independent tests left for the evaluator to p erform would be only 
superficially different from those included in an extensive developer test set 
(possibly because the developer has performed more testing than necessary 
to satisfy the Coverage (ATE_COV) and Depth (ATE_DPT) criteria) then it 
would be appropriate for the evaluator to give greater focus to the repetition 
of developer tests. Note that this does not necessarily imply a requirement for 
a high percentage sample for repetition of developer tests; indeed, g iven an 
extensive developer test set, the evaluator may be able to justify a low 
percentage sample. 
1889 Where the developer has used an automated test suite to perform functional 
testing, it will usually be easier for the evaluator to re -run the entire test suite 
rather than repeat only a sample of developer tests. However the evaluator 
does have an obligation to check that the automatic testing does not give 
misrepresentative results. The implication is thus that this check must be 
performed for a sample of th e automatic test suite, with the principles for 
selecting some tests in preference to others and ensuring a sufficient sample 
size applying equally in this case. 
1890 The following principles should be followed whenever sampling is 
performed:  
a) Sampling should not be random, rather it should be chosen such that 
it is representative of all of the evidence. The sample size and 
composition must always be justified.  
General evaluation guidance 
Page 392 of 430 Version 3.1 April 2017 
b) When sampling relates to the correct implementation of the TOE, the 
sample should be representative o f all aspects relevant to the areas 
that are sampled. In particular, the selection should cover a variety of 
components, interfaces, developer and operational sites (if more than 
one is involved) and hardware platform types (if more than one is 
involved). The sample size should be commensurate with the cost 
effectiveness of the evaluation and will depend on a number of TOE 
dependent factors (e.g. the size and complexity of the TOE, the 
amount of documentation).  
c) Also, when sampling relates to specifically g aining evidence that the 
developer testing is repeatable and reproducible the sample used must 
be sufficient to represent all distinct aspects of developer testing, such 
as different test regimes. The sample used must be sufficient to detect 
any systematic problem in the developer's functional testing process. 
The evaluator contribution resulting from the combination of 
repeating developer tests and performing independent tests must be 
sufficient to address the major points of concern for the TOE.  
d) Where sa mpling relates to gaining evidence that a process (e.g. 
visitor control or design review) the evaluator should sample 
sufficient information to gain reasonable confidence that the 
procedure is being followed.  
e) The sponsor and developer should not be inform ed in advance of the 
exact composition of the sample, subject to ensuring timely delivery 
of the sample and supporting deliverable, e.g. test harnesses and 
equipment to the evaluator in accordance with the evaluation 
schedule.  
f) The choice of the sample sho uld be free from bias to the degree 
possible (one should not always choose the first or last item). Ideally 
the sample selection should be done by someone other than the 
evaluator.  
1891 Errors found in the sample can be categorised as being either systematic o r 
sporadic. If the error is systematic, the problem should be corrected and a 
complete new sample taken. If properly explained, sporadic errors might be 
solved without the need for a new sample, although the explanation should 
be confirmed. The evaluator should use judgement in determining whether to 
increase the sample size or use a different sample. 
A.3 Dependencies 
1892 In general it is possible to perform the required evaluation activities, sub -
activities, and actions in any order or in parallel. However, there are different 
kinds of dependencies which have to be considered by the evaluator. This 
Section provides general guidance on dependencies between different 
activities, sub-activities, and actions. 
General evaluation guidance 
April 2017 Version 3.1 Page 393 of 430 
A.3.1 Dependencies between activities 
1893 For some cases the different  assurance classes may recommend or even 
require a sequence for the related activities. A specific instance is the ST 
activity. The ST evaluation activity is started prior to any TOE evaluation 
activities since the ST provides the basis and context to perf orm them. 
However, a final verdict on the ST evaluation may not be possible until the 
TOE evaluation is complete, since changes to the ST may result from activity 
findings during the TOE evaluation. 
A.3.2 Dependencies between sub-activities 
1894 Dependencies identifi ed between components in CC Part 3 have to be 
considered by the evaluator. Most dependencies are one way, e.g. Evaluation 
of sub -activity (AVA_VAN.1)  claims a dependency on Evaluation of sub -
activity (ADV_FSP.1) and Evaluation of sub -activity (AGD_OPE.1). There 
are also instances of mutual dependencies, where both components depend 
on each other. An example of this is Evaluation of sub -activity 
(ATE_FUN.1) and Evaluation of sub-activity (ATE_COV.1). 
1895 A sub-activity can be assigned a pass verdict normally only if all those sub -
activities are successfully completed on which it has a one -way dependency. 
For example, a pass verdict on Evaluation of sub-activity (AVA_VAN.1) can 
normally only be assigned if the sub -activities related to Evaluation of sub -
activity (ADV_FSP.1)  and Evaluation of sub -activity (AGD_OPE.1)  are 
assigned a pass verdict too. In the case of mutual dependency the ordering of 
these components is down to the evaluator deciding which sub -activity to 
perform first. Note this indicates that pass verdicts can normally only be 
assigned once both sub-activities have been successful. 
1896 So when determining whether a sub-activity will impact another sub-activity, 
the evaluator should consider whether this activity depends on potential 
evaluation results from any dependent sub -activities. Indeed, it may be the 
case that a dependent sub -activity will impact this sub -activity, requiring 
previously completed evaluator actions to be performed again. 
1897 A significant dependency effect occurs in the case of evaluator -detected 
flaws. If a flaw is identified as a result of conducting one sub -activity, the 
assignment of a pass verdict to a dependent sub -activity may not be possible 
until all flaws related to the sub-activity upon which it depends are resolved. 
A.3.3 Dependencies between actions 
1898 It may be the case, that results which are generated by the evaluator during 
one action are used for performing another action. For example, actions for 
completeness and consistency cannot be completed until the checks for 
content and presentation have been completed. This means for example that 
the evaluator is recommended to evaluate the PP/ST rationale after 
evaluating the constituent parts of the PP/ST. 
General evaluation guidance 
Page 394 of 430 Version 3.1 April 2017 
A.4 Site Visits 
A.4.1 Introduction 
1899 The assurance class ALC includes requirements for  
a) the application of configuration management, ensuring that the 
integrity of the TOE is preserved;  
b) measures, procedures, and standards concerned with secure delivery 
of the TOE, ensuring that the security protection offered by the TOE 
is not compromised during the transfer to the user,  
c) security measures, used to protect the development environment.  
1900 A development site visit is a useful means whereby the evaluator determines 
whether procedures are being followed in a manner consistent with that 
described in the documentation. 
1901 Reasons for visiting sites include:  
a) to observe the use of the CM system as described in the CM plan;  
b) to observe the practical application of delivery procedures as 
described in the delivery documentation;  
c) to observe the application of security measures during development 
and maintenance of the TOE as described in the development security 
documentation.  
1902 Specific and detailed information is given in work units for those activities 
where site visits are performed:  
a) CM capabilities (ALC_CMC) .n with n>=3 (especially work unit 
ALC_CMC.3-10 = ALC_CMC.4-13 = ALC_CMC.5-19);  
b) Delivery (ALC_DEL) (especially work unit ALC_DEL.1-2);  
c) Development secu rity (ALC_DVS)  (especially work unit 
ALC_DVS.1-3 = ALC_DVS.2-4).  
A.4.2 General Approach 
1903 During an evaluation it is often necessary that the evaluator will meet the 
developer more than once and it is a question of good planning to combine 
the site visit with another meeting to reduce costs. For example one might 
combine the site visits for configuration management, for the developer's 
security and for delivery. It may also be necessary to perform more than one 
site visit to the same  site to allow the checking of all development phases. It 
should be considered that development could occur at multiple facilities 
within a single building, multiple buildings at the same site, or at multiple 
sites. 
General evaluation guidance 
April 2017 Version 3.1 Page 395 of 430 
1904 The first site visit should be scheduled  early during the evaluation. In the 
case of an evaluation which starts during the development phase of the TOE, 
this will allow corrective actions to be taken, if necessary. In the case of an 
evaluation which starts after the development of the TOE, an ea rly site visit 
could allow corrective measures to be put in place if serious deficiencies in 
the applied procedures emerge. This avoids unnecessary evaluation effort. 
1905 Interviews are also a useful means of determining whether the written 
procedures reflect what is done. In conducting such interviews, the evaluator 
aims to gain a deeper understanding of the analysed procedures at the 
development site, how they are used in practise and whether they are being 
applied as described in the provided evaluation evid ence. Such interviews 
complement but do not replace the examination of evaluation evidence. 
1906 As a first step preparing the site visits the evaluators should perform the 
evaluator work units concerning the assurance class ALC excluding the 
aspects describing the results of the site visit. Based on the information 
provided by the relevant developer documentation and the remaining open 
questions which were not answered by the documentation the evaluators 
compile a check list of the qu estions which are to be resolved by the site 
visits. 
1907 The first version of the evaluation report concerning the ALC class and the 
check list serves as input for the consultation with the evaluation authority 
concerning the site visits. 
1908 The check list serve as a guide line for the site visits, which questions are to 
be answered by inspection of the relevant measures, their application and 
results, and by interviews. Where appropriate, sampling is used for gaining 
the required level of confidence (see Section A.2). 
1909 The results of the site visits are recorded and serve as input for the final 
version of the evaluation report concerning the assurance class ALC. 
1910 Other approac hes to gain confidence should be considered that provide an 
equivalent level of assurance (e.g. to analyse evaluation evidence). Any 
decision not to make a visit should be determined in consultation with the 
evaluation authority. Appropriate security crite ria and a methodology should 
be based on other standards of the Information Security Management 
Systems area. 
A.4.3 Orientation Guide for the Preparation of the Check List 
1911 In the following some keywords are provided, which topics should be 
checked during an audit. 
A.4.3.1 Aspects of configuration management 
1912 Basic  
General evaluation guidance 
Page 396 of 430 Version 3.1 April 2017 
 Items of the configuration list, including TOE, source code, run time 
libraries, design documentation, development tools (ALC_CMC.3-8).  
 Tracking of design documentation, source code, use r guidance to 
different versions of the TOE.  
 Integration of the configuration system in the design and 
development process, test planning, test analysis and quality 
management procedures.  
1913 Test analysis  
 Tracking of test plans and results to specific conf igurations and 
versions of the TOE.  
1914 Access control to development systems  
 Policies for access control and logging.  
 Policies for project specific assignment and changing of access rights.  
1915 Clearance  
 Policies for clearance of the TOE and user guidance to the customer.  
 Policies for testing and approving of components and the TOE before 
deployment.  
A.4.3.2 Aspects of development security 
1916 Infrastructure  
 Security measures for physical access control to the development site 
and rationale for the effectiveness of these measures.  
1917 Organisational measures  
 Organisational structure of the company in respect of the security of 
the development environment.  
 Organisational separation between development, production, testing 
and quality assurance.  
1918 Personal measures  
 Measures for education of the personnel in respect of development 
security.  
 Measures and legal agreements of non disclosure of internal 
information.  
1919 Access control  
General evaluation guidance 
April 2017 Version 3.1 Page 397 of 430 
 Assignment of secured objects (for instance TOE, source code, run 
time libraries, design docume ntation, development tools, user 
guidance) and security policies.  
 Policies and responsibilities concerning the access control and the 
handling of authentication information.  
 Policies for logging of any kind access to the development site and 
protection of the logging data.  
1920 Input, processing and output of data  
 Security measures for protection of output and output devices (printer, 
plotter and displays).  
 Securing of local networks and communication connections.  
1921 Storage, transfer and destruction of documents and data media.  
 Policies for handling of documents and data media.  
 Policies and responsibilities for destruction of sorted out documents 
and logging of these events.  
1922 Data protection  
 Policies and responsibilities for data and information protection  (e.g. 
for performing backups).  
1923 Contingency plan  
 Practises in case of emergency and responsibilities.  
 Documentation of the contingency measures concerning access 
control.  
 Information of the personnel about applicable practises in extreme 
cases. protection (e.g. for performing backups).  
A.4.4 Example of a checklist 
1924 The examples of checklists for site visits consist in tables for the preparation 
of an audit and for the presentation of the results of an audit. 
1925 The checklist structure given in the following is p reliminary. Dependent on 
the concrete contents of the new guideline, changes might become necessary. 
1926 The checklist is divided into three sections according to the subjects 
indicated in the introduction (Section A.4.1).  
a) Configuration management system.  
General evaluation guidance 
Page 398 of 430 Version 3.1 April 2017 
b) Delivery procedures.  
c) Security measures during development.  
1927 These sections correspond to the actual CC class ALC, especially the 
families CM capabilities (ALC_CMC) .n with n> =3, Delivery (ALC_DEL)  
and Development security (ALC_DVS). 
1928 The sections are subdivided further into rows corresponding to the relevant 
work units of the CEM. 
1929 The columns of the checklist contain in turn  
 a consecutive number,  
 the referenced work unit,  
 the references to the corresponding developer documentation,  
 the explicit reproduction of the developer measures,  
 special remarks and questions to be clarified on the visit (beyond the 
standard evaluator task to verify  the application of the indicated 
measures),  
 the result of the examinations during the visit.  
1930 If it is decided to have separate checklists for preparation and reporting of the 
audit, the result column is omitted in the preparation list and the remarks an d 
questions column is omitted in the reporting list. The remaining columns 
should be identical in both lists. 
Table 1  Example of a checklist at EAL 4 (extract)  
A. Examination of the CM system (ALC_CMC.4 and ALC_CMS.4) 
No. Work Unit Developer 
Documentation Measures Questions and 
Remarks Result 
A.1 ALC_CMC.4-11, 
ALC_CMC.4-12 
“Configuration 
Management 
System”, ch. ... 
The system 
automatically 
managing the 
source code 
files is 
capable of 
administering 
user profiles 
and graded 
access rights, 
and of 
checking 
identification 
and 
Does reading 
or updating of 
a source code 
file require a 
user 
authentication? 
If a user 
has not the 
right to 
access a 
confidential 
document, 
it is not 
even 
displayed 
to him in 
the file list. 
General evaluation guidance 
April 2017 Version 3.1 Page 399 of 430 
A. Examination of the CM system (ALC_CMC.4 and ALC_CMS.4) 
No. Work Unit Developer 
Documentation Measures Questions and 
Remarks Result 
authentication 
of users. 
... ... ... ... ... ... 
B. Examination of the Delivery Procedures (ALC_DEL.1) 
No. Work Unit Developer 
Documentation Measures Questions and 
Remarks Result 
B.1 ALC_DEL.1-1, 
ALC_DEL.1-2 
“Delivery of 
the TOE”, 
ch. ... 
The software 
is transmitted 
PGP-signed 
and 
encrypted to 
the customer. 
--- 
The 
evaluators 
have 
checked the 
process and 
found it as 
described, 
additionally 
a checksum 
is 
transmitted. 
... ... ... ... ... ... 
C. Examination of the organisational and infrastructural developer security (ALC_DVS.1, 
ALC_LCD.1, ALC_TAT.1) 
No. Work Unit Developer 
Documentation Measures Questions and 
Remarks Result 
C.1 ALC_DVS.1-1, 
ALC_DVS.1-2 
“Security of 
the 
development 
environment”, 
ch. ... 
(Premises) 
The premises 
are protected 
by security 
fencing. 
Is the fencing 
sufficiently 
strong and 
high to 
prevent an 
easy intrusion 
into the 
premises? 
The 
evaluators 
considered 
the fencing 
to be 
sufficiently 
strong and 
high. 
C.2 ALC_DVS.1-1, 
ALC_DVS.1-2 
“Security of 
the 
development 
environment”, 
ch. ... 
(Building) 
The building 
has the 
following 
access 
possibilities: 
The main 
entrance 
which is 
surveyed by 
the reception 
and is closed 
if the 
reception is 
not manned. 
And an 
access in the 
goods 
Is the listing 
of the access 
possibilities 
complete? 
Beyond the 
indicated 
access 
possibilities, 
there is an 
emergency 
exit that 
cannot be 
opened 
from the 
outside. The 
roller 
shutters 
mentioned 
before can 
be operated 
only from 
General evaluation guidance 
Page 400 of 430 Version 3.1 April 2017 
C. Examination of the organisational and infrastructural developer security (ALC_DVS.1, 
ALC_LCD.1, ALC_TAT.1) 
No. Work Unit Developer 
Documentation Measures Questions and 
Remarks Result 
reception 
which is 
secured by 
two roller 
shutters. 
inside. 
... ... ... ... ... ... 
A.5 Scheme Responsibilities 
1931 This CEM describes the minimum technical work that evaluations conducted 
under oversight (scheme) bodies must perform. However, it also recognises 
(both explicitly and implicitly) that there are activities or methods upon 
which mutual recognition of evaluation results do not rely. For the purposes 
of thoroughness and clarity, and to better delineate where the CEM ends and 
an individual scheme's methodology begins, the following matters are left up 
to the discretion of the schemes. Schemes may choos e to provide the 
following, although they may choose to leave some unspecified. (Every 
effort has been made to ensure this list is complete; evaluators encountering 
a subject neither listed here nor addressed in the CEM should consult with 
their evaluation  schemes to determine under whose auspices the subject 
falls.) 
1932 The matters that schemes may choose to specify include:  
a) what is required in ensuring that an evaluation was done sufficiently - 
every scheme has a means of verifying the technical competence, 
understanding of work and the work of its evaluators, whether by 
requiring the evaluators to present their findings to the oversight body, 
by requiring the oversight body to redo the evaluator's work, or by 
some other means that assures the scheme that all  evaluation bodies 
are adequate and comparable;  
b) process for disposing of evaluation evidence upon completion of an 
evaluation;  
c) any requirements for confidentiality (on the part of the evaluator and 
the non-disclosure of information obtained during evaluation);  
d) the course of action to be taken if a problem is encountered during the 
evaluation (whether the evaluation continues once the problem is 
remedied, or the evaluation ends immediately and the remedied 
product must be re-submitted for evaluation);  
e) any specific (natural) language in which documentation must be 
provided;  
General evaluation guidance 
April 2017 Version 3.1 Page 401 of 430 
f) any recorded evidence that must be submitted in the ETR - this CEM 
specifies the minimum to be reported in an ETR; however, individual 
schemes may require additional information to be included;  
g) any additional reports (other than the ETR) required from the 
evaluators -for example, testing reports;  
h) any specific ORs that may be required by the scheme, including the 
structure, recipients, etc. of any such ORs;  
i) any specific content structure of any written report as a result from an 
ST evaluation - a scheme may have a specific format for all of its 
reports detailing results of an evaluation, be it the evaluation of a 
TOE or of an ST;  
j) any additional PP/ST identification information required;  
k) any activities to determine the suitability of explicitly -stated 
requirements in an ST;  
l) any requirements for provision of evaluator evidence to support re -
evaluation and re-use of evidence;  
m) any specific handling of scheme identifiers, logos, trademarks, etc.;  
n) any specific guidance in dealing with cryptography;  
o) handling and application of scheme, national and international 
interpretations;  
p) a list or characterisations of suitable alternative approaches to testing 
where testing is infeasible;  
q) the mechanism by which an evaluation authority can determine what 
steps an evaluator took while testing;  
r) preferred test approach (if any): at internal interface or at external 
interface;  
s) a list or characterisation of acceptable means of conducting the 
evaluator's vulnerability analysis (e.g. flaw hypothesis methodology);  
t) information regarding any vulnerabilities and weaknesses to be 
considered.  
Vulnerability Assessment (AVA) 
Page 402 of 430 Version 3.1 April 2017 
B Vulnerability Assessment (AVA) 
(informative) 
1933 This annex provides an explanation of the AVA_VAN criteria and examples 
of their application. This annex does not define the AVA criteria; this 
definition can be found in CC Part 3 Section Class AVA: Vulnerability 
assessment. 
1934 This annex consists of 2 major parts:  
a) Guidance for completing an independent vulnerability analysis . This 
is summarised in section B.1, and described in more detail in section 
B.2 . These sections describe how an evaluator should  approach the 
construction of an independent Vulnerability Analysis.  
b) How to characterise and use assumed Attack Potential of an attacker. 
This is described in sections B.3 to B.5. These sections provid e an 
example of describe how an attack potential can be characterised and 
should be used, and provide examples.  
B.1 What is Vulnerability Analysis 
1935 The purpose of the vulnerability assessment activity is to determine the 
existence and exploitability of flaws o r weaknesses in the TOE in the 
operational environment. This determination is based upon analysis 
performed by the evaluator, and is supported by evaluator testing. 
1936 At the lowest levels of Vulnerability analysis (AVA_VAN)  the evaluator 
simply performs a search of publicly available information to identify any 
known weaknesses in the TOE, while at the higher levels the evaluator 
performs a structured analysis of the TOE evaluation evidence. 
1937 There are three main factors in performing a vulnerability analysis, namely:  
a) the identification of potential vulnerabilities;  
b) assessment to determine whether the identified potential 
vulnerabilities could allow an attacker with the relevant attack 
potential to violate the SFRs.  
c) penetration testing to determine whether the identified potential 
vulnerabilities are exploitable in the operational environment of the 
TOE.  
1938 The identification of vulnerabilities can be further decomposed into the 
evidence to be searched and how hard to search that evidence to identify 
potential vulnerabilities. In a similar manner, the penetration testing can be 
further decomposed into analysis of the potential vulnerability to identify 
attack methods and the demonstration of the attack methods. 
Vulnerability Assessment (AVA) 
April 2017 Version 3.1 Page 403 of 430 
1939 These main factors are iterative  in nature, i.e. penetration testing of potential 
vulnerabilities may lead to the identification of further potential 
vulnerabilities. Hence, these are performed as a single vulnerability analysis 
activity. 
B.2 Evaluator construction of a Vulnerability Analysis 
1940 The evaluator vulnerability analysis is to determine that the TOE is resistant 
to penetration attacks performed by an attacker possessing a Basic (for 
AVA_VAN.1 and AVA_VAN.2), Enhanced -Basic (for AVA_VAN.3), 
Moderate (for AVA_VAN.4) or High (for AVA_VAN.5) attack potential. 
The evaluator first assesses the exploitability of all identified pot ential 
vulnerabilities. This is accomplished by conducting penetration testing. The 
evaluator should assume the role of an attacker with a Basic (for 
AVA_VAN.1 and AVA_VAN.2), Enhanced -Basic (for AVA_VAN.3), 
Moderate (for AVA_VAN.4) or High (for AVA_VAN.5) attack potential 
when attempting to penetrate the TOE. 
1941 The evaluator considers potential v ulnerabilities encountered by the 
evaluator during the conduct of other evaluation activities. The evaluator 
penetration testing determining TOE resistance to these potential 
vulnerabilities should be performed assuming the role of an attacker with a 
Basic (for AVA_VAN.1 and AVA_VAN.2), Enhanced -Basic (for 
AVA_VAN.3), Moderate (for AVA_VAN.4) or High (for AVA_VAN.5) 
attack potential. 
1942 However, vulnerability analysis should not be performed as an isolated 
activity. It is closely linked with ADV and AGD. The evaluator performs 
these other evaluat ion activities with a focus on identifying potential 
vulnerabilities or “areas of concern”. Therefore, evaluator familiarity with 
the generic vulnerability guidance (provided in Section B.2.1) is required. 
B.2.1 Generic vulnerability guidance 
1943 The following five categories provide discussion of generic vulnerabilities. 
B.2.1.1 Bypassing 
1944 Bypassing includes any means by which an attacker could avoid security 
enforcement, by:  
a) exploiting the capabilities of interfaces to the TOE, or of utilities 
which can interact with the TOE;  
b) inheriting privileges or other capabilities that should otherwise be 
denied;  
c) (where confidentiality is a concern) reading sensitive data stored or 
copied to inadequately protected areas.  
Vulnerability Assessment (AVA) 
Page 404 of 430 Version 3.1 April 2017 
1945 Each of the following should be cons idered (where relevant) in the 
evaluator's independent vulnerability analysis.  
a) Attacks based on exploiting the capabilities of interfaces or utilities 
generally take advantage of the absence of the required security 
enforcement on those interfaces. For ex ample, gaining access to 
functionality that is implemented at a lower level than that at which 
access control is enforced. Relevant items include:  
1) changing the predefined sequence of invocation of TSFI;  
2) invoking an additional TSFI;  
3) using a component in an unexpected context or for an 
unexpected purpose;  
4) using implementation detail introduced in less abstract 
representations;  
5) using the delay between time of access check and time of use.  
b) Changing the predefined sequence of invocation of components 
should be considered where there is an expected order in which 
interfaces to the TOE (e.g. user commands) are called to invoke a 
TSFI (e.g. opening a file for access and then reading data from it). If 
a TSFI is invoked through one of the TOE interfaces (e.g. an  access 
control check), the evaluator should consider whether it is possible to 
bypass the control by performing the call at a later point in the 
sequence or by missing it out altogether.  
c) Executing an additional component (in the predefined sequence) is a  
similar form of attack to the one described above, but involves the 
calling of some other TOE interface at some point in the sequence. It 
can also involve attacks based on interception of sensitive data passed 
over a network by use of network traffic anal ysers (the additional 
component here being the network traffic analyser).  
d) Using a component in an unexpected context or for an unexpected 
purpose includes using an unrelated TOE interface to bypass the TSF 
by using it to achieve a purpose that it was not designed or intended 
to achieve. Covert channels are an example of this type of attack (see 
B.2.1.4 for further discussion of covert channels). The use of 
undocumented interfaces, which may be insecure, also falls into this 
category. Such interfaces may include undocumented support and 
help facilities.  
e) Using implementation detail introduced in lower representations may 
allow an attacker to take advantage of additional functions, resources 
or attributes that are introduced to t he TOE as a consequence of the 
refinement process. Additional functionality may include test harness 
Vulnerability Assessment (AVA) 
April 2017 Version 3.1 Page 405 of 430 
code contained in software modules and back -doors introduced 
during the implementation process.  
f) Using the delay between time of check and time of use incl udes 
scenarios where an access control check is made and access granted, 
and an attacker is subsequently able to create conditions in which, 
had they applied at the time the access check was made, would have 
caused the check to fail. An example would be a user creating a 
background process to read and send highly sensitive data to the 
user's terminal, and then logging out and logging back in again at a 
lower sensitivity level. If the background process is not terminated 
when the user logs off, the MAC check s would have been effectively 
bypassed.  
g) Attacks based on inheriting privileges are generally based on illicitly 
acquiring the privileges or capabilities of some privileged component, 
usually by exiting from it in an uncontrolled or unexpected manner. 
Relevant items include:  
1) executing data not intended to be executable, or making it 
executable;  
2) generating unexpected input for a component;  
3) invalidating assumptions and properties on which lower -level 
components rely.  
h) Executing data not intended to be executable, or making it executable 
includes attacks involving viruses (e.g. putting executable code or 
commands in a file which are automatically executed when the file is 
edited or accessed, thus inheriting any privileges the owner of the file 
has).  
i) Generating unexpected input for a component can have unexpected 
effects which an attacker could take advantage of. For example, if the 
TSF could be bypassed if a user gains access to the underlying 
operating system, it may be possible to gain such access followin g 
the login sequence by exploring the effect of hitting various control 
or escape sequences whilst a password is being authenticated.  
j) Invalidating assumptions and properties on which lower level 
components rely includes attacks based on breaking out of th e 
constraints of an application to gain access to an underlying operating 
system in order to bypass the TSF of an application. In this case the 
assumption being invalidated is that it is not possible for a user of the 
application to gain such access. A sim ilar attack can be envisaged 
against an application on an underlying database management 
system: again the TSF could be bypassed if an attacker can break out 
of the constraints of the application.  
Vulnerability Assessment (AVA) 
Page 406 of 430 Version 3.1 April 2017 
k) Attacks based on reading sensitive data stored in inadequa tely 
protected areas (applicable where confidentiality is a concern) 
include the following issues which should be considered as possible 
means of gaining access to sensitive data:  
1) disk scavenging;  
2) access to unprotected memory;  
3) exploiting access to share d writable files or other shared 
resources (e.g. swap files);  
4) Activating error recovery to determine what access users can 
obtain. For example, after a crash an automatic file recovery 
system may employ a lost and found directory for headerless 
files, which are on disk without labels. If the TOE implements 
mandatory access controls, it is important to investigate at 
what security level this directory is kept (e.g. at system high), 
and who has access to this directory.  
1946 There are a number of different metho ds through which an evaluator may 
identify a back-door, including two main techniques. Firstly, by the evaluator 
inadvertently identifying during testing an interface that can be misused. 
Secondly, through testing each external interface of the TSF in a de bugging 
mode to identify any modules that are not called as a part of testing the 
documented interfaces and then inspecting the code that is not called to 
consider whether it is a back-door. 
1947 For a software TOE where Evaluation of sub -activity (ADV_IMP.2)  and 
ALC_TAT.2 or higher components are included in the assurance package, 
the evaluator may consider during their analysis of the tools the libraries and 
packages that are linked by the compiler at compi lation stage to determine 
that back-doors are not introduced at this stage. 
B.2.1.2 Tampering 
1948 Tampering includes any attack based on an attacker attempting to influence 
the behaviour of the TSF (i.e. corruption or de-activation), for example by:  
a) accessing data on whose confidentiality or integrity the TSF relies;  
b) forcing the TOE to cope with unusual or unexpected circumstances;  
c) disabling or delaying security enforcement;  
d) physical modification the TOE.  
1949 Each of the following should be considered (where relevant)  in the 
evaluator's independent vulnerability analysis.  
a) Attacks based on accessing data, whose confidentiality or integrity 
are protected, include:  
Vulnerability Assessment (AVA) 
April 2017 Version 3.1 Page 407 of 430 
1) reading, writing or modifying internal data directly or 
indirectly;  
2) using a component in an unexpected co ntext or for an 
unexpected purpose;  
3) using interfaces between components that are not visible at a 
higher level of abstraction.  
b) Reading, writing or modifying internal data directly or indirectly 
includes the following types of attack which should be considered:  
1) reading “secrets” stored internally, such as user passwords;  
2) spoofing internal data that security enforcing mechanisms rely 
upon;  
3) modifying environment variables (e.g. logical names), or data 
in configuration files or temporary files. 
c) It may be p ossible to deceive a trusted process into modifying a 
protected file that it wouldn't normally access.  
d) The evaluator should also consider the following “dangerous 
features”:  
1) source code resident on the TOE along with a compiler (for 
instance, it may be possible to modify the login source code);  
2) an interactive debugger and patch facility (for instance, it may 
be possible to modify the executable image);  
3) the possibility of making changes at device controller level, 
where file protection does not exist;  
4) diagnostic code which exists in the source code and that may 
be optionally included;  
5) developer's tools left in the TOE.  
e) Using a component in an unexpected context or for an unexpected 
purpose includes (for example), where the TOE is an application built 
upon an operating system, users exploiting knowledge of a word 
processor package or other editor to modify their own command file 
(e.g. to acquire greater privileges).  
f) Using interfaces between components which are not visible at a 
higher level of abstracti on includes attacks exploiting shared access 
to resources, where modification of a resource by one component can 
influence the behaviour of another (trusted) component, e.g. at source 
code level, through the use of global data or indirect mechanisms 
such as shared memory or semaphores.  
Vulnerability Assessment (AVA) 
Page 408 of 430 Version 3.1 April 2017 
g) Attacks based on forcing the TOE to cope with unusual or 
unexpected circumstances should always be considered. Relevant 
items include:  
1) generating unexpected input for a component;  
2) invalidating assumptions and properties on  which lower-level 
components rely.  
h) Generating unexpected input for a component includes investigating 
the behaviour of the TOE when:  
1) command input buffers overflow (possibly “crashing the 
stack” or overwriting other storage, which an attacker may be 
able to take advantage of, or forcing a crash dump that may 
contain sensitive information such as clear-text passwords);  
2) invalid commands or parameters are entered (including 
supplying a read-only parameter to an interface which expects 
to return data via th at parameter and supplying improperly 
formatted input that should fail parsing such as SQL -injection, 
format strings);  
3) an end -of-file marker (e.g. CTRL -Z or CTRL -D) or null 
character is inserted in an audit trail.  
i) Invalidating assumptions and properties on which lower -level 
components rely includes attacks taking advantage of errors in the 
source code where the code assumes (explicitly or implicitly) that 
security relevant data is in a particular format or has a particular 
range of values. In these cases the evaluator should determine 
whether they can invalidate such assumptions by causing the data to 
be in a different format or to have different values, and if so whether 
this could confer advantage to an attacker.  
j) The correct behaviour of the TSF may be dependent on assumptions 
that are invalidated under extreme circumstances where resource 
limits are reached or parameters reach their maximum value. The 
evaluator should consider (where practical) the behaviour of the TOE 
when these limits are reached, for example:  
1) changing dates (e.g. examining how the TOE behaves when a 
critical date threshold is passed);  
2) filling disks;  
3) exceeding the maximum number of users;  
4) filling the audit log;  
5) saturating security alarm queues at a console;  
Vulnerability Assessment (AVA) 
April 2017 Version 3.1 Page 409 of 430 
6) overloading various pa rts of a multi -user TOE which relies 
heavily upon communications components;  
7) swamping a network, or individual hosts, with traffic;  
8) filling buffers or fields.  
k) Attacks based on disabling or delaying security enforcement include 
the following items:  
1) using interrupts or scheduling functions to disrupt sequencing;  
2) disrupting concurrence;  
3) using interfaces between components which are not visible at 
a higher level of abstraction.  
l) Using interrupts or scheduling functions to disrupt sequencing 
includes investigating the behaviour of the TOE when:  
1) a command is interrupted (with CTRL-C, CTRL-Y, etc.);  
2) a second interrupt is issued before the first is acknowledged.  
m) The effects of terminating security critical processes (e.g. an audit 
daemon) should be explored . Similarly, it may be possible to delay 
the logging of audit records or the issuing or receipt of alarms such 
that it is of no use to an administrator (since the attack may already 
have succeeded).  
n) Disrupting concurrence includes investigating the behavi our of the 
TOE when two or more subjects attempt simultaneous access. It may 
be that the TOE can cope with the interlocking required when two 
subjects attempt simultaneous access, but that the behaviour becomes 
less well defined in the presence of further subjects. For example, a 
critical security process could be put into a resource -wait state if two 
other processes are accessing a resource which it requires.  
o) Using interfaces between components which are not visible at a 
higher level of abstraction may pr ovide a means of delaying a time -
critical trusted process.  
p) Physical attacks can be categorised into physical probing, physical 
manipulation, physical modification, and substitution.  
1) Physical probing by penetrating the TOE targeting internals of 
the TOE, e.g. reading at internal communication interfaces, 
lines or memories.  
2) Physical manipulation can be with the TOE internals aiming 
at internal modifications of the TOE (e.g. by using optical 
fault induction as an interaction process), at the external 
Vulnerability Assessment (AVA) 
Page 410 of 430 Version 3.1 April 2017 
interfaces of the TOE (e.g. by power or clock glitches) and at 
the TOE environment (e.g. by modifying temperature).  
3) Physical modification of TOE internal security enforcing 
attributes to inherit privileges or other capabilities that should 
be denied in regular operation. Such modifications can be 
caused, e.g., by optical fault induction. Attacks based on 
physical modification may also yield a modification of the 
TSF itself, e.g. by causing faults at TOE internal program data 
transfers before execution. Note, tha t such kind of bypassing 
by modifying the TSF itself can jeopardise every TSF unless 
there are other measures (possibly environmental measures) 
that prevent an attacker from gaining physical access to the 
TOE.  
4) Physical substitution to replace the TOE with  another IT 
entity, during delivery or operation of the TOE. Substitution 
during delivery of the TOE from the development 
environment to the user should be prevented through 
application of secure delivery procedures (such as those 
considered under Development secu rity (ALC_DVS) ). 
Substitution of the TOE during operation may be considered 
through a combination of user guidance and the operational 
environment, such that the user is able to be confident that 
they are interacting with the TOE.  
B.2.1.3 Direct attacks 
1950 Direct attack includes the identification of any penetration tests necessary to 
test the strength of permutational or probabilistic mechanism and other 
mechanisms to ensure they withstand direct attack. 
1951 For example, it may be a flawed ass umption that a particular implementation 
of a pseudo -random number generator will possess the required entropy 
necessary to seed the security mechanism. 
1952 Where a probabilistic or permutational mechanism relies on selection of 
security attribute value (e.g. selection of password length) or entry of data by 
a human user (e.g. choice of password), the assumptions made should reflect 
the worst case. 
1953 Probabilistic or permutational mechanisms should be identified during 
examination of evaluation evidence required as input to this sub -activity 
(security target, functional specification, TOE design and implementation 
representation subset) and any other TOE (e.g. guidance) documentation may 
identify additional probabilistic or permutational mechanisms. 
1954 Where the desi gn evidence or guidance includes assertions or assumptions 
(e.g. about how many authentication attempts are possible per minute), the 
evaluator should independently confirm that these are correct. This may be 
achieved through testing or through independent analysis. 
Vulnerability Assessment (AVA) 
April 2017 Version 3.1 Page 411 of 430 
1955 Direct attacks reliant upon a weakness in a cryptographic algorithm should 
not be considered under Vulnerability analysis (AVA_VAN) , as this is 
outside the scope of the CC. Correctness of the implementation of the 
cryptographic algorithm is considered during the ADV and ATE activities. 
B.2.1.4 Monitoring 
1956 Information is an abstract view on relation between the properties of entities, 
i.e. a signal contains information for a system, i f the TOE is able to react to 
this signal. The TOE resources processes and stores information represented 
by user data. Therefore:  
a) information may flow with the user data between subjects by internal 
TOE transfer or export from the TOE;  
b) information may be generated and passed to other user data;  
c) information may be gained through monitoring the operations on data 
representing the information.  
1957 The information represented by user data may be characterised by security 
attributes like “classification level” having values, for example unclassified, 
confidential, secret, top secret, to control operations to the data. This 
information and therefore the security attributes may be changed by 
operations e.g. FDP_ACC.2 may describe d ecrease of the level by 
“sanitarisation” or increase of level by combination of data. This is one 
aspects of an information flow analysis focused on controlled operations of 
controlled subjects on controlled objects. 
1958 The other aspect is the analysis of illicit information flow . This aspect is 
more general than the direct access to objects containing user data addressed 
by the FDP_ACC family. An unenforced signalling channel carrying 
information under control of the information  flow control policy can also be 
caused by monitoring of the processing of any object containing or related to 
this information (e.g. side channels). An enforced signalling channels may 
be identified in terms of the subjects manipulating resources and the subject 
or user that observe such manipulation. Classically, covert channels have 
been identified as timing or storage channels, according to the resource being 
modified or modulated. As for other monitoring attacks, the use of the TOE 
is in accordance with the SFRs. 
1959 Covert channels are normally applicable in the case when the TOE has 
unobservability AND multi -level separation policy requirements. Covert 
channels may be routinely spotted during vulnerability analysis and design 
activities, and should theref ore be tested. However, generally such 
monitoring attacks are only identified through specialised analysis 
techniques commonly referred to as “covert channel analysis”. These 
techniques have been the subject of much research and there are many papers 
published on this subject. Guidance for the conduct of covert channel 
analysis should be sought from the evaluation authority. 
Vulnerability Assessment (AVA) 
Page 412 of 430 Version 3.1 April 2017 
1960 Unenforced information flow monitoring attacks include passive analysis 
techniques aiming at disclosure of sensitive internal data of the TOE by 
operating the TOE in the way that corresponds to the guidance documents. 
1961 Side Channel Analysis includes crypt analytical techniques based on physical 
leakage of the TOE. Physical leakage can occur by timing information, 
power consumption or powe r emanation during computation of a TSF. 
Timing information can be collected also by a remote -attacker (having 
network access to the TOE), power based information channels requires that 
the attacker is in the near-by environment of the TOE. 
1962 Eavesdropping techniques include interception of all forms of energy, e.g., 
electromagnetic or optical emanation of computer displays, not necessarily in 
the near-field of the TOE. 
1963 Monitoring also includes exploits of protocol flaws, e.g., an attack on SSL 
implementation. 
B.2.1.5 Misuse 
1964 Misuse may arise from:  
a) incomplete guidance documentation;  
b) unreasonable guidance;  
c) unintended misconfiguration of the TOE;  
d) forced exception behaviour of the TOE.  
1965 If the guidance documentation is incomplete the user may not know how to 
operate the TOE in accordance with the SFRs. The evaluator should apply 
familiarity with the TOE gained from performing other evaluation activities 
to determine that the guidance is complete. In particular, the evaluator should 
consider the functional specification . The TSF described in this document 
should be described in the guidance as required to permit secure 
administration and use through the TSFI available to human users. In 
addition, the different modes of operation should be considered to ensure that 
guidance is provided for all modes of operation. 
1966 The evaluator may, as an aid, prepare an informal mapping between the 
guidance and these documents. Any omissions in this mapping may indicate 
incompleteness. 
1967 The guidance is considered to be unreasonable if it ma kes demands on the 
TOE's usage or operational environment that are inconsistent with the ST or 
unduly onerous to maintain security. 
1968 A TOE may use a variety of ways to assist the consumer in effectively using 
that TOE in accordance with the SFRs and prevent  unintentional 
misconfiguration. A TOE may employ functionality (features) to alert the 
consumer when the TOE is in a state that is inconsistent with the SFRs, 
Vulnerability Assessment (AVA) 
April 2017 Version 3.1 Page 413 of 430 
whilst other TOEs may be delivered with enhanced guidance containing 
suggestions, hints, procedu res, etc. on using the existing security features 
most effectively; for instance, guidance on using the audit feature as an aid 
for detecting when the SFRs are being compromised; namely insecure. 
1969 The evaluator considers the TOE's functionality, its purpose  and security 
objectives for the operational environment to arrive at a conclusion of 
whether or not there is reasonable expectation that use of the guidance would 
permit transition into an insecure state to be detected in a timely manner. 
1970 The potential fo r the TOE to enter into insecure states may be determined 
using the evaluation deliverables, such as the ST, the functional specification 
and any other design representations provided as evidence for components 
included in the assurance package for the TOE  (e.g. the TOE/TSF design 
specification if a component from TOE design (ADV_TDS) is included). 
1971 Instances of forced exception behaviour of the TSF could include, but are not 
limited to, the following:  
a) behaviour of the TOE when start -up, close-down or error recovery is 
activated;  
b) behaviour of the TOE under extreme circumstances (sometimes 
termed overload or asymptotic behaviour), particularly where this 
could lead to the de-activation or disabling of parts of the TSF;  
c) any potential for u nintentional misconfiguration or insecure use 
arising from attacks noted in the section on tampering above.  
B.2.2 Identification of Potential Vulnerabilities 
1972 Potential vulnerabilities may be identified by the evaluator during different 
activities. They may beco me apparent during an evaluation activity or they 
may be identified as a result of analysis of evidence to search for 
vulnerabilities. 
B.2.2.1 Encountered 
1973 The encountered identification of vulnerabilities is where potential 
vulnerabilities are identified by the ev aluator during the conduct of 
evaluation activities, i.e. the evidence are not being analysed with the express 
aim of identifying potential vulnerabilities. 
1974 The encountered method of identification is dependent on the evaluator's 
experience and knowledge; which is monitored and controlled by the 
evaluation authority. It is not reproducible in approach, but will be 
documented to ensure repeatability of the conclusions from the reported 
potential vulnerabilities. 
1975 There are no formal analysis criteria required  for this method. Potential 
vulnerabilities are identified from the evidence provided as a result of 
Vulnerability Assessment (AVA) 
Page 414 of 430 Version 3.1 April 2017 
knowledge and experience. However, this method of identification is not 
constrained to any particular subset of evidence. 
1976 Evaluator is assumed to have know ledge of the TOE -type technology and 
known security flaws as documented in the public domain. The level of 
knowledge assumed is that which can be gained from a security e -mail list 
relevant to the TOE type, the regular bulletins (bug, vulnerability and 
security flaw lists) published by those organisations researching security 
issues in products and technologies in widespread use. This knowledge is not 
expected to extend to specific conference proceedings or detailed theses 
produced by university research fo r AVA_VAN.1 or AVA_VAN.2. 
However, to ensure the knowledge applied is up to date, the evaluator may 
need to perform a search of public domain material. 
1977 For AVA_VAN.3 to AVA_VAN.5 the search of publicly available 
information is expected to include conference proceeding and theses 
produced during research activities by universities and other relevant 
organisations. 
1978 Examples of ho w these may arise (how the evaluator may encounter 
potential vulnerabilities):  
a) while the evaluator is examining some evidence, it sparks a memory 
of a potential vulnerability identified in a similar product type, that 
the evaluator believes to also be present in the TOE under evaluation;  
b) while examining some evidence, the evaluator spots a flaw in the 
specification of an interface, that reflects a potential vulnerability. 
1979 This may include becoming aware of a potential vulnerability in a TOE 
through reading about generic vulnerabilities in a particular product type in 
an IT security publication or on a security e -mail list to which the evaluator 
is subscribed. 
1980 Attack methods can be developed directly from these potential vulnerabilities. 
Therefore, the encountered potential vulnerabilities are collated at the time of 
producing penetration tests based on the evaluator's vulnerability analysis. 
There is no explicit action for the evaluator to encounter potential 
vulnerabilities. Therefore, the evaluator is directed through an implicit action 
specified in AVA_VAN.1.2E and AVA_VAN.*.4E. 
1981 Current information regarding public domain vulnerabilities and attacks may 
be provided to the evaluator by, for example, an  evaluation authority. This 
information is to be taken into account by the evaluator when collating 
encountered vulnerabilities and attack methods when developing penetration 
tests. 
B.2.2.2 Analysis 
1982 The following types of analysis are presented in terms of the eva luator 
actions. 
Vulnerability Assessment (AVA) 
April 2017 Version 3.1 Page 415 of 430 
B.2.2.2.1 Unstructured Analysis 
1983 The unstructured analysis to be performed by the evaluator (for Evaluation of 
sub-activity (AVA_VAN.2) ) permits the evaluator to consider the generic 
vulnerabilities (as discussed in B.2.1). The evaluator will also apply their 
experience and knowledge of flaws in similar technology types. 
B.2.2.2.2 Focused 
1984 During the conduct of evaluation activities the evaluator may also identify 
areas of concern. These are specific portions of the TOE evidence that the 
evaluator has some reservation about, although the evidence meets the 
requirements for the activity with which the evidence is associated. For 
example, a particular interface specification looks particularly complex, and 
therefore may be prone to error either in the development of the TOE or in 
the operation of the TOE. There is no potential vulnerability apparent at this 
stage, further investigation is required. This is beyond the bounds of 
encountered, as further investigation is required. 
1985 Difference between potential vulnerability and area of concern:  
a) Potential vulnerability - The evaluator knows a method of attack that 
can be used to exploit the weakness or the evaluator knows of 
vulnerability information that is relevant to the TOE.  
b) Area of concern - The evaluator may be able to discount concern as a 
potential vulnerability based on information provided elsewhere. 
While reading interface specification, the evaluator identifies that due 
to the extreme (unnecessary) complexity of an  interface a potential 
vulnerability may lay within that area, although it is not apparent 
through this initial examination. 
1986 The focused approach to the identification of vulnerabilities is an analysis of 
the evidence with the aim of identifying any potent ial vulnerabilities evident 
through the contained information. It is an unstructured analysis, as the 
approach is not predetermined. This approach to the identification of 
potential vulnerabilities can be used during the independent vulnerability 
analysis required by Evaluation of sub-activity (AVA_VAN.3). 
1987 This analysis can be achieved through different approaches, that will lead to 
commensurate levels of confidence. None of the approaches have a rigid 
format for the examination of evidence to be performed. 
1988 The approach taken is directed by the results of the evaluator's assessment of 
the evidence to determine it meets the requirements of the AVA/AGD sub-
activities. Therefore, the inv estigation of the evidence for the existence of 
potential vulnerabilities may be directed by any of the following:  
a) areas of concern identified during examination of the evidence during 
the conduct of evaluation activities;  
Vulnerability Assessment (AVA) 
Page 416 of 430 Version 3.1 April 2017 
b) reliance on particular function ality to provide separation, identified 
during the analysis of the architectural design (as in Evaluation of 
sub-activity (ADV_ARC.1)), requiring further analysis to determine 
it cannot be bypassed;  
c) representative examination of the e vidence to hypothesise potential 
vulnerabilities in the TOE. 
1989 The evaluator will report what actions were taken to identify potential 
vulnerabilities in the evidence. However, the evaluator may not be able to 
describe the steps in identifying potential vuln erabilities before the outset of 
the examination. The approach will evolve as a result of the outcome of 
evaluation activities. 
1990 The areas of concern may arise from examination of any of the evidence 
provided to satisfy the SARs specified for the TOE evalua tion. The 
information publicly accessible is also considered. 
1991 The activities performed by the evaluator can be repeated and the same 
conclusions, in terms of the level of assurance in the TOE, can be reached 
although the steps taken to achieve those conclu sions may vary. As the 
evaluator is documenting the form the analysis took, the actual steps taken to 
achieve those conclusions are also reproducible. 
B.2.2.2.3 Methodical 
1992 The methodical analysis approach takes the form of a structured examination 
of the evidence. T his method requires the evaluator to specify the structure 
and form the analysis will take (i.e. the manner in which the analysis is 
performed is predetermined, unlike the focused identification method). The 
method is specified in terms of the information that will be considered and 
how/why it will be considered. This approach to the identification of 
potential vulnerabilities can be used during the independent vulnerability 
analysis required by Evaluation of sub -activity (AVA_VAN.4)  and 
Evaluation of sub-activity (AVA_VAN.5). 
1993 This analysis of the evidence is deliberate and pre -planned in approach, 
considering all evidence identified as an input into the analysis. 
1994 All evidence provided to satisfy the ( ADV) assurance requirements specified 
in the assurance package are used as input to the potential vulnerability 
identification activity. 
1995 The “methodical” descriptor for this analysis has been used in an attempt to 
capture the characterisation that this identification of potential vulnerabilities 
is to take an ordered and planned approach. A “method” or “system” is to be 
applied in the examination. The evaluator is to describe the method to be 
used in terms of what evidence will be considered, the information within the 
evidence that is to be examined, the manner in which this information is to 
be considered; and the hypothesis that is to be generated. 
Vulnerability Assessment (AVA) 
April 2017 Version 3.1 Page 417 of 430 
1996 The following provide some examples that a hypothesis may take:  
a) consideration of malformed inpu t for interfaces available to an 
attacker at the external interfaces;  
b) examination of a security mechanism, such as domain separation, 
hypothesising internal buffer overflows leading to degradation of 
separation;  
c) analysis to identify any objects created i n the TOE implementation 
representation that are then not fully controlled by the TSF, and could 
be used by an attacker to undermine the SFRs.  
1997 For example, the evaluator may identify that interfaces are a potential area of 
weakness in the TOE and specify an approach to the analysis that “all 
interface specifications provided in the functional specification and TOE 
design will be analysed to hypothesise potential vulnerabilities” and go on to 
explain the methods used in the hypothesis. 
1998 This identification m ethod will provide a plan of attack of the TOE, that 
would be performed by an evaluator completing penetration testing of 
potential vulnerabilities in the TOE. The rationale for the method of 
identification would provide the evidence for the coverage and d epth of 
exploitation determination that would be performed on the TOE. 
B.3 When attack potential is used 
B.3.1 Developer 
1999 Attack potential is used by a PP/ST author during the development of the 
PP/ST, in consideration of the threat environment and the selection of 
assurance components. This may simply be a determination that the attack 
potential possessed by the assumed attackers of the TOE is generically 
characterised as Basic, Enhanced-Basic, Moderate or High. Alternatively, the 
PP/ST may wish to specify particular  levels of individual factors assumed to 
be possessed by attackers. (e.g. the attackers are assumed to be experts in the 
TOE technology type, with access to specialised equipment.) 
2000 The PP/ST author considers the threat profile developed during a risk 
assessment (outside the scope of the CC, but used as an input into the 
development of the PP/ST in terms of the Security Problem Definition or in 
the case of low assurance STs, the requirements statement). Consideration of 
this threat profile in terms of one of  the approaches discussed in the 
following sections will permit the specification of the attack potential the 
TOE is to resist. 
B.3.2 Evaluator 
2001 Attack potential is especially considered by the evaluator in two distinct 
ways during the ST evaluation and the vulnerability assessment activities. 
Vulnerability Assessment (AVA) 
Page 418 of 430 Version 3.1 April 2017 
2002 Attack potential is used by an evaluator during the conduct of the 
vulnerability analysis sub -activity to determine whether or not the TOE is 
resistant to attacks assuming a specific attack potential of an attacker. If the 
evaluator determines that a potential vulnerability is exploitable in the TOE, 
they have to confirm that it is exploitable considering all aspects of the 
intended environment, including the attack potential assumed by an attacker. 
2003 Therefore, using the infor mation provided in the threat statement of the 
Security Target, the evaluator determines the minimum attack potential 
required by an attacker to effect an attack, and arrives at some conclusion 
about the TOE's resistance to attacks. Table 2 demonstrates the relationship 
between this analysis and attack potential. 
Vulnerability 
Component 
TOE resistant to 
attacker with attack 
potential of: 
Residual vulnerabilities only 
exploitable by attacker with 
attack potential of: 
VAN.5 High Beyond High 
VAN.4 Moderate High 
VAN.3 Enhanced-Basic Moderate 
VAN.2 Basic Enhanced-Basic 
VAN.1 Basic Enhanced-Basic 
Table 2 Vulnerability testing and attack potential 
2004 The “beyond high” entry in the residual vulnerabilities column of the above 
table represents those potential vulnerabilities that would require an attacker 
to have an attack potential greater than that of “high” in order to exploit the 
potential vulnerability. A vulnerabili ty classified as residual in this instance 
reflects the fact that a known weakness exists in the TOE, but in the current 
operational environment, with the assumed attack potential, the weakness 
cannot be exploited. 
2005 At any level of attack potential a potent ial vulnerability may be deemed 
“infeasible” due to a countermeasure in the operational environment that 
prevents the vulnerability from being exploited. 
2006 A vulnerability analysis applies to all TSFI, including ones that access 
probabilistic or permutationa l mechanisms. No assumptions are made 
regarding the correctness of the design and implementation of the TSFI; nor 
are constraints placed on the attack method or the attacker's interaction with 
the TOE - if an attack is possible, then it is to be considered  during the 
vulnerability analysis. As shown in Table 2, successful evaluation against a 
vulnerability assurance component reflects that the TSF is designed and 
implemented to protect against the required level of threat. 
2007 It is not n ecessary for an evaluator to perform an attack potential calculation 
for each potential vulnerability. In some cases it is apparent when developing 
the attack method whether or not the attack potential required to develop and 
run the attack method is comme nsurate with that assumed of the attacker in 
the operational environment. For any vulnerabilities for which an 
exploitation is determined, the evaluator performs an attack potential 
Vulnerability Assessment (AVA) 
April 2017 Version 3.1 Page 419 of 430 
calculation to determine that the exploitation is appropriate to the level  of 
attack potential assumed for the attacker. 
2008 The approach described below is to be applied whenever it is necessary to 
calculate attack potential, unless the evaluation authority provides mandatory 
guidance that an alternative approach is to be applied. The values given in 
Tables 3 and 4 below are not mathematically proven. Therefore, the values 
given in these example tables may need to be adjusted according to the 
technology type and specific environments. The e valuator should seek 
guidance from the evaluation authority. 
B.4 Calculating attack potential 
B.4.1 Application of attack potential 
2009 Attack potential is a function of expertise, resources and motivation. There 
are multiple methods of representing and quantifying thes e factors. Also, 
there may be other factors that are applicable for particular TOE types. 
B.4.1.1 Treatment of motivation 
2010 Motivation is an attack potential factor that can be used to describe several 
aspects related to the attacker and the assets the attacker desi res. Firstly, 
motivation can imply the likelihood of an attack - one can infer from a threat 
described as highly motivated that an attack is imminent, or that no attack is 
anticipated from an un -motivated threat. However, except for the two 
extreme levels of motivation, it is difficult to derive a probability of an attack 
occurring from motivation. 
2011 Secondly, motivation can imply the value of the asset, monetarily or 
otherwise, to either the attacker or the asset holder. An asset of very high 
value is more likely to motivate an attack compared to an asset of little value. 
However, other than in a very general way, it is difficult to relate asset value 
to motivation because the value of an asset is subjective - it depends largely 
upon the value an asset holder places on it. 
2012 Thirdly, motivation can imply the expertise and resources with which an 
attacker is willing to effect an attack. One can infer that a highly motivated 
attacker is likely to acquire sufficient expertise and resources to defeat the 
measures protecting an asset. Conversely, one can infer that an attacker with 
significant expertise and resources is not willing to effect an attack using 
them if the attacker's motivation is low. 
2013 During the course of preparing for and conducting an evaluation, all t hree 
aspects of motivation are at some point considered. The first aspect, 
likelihood of attack, is what may inspire a developer to pursue an evaluation. 
If the developer believes that the attackers are sufficiently motivated to 
mount an attack, then an ev aluation can provide assurance of the ability of 
the TOE to thwart the attacker's efforts. Where the operational environment 
is well defined, for example in a system evaluation, the level of motivation 
Vulnerability Assessment (AVA) 
Page 420 of 430 Version 3.1 April 2017 
for an attack may be known, and will influence the sel ection of 
countermeasures. 
2014 Considering the second aspect, an asset holder may believe that the value of 
the assets (however measured) is sufficient to motivate attack against them. 
Once an evaluation is deemed necessary, the attacker's motivation is 
considered to determine the methods of attack that may be attempted, as well 
as the expertise and resources used in those attacks. Once examined, the 
developer is able to choose the appropriate assurance level, in particular the 
AVA requirement components, commensurate with the attack potential for 
the threats. During the course of the evaluation, and in particular as a result 
of completing the vulnerability assessment activity, the evaluator determines 
whether or not the TOE, operating  in its operational environment, is 
sufficient to thwart attackers with the identified expertise and resources. 
2015 It may be possible for a PP author to quantify the motivation of an attacker, 
as the PP author has greater knowledge of the operational environm ent in 
which the TOE (conforming to the requirements of the PP) is to be placed. 
Therefore, the motivation could form an explicit part of the expression of the 
attack potential in the PP, along with the necessary methods and measures to 
quantify the motivation. 
B.4.2 Characterising attack potential 
2016 This section examines the factors that determine attack potential, and 
provides some guidelines to help remove some of the subjectivity from this 
aspect of the evaluation process. 
B.4.2.1 Determining the attack potential 
2017 The d etermination of the attack potential for an attack corresponds to the 
identification of the effort required to create the attack, and to demonstrate 
that it can be successfully applied to the TOE (including setting up or 
building any necessary test equipme nt), thereby exploiting the vulnerability 
in the TOE. The demonstration that the attack can be successfully applied 
needs to consider any difficulties in expanding a result shown in the 
laboratory to create a useful attack. For example, where an experiment  
reveals some bits or bytes of a confidential data item (such as a key), it is 
necessary to consider how the remainder of the data item would be obtained 
(in this example some bits might be measured directly by further experiments, 
while others might be fo und by a different technique such as exhaustive 
search). It may not be necessary to carry out all of the experiments to identify 
the full attack, provided it is clear that the attack actually proves that access 
has been gained to a TOE asset, and that the complete attack could 
realistically be carried out in exploitation according to the AVA_VAN 
component targeted. In some cases the only way to prove that an attack can 
realistically be carried out in exploitation according to the AVA_VAN 
component targeted is to perform completely the attack and then rate it based 
upon the resources actually required. One of the outputs from the 
identification of a potential vulnerability is assumed to be a script that gives a 
Vulnerability Assessment (AVA) 
April 2017 Version 3.1 Page 421 of 430 
step-by-step description of how to carry out the attack that can be used in the 
exploitation of the vulnerability on another instance of the TOE. 
2018 In many cases, the evaluators will estimate the parameters for exploitation, 
rather than carry o ut the full exploitation. The estimates and their rationale 
will be documented in the ETR. 
B.4.2.2 Factors to be considered 
2019 The following factors should be considered during analysis of the attack 
potential required to exploit a vulnerability:  
a) Time taken to identify and exploit (Elapsed Time);  
b) Specialist technical expertise required (Specialist Expertise);  
c) Knowledge of the TOE design and operation ( Knowledge of the 
TOE);  
d) Window of opportunity;  
e) IT hardware/software or other equipment required for exploitation.  
2020 In many cases these factors are not independent, but may be substituted for 
each other in varying degrees. For example, expertise or hardware/software 
may be a substitute for time. A discussion of these factors follows. (The 
levels of each factor are discussed in increasing order of magnitude.) When it 
is the case, the less “expensive” combination is considered in the exploitation 
phase. 
2021 Elapsed time is the total amount of time taken by an attacker to identify that 
a particular potential vulnerability may exist in the TOE, to develop an attack 
method and to sustain effort required to mount the attack against the TOE. 
When considering this factor, the worst case scenario is used to estimate the 
amount of time required. The identified amount of time is as follows:  
a) less than one day; 
b) between one day and one week; 
c) between one week and two weeks; 
d) between two weeks and one month; 
e) each additional month up to 6 months leads to an increased value; 
f) more than 6 months. 
2022 Specialist expertise  refers to the level of gener ic knowledge of the 
underlying principles, product type or attack methods (e.g. Internet protocols, 
Unix operating systems, buffer overflows). The identified levels are as 
follows:  
Vulnerability Assessment (AVA) 
Page 422 of 430 Version 3.1 April 2017 
a) Laymen are unknowledgeable compared to experts or proficient 
persons, with no particular expertise;  
b) Proficient persons are knowledgeable in that they are familiar with 
the security behaviour of the product or system type;  
c) Experts are familiar with the underlying algorithms, protocols, 
hardware, structures, security behaviour, principles and concepts of 
security employed, techniques and tools for the definition of new 
attacks, cryptography, classical attacks for the product type, attack 
methods, etc. implemented in the product or system type.  
d) The level “Multiple Expert” is intr oduced to allow for a situation, 
where different fields of expertise are required at an Expert level for 
distinct steps of an attack. 
2023 It may occur that several types of expertise are required. By default, the 
higher of the different expertises factors is c hosen. In very specific cases, the 
“multiple expert” level could be used but it should be noted that the expertise 
must concern fields that are strictly different like for example HW 
manipulation and cryptography. 
2024 Knowledge of the TOE  refers to specific ex pertise in relation to the TOE. 
This is distinct from generic expertise, but not unrelated to it. Identified 
levels are as follows:  
a) Public information concerning the TOE (e.g. as gained from the 
Internet);  
b) Restricted information concerning the TOE (e.g. knowledge that is 
controlled within the developer organisation and shared with other 
organisations under a non-disclosure agreement)  
c) Sensitive information about the TOE (e.g. knowledge that is shared 
between discreet teams within the developer organisatio n, access to 
which is constrained only to members of the specified teams);  
d) Critical information about the TOE (e.g. knowledge that is known by 
only a few individuals, access to which is very tightly controlled on a 
strict need to know basis and individual undertaking).  
2025 The knowledge of the TOE may graduate according to design abstraction, 
although this can only be done on a TOE by TOE basis. Some TOE designs 
may be public source (or heavily based on public source) and therefore even 
the design representat ion would be classified as public or at most restricted, 
while the implementation representation for other TOEs is very closely 
controlled as it would give an attacker information that would aid an attack 
and is therefore considered to be sensitive or even critical. 
2026 It may occur that several types of knowledge are required. In such cases, the 
higher of the different knowledge factors is chosen. 
Vulnerability Assessment (AVA) 
April 2017 Version 3.1 Page 423 of 430 
2027 Window of opportunity (Opportunity) is also an important consideration, and 
has a relationship to the Elapsed Time  factor. Identification or exploitation 
of a vulnerability may require considerable amounts of access to a TOE that 
may increase the likelihood of detection. Some attack methods may require 
considerable effort off -line, and only brief access to the TOE to exploit. 
Access may also need to be continuous, or over a number of sessions. 
2028 For some TOEs the Window of opportunity  may equate to the number of 
samples of the TOE that the attacker can obtain. This is particularly relevant 
where attempts to penetrate the  TOE and undermine the SFRs may result in 
the destruction of the TOE preventing use of that TOE sample for further 
testing, e.g. hardware devices. Often in these cases distribution of the TOE is 
controlled and so the attacker must apply effort to obtain fu rther samples of 
the TOE. 
2029 For the purposes of this discussion:  
a) unnecessary/unlimited access means that the attack doesn't need any 
kind of opportunity to be realised because there is no risk of being 
detected during access to the TOE and it is no problem to access the 
number of TOE samples for the attack; 
b) easy means that access is required for less than a day and that the 
number of TOE samples required to perform the attack is less than 
ten; 
c) moderate means that access is required for less than a month and that 
the number of TOE samples required to perform the attack is less 
than one hundred; 
d) difficult means that access is required for at least a month or that the 
number of TOE samples required to perform the attack is at least one 
hundred; 
e) none means that t he opportunity window is not sufficient to perform 
the attack (the length for which the asset to be exploited is available 
or is sensitive is less than the opportunity length needed to perform 
the attack - for example, if the asset key is changed each week  and 
the attack needs two weeks); another case is, that a sufficient number 
of TOE samples needed to perform the attack is not accessible to the 
attacker - for example if the TOE is a hardware and the probability to 
destroy the TOE during the attack instea d of being successful is very 
high and the attacker has only access to one sample of the TOE. 
2030 Consideration of this factor may result in determining that it is not possible 
to complete the exploit, due to requirements for time availability that are 
greater than the opportunity time. 
2031 IT hardware/software or other equipment  refers to the equipment required 
to identify or exploit a vulnerability.  
Vulnerability Assessment (AVA) 
Page 424 of 430 Version 3.1 April 2017 
a) Standard equipment is readily available to the attacker, either for the 
identification of a vulnerability or for a n attack. This equipment may 
be a part of the TOE itself (e.g. a debugger in an operating system), 
or can be readily obtained (e.g. Internet downloads, protocol analyser 
or simple attack scripts).  
b) Specialised equipment is not readily available to the atta cker, but 
could be acquired without undue effort. This could include purchase 
of moderate amounts of equipment (e.g. power analysis tools, use of 
hundreds of PCs linked across the Internet would fall into this 
category), or development of more extensive at tack scripts or 
programs. If clearly different test benches consisting of specialised 
equipment are required for distinct steps of an attack this would be 
rated as bespoke.  
c) Bespoke equipment is not readily available to the public as it may 
need to be spec ially produced (e.g. very sophisticated software), or 
because the equipment is so specialised that its distribution is 
controlled, possibly even restricted. Alternatively, the equipment may 
be very expensive.  
d) The level “Multiple Bespoke” is introduced to allow for a situation, 
where different types of bespoke equipment are required for distinct 
steps of an attack. 
2032 Specialist expertise and Knowledge of the TOE  are concerned with the 
information required for persons to be able to attack a TOE. There is an 
implicit relationship between an attacker's expertise (where the attacker may 
be one or more persons with complementary areas of knowledge) and the 
ability to effectively make use of equipment in an attack. The weaker the 
attacker's expertise, the lower the potential to use equipment (IT 
hardware/software or other equipment). Likewise, the greater the expertise, 
the greater the potential for equipment to be used in the attack. Although 
implicit, this relationship between expertise and the use of equipment doe s 
not always apply, for instance, when environmental measures prevent an 
expert attacker's use of equipment, or when, through the efforts of others, 
attack tools requiring little expertise to be effectively used are created and 
freely distributed (e.g. via the Internet). 
B.4.2.3 Calculation of attack potential 
2033 Table 3 identifies the factors discussed in the previous section and associates 
numeric values with the total value of each factor. 
2034 Where a factor falls close to the boundary of a range the evaluator should 
consider use of an intermediate value to those in the table. For example, if 
twenty samples are required to perform the attack then a value between one 
and four may be selected for that factor, or if the design is based on a 
publicly available design but the developer has made some alterations then a 
value between zero and three should be selected according to the evaluator's 
view of the impact of those design changes. The table is intended as a guide. 
Vulnerability Assessment (AVA) 
April 2017 Version 3.1 Page 425 of 430 
2035 The “**” specification in the tabl e in considering Window of Opportunity is 
not to be seen as a natural progression from the timescales specified in the 
preceding ranges associated with this factor. This specification identifies that 
for a particular reason the potential vulnerability cann ot be exploited in the 
TOE in its intended operational environment. For example, access to the 
TOE may be detected after a certain amount of time in a TOE with a known 
environment (i.e. in the case of a system) where regular patrols are 
completed, and the attacker could not gain access to the TOE for the required 
two weeks undetected. However, this would not be applicable to a TOE 
connected to the network where remote access is possible, or where the 
physical environment of the TOE is unknown. 
Vulnerability Assessment (AVA) 
Page 426 of 430 Version 3.1 April 2017 
 
Factor Value 
Elapsed Time  
<= one day 0 
<= one week 1 
<= two weeks 2 
<= one month 4 
<= two months 7 
<= three months 10 
<= four months 13 
<= five months 15 
<= six months 17 
> six months 19 
Expertise  
Layman 0 
Proficient 3*(1) 
Expert 6 
Multiple experts 8 
Knowledge of TOE  
Public 0 
Restricted 3 
Sensitive 7 
Critical 11 
Window of Opportunity  
Unnecessary / unlimited access 0 
Easy 1 
Moderate 4 
Difficult 10 
None **(2) 
Equipment  
Standard 0 
Specialised 4(3) 
Bespoke 7 
Multiple bespoke 9 
(1) When several proficient persons are required to complete the attack path, the resulting level of expertise still 
remains “proficient” (which leads to a 3 rating). 
(2) Indicates that the attack path is not exploitable due to other measures in the intended oper ational 
environment of the TOE. 
(3) If clearly different test benches consisting of specialised equipment are required for distinct steps of an 
attack, this should be rated as bespoke. 
Table 3 Calculation of attack potential 
2036 To determine the resistance of the TOE to the potential vulnerabilities 
identified the following steps should be applied:  
a) Define the possible attack scenarios {AS1, AS2, ..., ASn} for the 
TOE in the operational environment. 
Vulnerability Assessment (AVA) 
April 2017 Version 3.1 Page 427 of 430 
b) For each attack scenario, perform a theoretical analysis and calculate 
the relevant attack potential using Table 3. 
c) For each attack scenario, if necessary, perform penetration tests in 
order to confirm or to disprove the theoretical analysis. 
d) Divide all attack scenarios {AS1, AS2, ..., ASn} into two groups:  
1) the attack scenarios having been successful (i.e. those that 
have been used to successfully undermine the SFRs), and 
2) the attack scenarios that have been demonstrated to b e 
unsuccessful. 
e) For each successful attack scenario, apply Table 4 and determine, 
whether there is a contradiction between the resistance of the TOE 
and the chosen AVA_VAN assurance component, see the last column 
of Table 4. 
f) Should one contradiction be found, the vulnerability assessment will 
fail, e.g. the author of the ST chose the component AVA_VAN.5 and 
an attack scenario with an attack potential of  21 points (high) has 
broken the security of the TOE. In this case the TOE is resistant to 
attacker with attack potential 'Moderate', this contradicts to 
AVA_VAN.5, hence, the vulnerability assessment fails. 
2037 The “Values” co lumn of Table 4 indicates the range of attack potential 
values (calculated using Table 3) of an attack scenario that results in the 
SFRs being undermined. 
Vulnerability Assessment (AVA) 
Page 428 of 430 Version 3.1 April 2017 
 
Values 
Attack 
potential 
required to 
exploit 
scenario: 
TOE 
resistant to 
attackers 
with attack 
potential 
of: 
Meets assurance 
components:: 
Failure of 
components: 
0-9 Basic No rating - 
AVA_VAN.1, 
AVA_VAN.2, 
AVA_VAN.3, 
AVA_VAN.4, 
AVA_VAN.5 
10-13 Enhanced-
Basic Basic AVA_VAN.1, 
AVA_VAN.2 
AVA_VAN.3, 
AVA_VAN.4, 
AVA_VAN.5 
14-19 Moderate Enhanced-
Basic 
AVA_VAN.1, 
AVA_VAN.2, 
AVA_VAN.3 
AVA_VAN.4, 
AVA_VAN.5 
20-24 High Moderate 
AVA_VAN.1, 
AVA_VAN.2, 
AVA_VAN.3, 
AVA_VAN.4 
AVA_VAN.5 
=>25 Beyond 
High High 
AVA_VAN.1, 
AVA_VAN.2, 
AVA_VAN.3, 
AVA_VAN.4, 
AVA_VAN.5 
- 
Table 4 Rating of vulnerabilities and TOE resistance 
2038 An approach such as this cannot take account of every circumstance or factor, 
but should give a better indication of the level of resistance to attack required 
to achieve the standard ratings. Other factors, such as the reliance on unlikely 
chance occurrences are not included in the basic model, but can be used by 
an evaluator as justification for a rating other than those that the basic model 
might indicate. 
2039 It should be noted that whereas a number of vulnerabilities rated individually 
may indicate high resistance to attack, collectively the combination of 
vulnerabilities may indicate that o verall a lower rating is applicable. The 
presence of one vulnerability may make another easier to exploit. 
2040 If a PP/ST author wants to use the attack potential table for the determination 
of the level of attack the TOE should withstand (selection of Vulnera bility 
analysis ( AVA_VAN) component), he should proceed as follows: For all 
different attack scenarios (i.e. for all different types of attacker and/or 
different types of attack the author has in mind) which must not violate the 
SFRs, several passes through Table 3 should be made to determine the 
different values of attack potential assumed for each such unsuccessful attack 
scenario. The PP/ST author then chooses the highest value of them in order 
Vulnerability Assessment (AVA) 
April 2017 Version 3.1 Page 429 of 430 
to determine the level of the TOE resistance to be claimed from Table 4: the 
TOE resistance must be at least equal to this highest value determined. For 
example, the highest value of attack potentials of all attack scenarios, which 
must not u ndermine the TOE security policy, determined in such a way is 
Moderate; hence, the TOE resistance shall be at least Moderate (i.e. 
Moderate or High); therefore, the PP/ST author can choose either 
AVA_VAN.4 (for Moderate) or  AVA_VAN.5 (for High) as the appropriate 
assurance component. 
B.5 Example calculation for direct attack 
2041 Mechanisms subject to direct attack are often vital for system security and 
developers often strengthen these mechanisms. A s an example, a TOE might 
use a simple pass number authentication mechanism that can be overcome by 
an attacker who has the opportunity to repeatedly guess another user's pass 
number. The system can strengthen this mechanism by restricting pass 
numbers and their use in various ways. During the course of the evaluation 
an analysis of this direct attack could proceed as follows: 
2042 Information gleaned from the ST and design evidence reveals that 
identification and authentication provides the basis upon which to control 
access to network resources from widely distributed terminals. Physical 
access to the terminals is not controlled by any effective means. The duration 
of access to a terminal is not controlled by any effective means. Authorised 
users of the system choose their own pass numbers when initially authorised 
to use the system, and thereafter upon user request. The system places the 
following restrictions on the pass numbers selected by the user:  
a) the pass number must be at least four and no greater than s ix digits 
long;  
b) consecutive numerical sequences are disallowed (such as 7,6,5,4,3);  
c) repeating digits is disallowed (each digit must be unique).  
2043 Guidance provided to the users at the time of pass number selection is that 
pass numbers should be as random as possible and should not be affiliated 
with the user in some way - a date of birth, for instance. 
2044 The pass number space is calculated as follows:  
a) Patterns of human usage are important considerations that can 
influence the approach to searching a passwor d space. Assuming the 
worst case scenario and the user chooses a number comprising only 
four digits, the number of pass number permutations assuming that 
each digit must be unique is:  
Vulnerability Assessment (AVA) 
Page 430 of 430 Version 3.1 April 2017 
 
b) The number of possible increasing sequences is seven, as is the 
number of decreasing sequences. The pass number space after 
disallowing sequences is:  
 
2045 Based on further information gleaned from the design evidence, the pass 
number mechanism is designed with a terminal locking feature. Upon the 
sixth failed authentication a ttempt the terminal is locked for one hour. The 
failed authentication count is reset after five minutes so that an attacker can 
at best attempt five pass number entries every five minutes, or 60 pass 
number entries every hour. 
2046 On average, an attacker would  have to enter 2513 pass numbers, over 2513 
minutes, before entering the correct pass number. The average successful 
attack would, as a result, occur in slightly less than:  
 
2047 Using the approach to calculate the attack potential, described in the previous 
section, identifies that it is possible that a layman can defeat the mechanism 
within days (given easy access to the TOE), with the use of standard 
equipment, and with no knowledge of the TOE, giving a value of 1. Given 
the resulting sum, 1, the attack potential required to effect a successful attack 
is not rated, as it falls below that considered to be Basic. 
 